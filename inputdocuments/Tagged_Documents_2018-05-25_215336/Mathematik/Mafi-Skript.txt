Skript zu den Vorlesungen

Mathematik fĂźr Informatiker I und II
(WiSe 2009/10 und SoSe 2010)

Im WiSe 2009/10 gehalten von:
Prof. Dr. Barbara Baumeister
Lehrstuhl fĂźr Algebra
Fachbereich Mathematik
UniversitĂ¤t Dortmund
b.Baumeister@math.uni-dortmund.de

Autor: Martin Skutella
Lehrstuhl fĂźr Diskrete Optimierung
Fachbereich Mathematik
UniversitĂ¤t Dortmund
martin.skutella@uni-dortmund.de

(Version vom 15. Oktober 2007)

Vorwort
Das vorliegende Skript entstand im Winter- und Sommersemester 2005/06 waĚhrend ich die Vorlesungen Mathematik fuĚr Informatiker I und IIâ an der Univerâ
sitaĚt Dortmund hielt. Ich habe versucht, die wichtigsten Punkte der behandelten
Themen darin zusammen zu stellen, um den HoĚrerinnen und HoĚrern einen Leitfaden fuĚr die Nachbereitung der Vorlesung an die Hand zu geben. Das Skript
erhebt nicht den Anspruch eines Lehrbuchs hinsichtlich Exaktheit, VollstaĚndigkeit und PraĚsentation der Themen. Ich moĚchte beispielhaft auf einige LehrbuĚcher
verweisen, die beim weiteren Studium der Materie hilfreich sein koĚnnten.
â˘ M. Aigner. Diskrete Mathematik. Vieweg Verlag, 2004.
â˘ M. Brill. Mathematik fuĚr Informatiker. Hanser Verlag, 2001.
â˘ D. Hachenberger. Mathematik fuĚr Informatiker. Pearson Studium, 2005.
â˘ P. Hartmann. Mathematik fuĚr Informatiker. Vieweg Verlag, 2004.
â˘ G. Rosenberger. Lineare Algebra und algebraische Strukturen fuĚr Informatiker. Shaker Verlag, 2002.
â˘ A. Steger. Diskrete Strukturen (Band 1). Springer Verlag, 2001.
â˘ M. Wolff, P. Hauck und W. KuĚchlin. Mathematik fuĚr Informatik und Bioinformatik. Springer Verlag, 2004.
DaruĚber hinaus gibt es natuĚrlich eine Vielzahl weiterer LehrbuĚcher, auf die ich
hier jedoch nicht naĚher eingehe.
Teile dieses Skripts basieren auf Skripten und Aufzeichnungen zu fruĚheren
Vorlesungen an der UniversitaĚt Dortmund, die mir meine Kollegen freundlicherweise zur VerfuĚgung gestellt haben. Mehr dazu findet sich zu Beginn der entsprechenden Kapitel. Die Assistenten der beiden Vorlesungen, Ronald Koch und
Sammy Barkowski, haben mit zahlreichen wertvollen Text- und BildbeitraĚgen,
Hinweisen und VerbesserungsvorschlaĚgen wesentlich zum Gelingen des Skripts
beigetragen. DafuĚr sei ihnen ganz herzlich gedankt.
iii

iv

Mathematik fuĚr Informatiker

M. Skutella

Aufgrund der begrenzten Zeit, die ich auf das Erstellen dieses Skripts verwenden konnte, ist es sicherlich weit davon entfernt, fehlerfrei zu sein. FuĚr entsprechende Hinweise (am besten per Email an martin.skutella@uni-dortmund.de)
bin ich jederzeit dankbar.

Dortmund, im Juli 2006

Martin Skutella

Inhaltsverzeichnis
1 Aussagen, Mengen, Abbildungen, Relationen
1.1 Aussagen . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1.1 Informelle Definition von Aussagen . . . . . . . .
1.1.2 Logische VerknuĚpfungen . . . . . . . . . . . . . .
1.2 Mengen . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.1 Mengen und deren Beschreibungen . . . . . . . .
1.2.2 Allquantor und Existenzquantor . . . . . . . . . .
1.2.3 Mengenoperationen . . . . . . . . . . . . . . . . .
1.2.4 MaĚchtigkeit endlicher Mengen . . . . . . . . . . .
1.3 Abbildungen . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.1 Abbildungsvorschrift, Definitions- und Bildbereich
1.3.2 Bilder und Urbilder . . . . . . . . . . . . . . . . .
1.3.3 Eigenschaften und Komposition von Abbildungen
1.3.4 Bijektive Abbildungen . . . . . . . . . . . . . . .
1.4 MaĚchtigkeit von Mengen . . . . . . . . . . . . . . . . . .
1.5 Relationen . . . . . . . . . . . . . . . . . . . . . . . . . .
1.5.1 Grundbegriffe und Notationen . . . . . . . . . . .
1.5.2 Verkettung und Inverse . . . . . . . . . . . . . . .
1.5.3 AĚquivalenzrelationen . . . . . . . . . . . . . . . .
1.5.4 Ordnungsrelationen . . . . . . . . . . . . . . . . .
1.5.5 VerbaĚnde . . . . . . . . . . . . . . . . . . . . . .
2 Zahlbereiche
2.1 NatuĚrliche Zahlen, vollstaĚndige Induktion und Rekursion
2.1.1 Axiome der natuĚrlichen Zahlen . . . . . . . . . .
2.1.2 VollstaĚndige Induktion . . . . . . . . . . . . . . .
2.1.3 Rekursive Abbildungen . . . . . . . . . . . . . . .
2.2 Gruppen, Ringe, KoĚrper . . . . . . . . . . . . . . . . . .
2.2.1 Halbgruppen, Monoide, Gruppen . . . . . . . . .
2.2.2 Ringe . . . . . . . . . . . . . . . . . . . . . . . .
2.2.3 KoĚrper . . . . . . . . . . . . . . . . . . . . . . . .
2.2.4 Homomorphismen . . . . . . . . . . . . . . . . . .
2.3 Die komplexen Zahlen . . . . . . . . . . . . . . . . . . .
v

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

1
1
1
3
5
5
7
8
10
11
11
12
14
16
17
20
20
22
23
25
29

.
.
.
.
.
.
.
.
.
.

31
31
31
32
34
35
35
38
41
42
44

vi

Mathematik fuĚr Informatiker
2.4

2.5

M. Skutella

Primfaktorzerlegung und der euklidische Algorithmus
2.4.1 Division mit Rest . . . . . . . . . . . . . . . .
2.4.2 Der euklidische Algorithmus . . . . . . . . . .
2.4.3 Primzahlen und Primfaktorzerlegung . . . . .
Modulare Arithmetik . . . . . . . . . . . . . . . . . .
2.5.1 Addition und Multiplikation modulo m . . . .
2.5.2 Einheiten und Inverse . . . . . . . . . . . . .
2.5.3 Nullteiler . . . . . . . . . . . . . . . . . . . .
2.5.4 Chinesischer Restesatz . . . . . . . . . . . . .

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

3 Lineare Algebra
3.1 Lineare Gleichungssysteme und Matrizen . . . . . . . . .
3.1.1 Das GauĂâsche Eliminationsverfahren . . . . . . .
3.1.2 Matrizenrechnung . . . . . . . . . . . . . . . . . .
3.2 VektorraĚume . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Definition . . . . . . . . . . . . . . . . . . . . . .
3.2.2 TeilraĚume . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Linearkombinationen und Erzeugendensysteme . .
3.2.4 Lineare AbhaĚngigkeit und lineare UnabhaĚngigkeit
3.2.5 Basen . . . . . . . . . . . . . . . . . . . . . . . .
3.2.6 Dimension . . . . . . . . . . . . . . . . . . . . . .
3.2.7 Eine Anwendung: Endliche KoĚrper . . . . . . . .
3.3 Lineare Abbildungen und Matrizen . . . . . . . . . . . .
3.3.1 Lineare Abbildungen . . . . . . . . . . . . . . . .
3.3.2 Isomorphismen . . . . . . . . . . . . . . . . . . .
3.3.3 Kern und Bild . . . . . . . . . . . . . . . . . . . .
3.3.4 Homomorphiesatz . . . . . . . . . . . . . . . . . .
3.3.5 Rang einer Matrix . . . . . . . . . . . . . . . . .
3.3.6 Eine Anwendung: Polynomfunktionen . . . . . . .
3.3.7 Matrix einer linearen Abbildung . . . . . . . . . .
3.3.8 Basiswechsel . . . . . . . . . . . . . . . . . . . . .
3.3.9 Algebra der linearen Abbildungen . . . . . . . . .
3.3.10 Die volle lineare Gruppe . . . . . . . . . . . . . .
3.4 Determinanten . . . . . . . . . . . . . . . . . . . . . . .
3.4.1 Alternierende Multilinearformen . . . . . . . . . .
4 Analysis
4.1 Folgen
4.1.1
4.1.2
4.1.3
4.1.4
4.1.5

und Reihen . . . . . . . . . . . . . . .
Die VollstaĚndigkeit der reellen Zahlen .
Folgen . . . . . . . . . . . . . . . . . .
Reihen . . . . . . . . . . . . . . . . . .
Potenzreihen . . . . . . . . . . . . . .
Exponentialfunktion und Logarithmus

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.
.
.
.

51
51
52
55
58
59
61
63
64

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

67
67
68
76
79
79
82
85
88
93
96
102
105
105
110
111
115
119
123
124
130
132
135
140
140

.
.
.
.
.
.

141
141
141
144
150
158
161

Mathematik fuĚr Informatiker

4.2

4.3

4.4

4.5

M. Skutella

4.1.6 Landau-Symbole . . . . . . . . . . . . . . . . . .
Stetige Funktionen . . . . . . . . . . . . . . . . . . . . .
4.2.1 BeruĚhrungspunkte . . . . . . . . . . . . . . . . .
4.2.2 Grenzwerte von Funktionen . . . . . . . . . . . .
4.2.3 Stetigkeit . . . . . . . . . . . . . . . . . . . . . .
4.2.4 Elementare Funktionen: exp, ln, cos, sin, tan etc.
4.2.5 Nullstellensatz und Zwischenwertsatz . . . . . . .
Differenzialrechnung . . . . . . . . . . . . . . . . . . . .
4.3.1 Differenzierbarkeit und Ableitung von Funktionen
4.3.2 Ableitungsregeln . . . . . . . . . . . . . . . . . .
4.3.3 MittelwertsaĚtze und Extrema . . . . . . . . . . .
4.3.4 Taylorreihen . . . . . . . . . . . . . . . . . . . . .
4.3.5 Funktionen mehrerer VeraĚnderlicher . . . . . . . .
Integralrechnung . . . . . . . . . . . . . . . . . . . . . .
4.4.1 Das Integral einer Treppenfunktion . . . . . . . .
4.4.2 Riemann-integrierbare Funktionen . . . . . . . . .
4.4.3 Integration und Differentiation . . . . . . . . . . .
4.4.4 Integrationsregeln . . . . . . . . . . . . . . . . . .
4.4.5 Uneigentliche Integrale . . . . . . . . . . . . . . .
Differentialgleichungen . . . . . . . . . . . . . . . . . . .
4.5.1 Lineare Differentialgleichungen . . . . . . . . . .
4.5.2 Eine nichtlineare Differentialgleichung . . . . . . .
4.5.3 Lineare Schwingungsgleichung . . . . . . . . . . .

5 Kombinatorik und Graphentheorie
5.1 AbzaĚhlende Kombinatorik . . . . . . . . . . . . . . . . .
5.1.1 Einige elementare ZaĚhlprinzipien . . . . . . . . .
5.1.2 Binomialkoeffizienten . . . . . . . . . . . . . . . .
5.1.3 Auswahlen aus einer Menge . . . . . . . . . . . .
5.1.4 Ein- und AusschlieĂen . . . . . . . . . . . . . . .
5.1.5 Partitionen und Stirlingzahlen zweiter Art . . . .
5.1.6 Stirlingzahlen erster Art . . . . . . . . . . . . . .
5.1.7 Zerlegungen einer natuĚrlichen Zahl . . . . . . . .
5.2 Rekursion und erzeugende Funktionen . . . . . . . . . .
5.2.1 Formale Potenzreihen und erzeugende Funktionen
5.2.2 Lineare Rekursionsgleichungen . . . . . . . . . . .
5.3 Graphentheorie . . . . . . . . . . . . . . . . . . . . . . .
5.3.1 Grundlegende Begriffe der Graphentheorie . . . .
5.3.2 ZusammenhaĚngende Graphen und Euler-Touren .
5.3.3 BaĚume und WaĚlder . . . . . . . . . . . . . . . . .

vii
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

168
171
172
173
178
181
187
189
189
193
199
204
208
213
214
217
221
223
227
229
231
232
233

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

235
236
236
238
243
246
250
252
254
255
256
263
269
269
273
277

viii

Mathematik fuĚr Informatiker

6 Algebra
6.1 Gruppentheorie . . . . . . . . . . . . . . . . . . . . . .
6.1.1 Untergruppen und erzeugte Untergruppen . . .
6.1.2 Gruppenordnungen und der Satz von Lagrange
6.1.3 Der Homomorphiesatz fuĚr Gruppen . . . . . . .
6.2 Ringtheorie . . . . . . . . . . . . . . . . . . . . . . . .
6.2.1 Faktorringe und Ideale . . . . . . . . . . . . . .
6.2.2 Polynomringe . . . . . . . . . . . . . . . . . . .
6.2.3 GroĚĂter gemeinsamer Teiler in Polynomringen .

M. Skutella

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

281
281
281
285
288
291
292
296
298

Kapitel 1
Aussagen, Mengen, Abbildungen,
Relationen
Das erste Kapitel dieses Vorlesungsskriptes beruht teilweise auf Skripten von
Herrn Kahlhoff, Herrn MoĚller und Herrn Scharlau, denen ich hiermit ganz herzlich
danke.

1.1
1.1.1

Aussagen
Informelle Definition von Aussagen

Im taĚglichen Leben ziehen Menschen mehr oder weniger korrekte Schlussfolgerungen, ohne sich der Gesetze bewusst zu sein, nach denen sich dieses SchlieĂen
vollzieht. FuĚr wissenschaftliches, insbesondere mathematisches Arbeiten erweist
sich dieses intuitive SchlieĂen als unzureichend. Zudem zeigt sich, dass die Umgangssprache in mancher Hinsicht zu diffus ist, um mit ihr praĚzise einen mathematischen Sachverhalt ausdruĚcken zu koĚnnen. Der Begriffsinhalt von Substantiven
und Adjektiven ist manchmal mehrdeutig, manchmal nur unscharf abgegrenzt
und zudem Schwankungen unterworfen, sowohl von Mensch zu Mensch wie auch
fuĚr den einzelnen selbst im Laufe seines Lebens. Beispiele:
â˘ Schloss â Bank â Hahn â Messe â Steuer â . . .
â˘ alter Mensch â Freiheit â groĂ â unertraĚglich â warm â kalt â . . .
Bei den ersten fuĚnf Worten liegt Mehrdeutigkeit vor (das bekannte Kinderspiel
des Teekesselratensâ beruht gerade auf solchen Mehrdeutigkeiten), die auch bei
â
wissenschaftlichen Bezeichnungen (bedauerlicherweise) zu finden ist. Die weiteren Begriffe weisen ein diffuses, subjektives Begriffsspektrum auf. So ist eine Jugendliche geneigt, einen VierzigjaĚhrigen schon als alten Mannâ zu bezeichnen,
â
waĚhrend eine AchtzigjaĚhrige in diesem noch einen jungen Mann sieht. Ebenso ist
1

2

Mathematik fuĚr Informatiker

M. Skutella

beispielsweise die Abgrenzung von warmâ und kaltâ nicht eindeutig an einer
â
â
Temperaturgrenze festzumachen.
Auch die Satzverbindungen, die die logischen ZusammenhaĚnge beinhalten,
werden in wechselnden Bedeutungen verwendet. So etwa im Falle des Wortes
undâ:
â
â˘ Lena und Jakob sind Skifahrer.
â˘ 3 und 5 sind Primzahlen.
â˘ Lena und Jakob sind befreundet.
â˘ 3 und 5 ist 8.
â˘ Lena und Jakob haben ein Auto.
â˘ Jakob wird krank und der Arzt kommt.
â˘ Der Arzt kommt und Lena wird krank.
â˘ . . . na und ?
Die somit fuĚr den wissenschaftlichen Gebrauch notwendige begriffliche PraĚzisierung der Sprache fuĚhrt einerseits zu den in Definitionen klar umrissenen FachausdruĚcken (deren Bedeutung freilich bei verschiedenen Autoren unterschiedlich
sein kann) und andererseits im Falle der Satzverbindungen zu logischen Operationsvorschriften, die Einzelaussagen zu einer neuen Aussage verbinden. Was sind
aber zunaĚchst Aussagen?
ErklaĚrung 1.1.1. Aussagen sind sprachliche Gebilde, denen genau einer der
Wahrheitswerte w (wahr) oder f (falsch) zugeordnet ist.
Beispiele.
â˘ A1 := Die Erde ist eine Scheibe.â ist Aussage (Wahrheitswert f ).
â
â˘ A2 := 64 ist durch 4 teilbar.â ist Aussage (Wahrheitswert w).
â
â˘ A3 := Diese Aussage ist falsch.â ist keine Aussage.
â
â˘ A4 := 225964951 â 1 ist eine Primzahl.â ist Aussage (Wahrheitswert w).
â
â˘ A5 := Jede gerade Zahl âĽ 4 ist Summe zweier Primzahlen.â ist Aussage
â
(Wahrheitswert unbekannt, Goldbachsche Vermutung, ...12 = 5 + 7...).
â˘ A6 := Es gibt unendlich viele Zahlen a, so dass a und a + 2 Primzahlen
â
sind.â ist Aussage (Wahrheitswert unbekannt, z.B. 5 und 7 oder 9629 und
9631).

Kapitel 1

1.1.2

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

3

Logische VerknuĚpfungen

Durch Negation und VerknuĚpfung (Junktion) von Aussagen erhaĚlt man neue
Aussagen, die wir im Folgenden definieren.
Definition 1.1.2. Im Folgenden seien A und B zwei Aussagen.
a) Als Negation von A bezeichnen wir die Aussage nicht Aâ und schreiben
â
kurz ÂŹA. Die Negation ÂŹA hat den Wahrheitswert f , wenn A den Wahrheitswert w hat; hat umgekehrt A den Wahrheitswert f , so hat ÂŹA den Wahrheitswert w.
Beispiel. ÂŹA2 = 64 ist nicht durch 4 teilbar.â (falsch)
â
ÂŹA5 = Es gibt eine gerade Zahl âĽ 4, die nicht als Summe zweier Primzahlen
â
geschrieben werden kann.â (Wahrheitswert unbekannt)
b) Die Verkettung der Aussagen A und B durch das logische undâ nennen wir
â
Konjunktion und schreiben kurz A â§ B. Die Konjunktion A â§ B ist nur dann
wahr, wenn sowohl A als auch B wahr sind.
Beispiel. A2 â§ A5 = 64 ist durch 4 teilbar und jede gerade Zahl âĽ 4 ist
â
Summe zweier Primzahlen.â (Wahrheitswert unbekannt)
c) Die Verkettung der Aussagen A und B durch das logische oderâ nennen wir
â
Disjunktion und schreiben kurz A â¨ B. Die Disjunktion A â¨ B ist wahr, falls A
oder B oder beide wahr sind.
Beispiel. A2 â¨ A5 = 64 ist durch 4 teilbar oder jede gerade Zahl âĽ 4 ist
â
Summe zweier Primzahlen (oder beides).â (wahr)
d) Die Verkettung der Aussagen A und B zu wenn A, dann Bâ nennen wir
â
logische Folgerung oder Implikation und schreiben kurz A â B. Wir nennen A
Voraussetzung und B Behauptung der Implikation. Die Implikation ist wahr,
falls A falsch ist oder B wahr ist (oder A falsch und B wahr ist).
Beispiel. A := Jeder Tag ist ein Sonntag.â (falsch), B := Der BVB ist Deutâ
â
scher Meister.â (falsch)
(A â B)= Wenn jeder Tag ein Sonntag ist, dann ist der BVB Deutscher
â
Meister.â (wahr)
e) Die VerknuĚpfung der Aussagen A und B zu genau dann A, wenn Bâ nennen
â
wir AĚquivalenz und schreiben kurz A â B. Die AĚquivalenz ist wahr, falls A
und B denselben Wahrheitswert haben.
Beispiel. (A â B)= Genau dann, wenn jeder Tag ein Sonntag ist, ist der
â
BVB Deutscher Meister.â (wahr)

4

Mathematik fuĚr Informatiker

M. Skutella

Wir fassen die in Definition 1.1.2 getroffenen Vereinbarungen in der folgenden
Wahrheitstafel zusammen:
A
w
w
f
f

B
w
f
w
f

ÂŹA
f
f
w
w

ÂŹB
f
w
f
w

Aâ§B
w
f
f
f

Aâ¨B
w
w
w
f

AâB
w
f
w
w

AâB
w
f
f
w

Definition 1.1.3. Ein logischer Ausdruck, der fuĚr beliebige Wahrheitswerte der
enthaltenen Aussagen immer wahr ist, heiĂt Tautologie.
Satz 1.1.4. Es seien A, B und C beliebige Aussagen. Dann sind die folgenden
logischen AusdruĚcke Tautologien:
a) (A â§ f ) â f
(A â¨ w) â w
(A â¨ f ) â A
(A â§ w) â A

(NeutralitaĚt von f bzgl. â¨)
(NeutralitaĚt von w bzgl. â§)

b) (A â§ A) â A
(A â¨ A) â A

(Idempotenz von â§)
(Idempotenz von â¨)

c) (A â§ B) â (B â§ A)
(A â¨ B) â (B â¨ A)
d) ((A â§ B) â§ C) â (A â§ (B â§ C))
((A â¨ B) â¨ C) â (A â¨ (B â¨ C))
e) (A â¨ (B â§ C)) â ((A â¨ B) â§ (A â¨ C))
(A â§ (B â¨ C)) â ((A â§ B) â¨ (A â§ C))
f ) ÂŹ(A â¨ B) â (ÂŹA â§ ÂŹB)
ÂŹ(A â§ B) â (ÂŹA â¨ ÂŹB)

(KommutativitaĚt von â§)
(KommutativitaĚt von â¨)
(AssoziativitaĚt von â§)
(AssoziativitaĚt von â¨)
(DistributivitaĚt)
(DistributivitaĚt)
(De Morganâsche Regel)
(De Morganâsche Regel)

g) (A â B) â (ÂŹA â¨ B)
h) (A â B) â (ÂŹB â ÂŹA)
i) (A â B) â (A â§ B) â¨ (ÂŹA â§ ÂŹB)
j) (A â B) â ((A â B) â§ (B â A))
Teil h) des Satzes ist Grundlage fuĚr den Widerspruchsbeweis: Wenn man beweisen moĚchte, dass unter einer Voraussetzung A eine Behauptung B gilt, dann
genuĚgt es zu beweisen, dass die Voraussetzung A nicht erfuĚllt ist, falls die Behauptung B nicht erfuĚllt ist.

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

5

Auch Teil j) ist von Bedeutung in der Beweistechnik. Wenn man beweisen
moĚchte, dass zwei Aussagen A und B aĚquivalent sind, dann zeigt man das in den
allermeisten FaĚllen in zwei Schritten: Man beweist, dass aus A die Aussage B
folgt und dass aus B die Aussage A folgt.
Beweis. Wir beweisen beispielhaft den ersten Teil von f) mit Hilfe einer Wahrheitstafel. Die anderen Behauptungen des Satzes koĚnnen analog bewiesen werden.
A
w
w
f
f

B
w
f
w
f

ÂŹA
f
f
w
w

ÂŹB
f
w
f
w

ÂŹ(A â¨ B)
f
f
f
w

ÂŹA â§ ÂŹB
f
f
f
w

ÂŹ(A â¨ B) â (ÂŹA â§ ÂŹB)
w
w
w
w

Aus der letzten Spalte der Tabelle folgt, dass die Aussage ÂŹ(A â¨ B) â (ÂŹA â§ ÂŹB)
unabhaĚngig von den Wahrheitswerten von A und B immer wahr ist.


1.2
1.2.1

Mengen
Mengen und deren Beschreibungen

Wir verzichten hier auf eine formale axiomatische EinfuĚhrung der Mengenlehre
und beschraĚnken uns bei der Definition des Begriffs Mengeâ auf die folgende Beâ
schreibung, die auf Georg Cantor (1845â1918), den BegruĚnder der Mengenlehre,
zuruĚckgeht.
ErklaĚrung 1.2.1. Eine Menge ist eine Zusammenfassung bestimmter wohlunterschiedener Objekte unserer Anschauung oder unseres Denkens â welche die
Elemente der Menge genannt werden â zu einem Ganzen.
Wir verwenden die folgenden Schreibweisen:
â˘ x â M steht fuĚr die Aussage x ist ein Element der Menge M .â
â
â˘ Die Negation dieser Aussage bezeichnen wir mit x 6â M , d.h. x ist kein
â
Element von M .â
Beispiel. Hose â {Jacke, Hose}, Hut 6â {Jacke, Hose}
Definition
N =
N0 =
Z =
Q =
R
â

1.2.2 (Standard-Bezeichnungen fuĚr Mengen).
{1, 2, 3, 4, . . .} die natuĚrlichen Zahlen
{0, 1, 2, 3, 4, . . .} die natuĚrlichen Zahlen mit Null
{. . . , â2, â1, 0, 1, 2, . . .} die ganzen Zahlen
{m
| m â Z, n â N} die Bruchzahlen, rationalen Zahlen
n
die reellen Zahlen
die leere Menge

6

Mathematik fuĚr Informatiker

M. Skutella

ErklaĚrung 1.2.3 (Beschreibung von Mengen).
I. Durch AufzaĚhlung der Elemente, z.B.
M = {1, 3, 5, 6},

X = {a, b, c, d, e, f } ;

dieses ist prinzipiell bei endlichen Mengen moĚglich, unter UmstaĚnden auch
bei unendlichen Mengen, wenn keine MissverstaĚndnisse zu befuĚrchten sind:
N0 = {0, 1, 2, 3, 4 . . .},
G = {2, 4, 6, 8, . . .} die Menge der geraden Zahlen.
II. In beschreibender Form, d.h. durch Angabe der Eigenschaften der Elemente,
z.B.
G = {x | x â N und x ist gerade} .
Die allgemeine Form ist:
M = {x | A(x)} ,
dabei ist A(x) eine Aussage uĚber x, also z.B. x ist eine natuĚrliche Zahl
â
und x ist gerade.â
Man kann auch schreiben:
G = {x â N | x ist gerade},
d.h. die âGrundmengeâ, in der sich die Elemente der zu definierenden Menge befinden, hier die Menge N, wird nicht unter den Aussagen (bzw. Eigenschaften), sondern bereits vor dem Trennstrich in der Mengenklammer
genannt.
III. In abgekuĚrzter beschreibender Form, z.B.
G = {2 Âˇ m | m â N} .
Man verzichtet hier auf einen speziellen Namen fuĚr die Elemente und gibt
sofort ein Bildungsgesetz, z.B. einen Term oder algebraischen Ausdruck, an.
Ein anderes Beispiel hierzu:
K = {1 + 3z | z â Z}
= {. . . , â5, â2, 1, 4, 7, 10, . . . } .
Beispiel. Die Menge der Quadratzahlen in allen drei Beschreibungsformen:
Q = {1, 4, 9, 16, 25, . . .}
= {y | y â N und es existiert ein x â N mit x2 = y}
= {x2 | x â N}

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

7

Kurzer Exkurs. Wir weisen an dieser Stelle darauf hin, dass ein naiver Umgang mit Mengen schnell zu scheinbar unaufloĚsbaren WiderspruĚchen fuĚhren kann.
Ein schoĚnes Beispiel hierfuĚr ist die Russellsche Antinomie: Es sei M die Menge
â
aller Mengen, die sich nicht selbst enthalten, also
M := {X | X 6â X} .â
Die Frage, ob M in sich selbst enthalten ist oder nicht, fuĚhrt zu einem unaufloĚsbaren Widerspruch. Ein sauberer axiomatischer Aufbau der Mengenlehre erlaubt
daher keine solche Menge M .
Das beschriebene Pardoxon kann auch leicht in das taĚgliche Leben uĚbersetzt
werden. Man stelle sich vor, es gaĚbe in einer Bibliothek ein Nachschlagewerk, das
alle BuĚcher der Bibliothek zitiert (auflistet), die sich nicht selbst zitieren. Die
Frage, ob dieses Nachschlagewerk sich selbst zitiert oder nicht, fuĚhrt zu demselben Paradoxon. Ein anderes bekanntes Paradoxon ist der Dorf-Barbier, der alle
MaĚnner des Dorfes rasiert, die sich nicht selbst rasieren. . .

1.2.2

Allquantor und Existenzquantor

Definition 1.2.4 (Allquantor und Existenzquantor). Es sei M eine nichtleere
Menge und fuĚr jedes x â M sei A(x) eine Aussage.
a) Mit âx â M : A(x) bezeichnen wir die Aussage FuĚr alle x â M gilt A(x).â
â
b) Mit âx â M : A(x) bezeichnen wir die Aussage Es gibt ein x â M , fuĚr
â
das A(x) gilt.â
c) Mit â!x â M : A(x) bezeichnen wir die Aussage Es gibt genau ein x â M ,
â
fuĚr das A(x) gilt.â
Man nennt â den Allquantor und â den Existenzquantor.
Beispiel. Es sei M die Menge der Studentinnen und Studenten dieser Vorlesung
und fuĚr einen Studierenden x â M sei A(x) die Aussage x faĚhrt mit dem Fahrrad
â
zur Uni.â Dann steht âx â M : A(x) fuĚr die Aussage Alle Studierenden dieser
â
Vorlesung fahren mit dem Fahrrad zur Uni.â Der Ausdruck âx â M : A(x) steht
fuĚr Mindestens eine(r) der Studierenden dieser Vorlesung faĚhrt mit dem Fahrrad
â
zur Uni.â SchlieĂlich steht der Ausdruck â!x â M : A(x) fuĚr Genau eine(r) der
â
Studierenden dieser Vorlesung faĚhrt mit dem Fahrrad zur Uni.â
Lemma 1.2.5. Es sei M eine nichtleere Menge und fuĚr jedes x â M sei A(x)
eine Aussage. Die Negation der Aussage âx â M : A(x) ist die Aussage âx â
M : ÂŹA(x), d.h.
ÂŹ(âx â M : A(x)) â (âx â M : ÂŹA(x)) .

8

Mathematik fuĚr Informatiker

M. Skutella

Beispiel. In Fortsetzung des Beispiels von oben stellen wir fest, dass die Negation von Alle Studierenden dieser Vorlesung fahren mit dem Fahrrad zur Uniâ
â
die folgende Aussage ist: Es gibt eine Studentin oder einen Studenten dieser
â
Vorlesung, die/der nicht mit dem Fahrrad zur Uni faĚhrt.â
Lemma 1.2.5 ist die formale Rechtfertigung fuĚr den Beweis durch Gegenbeispiel. Wenn man etwa beweisen moĚchte, dass die Aussage Alle Studentinnen
â
und Studenten dieser Vorlesung fahren mit dem Fahrrad zur Uniâ falsch ist, so
genuĚgt es, eine Studentin oder einen Studenten zu finden, die/der nicht mit dem
Fahrrad zur Uni faĚhrt.

1.2.3

Mengenoperationen

Definition 1.2.6 (Teilmenge).
a) Eine Menge X heiĂt Teilmenge einer Menge M , falls jedes Element von X
auch Element von M ist (d.h.: âx â X : x â M ). Die entsprechende Beziehung
zwischen X und M heiĂt auch Inklusion (von X in M ).
Bezeichnung:

XâM .

Wir weisen ausdruĚcklich darauf hin, dass bei der Inklusion die Gleichheit der
beiden Mengen erlaubt ist: Es gilt M â M .
b) Eine Menge X heiĂt echte Teilmenge einer Menge M , falls X Teilmenge von
M und X 6= M ist. Die entsprechende Beziehung zwischen X und M heiĂt
auch echte Inklusion (von X in M ).
Bezeichnung:

X(M

oder

X&M

oder

X â M.

Definition 1.2.7 (Operationen mit Mengen). Es seien X und Y zwei Mengen.
Wir definieren:
(i) X âŠ Y := {x | x â X â§ x â Y }

(Durchschnitt)

(ii) X âŞ Y := {x | x â X â¨ x â Y }

(Vereinigung)

(iii) X \ Y := {x | x â X â§ x 6â Y }

(Differenzmenge)

Ist X âŠ Y = â, dann sagt man, dass X und Y disjunkt sind.
Bemerkung. Man beachte, dass bei der Differenzmenge X \ Y die Menge Y
nicht in der Menge X enthalten sein muss. Man kann sich allerdings immer auf
diesen Fall zuruĚckziehen, denn es gilt offensichtlich
X \ Y = X \ (X âŠ Y ) .
Veranschaulichung im sogenannten Venn-Diagramm:

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella
X

X

Y

X \Y

9

Y

X \Y

Definition 1.2.8 (Komplement). Ist X Teilmenge der Grundmenge M , so bezeichnen wir das Komplement von X in M mit X := M \ X.
Satz 1.2.9 (Grundgesetze bei Mengenoperationen). Es seien X, Y und Z Teilmengen einer Grundmenge M . Dann gelten die folgenden Gesetze:
a) X
X
X
X

âŠâ=â
âŞM =M
âŞâ=X
âŠM =X

(NeutralitaĚt von â bzgl. âŞ)
(NeutralitaĚt von M bzgl. âŠ)

b) X âŠ X = X und X âŞ X = X

(Idempotenz)

c) X âŠ Y = Y âŠ X und X âŞ Y = Y âŞ X

(KommutativitaĚt)

d) (X âŠ Y ) âŠ Z = X âŠ (Y âŠ Z) und (X âŞ Y ) âŞ Z = X âŞ (Y âŞ Z)(AssoziativitaĚt)
e) X âŞ (Y âŠ Z) = (X âŞ Y ) âŠ (X âŞ Z) und X âŠ (Y âŞ Z) = (X âŠ Y ) âŞ (X âŠ Z)
(DistributivitaĚt)
f ) X âŠ Y = X âŞ Y und X âŞ Y = X âŠ Y

(De Morganâsche Regeln)

Beweis. Die Gesetze folgen im Wesentlichen aus den in Satz 1.1.4 a)âf) beschriebenen Gesetzen fuĚr die VerknuĚpfung von Aussagen. Wir machen den Zusammenhang beispielhaft fuĚr Teil c) klar. Dazu definieren wir fuĚr x â M die Aussagen A(x) := x ist Element der Menge X.â und B(x) := x ist Element der
â
â
Menge Y .â Die Aussagen in c) koĚnnen dann wie folgt neu formuliert werden:
âx â M : (A(x) â§ B(x)) â (B(x) â§ A(x))
âx â M : (A(x) â¨ B(x)) â (B(x) â¨ A(x))
Aus dem entsprechenden Teil von Satz 1.1.4 folgt sofort, dass diese Aussagen
wahr sind.

Definition 1.2.10 (Kartesisches Produkt).
a) Das kartesische Produkt zweier Mengen X und Y ist definiert als
X ĂY
:= {(x, y) | x â X â§ y â Y } .
X kreuz Y â
â
Ein Element (x, y) â X Ă Y heiĂt geordnetes Paar. Nach Definition gilt fuĚr
beliebige x, x0 â X und y, y 0 â Y :
(x, y) = (x0 , y 0 ) â (x = x0 â§ y = y 0 ) .

10

Mathematik fuĚr Informatiker

M. Skutella

b) Allgemeiner ist das kartesische Produkt von n Mengen X1 , X2 , . . . , Xn definiert
als
X1 Ă X2 Ă Âˇ Âˇ Âˇ Ă Xn := {(x1 , x2 , . . . , xn ) | xi â Xi fuĚr i = 1, . . . , n} .
Ein Element (x1 , x2 , . . . , xn ) â X1 Ă X2 Ă Âˇ Âˇ Âˇ Ă Xn heiĂt n-Tupel. Nach Definition gilt fuĚr beliebige xi , yi â Xi , i = 1, . . . , n:
(x1 , x2 , . . . , xn ) = (y1 , y2 , . . . , yn ) â (xi = yi fuĚr i = 1, . . . , n) .
Zwei n-Tupel sind also nur dann gleich, wenn an entsprechenden Stellen dasselbe Element der jeweiligen Menge Xi steht. Insbesondere kommt es in geordneten Paaren auf die Reihenfolge der beiden Elemente an: Es gilt (x, y) 6= (y, x),
falls x 6= y. (Es muĚssen x und y beide in X und Y liegen, damit die fraglichen
Paare in X Ă Y liegen. Wir denken bei dieser Bemerkung insbesondere an den
wichtigen Fall X = Y .) BezuĚglich Reihenfolge verhaĚlt sich also (x, y) anders als
die Menge {x, y}, fuĚr die offenbar {x, y} = {y, x} gilt. UĚbrigens sollte man die
Notation {x, y} nur benutzen, wenn x 6= y ist (sonst notiert man die einelementige Menge natuĚrlich als {x}), waĚhrend ein geordnetes Paar (x, x) durchaus Sinn
macht.
Bei n-Tupeln (wir nehmen hier der Einfachheit halber den Fall X1 = X2 =
Âˇ Âˇ Âˇ = Xn =: X an) kommt es erst recht auf die Reihenfolge an: Wenn etwa x, y, z
drei verschiedene Elemente aus X sind, dann koĚnnen wir hieraus 6 verschiedene
Tripel in X Ă X Ă X bilden, naĚmlich
(x, y, z), (x, z, y), (y, x, z), (y, z, x), (z, x, y), (z, y, x) .

1.2.4

MaĚchtigkeit endlicher Mengen

Definition 1.2.11 (MaĚchtigkeit, KardinalitaĚt). Eine Menge M heiĂt endlich,
wenn sie aus nur endlich vielen Elementen besteht. Andernfalls heiĂt sie unendlich. Die Anzahl der Elemente einer endlichen Menge heiĂt die MaĚchtigkeit oder
auch KardinalitaĚt von M , in Zeichen |M | oder #M .
In Abschnitt 1.4 kommen wir auf den Begriff der MaĚchtigkeit zuruĚck und
gehen dann auch auf unendliche Mengen ein.
Lemma 1.2.12. Es seien M und N zwei endliche Mengen. Dann ist auch ihr kartesiches Produkt endlich und seine MaĚchtigkeit gleich dem Produkt der MaĚchtigkeiten von M und N :
|M Ă N | = |M | Âˇ |N | .
Definition 1.2.13 (Potenzmenge). Die Menge aller Teilmengen einer Menge M
heiĂt Potenzmenge von M und wird mit P(M ) bezeichnet:
P(M ) := {X | X â M } .

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

11

Beispiel. Es sei M = {x, y, z}. Dann ist
P(M ) = {â, {x}, {y}, {z}, {x, y}, {x, z}, {y, z}, M } .
Lemma 1.2.14. Wenn M eine endliche Menge ist, dann besteht P(M ) aus 2|M |
Elementen:
|P(M )| = 2|M | .
Definition 1.2.15 (Disjunktes Mengensystem, Partition). Es sei M eine Menge
und S â P(M ) ein Mengensystem uĚber M .
a) Falls je zwei verschiedene Elemente X und Y von S disjunkt sind (d.h. âX, Y â
S : X 6= Y â X âŠ Y = â), so nennt man S ein disjunktes Mengensystem.
b) Ist S ein disjunktes Mengensystem uĚber M , das nicht die leere Menge enthaĚlt,
und ist jedes Element von M in einer (und damit in genau einer) Menge von S
enthalten, dann heiĂt S Partition oder Zerlegung von M .
Beispiel. Es sei M := {a, b, c, d, e, f }. Dann ist S = {{c, e}, {b, d, f }} ein disjunktes Mengensystem und S âŞ {{a}} ist eine Partition von M .
Das naĚchste Lemma folgt mit einem einfachen AbzaĚhlargument.
Lemma 1.2.16. Ist M eine endliche Menge und S eine Partition von M , dann
ist die KardinalitaĚt von M die Summe der KardinalitaĚten der Mengen in S.

1.3
1.3.1

Abbildungen
Abbildungsvorschrift, Definitions- und Bildbereich

Definition 1.3.1 (Abbildung). Es seien X und Y zwei Mengen. Eine Abbildung
von X in Y ist gegeben durch eine Vorschrift f , die jedem Element x â X genau
ein Element y â Y zuordnet. Man schreibt y = f (x) (lies: f von xâ). FuĚr die
â
gesamte Abbildung schreibt man
f : X â Y (lies: f von X nach Y â oder . . . in Yâ).
â
â
FuĚr ein Element x â X benutzt man die Notation
x 7â f (x) (lies: x wird abgebildet auf f (x)â).
â
f (x) heiĂt das Bild von x unter f .
X
heiĂt Definitionsbereich.
Y
heiĂt Bildbereich oder Wertebereich.

12

Mathematik fuĚr Informatiker

M. Skutella

Wichtig: Zwei Abbildungen sind nur dann gleich, wenn die Vorschriften und auch
die Definitions- und Bildbereiche uĚbereinstimmen.
Die Abbildungen (1)â(3) des folgenden Beispiels sind alle verschieden, auch
wenn die Vorschrift immer die gleiche, naĚmlich das Quadrieren einer Zahl ist.
Beispiele.
(1) X = N,

Y = N,

(2) X = Z,

Y = N0 ,

(3) X = Z,

Y = Z,

f (x) = x2
f (x) = x2
f (x) = x2

(4) X = Y = R, f (x) = ex , cos x, sin x
Reelle Funktionenâ, wie man sie in der Analysis studiert, sind ebenfalls
â
Abbildungen.
(5) Die Menge X sei endlich. Dann kann die Vorschriftâ als eine (endliche) Taâ
belle aufgefasst werden. Zum Beispiel: X = {1, 2, 3, 4, 5}, Y = {u, v, w, x, y, z}
1 2 3 4 5
x
f (x) y v w x w
Veranschaulichung mit Pfeildiagramm:
1

u

2

v

3

w

4

x

5

y
z

Bei jedem Element des Definitionsbereichs X beginnt genau ein Pfeil.
Definition 1.3.2. Es seien X und Y zwei Mengen und X 0 â X. Die EinschraĚnkung einer Abbildung f : X â Y auf X 0 ist die Abbildung
f |X 0 : X 0 â Y

1.3.2

mit

f |X 0 (x) := f (x) fuĚr alle x â X 0 .

Bilder und Urbilder

Definition 1.3.3 (Bilder und Urbilder von Teilmengen). Es sei f : X â Y eine
Abildung.
a) FuĚr Z â X definieren wir
f (Z) := {y â Y | es gibt ein x â Z mit f (x) = y}
= {f (x) | x â Z} .
Wir nennen f (Z) das Bild von Z unter f .

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

13

b) Die Menge f (X) (also das Bild von ganz X unter f ) heiĂt auch die Bildmenge
oder einfach das Bild von f .
c) FuĚr Z â Y definieren wir f â1 (Z) := {x â X | f (x) â Z} und nennen f â1 (Z)
das Urbild von Z unter f .
d) FuĚr einelementiges Z = {z} schreiben wir kurz f â1 (z) := f â1 ({z}).
Beispiele. Wir betrachten einige Beispielabbildungen von oben.
(1) X = N, Y = N, f (x) = x2
f ({1, 2, 3}) = {1, 4, 9}
f ({5, 7, 12}) = {25, 49, 144}
f â1 ({25, 36, 49}) = {5, 6, 7}
f â1 ({10, 11, 12, . . . , 20}) = {4}
f â1 ({100, 101, . . . , 200}) = {10, 11, 12, 13, 14}
(3) X = Z, Y = Z, f (x) = x2
f â1 ({25}) = {5, â5}
f â1 ({25, 36, 49}) = {Âą5, Âą6, Âą7} (6 Elemente)
f â1 ({â1, â2, â3, . . .}) = â
(5) X = {1, 2, 3, 4, 5}, Y = {u, v, w, x, y, z}, f : X â Y
1

u

2

v

3

w

4

x

5

y
z

f â1 ({u, v}) = {2}
f â1 ({z}) = â
f â1 ({v, w}) = {2, 3, 5}
Lemma 1.3.4. Ist f : X â Y eine Abbildung, so ist
S := {f â1 (y) | y â Y } \ {â}
eine Partition von X.
Beweis. Wir zeigen zunaĚchst, dass S ein disjunktes Mengensystem ist. Es seien U, V â S mit U 6= V . Dann gibt es u, v â Y mit u 6= v, U = f â1 (u)
und V = f â1 (v). Im Widerspruch zur Behauptung nehmen wir an, dass x â U âŠV .
Dann gilt f (x) = u, da x â U , und f (x) = v, da x â V , also u = v â ein Widerspruch.

14

Mathematik fuĚr Informatiker

M. Skutella

Um zu beweisen, dass S eine Partition ist, muĚssen wir noch zeigen, dass
jedes x â X in einer Teilmenge aus S liegt. Das ist aber klar, da x â f â1 (f (x)) â
S.

Beispiel. Wir betrachten noch einmal Beispiel (5) von oben. Hier gilt
{f â1 (y) | y â Y } \ â = {{2}, {3, 5}, {4}, {1}} ,
was offenbar eine Partition der Menge X = {1, 2, 3, 4, 5} ist.

1.3.3

Eigenschaften und Komposition von Abbildungen

Definition 1.3.5 (InjektivitaĚt, SurjektivitaĚt, BijektivitaĚt). Eine Abbildung f :
X â Y heiĂt
a) injektiv :ââ (âx, y â X : x 6= y â f (x) 6= f (y));
d.h. verschiedene Elemente in X haben auch verschiedene Bilder unter f .
b) surjektiv :ââ f (X) = Y ;
d.h. jedes Element in Y kommt als Bild unter f vor.
c) bijektiv :ââ f ist injektiv und surjektiv.
Im Pfeildiagramm bedeuten diese Eigenschaften:
injektiv
surjektiv
bijektiv

: Es laufen keine zwei Pfeile zusammen.
: Bei jedem y â Y endet ein Pfeil.
: Bei jedem y â Y endet genau ein Pfeil.

Aus einer beliebigen Abbildung f : X â Y kann man leicht eine surjektive
Abbildung konstruieren: Man ersetze naĚmlich Y durch die Bildmenge f (X).
Definition 1.3.6 (Graph). Es sei f : X â Y eine Abbildung. Der Graph von f
ist definiert als
Îf := {(x, f (x)) | x â X} â X Ă Y .
Definition 1.3.7 (Komposition von Abbildungen). Es seien f : X â Y und
g : Y 0 â Z zwei Abbildungen, wobei der Wertebereich der ersten im Definitionsbereich der zweiten enthalten ist, d.h. Y â Y 0 . Die Komposition, Verkettung
oder HintereinanderausfuĚhrung
gâŚf :X âZ
(lies: g nach fâ) ist definiert durch
â
(g âŚ f )(x) = g(f (x))

fuĚr alle x â X .

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

15

Lemma 1.3.8. Es seien X, Y und Z Mengen und f : X â Y und g : Y â Z
zwei Abbildungen.
a) Sind f und g injektiv, so ist auch g âŚ f : X â Z injektiv.
b) Sind f und g surjektiv, so ist auch g âŚ f : X â Z surjektiv.
c) Sind f und g bijektiv, so ist auch g âŚ f : X â Z bijektiv.
Beweis. Zu a): Es seien x, x0 â X mit x 6= x0 . Da f injektiv ist, folgt f (x) 6= f (x0 ).
Da g auch injektiv ist, folgt daraus g(f (x)) 6= g(f (x0 )), so dass also g âŚ f injektiv
ist.
Zu b): Es sei z â Z. Da g surjektiv ist, gibt es ein y â Y mit g(y) = z.
Da f surjektiv ist, gibt es ein x â X mit f (x) = y. Damit gilt also (g âŚ f )(x) =
g(f (x)) = g(y) = z und folglich ist g âŚ f surjektiv.
Teil c) folgt nach Definition 1.3.5 aus a) und b).

Lemma 1.3.9. Die Komposition von Abbildungen ist assoziativ, d.h. wenn f :
X â Y , g : Y 0 â Z, h : Z 0 â W drei Abbildungen sind mit Y â Y 0 und Z â Z 0 ,
so ist
h âŚ (g âŚ f ) = (h âŚ g) âŚ f .
Beweis. FuĚr jedes beliebige Element x â X gilt
(h âŚ (g âŚ f ))(x) = h((g âŚ f )(x)) = h(g(f (x))) ,
((h âŚ g) âŚ f )(x) = (h âŚ g)(f (x)) = h(g(f (x))) .
Also sind die Abbildungsvorschriften gleich:
h âŚ (g âŚ f ) = (h âŚ g) âŚ f .
Der Definitionsbereich X und der Zielbereich W stimmen ebenfalls uĚberein.



Definition 1.3.10 (Identische Abbildung). Es sei X irgendeine Menge. Die identische Abbildung
idX : X â X
ist definiert durch idX (x) = x fuĚr alle x â X.
Bemerkung. FuĚr eine beliebige Abbildung f : X â Y gilt
f âŚ idX = f = idY âŚf .

16

Mathematik fuĚr Informatiker

1.3.4

M. Skutella

Bijektive Abbildungen

Satz 1.3.11 (Umkehrabbildung). Es sei f : X â Y eine Abbildung.
a) Die folgenden beiden Eigenschaften sind aĚquivalent:
(a1) f ist bijektiv.
(a2) Es gibt eine Abbildung g : Y â X mit
g(f (x)) = x fuĚr alle x â X, d.h. g âŚ f = idX und
f (g(y)) = y fuĚr alle y â Y , d.h. f âŚ g = idY .
Die Abbildung g ist eindeutig und heiĂt die zu f inverse Abbildung, oder
Umkehrabbildung von f . Man schreibt auch g = f â1 .
b) Wenn f : X â Y bijektiv ist, so ist auch f â1 : Y â X bijektiv und es gilt
(f â1 )â1 = f .
Beweis. Zu a): Nach Satz 1.1.4 j) sind zwei Implikationen zu zeigen:
(a1) =â (a2)â: Zu jedem y â Y gibt es genau ein x â X mit f (x) = y, denn
â
f ist surjektiv und injektiv. Definiere nun eine Abbildung g : Y â X gemaĚĂ
g(y) := x. Dann gilt nach Konstruktion
g(f (x)) = x fuĚr alle x â X ,
wie unter (a2) als erstes behauptet. Wir zeigen nun die zweite Behauptung unter (a2). Es sei y â Y beliebig. Weil f surjektiv ist, existiert ein x â X mit
f (x) = y. Es folgt
f (g(y)) = f (g(f (x))) = f (x) = y ,
wie gewuĚnscht.
(a2) =â (a1)â: Wir muĚssen zeigen, dass f sowohl injektiv als auch surjektiv
â
ist. Wir beginnen mit der InjektivitaĚt: Es seien x, x0 â X mit f (x) = f (x0 ). Dann
ist x = g(f (x)) = g(f (x0 )) = x0 , wie gewuĚnscht.
Es bleibt zu zeigen, dass f surjektiv ist: Es sei y â Y gegeben. Setze x := g(y).
Dann ist
f (x) = f (g(y)) = y ,
wie gewuĚnscht.
Wir beweisen als naĚchstes die Eindeutigkeit von g: Angenommen h : Y â X
hat die gleichen Eigenschaften wie g. Dann gilt
h = h âŚ idY = h âŚ (f âŚ g) = (h âŚ f ) âŚ g = idX âŚg = g .
Teil b) des Satzes folgt schlieĂlich aus a).



Lemma 1.3.12. Es seien X, Y und Z Mengen und f : X â Y und g : Y â Z
bijektive Abbildungen. Dann gilt
(g âŚ f )â1 = f â1 âŚ g â1 .

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

17

Beweis. Es gilt wegen Lemma 1.3.9 (AssoziativitaĚt)
(f â1 âŚ g â1 ) âŚ (g âŚ f ) = f â1 âŚ ((g â1 âŚ g) âŚ f ) = f â1 âŚ (idY âŚf ) = f â1 âŚ f = idX ,
und
(g âŚ f ) âŚ (f â1 âŚ g â1 ) = (g âŚ (f âŚ f â1 )) âŚ g â1 = (g âŚ idY ) âŚ g â1 = g âŚ g â1 = idZ .
Die Behauptung folgt damit aus Satz 1.3.11.

1.4



MaĚchtigkeit von Mengen

Wir betrachten zunaĚchst noch einmal endliche Mengen.
Satz 1.4.1. Es seien X und Y endliche Mengen.
a) Es gibt eine surjektive Abbildung von X nach Y genau dann, wenn |X| âĽ |Y |.
b) Es gibt eine injektive Abbildung von X nach Y genau dann, wenn |X| â¤ |Y |.
c) Es gibt eine bijektive Abbildung von X nach Y genau dann, wenn |X| = |Y |.
Beweis. Es seien X = {x1 , x2 , . . . , x|X| } und Y = {y1 , y2 , . . . , y|Y | }.
Zu a): Wir nehmen zunaĚchst an, dass f : X â Y surjektiv ist. Betrachte
die Partition S = {f â1 (y) | y â Y } von X. Da die KardinalitaĚt von X nach
Lemma 1.3.4 und Lemma 1.2.16 die Summe der KardinalitaĚten der nichtleeren
Mengen f â1 (y) uĚber alle y â Y ist, gilt
|X| = |f â1 (y1 )| + |f â1 (y2 )| + Âˇ Âˇ Âˇ + |f â1 (y|Y | )| âĽ |Y | .
| {z } | {z }
| {z }
âĽ1

âĽ1

âĽ1

Ist umgekehrt |X| âĽ |Y |, dann ist die Abbildung f : X â Y mit
(
yi
falls i â¤ |Y |,
f (xi ) :=
y|Y | sonst,
nach Definition surjektiv.
Teil b) zeigt man analog. Teil c) folgt schlieĂlich aus a) und b).



Satz 1.4.1 c) motiviert die folgende Definition fuĚr den Fall unendlicher Mengen.
Definition 1.4.2 (AbzaĚhlbarkeit, UĚberabzaĚhlbarkeit).
a) Zwei undendliche Mengen X und Y heiĂen gleichmaĚchtig oder von gleicher
KardinalitaĚt, wenn es eine bijektive Abbildung von X nach Y (und damit auch
eine bijektive Abbildung von Y nach X) gibt.

18

Mathematik fuĚr Informatiker

M. Skutella

b) Eine Menge M heiĂt abzaĚhlbar unendlich oder kurz abzaĚhlbar, falls es eine
bijektive Abbildung von N auf M gibt.
c) Eine unendliche Menge, die nicht abzaĚhlbar ist, heiĂt uĚberabzaĚhlbar.
Beispiele.
(i) Die Mengen N und N0 sind gleichmaĚchtig, da die Abbildung pred : N â N0
mit pred(n) := n â 1 bijektiv ist. (Der Name pred kommt von predecessor
â VorgaĚnger.) Insbesondere ist also N0 abzaĚhlbar unendlich.
(ii) Die Mengen N0 und Z sind gleichmaĚchtig, da die Abbildung f : N0 â Z
mit
(
n+1
falls n ungerade,
2
f (n) :=
n
â 2 falls n gerade,
bijektiv ist. Die Komposition der bijektiven Abbildungen pred und f zu f âŚ
pred : N â Z zeigt nach Lemma 1.3.8 c), dass auch Z abzaĚhlbar unendlich
ist.
(iii) Es sei J := {x â R | 0 < x < 1}. Dann sind J und R gleichmaĚchtig. Um
dies zu zeigen, betrachte man die Abbildung f : J â R mit
f (x) :=

x â 21
.
x(1 â x)

Mit einfachen Methoden der Analysis kann man zeigen, dass f bijektiv ist.
Satz 1.4.3. Die Menge der rationalen Zahlen Q ist abzaĚhlbar.
Beweisskizze. Der Beweis verwendet das Diagonalisierungsschema von Cauchy.
Wir betrachten die folgende unendlich groĂe Tabelle, in der alle BruĚche pq mit p, q â
N stehen:
1

2

3

4

ÂˇÂˇÂˇ

1
2

2
2

3
2

4
2

ÂˇÂˇÂˇ

1
3

2
3

3
3

4
3

ÂˇÂˇÂˇ

1
4

2
4

3
4

4
4

ÂˇÂˇÂˇ
...

..
.

..
.

..
.

..
.

Man beachte, dass jede rationale Zahl mehrfach in dieser Tabelle auftaucht. So
steht beispielsweise auf der Diagonalen (von links oben nach rechts unten) uĚberall
die Zahl eins. Wir koĚnnen alle BruĚche dieser Tabelle aufzaĚhlen, indem wir die
Tabelle wie folgt durchlaufen:
1 2

1
2

1
3

2
2

3 4

3
2

2
3

1
4

1
5

2
4

3
3

4
2

5 6

5
2

4
3

...

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

19

LoĚscht man aus dieser unendlichen Folge alle doppelten Zahlen, so erhaĚlt man
die unendliche Folge
1 2

1
2

1
3

3 4

3
2

2
3

1
4

1
5

5 6

5
2

4
3

... ,

in der jede positive rationale Zahl genau einmal vorkommt. Wir koĚnnen daraus leicht eine bijektive Abbildung f von N in die positiven rationalen Zahlen
konstruieren, indem wir f (n) fuĚr alle n â N als die n-te Zahl in dieser Folge definieren. Damit haben wir gezeigt, dass die Menge der positiven rationalen Zahlen
abzaĚhlbar ist. Die modifizierte Folge
0 1

â1 2

â2

1
2

â 21

1
3

â 13

3

â3 4

â4

3
2

â 32

liefert mit derselben Definition eine Bijektion zwischen N und Q.

2
3

â 32

...


Man kann zeigen, dass die Menge der reellen Zahlen R uĚberabzaĚhlbar ist. Da
man dazu etwas Hintergrundwissen uĚber reelle Zahlen benoĚtigt, beweisen wir hier
zunaĚchst ein verwandtes Resultat. Die Beweisidee ist fuĚr die reelen Zahlen jedoch
dieselbe.
Satz 1.4.4. Die Menge {0, 1}N aller Abbildungen von N nach {0, 1} (formal: {0, 1}N :=
{Ď | Ď : N â {0, 1}}) ist uĚberabzaĚhlbar.
Wir koĚnnen uns die Menge {0, 1}N als die Menge aller (unendlich langen)
Folgen von Nullen und Einsen vorstellen.
Beweis. Wir fuĚhren einen Widerspruchsbeweis. Wir nehmen an, die Menge {0, 1}N
sei abzaĚhlbar unendlich. Dann gibt es eine bijektive Abbildung f : N â {0, 1}N .
FuĚr n â N sei Ďn := f (n). Wir betrachten die folgende unendlich groĂe Tabelle:
Ď1 (1)
Ď2 (1)
Ď3 (1)
Ď4 (1)
..
.

Ď1 (2)
Ď2 (2)
Ď3 (2)
Ď4 (2)
..
.

Ď1 (3)
Ď2 (3)
Ď3 (3)
Ď4 (3)
..
.

Ď1 (4)
Ď2 (4)
Ď3 (4)
Ď4 (4)
..
.

ÂˇÂˇÂˇ
ÂˇÂˇÂˇ
ÂˇÂˇÂˇ
ÂˇÂˇÂˇ
...

Die i-te Zeile entspricht der Abbildung Ďi â {0, 1}N , also einer Folge von Nullen und Einsen. Da f bijektiv und damit insbesondere surjektiv ist, muss jede
moĚgliche Folge von Nullen und Einsen einer Zeile dieser Tabelle entsprechen. Betrachte die Abbildung Ď : N â {0, 1}, die definiert ist durch Ď(n) := 1 â Ďn (n)
fuĚr alle n â N. Anschaulich gesprochen haben wir die Folge von Nullen und Einsen definiert, die man erhaĚlt, wenn man entlang der Diagonale der Tabelle von
links oben nach rechts unten geht und dabei Nullen und Einsen miteinander vertauscht. Es bleibt zu zeigen, dass Ď 6= Ďk fuĚr alle k â N und damit Ď 6â f (N).
Das ist aber klar, da Ď(k) = 1 â Ďk (k) 6= Ďk (k).
Damit haben wir einen Widerspruch zu unserer urspruĚnglichen Annahme erzielt. Folglich ist die Menge {0, 1}N uĚberabzaĚhlbar.


20

Mathematik fuĚr Informatiker

M. Skutella

Das im Beweis verwendete Verfahren heiĂt Diagonalverfahren von Cantor. Es
findet auch im Rahmen der KomplexitaĚtstheorie Anwendung. Man verwendet es
dort um zu zeigen, dass es sogenannte nicht-entscheidbare Probleme gibt, also
Probleme, die nicht von Computern geloĚst werden koĚnnen.

1.5

Relationen

In diesem Abschnitt werden Relationen allgemein eingefuĚhrt. Es werden verschiedene Sichtweisen des Relationsbegriffs erlaĚutert und der Zusammenhang zu dem
bekannten Begriff einer Abbildung (Funktion) geklaĚrt. AĚhnlich wie Mengen und
Abbildungen gehoĚren Relationen zum Grundhandwerkszeug der modernen Mathematik (wie auch der Informatik). Zwar gibt es keine tief liegende Theorie uĚber
allgemeine Relationen, aber sie dienen zur Beschreibung und Formalisierung von
zahlreichen Problemfeldern und sind von daher allgegenwaĚrtig.

1.5.1

Grundbegriffe und Notationen

Informelle Definition. Eine (binaĚre) Relation auf einer Menge M bezieht
sich auf je zwei Elemente a, b â M (unter Beachtung der Reihenfolge). Es wird
festgelegt, ob a und b in Relation stehenâ oder nicht. Wie dieses festgelegt wird,
â
haĚngt von der Situation ab.
Verallgemeinerungen: Die Elemente a und b koĚnnen aus verschiedenen Mengen
M1 und M2 kommen; statt zwei Elemente kann eine Relation n Elemente fuĚr ein
festes n betrachten. Die folgenden einfachen Beispiele illustrieren das Konzept.
Beispiele (Relationen I).
(i) Die Gleichheitsrelation x = y auf einer beliebigen Menge M .
(ii) Die Teilbarkeitsrelation a | b ( a teilt bâ) auf der Menge Z.
â
(iii) Die Anordnung a â¤ b ( a ist kleiner oder gleich bâ) auf N, Z oder R.
â
(iv) Die Relation k ( parallelâ) auf der Menge G aller Geraden in der Ebene R2 :
â
g k h :ââ (g = h â¨ g âŠ h = â), fuĚr g, h â G.
(v) Die Relation ist Teilmenge vonâ auf der Potenzmenge P(M ) einer gegebeâ
nen Menge M . Notation: A â B fuĚr A, B â P(M ).
Wir sehen, dass es fuĚr uĚbliche Relationen Standardbezeichnungen gibt; das
Relationssymbol (z.B. =, |, â¤, k, â) steht dabei zwischen den in Frage stehenden Elementen (sogenannte Infix-Notation). Eine allgemeine Relation wuĚrden wir

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

21

etwa mit R bezeichnen und dann aRb schreiben, wenn a und b in Relation zueinander stehen. FuĚr jede Relation R auf einer Menge M koĚnnen wir die Menge
aller geordneten Paare aus in Relation stehenden Elementen betrachten:
R := {(x, y) â M Ă M | xRy} .
Aus dieser Menge von Paaren kann man die Relation in offensichtlicher Weise
zuruĚckgewinnen:
xRy ââ (x, y) â R .
Entsprechendes gilt natuĚrlich auch fuĚr eine Relation zwischen den Elementen von
zwei verschiedenen Mengen. Diese UĚberlegungen motivieren die uĚbliche mengentheoretische Definition einer Relation.
Definition 1.5.1 (Relation).
a) Eine binaĚre Relation R zwischen den Mengen M1 und M2 ist eine Teilmenge
des kartesischen Produktes M1 Ă M2 , also R â M1 Ă M2 . Im Fall M1 = M2 =:
M nennt man sie auch Relation in (oder auf ) M .
FuĚr (x, y) â R benutzt man die Sprechweise: x und y stehen in der Relatiâ
on Râ.
b) Eine n-aĚre oder n-stellige Relation zwischen n Mengen M1 , M2 , . . . , Mn ist
eine Teilmenge von M1 Ă M2 Ă Âˇ Âˇ Âˇ Ă Mn .
Die Infix-Notation benutzt man auch, wenn es kein spezielles Symbol fuĚr die
Relation (im Unterschied zur Paarmenge) gibt. Die Schreibweise ist dann also xR y statt (x, y) â R. FuĚr die Negation der Relation, also (x, y) 6â R, schreibt
man auch kurz xR
/ y. Wir geben im Folgenden noch einige Beispiele von Relationen in Mengennotation an.
Beispiel (Relationen II).
(i) M1 = M2 = R, R1 = {(x, y) â R2 | x2 = y}.
(ii) M1 = M2 = R, R2 = {(x, y) â R2 | x = y 2 }.
(iii) M1 := M beliebige Menge, M2 := P(M ) die Potenzmenge von M , R3 =
{(x, Y ) â M Ă P(M ) | x â Y }.
(iv) Die Elemente von R2 fassen wir wie uĚblich als Punkte der Ebene auf. Eine
ternaĚre (dreistellige) Relation R4 â R2 Ă R2 Ă R2 ist gegeben durch
R4 = {(P1 , P2 , P3 ) | P1 , P2 , P3 liegen auf einer Geraden} .
(v) M1 = M2 = M3 = Z, R5 = {(x, y, z) â Z3 | x â¤ y â¤ z}.

22

Mathematik fuĚr Informatiker

M. Skutella

Weiter oben haben wir den Begriff der Abbildung (Funktion) eingefuĚhrt ( einâ
deutige Zuordnungâ). Als mengentheoretisch praĚzise Definition gibt es den Graphen
Îf = {(x, f (x)) | x â X} â X Ă Y
einer Abbildung f : X â Y . Der Graph ist eine Teilmenge von X Ă Y , formal
also eine Relation zwischen X und Y . Jede Abbildung stellt also insbesondere
eine Relation dar. Wir fassen diese Beobachtung in der folgenden Bemerkung
zusammen.
Bemerkung. Jede Abbildung f : X â Y kann als Relation aufgefasst werden:
Jedes x â X steht mit seinem eindeutigen Bild f (x) und keinem weiteren Element
aus Y in Relation. Als Teilmenge von X Ă Y aufgefasst stimmt die Relation mit
dem Graphen der Abbildung uĚberein.

1.5.2

Verkettung und Inverse

Die folgende Definition der Verkettung zweier Relationen ist eine natuĚrliche Verallgemeinerung der Verkettung von Abbildungen.
Definition 1.5.2 (Verkettung von Relationen). Es seien M1 , M2 und M3 Mengen, R eine Relation zwischen M1 und M2 und S eine Relation zwischen M2
und M3 . Das Produkt oder die Komposition S âŚ R von R und S ist die wie folgt
definierte Relation zwischen M1 und M3 :
S âŚ R := {(x, z) â M1 Ă M3 | ây â M2 : xRy â§ ySz }.
Bemerkung. Man beachte besonders die Reihenfolge der Faktoren in S âŚ R.
Diese wird wegen des (formalen) Spezialfalles der Abbildungen so definiert (Verkettung x 7â g(f (x))). Die Infix-Notation xRy, ySz wuĚrde eher die Notation RâŚS
nahelegen.
Definition 1.5.3 (Inverse Relation). Es sei R eine Relation zwischen M1 und M2 .
Die zu R inverse Relation Râ1 â M2 Ă M1 ist dann wie folgt definiert:
Râ1 := {(y, x) â M2 Ă M1 | xRy} .
Beispiele.
(i) Die Inverse der Kleiner-oder-Gleich-Relation von Zahlen x â¤ y ist definitionsgemaĚĂ die GroĚĂer-oder-Gleich-Relation y âĽ x.
(ii) Die Inverse der Teilbarkeitsrelation a | b in Z ist die Vielfachen-Relation.
(iii) Die Inverse einer bijektiven Abbildung, aufgefasst als Relation, ist die bekannte Umkehrabbildung (inverse Abbildung); siehe Satz 1.3.11.

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

23

Bemerkung.
a) FuĚr eine beliebige Relation R gilt (Râ1 )â1 = R. Anders als bei bijektiven
Abbildungen ist aber R âŚ Râ1 in der Regel nicht die Gleichheitsrelation.
b) Unmittelbar aus der Definition der Komposition ergibt sich auch die folgende
Beobachtung: Es sei R eine Relation zwischen M1 und M2 und S eine Relation
zwischen M2 und M3 . Dann gilt
(S âŚ R)â1 = Râ1 âŚ S â1 .
FuĚr bijektive Abbildungen hatten wir das schon in Lemma 1.3.12 beobachtet.

1.5.3

AĚquivalenzrelationen

Eine Relation auf einer Menge M heiĂt AĚquivalenzrelation, wenn sie die charakteristischen Eigenschaften der Gleichheitsrelation besitzt. Nach der genauen
Definition und einigen einfachen Beispielen zeigen wir, dass jede beliebige AĚquivalenzrelation eine Partition von M liefert. Es gilt auch die Umkehrung: Zu einer
Partition von M kann man leicht eine Relation auf M definieren, die sich als
Aquivalenzrelation herausstellt.
Definition 1.5.4 (AĚquivalenzrelation). Es sei M eine nichtleere Menge und âź
eine binaĚre Relation auf M mit den folgenden Eigenschaften:
(i) FuĚr alle x â M gilt x âź x

(ReflexivitaĚt)

(ii) FuĚr alle x, y â M gilt: x âź y â y âź x

(Symmetrie)

(iii) FuĚr alle x, y, z â M gilt: (x âź y â§ y âź z) â x âź z

(TransitivitaĚt)

Dann heiĂt âź eine AĚquivalenzrelation. FuĚr x â M nennt man die Menge [x]âź :=
{y â M | x âź y} die AĚquivalenzklasse von x.
Bemerkung.
(i) Die in Definition 1.5.4 (ii) geforderte Symmetrie kann man alternativ auch
wie folgt definieren. Eine Relation R auf der Menge M ist symmetrisch,
falls R = Râ1 .
(ii) Aus Definition 1.5.4 (i) und (iii) folgt fuĚr eine AĚquivalenzrelation R auf
einer Menge M , dass R = R âŚ R.

24

Mathematik fuĚr Informatiker

M. Skutella

Beispiele.
(i) Es seien X und Y nichtleere Mengen und f : X â Y eine Abbildung. Dann
ist die (binaĚre) Relation âźf auf X mit
x âźf x0 :â f (x) = f (x0 )
eine AĚquivalenzrelation. Die AĚquivalenzklassen sind die Urbildmengen f â1 (y)
fuĚr y â f (X).
(ii) Eine AĚquivalenzrelation auf Z kann wie folgt definiert werden:
x âź y :â x â y gerade.
Die beiden verschiedenen AĚquivalenzklassen sind
[0]âź = {2k | k â Z} und [1]âź = {2k + 1 | k â Z} .
(iii) Es sei M := Z Ă N und âź die durch
(p, q) âź (p0 , q 0 ) :ââ p Âˇ q 0 = p0 Âˇ q
definierte Relation. Dann ist âź eine AĚquivalenzrelation. Diese AĚquivalenzrelation spielt bei der formalen Definition der rationalen Zahlen eine tragende
Rolle (siehe unten).
Satz 1.5.5.
a) Es sei âź eine AĚquivalenzrelation auf der Menge M . Dann gilt:
(a1) FuĚr x, y â M gilt: [x]âź 6= [y]âź â [x]âź âŠ [y]âź = â.
(a2) Es sei Z := {[x]âź | x â M } die Menge der AĚquivalenzklassen. Dann
ist Z eine Partition von M .
b) Ist M eine Menge und Z = {Zi | i â I} eine Partition von M , dann ist die
durch
x âź y :â x und y liegen in derselben Teilmenge Zi
definierte Relation âź auf M eine AĚquivalenzrelation, deren AĚquivalenzklassen
gerade die Zi sind.
Beweis. Zu (a1): Es sei [x]âź âŠ[y]âź 6= â. Wir muĚssen zeigen, dass dann [x]âź = [y]âź .
Es sei z â [x]âź âŠ [y]âź und u â [x]âź beliebig. Wegen Symmetrie ist y âź z âź x âź u
und daher wegen TransitivitaĚt y âź u, so dass u â [y]âź . Damit haben wir gezeigt,
dass [x]âź â [y]âź . Analog kann man zeigen, dass [y]âź â [x]âź und damit [x]âź = [y]âź .
Zu (a2): Wegen (a1) ist Z ein disjunktes Mengensystem. Aus der ReflexivitaĚt
von âź folgt, dass x â [x]âź fuĚr alle x â M . Daher ist Z eine Partition von M .
Zu (b): Man uĚberzeugt sich leicht davon, dass die so definierte Relation reflexiv, symmetrisch und transitiv ist.


Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

25

Die AĚquivalenzklassen einer AĚquivalenzrelation kann man als Elemente einer
neuen Menge (sogenannte Faktormenge oder Quotientenmenge) auffassen. Dieses ist ein wichtiges Prinzip zur Konstruktion neuer mathematischer Objekte aus
bekannten, das insbesondere bei algebraischen Strukturen genutzt wird. In diesem Zusammenhang interessiert man sich auch fuĚr sogenannte Vertretersysteme
(RepraĚsentantensysteme) einer Klasseneinteilung bzw. AĚquivalenzrelation.
Definition 1.5.6 (RepraĚsentantensystem). Es sei âź eine AĚquivalenzrelation auf
der Menge M und Z die Menge der AĚquivalenzklassen. Ist % : Z â M eine
Abbildung mit %([x]âź ) â [x]âź fuĚr alle x â M , dann heiĂt das Bild %(Z) RepraĚsentantensystem fuĚr âź.
Beispiel. Wir skizzieren kurz, wie die rationalen Zahlen Q aus den ganzen Zahlen Z konstruiertâ werden koĚnnen. Dazu betrachten wir zunaĚchst noch einmal
â
ein Beispiel von oben: Es sei M := Z Ă N und âź die durch

p0 
p
= 0
(p, q) âź (p0 , q 0 ) :ââ p Âˇ q 0 = p0 Âˇ q
ââ
q
q
definierte AĚquivalenzrelation.
0
FuĚr (p, q) â M erhaĚlt man durch KuĚrzen des Bruches pq zu pq0 das eindeutige
teilerfremde Zahlenpaar (p0 , q 0 ) â M mit (p, q) âź (p0 , q 0 ). Definiert man %([(p, q)]âź ) :=
(p0 , q 0 ) so erhaĚlt man eine bijektive Abbildung zwischen der Menge der AĚquivalenzklassen und den teilerfremden Zahlenpaaren in M . Letztere bilden also ein
RepraĚsentantensystem. Man hat damit insbesondere eine bijektive Abbildung
zwischen den AĚquivalenzklassen und den rationalen Zahlen Q definiert. Die rationalen Zahlen koĚnnen also mit den AĚquivalenzklassen identifiziert werden. Wir
werden diesen Zusammenhang im naĚchsten Kapitel weiter vertiefen.

1.5.4

Ordnungsrelationen

Definition 1.5.7 (Ordnungsrelation).
a) Eine Halbordnung (partielle Ordnung) auf einer Menge M ist eine Relation 
auf M mit
(i) FuĚr alle x â M gilt: x  x
(ii) FuĚr alle x, y â M gilt: (x  y â§ y  x) â x = y
(iii) FuĚr alle x, y, z â M gilt: (x  y â§ y  z) â x  z

(ReflexivitaĚt)
(Antisymmetrie)
(TransitivitaĚt)

Die Menge zusammen mit der Relation (M, ) wird ebenfalls als Halbordnung
bezeichnet, im Englischen poset (partially ordered set).
b) Eine totale Ordnung oder lineare Ordnung ist eine Halbordnung, in der je zwei
Elemente vergleichbar sind:
âx, y â M : x  y â¨ y  x .

26

Mathematik fuĚr Informatiker

M. Skutella

Wenn eine Halbordnung (totale Ordnung) (M, ) gegeben ist, sagt man auch
bequem, aber etwas unpraĚzise: Die Menge M ist partiell (linear) geordnet. Der
Begriff der Ordnungsrelationâ oder einfach Ordnungâ oder Anordnungâ wird
â
â
â
ebenfalls verwendet, ist aber nicht einheitlich definiert: Oft werden nur die Eigenschaften einer Halbordnung verlangt, anderswo ist eine Ordnung immer linear.
Auch die ReflexivitaĚt (die in gewissem Sinne unwesentlich ist, siehe unten) wird
nicht immer gefordert.
Beispiele.
(i) Die uĚbliche Anordnung, also die Kleiner-oder-Gleich-Relation x â¤ y auf N,
Z oder R ist eine Halbordnung, sogar eine lineare Ordnung.
(ii) Die Teilbarkeitsrelation a | b auf N ist eine Halbordnung.
(iii) Die Inklusions-Relation â ist eine Halbordnung auf der Potenzmenge P(M )
einer beliebigen Menge M .
Bemerkung. Wenn  eine Halbordnung auf M ist und wir
x  y :â y  x
definieren, dann ist auch (M, ) eine Halbordnung. Sie heiĂt die zu (M, ) duale
Halbordnung. (Man beachte, dass die hier definierte Relation  genau die inverse
Relation zur gegebenen Relation  im Sinn der allgemeinen Definition 1.5.3 ist.)
Bemerkung. FuĚr eine gegebene Halbordnung (M, ) ist die durch
x âş y :â x  y â§ x 6= y
definierte Relation âş ( strikte Ordnungâ) weiterhin antisymmetrisch und transiâ
tiv. Wenn umgekehrt eine antisymmetrische und transitive Relation âş gegeben
ist, dann ist die durch
x  y :â x âş y â¨ x = y
definierte Relation eine Halbordnung.
Halbordnungen lassen sich mit Hilfe von sogenannten Hasse-Diagrammen veranschaulichen. Dabei gilt x âş y, wenn eine Verbindung zwischen x und y besteht,
x aber tiefer als y liegt.
Beispiele.
(i) In Abbildung 1.1 ist das Hasse-Diagramm der Halbordnung (P({1, 2, 3}), â)
abgebildet.

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

27

{1, 2, 3}

{1, 2}

{1, 3}

{2, 3}

{1}

{2}

{3}

â
Abbildung 1.1: Das Hasse-Diagramm der Halbordnung (P({1, 2, 3}), â).
u.s.w.
8

12

18

20

27

28

u.s.w. (3 Primfaktoren)

4

6

9

10

14

15

u.s.w. (2 Primfaktoren)

2

3

5

7

11

13

u.s.w. (1 Primfaktor)

1
Abbildung 1.2: Das Hasse-Diagramm der Halbordnung (N, |).
(ii) Das Hasse-Diagramm der Halbordnung (N, â¤):
..
.
|
3
|
2
|
1
(iii) In Abbildung 1.2 ist das Hasse-Diagramm der Halbordnung (N, |) abgebildet.

28

Mathematik fuĚr Informatiker

M. Skutella

Definition 1.5.8. Es sei (M, ) eine Halbordnung und X Teilmenge von M .


minimales
a) Ein Element a â X heiĂt
Element in X, wenn fuĚr kein x â X
maximales


xâşa
gilt
.
xa


kleinstes
b) Ein Element a â X heiĂt
Element in X, wenn fuĚr alle x â X
groĚĂtes


ax
gilt
.
ax


untere
c) Ein Element b â M heiĂt
Schranke von X, wenn fuĚr alle x â X
obere


bx
gilt
.
bx




Infimum
groĚĂtes
d) Ein Element b â M heiĂt
von X, wenn b
EleSupremum
kleinstes


unteren
ment der Menge aller
Schranken von X ist.
oberen
Ob minimale, maximale, kleinste und groĚĂte Elemente in X existieren, haĚngt
von X und der Halbordnung ab. Genauso ist es bei Schranken und beim Supremum und Infimum.
Bemerkung.
(i) Ein kleinstes bzw. groĚĂtes Element einer Teilmenge X ist (erst recht) auch
minimal bzw. maximal in X.
(ii) Bei total geordneten Mengen fallen die Begriffe zusammen.
(iii) Ein kleinstes bzw. groĚĂtes Element von X ist auch Infimum bzw. Supremum
von X.
(iv) Infimum bzw. Supremum muĚssen nicht selbst in X liegen.
(v) Wenn ein Infimum bzw. Supremum in X liegt, dann ist es auch kleinstes
bzw. groĚĂtes Element von X.
Bemerkung. Eine Teilmenge X einer Halbordnung (M, ) kann hoĚchstens ein
kleinstes (groĚĂtes) Element und hoĚchstens ein Infimum (Supremum) besitzen.
Falls es existiert, spricht man von dem kleinsten (groĚĂten) Element, auch Minimum (Maximum) genannt, und von dem Infimum (Supremum) der Teilmenge X.
Bezeichnung
min X, max X, inf X, sup X .

Kapitel 1

F. Kahlhoff, H. M. MoĚller, R. Scharlau, M. Skutella

29

g

e

f

d

c

a
Abbildung 1.3: Hasse-Diagramm
ge {a, b, c, d, e, f, g}.

b
einer

Halbordnung

auf

der

Men-

Beispiel. Es sei auf M := {a, b, c, d, e, f, g} eine Halbordnung durch das in Abbildung 1.3 gegebene Hasse-Diagramm definiert.
â˘ Die Teilmenge X = {d, e, f, g} besitzt d als kleinstes (und damit auch als
minimales) Element.
â˘ In {e, f, g} sind e und f minimale Elemente, aber es gibt kein kleinstes
Element.
â˘ {e, f, g} hat a, b, c, d als untere Schranken, d ist Infimum (groĚĂte untere
Schranke).
â˘ {a, b, c} hat keine untere Schranke.

1.5.5

VerbaĚnde

Infimum und Supremum sind schon fuĚr zweielementige Teilmengen interessant.
Definition 1.5.9. Eine Halbordnung (M, ), in der fuĚr jede zweielementige Teilmenge {x, y} â M das Infimum und das Supremum existieren, heiĂt Verband.
Man schreibt dann
inf{x, y} := x â§ y (Englisch: meet),

sup{x, y} := x â¨ y (Englisch: join).

Bemerkung. Das Element s = x â§ y ist definitionsgemaĚĂ charakterisiert durch
die folgenden zwei Eigenschaften:

30

Mathematik fuĚr Informatiker

M. Skutella

(i) s â¤ x und s â¤ y (d.h. s ist untere Schranke von x und y).
(ii) Aus z â¤ x und z â¤ y folgt z â¤ s (d.h. s ist groĚĂte untere Schranke).
Dualisieren gibt die analoge Beschreibung fuĚr x â¨ y.
Beispiele.
(i) Jede total geordnete Menge (M, ) ist ein Verband mit x â§ y = min{x, y}
und x â¨ y = max{x, y}.
(ii) N mit der Teilbarkeitsrelation a | b als Halbordnung ist ein Verband. Dabei
ist a â§ b = ggT(a, b) (groĚĂter gemeinsamer Teiler) und a â¨ b = kgV(a, b)
(kleinstes gemeinsames Vielfaches).
(iii) Die Potenzmenge (P(M ), â) einer beliebigen Menge M ist ein Verband.
Hier gilt A â§ B = A âŠ B und A â¨ B = A âŞ B fuĚr A, B â M .
Bemerkung. In einem Verband besitzt jede endliche Teilmenge ein Infimum und
ein Supremum. Falls dieses sogar fuĚr beliebige Teilmengen gilt, spricht man von
einem vollstaĚndigen Verband.
Aus der Definition eines Verbandes laĚĂt sich eine Anzahl von weiteren Eigenschaften ableiten. So gilt beispielsweise der folgende Satz.
Satz 1.5.10. Es sei (M, ) ein Verband. Dann gelten fuĚr â§ und â¨ die Gesetze
a) x â§ x = x, x â¨ x = x
b) x â§ y = y â§ x, x â¨ y = y â¨ x
c) x â§ (y â§ z) = (x â§ y) â§ z, x â¨ (y â¨ z) = (x â¨ y) â¨ z

(Idempotenz)
(KommutativitaĚt)
(AssoziativitaĚt)

d) x â§ (x â¨ y) = x, x â¨ (x â§ y) = x

(Absorption)

e) x  y ââ x â§ y = x ââ x â¨ y = y

(Konsistenz)

Definition 1.5.11. Ein distributiver Verband ist ein Verband (M, ), in dem die
folgenden beiden Distributivgesetze gelten:
(i) âx, y, z â M : x â¨ (y â§ z) = (x â¨ y) â§ (x â¨ z)
(ii) âx, y, z â M : x â§ (y â¨ z) = (x â§ y) â¨ (x â§ z)
Bemerkung. Eine total geordnete Menge ist nicht nur ein Verband, sondern
sogar distributiv. Dieses ist aber nur als ein âtrivialer Fallâ von DistributivitaĚt
anzusehen. Jeder Potenzmengenverband ist distributiv.

Kapitel 2
Zahlbereiche
Das zweite Kapitel dieses Vorlesungsskriptes beruht teilweise auf Skripten von
Herrn Scharlau, dem ich hiermit ganz herzlich danke.

2.1
2.1.1

NatuĚrliche Zahlen, vollstaĚndige Induktion
und Rekursion
Axiome der natuĚrlichen Zahlen

Die natuĚrlichen Zahlen und ihre grundsaĚtzlichen Eigenschaften sind uns schon von
Kindheit an bekannt und wir haben einen vertrauten Umgang mit diesen Zahlen
erlernt. Eine saubereâ Beschreibung (und Definition) der Menge der natuĚrlichen
â
Zahlen N kann man wie folgt erhalten.
Definition 2.1.1 (Peano Axiome). Die Menge N der natuĚrlichen Zahlen wird
wie folgt definiert:
(i) 1 ist eine natuĚrliche Zahl.
(ii) Jede natuĚrliche Zahl n hat genau einen von 1 verschiedenen Nachfolger n+ ,
der eine natuĚrliche Zahl ist.
(iii) Verschiedene natuĚrliche Zahlen haben verschiedene Nachfolger.
(iv) Ist M â N mit 1 â M und der Eigenschaft, dass aus n â M auch n+ â M
folgt, so ist M = N.
Die Eigenschaften (i)â(iv) heiĂen Peano Axiome 1 . Sie stehen ganz am Anfang
der Theorie der natuĚrlichen Zahlen und bilden die Grundlage fuĚr alles Weitere.
1

Als Axiome werden im Allgemeinen die grundlegenden Definitionen der Mathematik bezeichnet, auf denen dann ganze TheoriegebaĚude aufgebaut werden. Das bedeutet, dass alle
bekannten Resultate aus diesen Axiomen herleitbar sind, die Axiome selbst jedoch nicht bewiesen oder gefolgert werden koĚnnen, jedoch als gegebene Grundsteine allgemein akzeptiert
sind.

31

32

Mathematik fuĚr Informatiker

M. Skutella

Mit dem in (ii) geforderten Nachfolger der natuĚrlichen Zahl n ist offenbar die
natuĚrliche Zahl n + 1 gemeint.

2.1.2

VollstaĚndige Induktion

Aus dem Axiom in Definition 2.1.1 (iv) kann man jetzt unmittelbar das Beweisprinzip der vollstaĚndigen Induktion ableiten.
Satz 2.1.2 (VollstaĚndige Induktion). FuĚr alle n â N sei A(n) eine Aussage uĚber
die natuĚrliche Zahl n. Dann gilt



A(1) â§ ân â N : A(n) â A(n + 1)
=â ân â N : A(n) .
In Worten bedeutet das: Ist die Aussage A(1) wahr ( Induktionsanfangâ) und
â
folgt fuĚr jedes n â N aus der Aussage A(n) die Aussage A(n + 1) ( Induktionsâ
schlussâ), dann ist die Aussage A(n) fuĚr alle n â N wahr.
Beweis. Wir nehmen an, dass A(1) wahr ist und fuĚr alle n â N gilt, dass aus A(n)
die Aussage A(n + 1) folgt. Es sei M := {n â N | A(n)}. Aus Definition 2.1.1 (iv)
folgt dann M = N und damit die Behauptung des Satzes.

Als erste Anwendung des Beweisprinzips der vollstaĚndigen Induktion beweisen
wir die folgende Aussage uĚber geometrische Summen.
Lemma 2.1.3 (Geometrische Summe). Es sei x â R \ {1}. Dann gilt fuĚr alle
nâN
x0 + x1 + x2 + Âˇ Âˇ Âˇ + xn =

xn+1 â 1
.
xâ1

(2.1)

Beweis. FuĚr n â N sei A(n) die Aussage (2.1). Induktionsanfang: A(1) ist wahr,
denn
xâ1
x2 â 1
x0 + x1 = 1 + x = (x + 1) Âˇ
=
.
xâ1
xâ1
Induktionsschluss: Es sei jetzt n â N beliebig aber fest gewaĚhlt. Ist A(n) wahr,
dann gilt
xn+1 â 1
xn+1 â 1
xâ1
+ xn+1 =
+ xn+1 Âˇ
xâ1
xâ1
xâ1
n+1
n+2
n+1
n+2
x
â1 x
âx
x
â1
=
+
=
.
xâ1
xâ1
xâ1

x0 +x1 + Âˇ Âˇ Âˇ + xn + xn+1 =

Damit haben wir also gezeigt, dass A(n + 1) wahr ist, falls A(n) wahr ist (Induktionsschluss). Die Behauptung des Lemmas folgt mit vollstaĚndiger Induktion
(Satz 2.1.2).


Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

33

Das Prinzip der vollstaĚndigen Induktion aus Satz 2.1.2 kann wie folgt verallgemeinert werden.
Korollar 2.1.4. Es sei n0 â Z. FuĚr alle ganzen Zahlen n âĽ n0 sei A(n) eine
Aussage uĚber die Zahl n. Dann gilt



A(n0 ) â§ ân âĽ n0 : A(n) â A(n + 1)
=â ân âĽ n0 : A(n) .
Wir geben im Folgenden eine weitere Verallgemeinerung des Induktionsprinzips an.
Satz 2.1.5. Es sei n0 â Z. FuĚr alle ganzen Zahlen n âĽ n0 sei A(n) eine Aussage
uĚber n. Dann gilt




A(n0 ) â§ ân âĽ n0 : ân0 â¤ k â¤ n : A(k) â A(n + 1)
=â ân âĽ n0 : A(n) .
In Worten bedeutet das: Ist die Aussage A(n0 ) wahr und folgt aus den Aussagen A(k) mit n0 â¤ k â¤ n die Aussage A(n + 1), dann ist die Aussage A(n) fuĚr
alle n âĽ n0 wahr.
Formal ist dieses Induktionsprinzip staĚrker als die Version aus Satz 2.1.2: Man
darf beim Induktionsschluss mehr voraussetzen. Das verallgemeinerte Induktionsprinzip ist beispielsweise beim Beweis des folgenden Lemmas von Nutzen.
Lemma 2.1.6. Ist n âĽ 2 eine natuĚrliche Zahl, so gibt es eine Primzahl p, die n
teilt.
Bevor wir das Lemma beweisen, reichen wir noch eine formale Definition des
Begriffs Primzahl nach.
Definition 2.1.7. Eine natuĚrliche Zahl n âĽ 2 heiĂt Primzahl, falls sie nur von 1
und sich selbst geteilt wird, d.h. wenn gilt:
âm â N : (m|n â m â {1, n}) .
Beweis von Lemma 2.1.6. Wir beweisen das Lemma mit Hilfe der verallgemeinerten vollstaĚndigen Induktion (siehe Satz 2.1.5). Induktionsanfang: Die Behauptung ist offenbar wahr fuĚr n = 2, da 2 eine Primzahl ist und sich selbst teilt.
Induktionsschluss: Es sei n âĽ 2 beliebig aber fest gewaĚhlt und die Behauptung
gelte fuĚr alle 2 â¤ k â¤ n. Ist n + 1 eine Primzahl, so gilt die Behauptung offensichtlich auch fuĚr n + 1. Ist n + 1 keine Primzahl, so besitzt n + 1 nach Definition
einen Teiler q mit 2 â¤ q < n + 1. Nach Induktionsvoraussetzung gibt es eine
Primzahl p mit p|q. Da die Teilerrelation transitiv ist, gilt dann p|(n + 1).


34

Mathematik fuĚr Informatiker

2.1.3

M. Skutella

Rekursive Abbildungen

Analog zum induktiven Beweis von Aussagen, die fuĚr alle n â N gelten, kann man
auch Abbildungen mit Definitionsbereich N induktivâ definieren. Hier spricht
â
man allerdings uĚblicherweise von einer rekursiven Definition. Wir erlaĚutern das
zunaĚchst anhand eines einfachen Beispiels.
Beispiel. Die FakultaĚtsfunktion g : N0 â N mit
g(n) := n! := 1 Âˇ 2 Âˇ 3 Âˇ . . . Âˇ (n â 1) Âˇ n
kann man praĚziser wie folgt rekursiv definieren:
(
1
fuĚr n = 0,
n! :=
n Âˇ (n â 1)! fuĚr n > 0.
Satz 2.1.8 (Rekursionssatz). Es sei n0 â Z, X := {n â Z | n âĽ n0 } und Y eine
beliebige, nicht leere Menge. Weiter sei f : X ĂY â Y eine Abbildung und s â Y .
Dann liefert die folgende rekursive Vorschrift eine eindeutige Abbildung g : X â
Y:
(i) g(n0 ) := s,
(ii) g(n + 1) := f (n, g(n)) fuĚr n âĽ n0 .
Beweis. Wir zeigen mit vollstaĚndiger Induktion, dass g(n) â Y fuĚr alle n âĽ n0
durch die gegebene Vorschrift eindeutig definiert ist. Induktionsanfang: g(n0 ) ist
offenbar durch (i) eindeutig definiert. Induktionsschluss: FuĚr ein beliebiges, fest
gewaĚhltes n âĽ 0 sei g(n) eindeutig definiert. Dann ist auch g(n + 1) durch (ii)
eindeutig definiert.

Beispiel.
(i) Es seien
Pn n0 â Z und ak â R fuĚr k âĽ n0 . FuĚr jedes n âĽ n0 definieren
wir k=n0 ak durch
n0
X
k=n0

ak := an0

und

n+1
X
k=n0

ak :=

n
X

ak + an+1

fuĚr n âĽ n0 .

k=n0

Damit koĚnnen wir in Zukunft die etwas unpraĚzise Notation
an0 + an0 +1 + Âˇ Âˇ Âˇ + an
vermeiden. FuĚr n < n0 definieren wir auĂerdem

Pn

k=n0

ak := 0.

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

35

(ii) Analog zu der Summendefinition in (i) koĚnnen wir auch beliebig lange Produkte definieren. Es sei
n0
Y
k=n0

ak := an0

und

n+1
Y

ak :=

k=n0

FuĚr n < n0 definieren wir auĂerdem

n
Y

ak Âˇ an+1

fuĚr n âĽ n0 .

k=n0

Qn

k=n0

ak := 1.

In Abschnitt 2.1.2 haben wir neben der Grundversion der vollstaĚndigen Induktion (siehe Satz 2.1.2) auch eine verallgemeinerte Version kennen gelernt (siehe
Satz 2.1.5). Ganz analog koĚnnen wir auch die rekursive Definition von Fuktionen
verallgemeinern. Wir verzichten hier auf eine formale Beschreibung und geben
stattdessen ein illustratives Beispiel an.
Beispiel (Fibonacci-Zahlen). Die Folge der Fibonacci 2 -Zahlen ist durch die folgenden Vorschriften rekursiv definiert:
F (0) := 0 ,
F (1) := 1 ,
F (n) := F (n â 1) + F (n â 2)

fuĚr n âĽ 2.

Die folgende explizite Beschreibung der Fibonacci-Zahlen kann mit Hilfe der
verallgemeinerten vollstaĚndigen Induktion (Satz 2.1.5) bewiesen werden.
Lemma 2.1.9. FuĚr n â N0 ist die n-te Fibonacci-Zahl F (n) wie folgt gegeben:
â
â
1
+
1
5
5
1
â
mit a :=
und b :=
.
F (n) = â Âˇ (an â bn )
2
2
5
Wir lassen den Beweis des Lemmas als UĚbungsaufgabe.

2.2

Gruppen, Ringe, KoĚrper

Wir studieren in diesem Abschnitt Mengen mit bestimmten VerknuĚpfungen, die
interessante algebraische Strukturen liefern. Das Studium dieser Strukturen ist
hauptsaĚchlich durch die uns bereits bekannten Zahlbereiche der ganzen Zahlen,
der rationalen Zahlen und der reellen Zahlen motiviert.

2.2.1

Halbgruppen, Monoide, Gruppen

Wir definieren zunaĚchst den Begriff einer VerknuĚpfung auf einer Menge. Man
kann dabei beispielsweise an Rechenoperationenâ wie Addition, Subtraktion,
â
Multiplikation und Division denken.
2

Leonardo di Pisa, genannt Fibonacciâ (ca. 1170â1250).
â

36

Mathematik fuĚr Informatiker

M. Skutella

Definition 2.2.1 (VerknuĚpfungen). Es sei M eine Menge. Eine VerknuĚpfung âŚ
auf M ist eine Abbildung
âŚ:M ĂM âM ,

(x, y) 7â x âŚ y .

Die VerknuĚpfung heiĂt:
â˘ kommutativ, falls x âŚ y = y âŚ x fuĚr alle x, y â M ;
â˘ assoziativ, falls (x âŚ y) âŚ z = x âŚ (y âŚ z) fuĚr alle x, y, z â M .
Mit Hilfe des Begriffs der VerknuĚpfung koĚnnen wir jetzt einige einfache und
grundlegende algebraische Strukturen definieren.
Definition 2.2.2 (Halbgruppen, Monoide, Gruppen).
a) Eine Menge H zusammen mit einer assoziativen VerknuĚpfung âŚ auf H heiĂt
Halbruppe (H, âŚ).
b) Eine Halbgruppe (M, âŚ) heiĂt Monoid, falls es ein e â M gibt mit
eâŚx = xâŚe = x

fuĚr alle x â M .

In diesem Fall heiĂt e neutrales Element oder Einselement des Monoids.
c) Ein Monoid (G, âŚ), in dem zu jedem x â G ein y â G existiert mit
xâŚy = yâŚx = e ,
heiĂt Gruppe. Zu gegebenem x ist das Element y dann eindeutig und heiĂt
zu x inverses Element, in Zeichen xâ1 := y.
d) Eine Gruppe (G, âŚ) mit kommutativer VerknuĚpfung âŚ heiĂt kommutative oder
abelsche 3 Gruppe.
Beispiele.
(i) Es sei X eine beliebige Menge und M die Menge der Abbildungen von X
nach X. Die in Definition 1.3.7 eingefuĚhrte Komposition âŚ von Abbildungen
definiert eine assoziative VerknuĚpfung (siehe Lemma 1.3.9) auf der Menge M . Damit ist also (M, âŚ) eine Halbgruppe und sogar ein Monoid, da die
identische Abbildung idX neutrales Element ist. Ist M 0 die Teilmenge der
bijektiven Abbildungen, so ist (M 0 , âŚ) eine Gruppe (siehe Satz 1.3.11). Da
die Komposition von Abbildungen jedoch im Allgemeinen nicht kommutativ
ist, handelt es sich nicht um eine abelsche Gruppe.
3

Niels Henrik Abel (1802â1829).

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

37

(ii) Die Addition + ist eine kommutative und assoziative VerknuĚpfung auf N0 , Z,
Q und R. Die Zahl 0 ist das neutrale Element. Damit ist (N0 , +) ein Monoid. AuĂerdem sind (Z, +), (Q, +) und (R, +) kommutative Gruppen: Das
inverse Element zu x ist âx.
(iii) Die Multiplikation Âˇ ist eine kommutative und assoziative VerknuĚpfung
auf N, Z, Q und R. Die Zahl 1 ist das neutrale Element. Damit sind (N, Âˇ),
(Z, Âˇ), (Q, Âˇ) und (R, Âˇ) Monoide. AuĂerdem sind (Q \ {0}, Âˇ) und (R \ {0}, Âˇ)
kommutative Gruppen: Das inverse Element zu x 6= 0 ist 1/x.
(iv) Die Subtraktion und die Division sind VerknuĚpfungen auf Q und R. Beide
VerknuĚpfungen sind weder kommutativ noch assoziativ. Man beachte, dass
die Subtraktion keine VerknuĚpfung auf N definiert und die Division weder
auf N noch auf Z eine VerknuĚpfung definiert.
Lemma 2.2.3 (Eindeutigkeit des neutralen Elements). Ein Monoid (M, âŚ) hat
genau ein neutrales Element.
Beweis. Es seien e, f â M neutrale Elemente. Dann gilt
e = eâŚf = f .

Lemma 2.2.4 (Eindeutigkeit des Inversen). Ist (G, âŚ) eine Gruppe, dann ist das
Inverse Element xâ1 zu x â G eindeutig bestimmt.
Beweis. Es sei x â G und y, z â G seien inverse Elemente zu x. Dann gilt:
y = y âŚ e = y âŚ (x âŚ z) = (y âŚ x) âŚ z = e âŚ z = z .

Aus dem Lemma folgt insbesondere, dass das neutrale Element e â G zu sich
selbst invers ist, d.h. eâ1 = e.
Lemma 2.2.5. Es sei (G, âŚ) eine Gruppe und x, y â G. Dann gilt
(x âŚ y)â1 = y â1 âŚ xâ1 .
Beweis. Es gilt

(x âŚ y) âŚ (y â1 âŚ xâ1 ) = x âŚ (y âŚ y â1 ) âŚ xâ1
= (x âŚ e) âŚ xâ1 = x âŚ xâ1 = e
und

(y â1 âŚ xâ1 ) âŚ (x âŚ y) = y â1 âŚ (xâ1 âŚ x) âŚ y
= (y â1 âŚ e) âŚ y = y â1 âŚ y = e .
Da das inverse Element nach Lemma 2.2.4 eindeutig ist, folgt daraus die Behauptung.


38

Mathematik fuĚr Informatiker

M. Skutella

Eine Teilmenge einer Gruppe, die selbst wieder eine Gruppe ist, nennt man
Untergruppe:
Definition 2.2.6 (Untergruppen). Es sei (G, âŚ) eine Gruppe mit neutralem Element e und H â G. Dann heiĂt (H, âŚ|HĂH ) Untergruppe von (G, âŚ), falls gilt:
(i) e â H,
(ii) x âŚ y â H fuĚr alle x, y â H,
(iii) xâ1 â H fuĚr alle x â H.
Lemma 2.2.7. Eine Untergruppe einer Gruppe ist selbst eine Gruppe.
Beispiele.
(i) Die Gruppe (Z, +) ist eine Untergruppe der Gruppe (R, +).
(ii) Die Gruppe ({1, â1}, Âˇ) ist eine Untergruppe der Gruppe (R \ {0}, Âˇ).
(iii) Die Gruppe (2Z, +) ist eine Untergruppe der Gruppe (Z, +).

2.2.2

Ringe

Die Betrachtung der ganzen Zahlen Z mit den beiden VerknuĚpfungen Addition
und Multiplikation motiviert die folgende Definition.
Definition 2.2.8 (Ringe). Es sei R eine Menge mit zwei VerknuĚpfungen + (Addition) und Âˇ (Multiplikation), so dass gilt:
(i) (R, +) ist eine kommutative Gruppe mit neutralem Element (Nullelement) 0.
(ii) (R, Âˇ) ist eine Halbgruppe.
(iii) FuĚr alle x, y, z â R gilt
x Âˇ (y + z) = x Âˇ y + x Âˇ z .

(DistributivitaĚt)

Dann heiĂt (R, +, Âˇ) ein Ring. Der Ring (R, +, Âˇ) heiĂt Ring mit Eins, falls (R, Âˇ)
ein Monoid ist, dessen neutrales Element 1 (Einselement) ungleich dem neutralen
Element 0 (Nullelement) der Addition ist. Der Ring (R, +, Âˇ) heiĂt kommutativ,
falls die Multiplikation kommutativ ist.
Beispiel.
(i) (Z, +, Âˇ) ist ein kommutativer Ring mit Eins.
(ii) (2Z, +, Âˇ) ist ein kommutativer Ring (aber ohne Eins), wobei 2Z := {2z |
z â Z} ist.

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

39

(iii) Wir definieren die folgende Addition und Multiplikation auf der Menge
{0, 1, 2, 3, 4, 5}:
+
0
1
2
3
4
5

0
0
1
2
3
4
5

1
1
2
3
4
5
0

2
2
3
4
5
0
1

3
3
4
5
0
1
2

4
4
5
0
1
2
3

Âˇ
0
1
2
3
4
5

5
5
0
1
2
3
4

0
0
0
0
0
0
0

1
0
1
2
3
4
5

2
0
2
4
0
2
4

3
0
3
0
3
0
3

4
0
4
2
0
4
2

5
0
5
4
3
2
1

Dann ist ({0, 1, 2, 3, 4, 5}, +, Âˇ) ein kommutativer Ring mit Eins.
(iv) Es sei X eine beliebige Menge und M := RX die Menge der Abbildungen
von X nach R. Wir definieren eine Addition â und eine Multiplikation
auf M . FuĚr zwei Abbildungen f, g â M sind die Summe f â g â M und
das Produkt f g â M wie folgt definiert:
(f â g)(x) := f (x) + g(x)

und

(f

g)(x) := f (x) Âˇ g(x)

fuĚr alle x â R. Dann ist (M, â, ) ein kommutativer Ring mit Eins.
(v) Als weiteres wichtiges Beispiel eines nichtkommutativen Rings werden wir
in der Linearen Algebra den Ring der n Ă n-Matrizen uĚber R kennen lernen.
Lemma 2.2.9. Ist (R, +, Âˇ) ein Ring mit Nullelement 0, so gilt
0Âˇx = xÂˇ0 = 0

fuĚr alle x â R.

Beweis. Es gilt
0 Âˇ x = (0 + 0) Âˇ x = 0 Âˇ x + 0 Âˇ x

(2.2)

Wir bezeichnen mit â(0 Âˇ x) das zu 0 Âˇ x inverse Element bezuĚglich der Addition,
d.h. (0 Âˇ x) + (â(0 Âˇ x)) = 0. Dann gilt
0Âˇx =
=
=
=
=

0 Âˇ x + 0 = 0 Âˇ x + (0 Âˇ x + (â(0 Âˇ x)))
(0 Âˇ x + 0 Âˇ x) + (â(0 Âˇ x))
(0 + 0) Âˇ x + (â(0 Âˇ x))
0 Âˇ x + (â(0 Âˇ x))
0 .

Analog zeigt man, dass x Âˇ 0 = 0 gilt.



40

Mathematik fuĚr Informatiker

M. Skutella

Analog wie bei Gruppen kann man auch bei Ringen Teilmengen betrachten,
die selbst wieder Ringe sind.
Definition 2.2.10 (Unterringe). Es sei (R, +, Âˇ) ein Ring und S â R. Dann
heiĂt (S, +|SĂS , Âˇ|SĂS ) Unterring von (R, +, Âˇ), falls gilt:
(i) (S, +|SĂS ) ist Untergruppe von (R, +),
(ii) x Âˇ y â S fuĚr alle x, y â S.
Lemma 2.2.11. Ein Unterring eines Rings ist selbst ein Ring.
Beispiel. (2Z, +, Âˇ) ist ein Unterring des Rings (Z, +, Âˇ).
Polynomringe
Ein wichtiger Spezialfall von Ringen sind Polynomringe, die von der Menge aller
Polynome mit Koeffizienten aus einem Ring R gebildet werden. Der Einfachheit
halber kann man sich im Folgenden immer die reellen Zahlen als zugrundeliegenden Ring R vorstellen. In diesem Fall betrachtet man also die bereits aus der
Schule bekannten Polynome mit Koeffizienten aus R.
Es sei (R, +, Âˇ) ein kommutativer Ring mit Eins und X eine Unbestimmte.
Dann nennen wir einen Ausdruck der Form
a0 X 0 + a1 X 1 + Âˇ Âˇ Âˇ + an X n

mit n â N0 und a0 , . . . , an â R

Polynom uĚber R. Der Grad eines Polynoms P = a0 X 0 + Âˇ Âˇ Âˇ + an X n ist wie folgt
definiert:
(
â1
falls a0 = Âˇ Âˇ Âˇ = an = 0,
grad(P ) :=
max{i | ai 6= 0} sonst.
Zwei Polynome
a0 X 0 + a1 X 1 + Âˇ Âˇ Âˇ + an X n

b0 X 0 + b1 X 1 + Âˇ Âˇ Âˇ + bm X m

und

mit m â¤ n sind nach Definition gleich, falls ai = bi fuĚr alle 0 â¤ i â¤ m und ai = 0
fuĚr alle m+1 â¤ i â¤ n. Die Menge aller Polynome uĚber R bezeichnen wir mit R[X].
Wir definieren auf R[X] die beiden folgenden VerknuĚpfungen:
â :R[X] Ă R[X] â R[X] ,
:R[X] Ă R[X] â R[X] ,

n
X
i=0
n
X
i=0

i

ai X ,
ai X i ,

n
X
i=0
m
X
i=0

bi X

i



7â


bi X i â
7

n
X

(ai + bi )X i ,

i=0
n+m
i
X X
i=0

j=0


aj Âˇ biâj X i .

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

41

(Man beachte, dass es genuĚgt, die Summe zweier Polynome fuĚr den Fall n = m zu
definieren. Ist naĚmlich beispielsweise m < n, so schreiben wir statt b0 X 0 + Âˇ Âˇ Âˇ +
bm X m einfach b0 X 0 +Âˇ Âˇ Âˇ+bm X m +0X m+1 +Âˇ Âˇ Âˇ+0X n .) Dann ist (R[X], â, ) ein
kommutativer Ring mit Eins. Das neutrale Element der Addition (Nullelement)
ist das Nullpolynom 0X 0 . Das neutrale Element der Multiplikation (Einselement)
ist 1X 0 .
Schreibweisen. Statt a0 X 0 + a1 X 1 + a2 X 2 + Âˇ Âˇ Âˇ + an X n schreibt man auch
einfach a0 + a1 X + a2 X 2 + Âˇ Âˇ Âˇ + an X n . An Stelle von 1X n kann man auch nur X n
schreiben. Terme der Form 0X k kann man auch einfach weglassen, also beispielsweise 3 + 4X 3 statt 3 + 0X + 0X 2 + 4X 3 .
Beispiel. Wir betrachten den Polynomring Z[X]. Die Summe der beiden Polynome 3 â 2X + 4X 2 und â1 + 3X + 3X 2 ist das Polynom 2 + X + 7X 2 . Das
Produkt der beiden Polynome ist â3 + 11X â X 2 + 6X 3 + 12X 4 . Wir stellen fest,
dass der Grad des Produkts zweier Polynome gleich der Summe der Grade der
Polynome ist.

2.2.3

KoĚrper

KoĚrper sind spezielle Ringe, die die Eigenschaften besitzen, die wir beispielsweise
von den reellen oder rationalen Zahlen kennen.
Definition 2.2.12 (KoĚrper). Ein kommutativer Ring mit Eins (K, +, Âˇ), in dem
jedes Element x 6= 0 ein multiplikatives Inverses hat, heiĂt KoĚrper.
Beispiele.
(i) (Q, +, Âˇ) und (R, +, Âˇ) sind KoĚrper.
(ii) Wir definieren die folgende Addition und Multiplikation auf der Menge {0, 1}:
+ 0 1
0 0 1
1 1 0

Âˇ 0 1
0 0 0
1 0 1

Dann ist ({0, 1}, +, Âˇ) ein (endlicher) KoĚrper mit zwei Elementen.
(iii) Wir definieren die folgende
{0, 1, 2}:
+ 0
0 0
1 1
2 2

Addition und Multiplikation auf der Menge
1
1
2
0

2
2
0
1

Âˇ
0
1
2

0
0
0
0

1
0
1
2

2
0
2
1

Dann ist ({0, 1, 2}, +, Âˇ) ein (endlicher) KoĚrper mit drei Elementen.

42

Mathematik fuĚr Informatiker

(iv) Wir definieren die folgende
{0, 1, a, b}:
+ 0 1
0 0 1
1 1 0
a a b
b b a

M. Skutella

Addition und Multiplikation auf der Menge
a
a
b
0
1

b
b
a
1
0

Âˇ
0
1
a
b

0
0
0
0
0

1
0
1
a
b

a
0
a
b
1

b
0
b
1
a

Dann ist ({0, 1, a, b}, +, Âˇ) ein (endlicher) KoĚrper mit vier Elementen.
Bemerkung. Die Folge von Beispielen oben soll nicht suggerieren, dass es zu
jedem q âĽ 2 einen KoĚrper mit q Elementen gibt. Man kann zeigen, dass es genau
dann einen KoĚrper mit q Elementen gibt, wenn q eine Primzahlpotenz ist, d.h.
wenn q = pm fuĚr eine Primzahl p und ein m â N. Wir werden spaĚter noch naĚher
auf diesen Sachverhalt eingehen.
Wir geben einige weitere Beispiele von KoĚrpern an.
Beispiele.
(i) Es sei K := Q Ă Q mit den beiden VerknuĚpfungen
â :K Ă K â K ,
:K Ă K â K ,

((a, b), (a0 , b0 )) 7â (a + a0 , b + b0 ) ,
((a, b), (a0 , b0 )) 7â (a Âˇ a0 + 2b Âˇ b0 , a Âˇ b0 + a0 Âˇ b) .

Dann
â ist (K, â, ) ein KoĚrper. Man bezeichnet diesen KoĚrper auch mit
Q[ 2] (lies: Q adjungiert
Wurzel 2â), da man das Element (a, b) â K mit
â
â
der reellen Zahl a + b 2 identifizieren kann.
(ii) In Fortsetzung des Beispiels nach Definition 1.5.6 in Kapitel 1 definieren
wir die folgenden beiden VerknuĚpfungen auf der dort betrachteten Menge
der AĚquivalenzklassen Z:
â :Z Ă Z â Z ,
:Z Ă Z â Z ,

([p, q]âź , [p0 , q 0 ]âź ) 7â [p Âˇ q 0 + p0 Âˇ q, q Âˇ q 0 ]âź ,
([p, q]âź , [p0 , q 0 ]âź ) 7â [p Âˇ p0 , q Âˇ q 0 ]âź .

Dann ist (Z, â, ) ein KoĚrper. Damit hat man den KoĚrper der rationalen
Zahlen Q formal definiert, indem man [p, q]âź mit der rationalen Zahl pq
identifiziert.

2.2.4

Homomorphismen

Wir betrachten in diesem Abschnitt sogenannte strukturerhaltende Abbildungen
auf Gruppen und Ringen. Das sind Abbildungen, die die VerknuĚpfungen respektieren. Wir beginnen zunaĚchst mit der Definition von Gruppenhomomorphismen.

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

43

Definition 2.2.13 (Gruppenhomomorphismen). Sind (G, âŚ) und (G0 , â˘) Gruppen und Ď : G â G0 eine Abbildung, dann heiĂt Ď Gruppenhomomorphismus,
falls
Ď(x âŚ y) = Ď(x) â˘ Ď(y)
fuĚr alle x, y â G.
Beispiele.
(i) Die Abbildung Ď : Z â 2Z mit Ď(x) := â2 Âˇ x ist ein Gruppenhomomorphismus zwischen den Gruppen (Z, +) und (2Z, +). Dies folgt aus dem
Distributivgesetz
(â2) Âˇ (x + y) = (â2) Âˇ x + (â2) Âˇ y .
(ii) Die Abbildung Ď : R â R \ {0} mit Ď(x) := 2x ist ein Gruppenhomomorphismus zwischen der Gruppe (R, +) und der Gruppe (R \ {0}, Âˇ). Das folgt
aus der Potenzrechenregel
2x+y = 2x Âˇ 2y

fuĚr x, y â R.

Lemma 2.2.14. Sind (G, âŚ) und (G0 , â˘) Gruppen mit neutralen Elementen e â G
und f â G0 und ist Ď : G â G0 ein Gruppenhomomorphismus, dann gilt Ď(e) = f
und Ď(xâ1 ) = Ď(x)â1 fuĚr alle x â G.
Beweis. FuĚr das neutrale Element e â G gilt
Ď(e) = Ď(e) â˘ f = Ď(e) â˘ (Ď(e) â˘ Ď(e)â1 ) = (Ď(e) â˘ Ď(e)) â˘ Ď(e)â1
= Ď(e âŚ e) â˘ Ď(e)â1 = Ď(e) â˘ Ď(e)â1 = f .
Es sei nun x â G beliebig. Dann gilt
Ď(xâ1 ) = Ď(xâ1 ) â˘ f = Ď(xâ1 ) â˘ (Ď(x) â˘ Ď(x)â1 ) = (Ď(xâ1 ) â˘ Ď(x)) â˘ Ď(x)â1
= Ď(xâ1 âŚ x) â˘ Ď(x)â1 = Ď(e) â˘ Ď(x)â1 = f â˘ Ď(x)â1 = Ď(x)â1 .

Lemma 2.2.15. Sind (G, âŚ) und (G0 , â˘) Gruppen mit neutralen Elementen e â G
und f â G0 und ist Ď : G â G0 ein Gruppenhomomorphismus, dann bilden die
Elemente in Kern(Ď) := {x â G | Ď(x) = f } â G (der Kern von Ď) eine
Untergruppe von G und die Elemente in Bild(Ď) := Ď(G) â G0 (das Bild von Ď)
eine Untergruppe von G0 .
Beweis. Wir beweisen, dass die Elemente in Kern(Ď) eine Untergruppe von G
bilden. Dazu uĚberpruĚfen wir die in Definition 2.2.6 geforderten Eigenschaften.
Eigenschaft (i) gilt, da nach Lemma 2.2.14 Ď(e) = f . Um Eigenschaft (ii) zu
uĚberpruĚfen, betrachten wir x, y â Kern(Ď). Dann gilt
Ď(x âŚ y) = Ď(x) â˘ Ď(y) = f â˘ f = f ,

44

Mathematik fuĚr Informatiker

M. Skutella

so dass also x âŚ y â Kern(Ď). Eigenschaft (iii) ist schlieĂlich erfuĚllt, da fuĚr x â
Kern(Ď) gilt, dass Ď(xâ1 ) = Ď(x)â1 = f â1 = f .
Den Beweis des zweiten Teils des Lemmas lassen wir als UĚbung.

Wir verallgemeinern als naĚchstes den Begriff des Homomorphismus auf Ringe.
Definition 2.2.16 (Ringhomomorphismen). Sind (R, +, Âˇ) und (R0 , â, ) Ringe
und Ď : R â R0 eine Abbildung, dann heiĂt Ď Ringhomomorphismus, falls
Ď(x + y) = Ď(x) â Ď(y)

und

Ď(x Âˇ y) = Ď(x)

Ď(y)

fuĚr alle x, y â R.
Beispiele.
(i) Die Abbildung Ď : 2Z â Z mit Ď(z) = z ist ein Ringhomomorphismus.
(ii) Es sei z â Z eine ganze Zahl. Dann ist die durch
n
X

ai X i 7â

i=1

n
X

ai z i

i=1

definierte Abbildung von Z[X] nach Z ein Ringhomomorphismus. Wir sprechen hier auch von dem Einsetzungshomomorphismus, da die Zahl z in ein
Polynom eingesetztâ wird.
â
Im Zusammenhang mit Homomorphismen (auf Gruppen oder auf Ringen)
verwendet man auch die folgenden Begriffe:
Definition 2.2.17 (Monomorphismus, Epimorphismus, Isomorphismus).
(i) Ein injektiver Homomorphismus heiĂt Monomorphismus.
(ii) Ein surjektiver Homomorphismus heiĂt Epimorphismus.
(iii) Ein bijektiver Homomorphismus heiĂt Isomorphismus.

2.3

Die komplexen Zahlen

Die komplexen Zahlen sind unverzichtbar fuĚr nahezu jede Art von hoĚherer Mathematik, z.B. fuĚr die in der Physik, der Elektrotechnik oder der Informationstechnik
verwendete Mathematik. Im systematischen Aufbau der Mathematik gehoĚren die
komplexen Zahlen zum einen in die Analysis, denn viele bekannte Funktionen sind
in natuĚrlicher Weise auf der Menge C der komplexen Zahlen definiert. Auch wenn
man vorrangig an reellen Funktionen interessiert ist, werden die Eigenschaften oft
transparenter, wenn man sie (auch) als komplexe Funktionen betrachtet. Auf der

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

45

anderen Seite gehoĚren die komplexen Zahlen genauso auch in die Algebra und
Zahlentheorie: Sie stellen eine natuĚrliche Erweiterung der uĚblichen Zahlbereiche
dar, auf die man beim LoĚsen algebraischer Gleichungen gefuĚhrt wird. Aufgrund
ihrer generellen Bedeutung tauchen die komplexen Zahlen natuĚrlich auch in der
Informatik im Zusammenhang mit diversen konkreten algorithmischen Problemen auf.
Bevor wir eine formale Konstruktion/Definition der komplexen Zahlen als
KoĚrper angeben, beschreiben wir sie zunaĚchst als eine Erweiterung der reellen
Zahlen:
â˘ GegenuĚber den reellen Zahlen R sind die komplexen Zahlen C dadurch
ausgezeichnet, dass es ein spezielles Element i â C gibt mit der Eigenschaft i2 = i Âˇ i = â1. Die Zahl i heiĂt auch imaginaĚre Zahl.
â˘ Damit koĚnnen wir die komplexen Zahlen jetzt wie folgt beschreiben: C =
{a + b Âˇ i | a, b â R}, wobei
a + b Âˇ i = a0 + b0 Âˇ i ââ (a = a0 â§ b = b0 ) .
â˘ FuĚr eine komplexe Zahl z = a + b Âˇ i = a + bi nennen wir Re(z) := a den
Realteil und Im(z) := b den ImaginaĚrteil von z.
Mit Hilfe dieser informellen Beschreibung koĚnnen wir jetzt schon mit komplexen
Zahlen rechnen:
Beispiel. 2 + 3i und 5 â 2i := 5 + (â2)i sind komplexe Zahlen. Die Summe und
das Produkt dieser Zahlen koĚnnen wie folgt berechnet werden:
(2 + 3i) + (5 â 2i) = (2 + 5) + (3i + (â2)i)
= (2 + 5) + (3 + (â2))i
=7+i
(2 + 3i) Âˇ (5 â 2i)

= 2 Âˇ 5 + 2 Âˇ (â2) Âˇ i + 3 Âˇ i Âˇ 5 + 3 Âˇ i Âˇ (â2) Âˇ i
= 2 Âˇ 5 + 2 Âˇ (â2) Âˇ i + 3 Âˇ 5 Âˇ i + 3 Âˇ (â2) Âˇ i Âˇ i
= 10 + (â6)(â1) + (â4 + 15) Âˇ i
= (10 + 6) + (15 â 4)i
= 16 + 11i

Wir geben jetzt eine formale Definition der komplexen Zahlen mit Addition
und Multiplikation an.
Definition 2.3.1 (Komplexe Zahlen). Es sei C := R Ă R = {(a, b) | a, b â R}.
Wir definieren auf der Menge C die VerknuĚpfungen â und wie folgt:
â :C Ă C â C ,
:C Ă C â C ,

((a, b), (a0 , b0 )) 7â (a + a0 , b + b0 ) ,
((a, b), (a0 , b0 )) 7â (a Âˇ a0 â b Âˇ b0 , a Âˇ b0 + b Âˇ a0 ) .

46

Mathematik fuĚr Informatiker

M. Skutella

Satz 2.3.2 (KoĚrper der komplexen Zahlen). Die komplexen Zahlen bilden einen
KoĚrper (C, â, ).
Beweisskizze. Es ist eine FleiĂarbeit, sich davon zu uĚberzeugen, dass die VerknuĚpfungen â und das Assoziativ-, Kommutativ- und Distributivgesetz erfuĚllen.
Das neutrale Element der Addition (Nullelement) ist (0, 0) und das inverse Element zu (a, b) bezuĚglich der Addition ist (âa, âb). Das neutrale Element der
Multiplikation (Einselement) ist (1, 0) und das inverse Element zu (a, b) 6= (0, 0)
(a, b)â1 =



a
âb 
,
.
a2 + b2 a2 + b2

Damit ist (C, â, ) also ein KoĚrper.



Anstelle der Schreibweise (a, b) fuĚr eine komplexe Zahl verwendet man normalerweise die bereits oben eingefuĚhrte Variante a + bi. Diese Schreibweise verdeutlicht, dass die komplexen Zahlen als Erweiterung der reellen Zahlen aufgefasst
werden koĚnnen. Mit anderen Worten werden die reellen Zahlen als Teilmenge
der komplexen Zahlen aufgefasst, indem man die reelle Zahl a mit der komplexen Zahl a + 0i identifiziert. Diese Interpretation wird durch den folgenden Satz
untermauert:
Satz 2.3.3. Die Abbildung Ď : R â C mit Ď(a) := a + 0i ist ein injektiver
Ringhomomorphismus (Ringmonomorphismus).
Beweis. Nach Definition gilt fuĚr a, a0 â R:
Ď(a + a0 ) = (a + a0 ) + 0i = (a + 0i) â (a0 + 0i) = Ď(a) â Ď(a0 )
und
Ď(a Âˇ a0 ) = (a Âˇ a0 ) + 0i = (a + 0i)

(a0 + 0i) = Ď(a)

Ď(a0 ) .

Folglich ist Ď ein Homomorphismus. AuĂerdem ist Ď injektiv, da aus a + 0i =
Ď(a) = Ď(a0 ) = a0 + 0i sofort a = a0 folgt.

Man verwendet daher fuĚr die Addition und Multiplikation komplexer Zahlen
die von den reellen Zahlen bekannten VerknuĚpfungssymbole + und Âˇ. Das Einselement von C schreibt man auch kurz als 1 (statt 1 + 0i) und das Nullelement
als 0 (statt 0 + 0i).
Die komplexen Zahlen koĚnnen als Punkte der Ebene R2 interpretiert werden.
Die beiden Koordinaten eines Punktes sind dann durch Realteil und ImaginaĚrteil
der entsprechenden komplexen Zahl gegeben:

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

47

Im(z)
z = a + bi

b

a

Re(z)

Die Addition zweier komplexer Zahlen entspricht dann der uĚblichen Addition von
Vektoren:
Im(z)
b + b0
b0

z + z0
z0

b

z
a0

a

a + a0

Re(z)

Definition 2.3.4 (Betrag). FuĚr z = a + bi â C heiĂt |z| :=
von z.

â

a2 + b2 der Betrag

Der Betrag einer komplexen Zahl ist also nach dem Satz des Pythagoras der
Abstand des entsprechenden Punktes in der Ebene vom Nullpunkt. Die Zahl
|z|2 = a2 + b2 kann man auch als (a + bi)(a â bi) schreiben. Der zweite Faktor war
uns schon beim Inversen einer komplexen Zahl begegnet. FuĚr diese Zahl gibt es
einen eigenen Namen.
Definition 2.3.5 (Konjugiert-komplexe Zahl). FuĚr eine gegebene komplexe Zahl
z = a+bi, a, b â R heiĂt z := aâbi die zu z konjugierte oder konjugiert-komplexe
Zahl. Die Abbildung C â C mit z 7â z heiĂt komplexe Konjugation.
FuĚr die komplexe Konjugation gelten die folgenden Rechenregeln:
Lemma 2.3.6. Es seien z, w â C. Dann gilt
(i) z + w = z + w,

48

Mathematik fuĚr Informatiker

M. Skutella

(ii) z Âˇ w = z Âˇ w,
(iii) Es seien z, w â C. Dann gilt |z|2 = z Âˇ z,
(iv) z â1 = z/|z|2 falls z 6= 0.
Beweis. Nachrechnen!



Geometrisch entspricht der UĚbergang zur konjugiert-komplexen Zahl der Spiegelung an der reellen Achse (x-Achse).
Im(z)
z = a + bi

b
|z |

Re(z)

a
âb

z = a â bi

Die Betragsfunktion hat die folgenden Eigenschaften:
Lemma 2.3.7. Es seien z, w â C. Dann gilt
(i) |z| âĽ 0,
(ii) |z| = 0 ââ z = 0,
(iii) |zw| = |z||w|,
(iv) |z + w| â¤ |z| + |w|

(Dreiecksungleichung).

Beweis. Nachrechnen!



Man kann die komplexen Zahlen z = a+bi statt in kartesischen Koordinatenâ
â
(a, b) auch in sogenannten Polarkoordinaten darstellen. Dazu betrachten wir den
Winkel Ď, den der Vektor (a, b) â R2 mit der reellen Achse einschlieĂt. Dieser
Winkel wird mit arg(z) bezeichnet (Argument von z).
Im(z)
z = a + bi

b
|z |

Ď = arg(z)

Ď
a

Re(z)

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

49

Dann gilt:
cos Ď =

a
|z|

und

sin Ď =

b
.
|z|

Im Vorgriff auf die Analysis verwenden wir hier schon einige elementare Fakten
uĚber trigonometrische Funktionen.
Satz 2.3.8 (Polarkoordinaten-Darstellung komplexer Zahlen).
a) Jede komplexe Zahl z 6= 0 kann eindeutig geschrieben werden als
z = r Âˇ (cos Ď + i sin Ď) mit r â RâĽ0 , Ď â [0, 2Ď[ .
Dabei ist r = |z|, und Ď entspricht dem Winkel zwischen z und der reellen
Achse. Die Zahlen (r, Ď) heiĂen Polarkoordinaten von z.
b) FuĚr die Multiplikation komplexer Zahlen gilt

z Âˇ z 0 = r Âˇ r0 Âˇ cos(Ď + Ď0 ) + i sin(Ď + Ď0 ) .
Das heiĂt, die BetraĚge der beiden komplexen Zahlen werden multipliziert und
die Winkel addiert.
Im(z)

Âˇ |z 0
|

z Âˇ z0

|z |

z
|z |

Ď + Ď0
Ď

0
|z |

z0

Ď0
Re(z)

â
Beispiel. Betrachte die komplexe Zahl Ď = 12 + 12 3 Âˇ i. Mit etwas Rechnung
zeigt man Ď 3 = â1, Ď 6 = 1. Mit
â Polarkoordinaten geht dieses ohne Rechnung:
1
Ď
Es ist |Ď| = 1 und 2 = cos( 3 ), 23 = sin( Ď3 ), also
Ď = cos

Ď
Ď
+ i sin .
3
3

Also ist Ď 3 = cos Ď + i sin Ď = â1, Ď 6 = cos(2Ď) + i sin(2Ď) = 1.

50

Mathematik fuĚr Informatiker

M. Skutella

Eine sehr wichtige Folgerung der Polarkoordinaten-Darstellung ist der folgende Satz.
Satz 2.3.9.
a) Jede
Zahl z = r Âˇ (cos Ď + i sin Ď) besitzt eine Quadratwurzel, naĚmlich
â komplexe
â
z := r Âˇ (cos Ď2 + i sin Ď2 ).
b) Allgemeiner besitzt z auch n-te Wurzeln fuĚr alle n â N, also Zahlen c â C mit
cn = z. Dieses sind die Zahlen



â
Ď
Ď
2kĎ
2kĎ
n
ck := r Âˇ cos + i sin
+ i sin
, k = 0, . . . , n â 1.
Âˇ cos
n
n
n
n
Die Zahlen
Ďnk := cos

2kĎ
2kĎ
+ i Âˇ sin
n
n

mit k = 0, 1, . . . , n â 1

heiĂen auch n-te Einheitswurzeln. Sie sind die LoĚsungen der Gleichung z n = 1.
In der Tat gilt mit Ďn := Ďn1 , dass Ďnk wirklich die k-te Potenz (Ďn )k ist.
In Wirklichkeit gilt in C noch viel mehr als nur die Existenz von Wurzeln:
Jede Gleichung n-ten Grades
an xn + anâ1 xnâ1 + . . . + a1 x + a0 = 0 mit ak â C, an 6= 0
besitzt in C wenigstens eine LoĚsung. Wenn man die LoĚsungen mit geeigneten
Vielfachheiten versieht, so besitzt die Gleichung sogar n LoĚsungen. Die genaue
Formulierung des Sachverhaltes geben wir im folgenden Satz ohne Beweis an.
Theorem 2.3.10 (Fundamentalsatz der Algebra). Jede Polynomfunktion f :
C â C mit
f (z) = an z n + anâ1 z nâ1 + . . . + a1 z + a0
mit komplexen Koeffizienten aj und an 6= 0 besitzt eine Darstellung
f (z) = an (z â c1 )(z â c2 ) Âˇ Âˇ Âˇ (z â cn )
mit n (nicht notwendig verschiedenen) komplexen Zahlen c1 , . . . , cn .
Satz 2.3.9 b) ist in dem Theorem natuĚrlich enthalten: Durch LoĚsen von
zn â a = 0
kann man die n-ten Wurzeln einer beliebigen komplexen Zahl a finden.

Kapiel 2: Zahlbereiche

2.4

R. Scharlau, M. Skutella

51

Primfaktorzerlegung und der euklidische Algorithmus

Dieser und der folgende Abschnitt dieses Kapitels sind im Zusammenhang zu
sehen: Sie handeln von dem Ring der ganzen Zahlen Z mit den VerknuĚpfungen
Addition und Multiplikation und von daraus abgeleiteten Strukturen. Die Addition auf Z birgt keinerlei Geheimnisse; sie reduziert sich, wenn man so will,
vollstaĚndig auf den durch die Peano-Axiome (siehe Definition 2.1.1) geregelten
Prozess des WeiterzaĚhlensâ (vergleiche auch mit dem Induktionsprinzip in Abâ
schnitt 2.1.2), sowie auf die Konstruktion negativer Zahlen. Ganz anders ist es
mit der multiplikativen Struktur von Z, die bei naĚherem Hinsehen sehr viel komplizierter ist (auch wenn sie von der Definition her vollstaĚndig auf die Addition
zuruĚckgefuĚhrt werden kann). Entscheidend ist hier der Begriff Primzahl (siehe
Definition 2.1.7), also einer Zahl, die bezuĚglich Multiplikation nicht weiter zerlegt werden kann. Es ist bekannt und nicht schwer zu zeigen, dass jede natuĚrliche
Zahl in ein Produkt von Primzahlen zerlegt werden kann. Deutlich schwieriger
ist es, exakt und luĚckenlos zu begruĚnden, dass eine solche Zerlegung eindeutig ist
(bis auf die Reihenfolge der Faktoren). Ein Beweis dieser Tatsache (sogenannter
âFundamentalsatz der Arithmetikâ) liegt fuĚr uns eher am Rande, zentral und
wichtig ist jedoch ein dabei benutztes Konzept, naĚmlich der groĚĂte gemeinsame
Teiler, kurz ggT zweier Zahlen sowie der euklidische Algorithmus, der den ggT
berechnet. Hier liegt der Schwerpunkt des folgenden Abschnitts.
Es ist seit langem bekannt, dass der ggT in der Zahlentheorie unabhaĚngig
von der Primfaktorzerlegung der beiden in Frage stehenden Zahlen behandelt
werden kann. In den letzten 30 Jahren hat sich gezeigt, dass an dieser Stelle auch
der Ausgangspunkt fuĚr auĂerordentlich wichtige Anwendungen der Zahlentheorie
in der Kryptographie liegt. Etwas verkuĚrzt zusammengefasst kann man sagen,
dass wichtige Kryptosysteme, insbesondere das bekannte RSA-Verfahren, darauf
beruhen, dass der euklidische Algorithmus und gewisse andere Operationen auch
fuĚr sehr groĂe Zahlen effizient durchfuĚhrbar sind, dass aber das Problem der
Primfaktorzerlegung algorithmisch schwerâ ist.
â

2.4.1

Division mit Rest

Wir halten zunaĚchst eine grundlegende Eigenschaft der ganzen Zahlen fest.
Lemma 2.4.1 (Division mit Rest in Z). Es sei a â Z und m â N. Dann gibt es
eindeutig bestimmte Zahlen q â Z und r â {0, 1, . . . , m â 1}, so dass
a = qm + r .
Die Zahl q heiĂt der Quotient und r heiĂt der Rest von a bei Division durch m.
Die Zahl r wird mit a mod m oder a % m bezeichnet.

52

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Es sei q die groĚĂte ganze Zahl mit q Âˇ m â¤ a. Dann gilt 0 â¤ a â q Âˇ m < m
und wir koĚnnen r := a â q Âˇ m setzen.

Beispiele.
m=6:

23
â2
4
m = 17 : 100
â50

=
=
=
=
=

3Âˇ6+5
(â1) Âˇ 6 + 4
0Âˇ6+4
5 Âˇ 17 + 15
(â3) Âˇ 17 + 1

Rest
Rest
Rest
Rest
Rest

r
r
r
r
r

=5
23 mod 6
=4
â2 mod 6
=4
4 mod 6
= 15 100 mod 17
= 1 â50 mod 17

=5
=4
=4
= 15
=1

Man sagt, dass a durch m teilbar ist, wenn die Division aufgeht, d.h. der
Rest r = 0 ist. Dadurch wird die Teilbarkeitsrelation definiert, die wir bereits in
Abschnitt 1.5 betrachtet hatten. DefinitionsgemaĚĂ gilt also
b|a

2.4.2

:ââ

âq â Z : a = q Âˇ b .

Der euklidische Algorithmus

Wir beschreiben im Folgenden den euklidischen Algorithmus, der den groĚĂten
gemeinsamen Teiler zweier positiver Zahlen x und y berechnet.
Euklidischer Algorithmus.
Eingabe: Zwei Zahlen x, y â N mit x â¤ y.
Ausgabe: Eine Zahl d â N.
1) Finde q â N und r â {0, 1, . . . , x â 1} mit y = q Âˇ x + r.
2) Ist r = 0, dann setze d := x und STOPP.
3) Rufe den Algorithmus rekursiv mit y := x und x := r auf und
gebe das berechnete d zuruĚck.
Beispiel. Wir beschreiben die Berechnungen des euklidischen Algorithmus fuĚr
die Eingabe x = 221 und y = 1001:
1001
221
117
104

= 4 Âˇ 221 + 117
= 1 Âˇ 117 + 104
= 1 Âˇ 104 + 13
= 8 Âˇ 13 + 0

Der Algorithmus gibt also die Zahl d = 13 zuruĚck.
Satz 2.4.2. Es seien x, y â N mit x â¤ y. Dann terminiert der euklidische Algorithmus und die berechnete Zahl d â N erfuĚllt die folgenden Bedingungen:
(i) d|x und d|y;

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

53

(ii) ist z â N mit z|x und z|y, so gilt z|d;
(iii) es gibt a, b â Z mit d = a Âˇ x + b Âˇ y.
Definition 2.4.3. Es seien x, y â Z und d â N, so dass d die Eigenschaften (i)
und (ii) aus Satz 2.4.2 erfuĚllt. Dann wird d der groĚĂte gemeinsame Teiler (ggT)
von x und y genannt. Man schreibt auch ggT(x, y) := d.
Bemerkung. Aus technischen GruĚnden verlangen wir, dass der euklidische Algorithmus als Eingabe nur positive ganze Zahlen erhaĚlt. Das ist jedoch keine
wirkliche EinschraĚnkung, da fuĚr alle x, y â Z gilt, dass
ggT(x, y) = ggT(âx, y) = ggT(x, ây) = ggT(âx, ây) .
Das liegt im Wesentlichen daran, dass fuĚr d, z â Z
d|z

ââ

d | (âz)

gilt.
Als Folgerung aus Satz 2.4.2 (iii) erhalten wir das folgende Korollar.
Korollar 2.4.4 (Lemma von Bezout). Sind x, y â Z, so gibt es ganze Zahlen a, b â Z mit
ggT(x, y) = a Âˇ x + b Âˇ y .
Beispiele. a) Wir betrachten noch einmal das Beispiel von oben mit x = 221
und y = 1001. Der groĚĂte gemeinsame Teiler von 221 und 1001 ist 13 und es
gilt 13 = (â9) Âˇ 221 + 2 Âˇ 1001.
b) Es sei x = 42 und y = 198. Der euklidische Algorithmus berechnet
198
42
30
12

=
=
=
=

4 Âˇ 42 + 30
1 Âˇ 30 + 12
2 Âˇ 12 + 6
2Âˇ6+0

(2.3)
(2.4)
(2.5)

und gibt d = 6 zuruĚck. Die Menge der positiven gemeinsamen Teiler von 42
und 198 ist {1, 2, 3, 6}, so dass 6 in der Tat der groĚĂte gemeinsame Teiler ist.
AuĂerdem gilt 6 = (â14) Âˇ 42 + 3 Âˇ 198.
Wir erlaĚutern kurz, wie man auf diese Darstellung von d = 6 kommt. Wegen (2.5) ist
6 = 1 Âˇ 30 + (â2) Âˇ 12 .

(2.6)

54

Mathematik fuĚr Informatiker

M. Skutella

Wegen (2.4) ist
12 = 1 Âˇ 42 + (â1) Âˇ 30 .

(2.7)

Einsetzen von (2.7) in (2.6) liefert
6 = 1 Âˇ 30 + (â2) Âˇ 12
= 1 Âˇ 30 + (â2) Âˇ (1 Âˇ 42 + (â1) Âˇ 30)
= 3 Âˇ 30 + (â2) Âˇ 42 .

(2.8)

Wegen (2.3) ist
30 = 1 Âˇ 198 + (â4) Âˇ 42 .

(2.9)

Einsetzen von (2.9) in (2.8) liefert schlieĂlich
6 = 3 Âˇ 30 + (â2) Âˇ 42
= 3 Âˇ (1 Âˇ 198 + (â4) Âˇ 42) + (â2) Âˇ 42
= (â14) Âˇ 42 + 3 Âˇ 198 .
Beweis von Satz 2.4.2. Wir beweisen zunaĚchst, dass der euklidische Algorithmus
fuĚr beliebige Eingaben x, y â N mit x â¤ y terminiert. Der Beweis funktioniert
mit vollstaĚndiger Induktion (siehe Satz 2.1.5) uĚber x. Induktionsanfang: Ist x =
1, so gilt y = y Âˇ x + 0 und der Algorithmus terminiert sofort in Schritt 2).
Induktionsschluss: Wir nehmen an, dass fuĚr ein beliebiges aber fest gewaĚhltes k â
N der Algorithmus fuĚr alle Eingaben mit x â¤ k terminiert. ErhaĚlt der Algorithmus
als Eingabe nun x = k + 1 und ein y âĽ x, so terminiert er entweder in Schritt 2)
(falls x|y) oder er ruft sich selbst rekursiv mit der Eingabe y := x und x := r auf.
Da r < x, terminiert der Algorithmus mit dieser Eingabe.
Wir zeigen als naĚchstes (i), also d|x und d|y. Auch diese Behauptung zeigen
wir mit vollstaĚndiger Induktion uĚber x. Induktionsanfang: Ist x = 1, so terminiert
der Algorithmus sofort in Schritt 2) und gibt d = x = 1 zuruĚck. Offensichtlich gilt
dann d|x und d|y. Induktionsschluss: Wir nehmen an, dass fuĚr ein beliebiges aber
fest gewaĚhltes k â N der Algorithmus fuĚr alle Eingaben mit x â¤ k eine Zahl d â N
mit d|x und d|y berechnet. Wir betrachten den Fall, dass der Algorithmus als
Eingabe nun x = k+1 und ein y âĽ x erhaĚlt. Gilt x|y, so terminiert er in Schritt 2)
und liefert d = x, so dass offenbar d|x und d|y. Andernfalls ist y = q Âˇ x + r
mit q â N und r â {0, 1, . . . , x â 1} und der Algorithmus berechnet in Schritt (3)
nach Induktion ein d mit d|r (also r = m Âˇ d mit m â N) und d|x (also x = n Âˇ d
mit n â N). Da
y = q Âˇ x + r = q Âˇ n Âˇ d + m Âˇ d = (q Âˇ n + m) Âˇ d ,

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

55

folgt auch d|y.
Wir zeigen als NaĚchstes (iii), wiederum mit vollstaĚndiger Induktion uĚber x.
Induktionsanfang: Ist x = 1, so terminiert der Algorithmus sofort in Schritt 2)
und gibt d = x = 1 zuruĚck. Dann gilt d = 1 Âˇ x + 0 Âˇ y. Induktionsschluss: Wir
nehmen an, dass fuĚr ein beliebiges aber fest gewaĚhltes k â N der Algorithmus fuĚr
alle Eingaben mit x â¤ k eine Zahl d â N mit d = aÂˇx+bÂˇy mit a, b â Z berechnet.
Wir betrachten den Fall, dass der Algorithmus als Eingabe nun x = k + 1 und
ein y âĽ x erhaĚlt. Gilt x|y, so terminiert er in Schritt 2) und liefert d = x, so
dass d = 1 Âˇ x + 0 Âˇ y gilt. Andernfalls ist y = q Âˇ x + r mit q â N und r â
{0, 1, . . . , x â 1} und der Algorithmus berechnet in Schritt (3) nach Induktion
ein d mit d = a0 Âˇ r + b0 Âˇ x mit a0 , b0 â Z. Dann gilt
d = a0 Âˇ r + b0 Âˇ x = a0 Âˇ (y â q Âˇ x) + b0 Âˇ x = (b0 â a0 Âˇ q) Âˇ x + a0 Âˇ y .
Setzt man also a := b0 â a0 Âˇ q â Z und b := a0 â Z, so gilt d = a Âˇ x + b Âˇ y.
Zu guter Letzt zeigen wir noch (ii). Es sei z â N mit z|x (also x = m Âˇ z
mit m â N) und z|y (also y = n Âˇ z mit n â N). Wegen (iii) gibt es a, b â Z, so
dass
d = a Âˇ x + b Âˇ y = a Âˇ m Âˇ z + b Âˇ n Âˇ z = (a Âˇ m + b Âˇ n) Âˇ z
und damit z|d.



Bemerkung. Es folgt aus Satz 2.4.2 und dem euklidischen Algorithmus, dass
wir die Funktion ggT : {(x, y) â N Ă N | x â¤ y} â N wie folgt rekursiv schreiben
koĚnnen:
(
x
falls x | y,
ggT(x, y) =
ggT(y mod x, x) sonst.

2.4.3

Primzahlen und Primfaktorzerlegung

Primzahlen sind nicht nur ein klassisches Thema der Mathematik, sondern auch
fuĚr die Konstruktion algebraischer Strukturen von groĂer Bedeutung, mit Bezug
auf die Informatik etwa fuĚr viele Fragen der Codierung und UĚbertragung von
Daten. Das Gleiche gilt fuĚr den (theoretischen wie algorithmischen) Umgang mit
beliebigen ganzen Zahlen. Es ist lohnend, sich mit dieser Grundstruktur etwas
ausfuĚhrlicher zu beschaĚftigen. Ziel dieses Unterabschnitts ist es, die Eindeutigkeit
der Primfaktorzerlegung herzuleiten und zu beweisen.
Definition 2.4.5 (Relativ prim, teilerfremd). Zwei Zahlen x, y â N heiĂen relativ
prim oder teilerfremd, falls ggT(x, y) = 1.
Beispiel. Die Zahlen 143 = 11 Âˇ 13 und 119 = 7 Âˇ 17 sind relativ prim. Die
Zahlen 126 = 2Âˇ3Âˇ3Âˇ7 und 231 = 3Âˇ7Âˇ11 sind nicht relativ prim, da ggT(126, 231) =
3 Âˇ 7 = 21.

56

Mathematik fuĚr Informatiker

M. Skutella

Aus dem Lemma von Bezout (Korollar 2.4.4) koĚnnen wir die folgende alternative Charakterisierung des Begriffs relativ primâ folgern.
â
Korollar 2.4.6. Zwei Zahlen x, y â N sind genau dann relativ prim, wenn es
ganze Zahlen a, b â Z gibt mit a Âˇ x + b Âˇ y = 1.
Wie wir weiter oben gesehen haben, kann man mit Hilfe des euklidischen
Algorithmus nicht nur feststellen, ob x und y relativ prim sind, sondern auch die
Zahlen a, b â Z berechnen.
Beweis von Korollar 2.4.6. Sind x und y relativ prim, so existieren die ganzen
Zahlen a, b â Z wie gefordert nach Korollar 2.4.4.
Wir nehmen jetzt umgekehrt an, dass es a, b â Z mit a Âˇ x + b Âˇ y = 1 gibt. Ist
nun z â N mit z|x und z|y, so folgt daraus z|1 (vergleiche auch den Beweis von
Satz 2.4.2 (ii)) und damit z = 1. Folglich ist der groĚĂte gemeinsame Teiler von x
und y gleich 1.

In Vorbereitung auf den Beweis der Eindeutigkeit der Primzahlzerlegung, beweisen wir zunaĚchst das folgende wichtige Lemma.
Lemma 2.4.7. Es seien x, y, z â N. Gilt x | (y Âˇ z) und sind x und y relativ prim,
dann gilt x | z.
Beweis. Da x und y relativ prim sind, gibt es nach Korollar 2.4.6 Zahlen a, b â Z
mit a Âˇ x + b Âˇ y = 1. Folglich gilt

y Âˇ z
z = (a Âˇ x + b Âˇ y) Âˇ z = a Âˇ z + b Âˇ
Âˇx .
(2.10)
x
Da x ein Teiler von y Âˇ z ist, ist yÂˇz
eine ganze Zahl. Folglich ist nach (2.10) die
x
Zahl z ein ganzzahliges Vielfaches von x, so dass x | z.

Der folgende bekannte Satz wird oft auch als der Hauptsatzâ oder Fundaâ
â
mentalsatz der Arithmetikâ bezeichnet.
Satz 2.4.8 (Eindeutigkeit der Primfaktorzerlegung).
a) Jede natuĚrliche Zahl n > 1 laĚsst sich als Produkt von Primzahlen schreiben:
n = p1 Âˇ p2 Âˇ . . . Âˇ pr ,

mit

p1 , p2 , . . . , pr Primzahlen.

b) Diese Zerlegung ist eindeutig bis auf die Reihenfolge der Faktoren. Das heiĂt,
wenn auch n = q1 Âˇ q2 Âˇ . . . Âˇ qs ist mit qj prim fuĚr j = 1, . . . , s, so ist r = s,
und wenn wir ferner p1 â¤ p2 â¤ . . . â¤ pr und q1 â¤ q2 â¤ . . . â¤ qr annehmen, so
ist pi = qi fuĚr i = 1, . . . , r.

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

57

Beweis. Wir beweisen zunaĚchst Teil a) des Satzes, also die Existenz einer Primfaktorzerlegung. Der Beweis benutzt vollstaĚndige Induktion uĚber n. Induktionsanfang: Die Behauptung ist klar fuĚr n = 2, da 2 selbst eine Primzahl ist. Induktionsschluss: Wir nehmen an, dass die Behauptung fuĚr alle n mit 2 â¤ n â¤ k
wahr ist und betrachten jetzt den Fall n := k + 1. Ist n eine Primzahl, so ist
die Behauptung klar. Andernfalls gibt es nach Lemma 2.1.6 eine Primzahl p
mit p | n. Nach Induktionsannahme gibt es eine Primfaktorzerlegung fuĚr die
Zahl np , d.h. np = p1 Âˇ p2 Âˇ Âˇ Âˇ Âˇ Âˇ pr mit pi Primzahl fuĚr 1 â¤ i â¤ r. Daraus erhaĚlt man
die folgende Primfaktorzerlegung fuĚr n:
n
n = pÂˇ
= p Âˇ p1 Âˇ p2 Âˇ Âˇ Âˇ Âˇ Âˇ pr .
p
Wir kommen jetzt zu Teil b) des Satzes, also zur Eindeutigkeit der Primfaktorzerlegung. Auch dieser Teil wird mit vollstaĚndiger Induktion bewiesen. Induktionsanfang: Die Behauptung ist klar fuĚr n = 2. Induktionsschluss: Wir nehmen
an, dass die Behauptung fuĚr alle n mit 2 â¤ n â¤ k wahr ist und betrachten jetzt
den Fall n := k + 1. Es seien
n = p1 Âˇ p2 Âˇ Âˇ Âˇ Âˇ Âˇ pr

(2.11)

n = q1 Âˇ q2 Âˇ Âˇ Âˇ Âˇ Âˇ qs

(2.12)

und

zwei Primfaktorzerlegungen von n mit p1 â¤ p2 â¤ Âˇ Âˇ Âˇ â¤ pr und q1 â¤ q2 â¤ Âˇ Âˇ Âˇ â¤ qs .
Gilt p1 = q1 , so ist n0 := p2 Âˇ Âˇ Âˇ Âˇ Âˇ pr = q2 Âˇ Âˇ Âˇ Âˇ Âˇ qs und aus der Induktionsannahme
folgt, dass die Zahl n0 < n eine eindeutige Primfaktorzerlegung besitzt. Daher
gilt dann r = s und pi = qi fuĚr alle 1 â¤ i â¤ r.
Es bleibt also nur noch zu zeigen, dass p1 = q1 . Wir fuĚhren einen Widerspruchsbeweis und nehmen an, dass p1 < q1 (der Fall p1 > q1 kann voĚllig analog
behandelt werden). Aus (2.11) folgt, dass p1 | n. Da p1 und q1 verschiedene
Primzahlen sind, sind sie relativ prim, so dass aus (2.12) und Lemma 2.4.7 folgt,
dass p1 | q2 Âˇ Âˇ Âˇ Âˇ Âˇ qs . Nach Induktionsannahme besitzt die Zahl n0 = q2 Âˇ Âˇ Âˇ Âˇ Âˇ qs
eine eindeutige Primfaktorzerlegung. Da p1 | n0 , muss also p1 = qi fuĚr ein i
mit 2 â¤ i â¤ s gelten4 . Dies fuĚhrt jedoch zu einem Widerspruch, da p1 < q1 â¤ qi
fuĚr 2 â¤ i â¤ s gilt.

Satz 2.4.8 sagt nur etwas uĚber die Existenz einer eindeutigen Primfaktorzerlegung aus, nicht aber, wie man eine solche tatsaĚchlich berechnen kann. Dazu kann
das folgende Verfahren verwendet werden.
4

Wir haben an dieser Stelle den Beweis etwas abgekuĚrzt. Formal muss man wie folgt argu0
mentieren: Da p1 | n0 , kann man n0 als Produkt der natuĚrlichen Zahlen p1 und pn1 schreiben.
0

Nimmt man jetzt eine Primfaktorzerlegung von pn1 , so erhaĚlt man damit eine Primfaktorzerlegung von n0 , in der die Primzahl p1 vorkommt. Aus der Eindeutigkeit der Primfaktorzerlegung
von n0 folgt dann die getroffene Behauptung.

58

Mathematik fuĚr Informatiker

M. Skutella

Man schreibt sich vorbereitend die ersten Primzahlen der GroĚĂe nach geordnet
in eine Liste:
p1 = 2, p2 = 3, p3 = 5, p4 = 7, . . . , pk .
Dann testet man Teilbarkeit von n durch 2, 3, 5, 7, . . . . Sei pi die kleinste Primzahl mit pi | n. Ersetze n durch n/pi und fahre so fort, beginnend nun mit der
Primzahl piâ
. Dieser kleinste Primteiler pi ist tatsaĚchlich âkleinâ, naĚmlich hoĚchstens gleich n, es sei denn, n ist selbst
â prim (warum?!). Man muss die Liste der
Primzahlen also nur bis zur GroĚĂe n anlegen, wenn n die zu zerlegende Zahl
ist.
Beispiel. Die Zahl 97 ist nicht durch 2, 3, 5, 7 teilbar, also Primzahl. Denn nach 7
ist 11 die naĚchste Primzahl und 11 Âˇ 11 > 97.
Bemerkung. Der angedeutete naive Algorithmus zur Primfaktorzerlegung ist
nicht besonders effizient. Wir sehen hier nur die Spitze eines Eisberges: In Wirklichkeit macht die Frage nach guten Algorithmen fuĚr die Primfaktorzerlegung und
deren theoretische Analyse ein eigenes Teilgebiet der Mathematik, genauer der so
genannten algorithmischen Zahlentheorie aus. Dabei spielen auch Konzepte der
theoretischen Informatik (KomplexitaĚtstheorie, probabilistische Algorithmen) eine bedeutende Rolle. Es gibt zwei weitere verwandte, aber nicht gleichwertige
Fragestellungen: Das Finden groĂer Primzahlen, und der Beweis, dass gewisse
Zahlen wirklich Primzahlen sind. Alle drei Probleme sind von groĂer Bedeutung
fuĚr VerschluĚsselungsverfahren und deren Sicherheit.
Zum Abschluss dieses Abschnitts beweisen wir noch, dass es unendlich viele
Primzahlen gibt.
Satz 2.4.9 (Unendlichkeit der Menge aller Primzahlen). Es gibt unendlich viele
Primzahlen.
Beweis. Wir fuĚhren einen Beweis durch Widerspruch. Wir nehmen an, dass die
Menge der Primzahlen
endlich ist, naĚmlich {p1 , p2 , . . . , pr }. Nun betrachten wir
Q
die Zahl n := 1 + ri=1 pi und fragen uns, wie die eindeutige Primfaktorzerlegung
von n aussieht. Da offenbar keine der Zahlen p1 , . . . , pr Teiler von n ist, kann
auch keine dieser Zahlen in der Primfaktorzerlegung von n vorkommen. Dies ist
ein Widerspruch zu Satz 2.4.8.


2.5

Modulare Arithmetik

Um die in der Einleitung zu Abschnitt 2.4 angedeuteten Verfahren fuĚr DatenverschluĚsselung im einzelnen durchzufuĚhren, aber auch fuĚr anders gelagerte Probleme der Speicherung und der Fehlerkorrektur von Daten, werden andere âZahlbereicheâ benoĚtigt als die bisher bekannten. In diesem Abschnitt betrachten wir
die wohl wichtigsten Beispiele solcher Rechenbereiche. Es wird zwar (auf den

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

59

ersten Blick) mit gewoĚhlichen ganzen Zahlen gearbeitet, genauer mit der Menge Zm = {0, 1, . . . , m â 1} fuĚr eine feste natuĚrliche Zahl m âĽ 2, aber die Rechenoperationen sind neu: Die Ergebnisse der gewoĚhnlichen Addition bzw. Multiplikation werden durch ihren jeweiligen Rest bei Division durch m ersetzt. Informell
bezeichnet man diese Operationen als modulo-m-Additionâ bzw. modulo-mâ
â
Multiplikationâ. Die resultierende Struktur (Zm , +m , Âˇm ) ist dann ein kommutativer Ring mit Eins.

2.5.1

Addition und Multiplikation modulo m

Definition 2.5.1 (mod-m-Addition und mod-m-Multiplikation). Es sei Zm :=
{0, 1, . . . , m â 1} die Menge aller moĚglichen Reste modulo m. Auf Zm definieren
wir die beiden VerknuĚpfungen +m und Âˇm wie folgt:
x +m y := (x + y) mod m
x Âˇm y := (x Âˇ y) mod m
Wir nennen sie Addition bzw. Multiplikation modulo m, kurz mod-m-Addition
bzw. mod-m-Multiplikation.
Beispiele. Wir schreiben im Folgenden die VerknuĚpfungstafeln beispielhaft fuĚr m =
5, 6 und 7 auf (siehe auch Abschnitt 2.2.2).
(i) Die VerknuĚpfungstafeln fuĚr m = 5:
+5
0
1
2
3
4

0
0
1
2
3
4

1
1
2
3
4
0

2
2
3
4
0
1

3
3
4
0
1
2

4
4
0
1
2
3

Âˇ5
0
1
2
3
4

0
0
0
0
0
0

1
0
1
2
3
4

2
0
2
4
1
3

3
0
3
1
4
2

4
0
4
3
2
1

Âˇ6
0
1
2
3
4
5

0
0
0
0
0
0
0

1
0
1
2
3
4
5

2
0
2
4
0
2
4

3
0
3
0
3
0
3

4
0
4
2
0
4
2

(ii) Die VerknuĚpfungstafeln fuĚr m = 6:
+6
0
1
2
3
4
5

0
0
1
2
3
4
5

1
1
2
3
4
5
0

2
2
3
4
5
0
1

3
3
4
5
0
1
2

4
4
5
0
1
2
3

5
5
0
1
2
3
4

5
0
5
4
3
2
1

60

Mathematik fuĚr Informatiker

M. Skutella

(iii) Die VerknuĚpfungstafeln fuĚr m = 7:
+7
0
1
2
3
4
5
6

0
0
1
2
3
4
5
6

1
1
2
3
4
5
6
0

2
2
3
4
5
6
0
1

3
3
4
5
6
0
1
2

4
4
5
6
0
1
2
3

5
5
6
0
1
2
3
4

6
6
0
1
2
3
4
5

Âˇ7
0
1
2
3
4
5
6

0
0
0
0
0
0
0
0

1
0
1
2
3
4
5
6

2
0
2
4
6
1
3
5

3
0
3
6
2
5
1
4

4
0
4
1
5
2
6
3

5
0
5
3
1
6
4
2

6
0
6
5
4
3
2
1

Die wesentlichen Eigenschaften der neuen Addition und Multiplikation werden
in dem folgenden Satz festgehalten.
Satz 2.5.2 (Ring Zm ). FuĚr jedes m â N ist (Zm , +m , Âˇm ) ein kommutativer Ring
mit Eins.
FuĚr den Beweis des Satzes muss man vor allem eine Reihe von Rechengesetzen
uĚberpruĚfen. Dabei ist die folgende allgemeine Rechenregel von Nutzen.
Regel: Man darf mehrschrittige Rechnungen in Zm zunaĚchst in Z fuĚhren und
erst zum Schluss die Reduktion mod m machen. So ist z.B.
a Âˇm x +m b Âˇm y = (ax + by) mod m .
AĚhnlich ist (aÂˇm b)Âˇm c = (abc) mod m und analog auch aÂˇm (bÂˇm c) = (abc) mod m,
woraus sich die AssoziativitaĚt bereits ergibt.
Wir verzichten auf einen ausfuĚhrlichen Beweis von Satz 2.5.2 und kehren stattdessen zu den obigen VerknuĚpfungstafeln zuruĚck, um einige interessante Beobachtungen zu machen.
â˘ Die Tafel fuĚr +m hat in allen FaĚllen eine offensichtliche zyklische Strukturâ:
â
Jede Zeile enthaĚlt die Elemente 0 bis m â 1 in der gleichen Reihenfolge,
wobei man nach m â 1 wieder mit der 0 beginnt; die jeweils naĚchste Zeile
entsteht aus der vorigen, indem man sie um eins nach links verschiebt. All
dies folgt direkt aus der Definition von +m . Insbesondere enthaĚlt jede Zeile
eine Permutation der Zahlen 0 bis m â 1, d.h. jede dieser Zahlen kommt
genau einmal vor.
â˘ Die Struktur der Tafel fuĚr die Multiplikation ist komplizierter. Wir schauen
im Augenblick nur auf die Frage der Permutation. In vielen FaĚllen ist die
Zeile zu a â Zm , d.h. die Liste der Vielfachen a Âˇm x mit x = 0, 1, . . . , m â 1,
eine Permutation von 0, 1, . . . , m â 1. Abgesehen von der Nullzeile zur 0 gilt
das bei m = 5 und m = 7 fuĚr alle Zeilen. Bei m = 6 haben wir fuĚr a = 2, 3
und 4 keine Permutation.

Kapiel 2: Zahlbereiche

2.5.2

R. Scharlau, M. Skutella

61

Einheiten und Inverse

Wir fragen uns nun fuĚr allgemeines m: FuĚr welche a â {0, 1, . . . , m â 1} ist die aZeile der VerknuĚpfungstafel eine Permutation von {0, 1, . . . , m â 1}? Wenn eine
Permutation vorliegt, so kommt insbesondere die 1 vor, d.h. die Gleichung aÂˇm x =
1 ist loĚsbar. Aus der Tatsache, dass wir in einem Ring arbeiten (genauer aus dem
Assoziativgesetz der Multiplikation) folgt, dass auch die Umkehrung gilt: Sobald
die 1 in der a-Zeile auftaucht, ist die Zeile eine Permutation. Wir entwickeln
diesen Sachverhalt, der diverse Anwendungen hat, gleich in allgemeinen Ringen.
Definition 2.5.3 (Einheiten). Es sei (R, +, Âˇ) ein Ring mit Eins. Ein Element
x â R heiĂt Einheit oder invertierbar, falls ein y â R existiert mit
xÂˇy = yÂˇx = 1 .
Die Menge der Einheiten in R wird mit Râ := {x â R | x Einheit} bezeichnet.
Wie im Fall von Gruppen (siehe Lemma 2.2.4) zeigt man, dass das inverse
Element y =: xâ1 zu gegebener Einheit x eindeutig bestimmt ist.
Beispiele.
(i) Einheiten des Ringes Z sind lediglich die Zahlen 1 und â1.
â
â
(ii) Wir betrachten
den
Teilring
Z[
2]
(lies
Z
adjungiert
2â) des KoĚrpers R
â
â
â
mit Z[ 2] := {x + y Âˇ 2 | x, y â Z}. In diesemâRing (mit der gewoĚhnlichen
â
2
keine
Einheit,
aber
1+
2
Addition und Multiplikation
reeller
Zahlen)
ist
â
â
ist eine, denn (1 + 2)(â1 + 2) = 1, und der zweite Faktor liegt wieder
im betrachteten Ring.
(iii) Die Einheiten des Polynomrings R[x] sind die Polynome aX 0 mit a â R\{0}.
Das inverse Element zu aX 0 ist aâ1 X 0 . Da der Grad des Produkts zweier
Polynome ungleich Null die Summe der Grade der beiden Polynome ist,
koĚnnen Polynome vom Grad groĚĂer Null keine Einheiten sein.
(iv) Das Nullelement eines beliebigen Rings R mit Eins ist keine Einheit, da
nach Lemma 2.2.9 gilt: 0 Âˇ x = x Âˇ 0 = 0 fuĚr alle x â R.
(v) In einem beliebigen KoĚrper (K, +, Âˇ) sind nach Definition alle Elemente ungleich Null Einheiten, d.h. K â = K \ {0}.
Lemma 2.5.4. Es sei (R, +, Âˇ) ein Ring mit Eins. Dann bilden die Einheiten
von R eine multiplikative Gruppe, d.h. (Râ , Âˇ) ist eine Gruppe.
Beweis. Wir muĚssen zunaĚchst zeigen, dass die Multiplikation eine (assoziative)
VerknuĚpfung auf Râ ist, das heiĂt, dass Râ abgeschlossen unter Multiplikation
ist. Es seien also x, y â Râ . Dann ist x Âˇ y â Râ , da
(x Âˇ y) Âˇ (y â1 Âˇ xâ1 ) = (x Âˇ (y Âˇ y â1 )) Âˇ xâ1 = (x Âˇ 1) Âˇ xâ1 = x Âˇ xâ1 = 1

62

Mathematik fuĚr Informatiker

M. Skutella

und
(y â1 Âˇ xâ1 ) Âˇ (x Âˇ y) = (y â1 Âˇ (xâ1 Âˇ x)) Âˇ y = (y â1 Âˇ 1) Âˇ y = y â1 Âˇ y = 1 .
Das neutrale Element der Gruppe ist natuĚrlich 1 â Râ . Das inverse Element
zu x â Râ ist das oben definierte xâ1 , das nach Definition auch wieder eine
Einheit und damit in Râ ist.

Wir formulieren und beweisen nun allgemein die oben an Beispielen beobachtete Kennzeichnung von Einheiten.
Lemma 2.5.5. Ein Element x eines Ringes (R, +, Âˇ) mit Eins ist genau dann
Einheit, wenn die Abbildung
Lx : R â R, y 7â x Âˇ y
bijektiv ist.
Beweis. Ist Lx , bijektiv, so gibt es ein y â R mit 1 = Lx (y) = x Âˇ y. Es bleibt zu
zeigen, dass auch y Âˇ x = 1 ist. Da die Abbildung Lx bijektiv ist, folgt dies aus
Lx (y Âˇ x) = x Âˇ (y Âˇ x) = (x Âˇ y) Âˇ x = 1 Âˇ x = x = x Âˇ 1 = Lx (1) .
Folglich ist x eine Einheit.
Wir nehmen nun umgekehrt an, dass x eine Einheit ist und zeigen, dass Lx
dann bijektiv ist. ZunaĚchst ist Lx surjektiv, da
Lx (xâ1 Âˇ y) = x Âˇ (xâ1 Âˇ y) = (x Âˇ xâ1 ) Âˇ y = 1 Âˇ y = y

fuĚr alle y â R.

Weiterhin ist Lx injektiv, da fuĚr y, z â R mit Lx (y) = Lx (z) gilt:
y = xâ1 Âˇ Lx (y) = xâ1 Âˇ Lx (z) = z .
Folglich ist Lx also bijektiv.



Der folgende Satz klaĚrt allgemein, welche Elemente Einheiten in (Zm , +m , Âˇm )
sind.
Satz 2.5.6 (Einheiten in Zm ). FuĚr m â N ist ein Element x â Zm genau dann
Einheit in Zm , wenn x und m relativ prim sind, d.h.
Zâm = {x â Zm | ggT(x, m) = 1} .
Beweis. Wenn x und m relativ prim sind, so gibt es nach Korollar 2.4.4 ganze
Zahlen a, b â Z mit
1 = ggT(x, m) = a Âˇ x + b Âˇ m .

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

63

Es folgt
1 = (a Âˇ x + b Âˇ m) mod m = a Âˇ x mod m = (a mod m) Âˇm x .
Also ist x Einheit mit Inversem a mod m.
Wenn umgekehrt x â Zâm ist, gibt es ein a â Zm mit a Âˇm x = 1. Es gibt also
ein Vielfaches b Âˇ m von m mit a Âˇ x + b Âˇ m = 1. Wegen Korollar 2.4.6 sind x und m
dann relativ prim.

Beispiele.
(i) Die Einheiten in Z6 sind die nicht durch 2 oder 3 teilbaren Zahlen in Z6 ,
also 1 und 5, wie oben schon aus der VerknuĚpfungstafel abgelesen wurde.
(ii) Die Einheiten in Z10 sind 1, 3, 7 und 9.
(iii) Besonders interessant und wichtig ist der Fall, wenn m = p eine Primzahl
ist. Dann kann der ggT von x und m nur 1 oder m sein, und fuĚr alle Elemente
x â Zm auĂer der Null muss er 1 sein, d.h. x ist Einheit.
Aus dem letzten Beispiel folgt der naĚchste Satz.
Satz 2.5.7 (KoĚrper Zp ). FuĚr jede Primzahl p ist (Zp , +p , Âˇp ) ein KoĚrper.

2.5.3

Nullteiler

Die Einheiten eines Ringes sind diejenigen Elemente, die sich bezuĚglich der Multiplikation so verhalten, wie man es in einem KoĚrper erwartet. Nun betrachten wir
gewisse Elemente, die eine Abweichung vom KoĚrper-Sein beinhalten, naĚmlich die
sogenannten Nullteiler. In einem KoĚrper gilt folgende, aus der Schule bekannte
Regel: Wenn ein Produkt Null ist, so ist schon einer der Faktoren Null. Nullteiler
sind diejenigen Elemente, die in Abweichungen von dieser Regel auftauchen. Der
Einfachheit halber definieren wir sie nur in kommutativen Ringen.
Definition 2.5.8 (Nullteiler, IntegritaĚtsbereich). Es sei (R, +, Âˇ) ein kommutativer Ring.
(i) Ein Element x â R heiĂt Nullteiler, falls x 6= 0 ist und ein y â R \ {0}
existiert mit x Âˇ y = 0.
(ii) Der Ring R heiĂt nullteilerfrei oder ein IntegritaĚtsbereich, falls R keine
Nullteiler enthaĚlt.
Beispiele.
(i) Jeder KoĚrper K ist nullteilerfrei.

64

Mathematik fuĚr Informatiker

M. Skutella

(ii) Der Ring der ganzen Zahlen Z ist nullteilerfrei.
(iii) Der Polynomring R[X] ist nullteilerfrei.
(iv) Der Ring Z6 besitzt Nullteiler, denn 2 Âˇ6 3 = 0 und 2, 3 â Z6 \ {0}.
Beispiel (i) wird in dem folgenden Lemma verallgemeinert.
Lemma 2.5.9. Es sei (R, +, Âˇ) ein kommutativer Ring mit Eins. Eine Einheit x â
Râ ist kein Nullteiler.
Beweis. Nach Lemma 2.5.5 ist fuĚr x â Râ die Abbildung y 7â x Âˇ y bijektiv und
damit injektiv. Da x Âˇ 0 = 0 (Lemma 2.2.9) gilt also x Âˇ y 6= 0 fuĚr alle y 6= 0. 
Der folgende Satz ist eine Erweiterung von Satz 2.5.7.
Satz 2.5.10. Es sei m â N, m âĽ 2. FuĚr den Ring (Zm , +m , Âˇm ) sind die folgenden
Aussagen aĚquivalent:
(i) Die Zahl m ist Primzahl.
(ii) Der Ring (Zm , +m , Âˇm ) ist nullteilerfrei.
(iii) Der Ring (Zm , +m , Âˇm ) ist ein KoĚrper.
Beweis. Wir beweisen den Satz mit einem sogenannten Ringschlussâ. Die Impliâ
kation (iii)=â(ii) folgt aus Lemma 2.5.9, da jedes Element ungleich Null in einem
KoĚrper nach Definition eine Einheit ist. Die Implikation (ii)=â(i) folgt (mittels
Kontraposition) unmittelbar aus der Definition einer Primzahl. Denn wenn m
keine Primzahl ist, so schreibe m = a Âˇ b mit a > 1 und b > 1. Dann ist a Âˇm b = 0
in Zm , aber beide Faktoren sind ungleich 0. Die Implikation (i)=â(iii) haben wir
bereits in Satz 2.5.7 festgestellt.


2.5.4

Chinesischer Restesatz

Der chinesische Restesatz ist einer der anwendungsreichsten SaĚtze der elementaren Zahlentheorie. Er spielt insbesondere im Rahmen der Kryptographie eine
bedeutende Rolle.
Satz 2.5.11 (Chinesischer Restesatz). Es sei k â N und m1 , . . . , mk â N \ {1}
relativ prim (also ggT(mi , mj ) = 1 fuĚr alle 1 â¤ i < j â¤ k). Dann gibt es zu
beliebigen ganzen Zahlen rQ
1 , . . . , rk mit 0 â¤ ri < mi fuĚr i = 1, . . . , k genau eine
ganze Zahl x mit 0 â¤ x < ki=1 mi , so dass
x mod mi = ri

fuĚr i = 1, . . . , k.

Kapiel 2: Zahlbereiche

R. Scharlau, M. Skutella

65

Bemerkung. Die Voraussetzung, dass die Zahlen m1 , . . . , mk relativ prim sind,
ist von entscheidender Bedeutung. Ohne diese Voraussetzung ist der Satz nicht
wahr.
Beispiele.
(i) Es sei k = 2, m1 = 10 und m2 = 21. Zu r1 = 1 und r2 = 15 gibt es genau
eine Zahl x â {0, 1, . . . , 209} mit
x mod 10 = 1

und

x mod 21 = 15 .

Durch geschicktes Ausprobieren findet man heraus, dass es sich dabei um
die Zahl x = 141 handelt.
(ii) Es sei wieder k = 2 und m1 = 10, doch diesmal waĚhlen wir m2 = 22. Dann
ist ggT(m1 , m2 ) = 2 und die beiden Zahlen sind damit nicht relativ prim.
Man uĚberzeugt sich leicht davon, dass es beispielsweise zu r1 = 0 und r2 = 1
keine ganze Zahl x gibt, so dass
x mod 10 = 0

und

x mod 22 = 1 .

Aus (x mod 10) = 0 folgt naĚmlich insbesondere, dass die Zahl x gerade ist,
waĚhrend (x mod 22) = 1 impliziert, dass x ungerade ist.
Q
Beweis von Satz 2.5.11. Es sei n := ki=1 mi . Wir betrachten die beiden Mengen
A := {0, 1, . . . , n â 1}

und
k

B := {(r1 , . . . , rk ) â Z | 0 â¤ ri < mi fuĚr i = 1, . . . , k} .
Nach Definition sind A und B gleichmaĚchtig; es gilt |A| = |B| = n. Wir betrachten nun die Abbildung f : A â B mit
f (x) := (x mod m1 , . . . , x mod mk )

fuĚr x â A.

Wir werden im Folgenden zeigen, dass die Abbildung f bijektiv ist. Das bedeutet,
dass es zu jedem (r1 , . . . , rk ) â B genau ein x â A mit f (x) = (r1 , . . . , rk ) gibt.
Das impliziert dann sofort die Behauptung des Satzes.
Wir zeigen zunaĚchst, dass die Abbildung f injektiv ist. Es seien x, y â A
mit f (x) = f (y). Dann gilt also
x mod mi = y mod mi

fuĚr i = 1, . . . , k.

Q
Wir zeigen mittels vollstaĚndiger Induktion uĚber k, dass n = ki=1 mi ein Teiler
von x â y ist. Induktionsanfang: FuĚr k = 1 folgt aus (x mod m1 ) = (yQ
mod m1 )
unmittelbar, dass m1 | (xây). Induktionsschluss: Wir nehmen an, dass kâ1
i=1 mi |

66

Mathematik fuĚr Informatiker

M. Skutella

(xây). AuĂerdem gilt wegen (x mod mk ) = (y mod mk ), dass mk | (xây). Damit
erhaĚlt man
mk

kâ1
Y

xây
mi Âˇ Qkâ1
.
i=1 mi
i=1
| {z } | {z }
âZ

âZ

Q
Da mk und kâ1
i=1 mi nach Voraussetzung des Satzes relativ prim sind, folgt mit
Lemma 2.4.7, dass
mk

xây
Qkâ1
i=1 mi

Q
und damit ki=1 mi | (x â y).
Wir haben also gezeigt, dass n ein Teiler von x â y ist. Da x, y â A, gilt
ân < x â y < n und damit folgt aus n | (x â y) sofort x â y = 0, also x = y.
Wir haben bislang gezeigt, dass f : A â B eine injektive Abbildung ist. Da
auĂerdem |A| = |B| ist, muss f sogar bijektiv sein.


Kapitel 3
Lineare Algebra
Dieses Kapitel beruht teilweise auf einer Vorlesung uĚber Lineare Algebra, die
im Wintersemester 1990/91 von Herrn Prof. Pahlings an der RWTH Aachen
gehalten wurde. Gegenstand dieses Kapitels sind lineare Gleichungssysteme, Matrizen, VektorraĚume und lineare Abbildungen. Lineare Gleichungssysteme treten
in vielen technischen und wirtschaftlichen ZusammenhaĚngen auf. Aus Sicht der
Informatik sind sie bei zahlreichen Problemstellungen von Bedeutung, beispielsweise bei geometrischen Problemen in der graphischen Datenverarbeitung oder in
der Robotik. Hier fasst man den uns umgebenden Raum als Vektorraum auf, so
dass jeder Punkt des Raumes durch einen Vektor repraĚsentiert wird. Um raĚumliche GegenstaĚnde in der Ebene darzustellen, beispielsweise auf einem Bildschirm,
muĚssen wir lineare Abbildungen vom dreidimensionalen in den zweidimensionalen
Raum durchfuĚhren. Solche lineare Abbildungen koĚnnen mit Hilfe von Matrizen
dargestellt werden.
Es sei im Folgenden immer (K, +, Âˇ) ein KoĚrper (z.B. Q, R, C, Z2 , Z3 . . . ). Die
Elemente des KoĚrpers K nennen wir auch Skalare.

3.1

Lineare Gleichungssysteme und Matrizen

In diesem Abschnitt beschaĚftigen wir uns mit linearen Gleichungssystemen und
deren LoĚsung mit Hilfe des GauĂâschen Eliminationsverfahrens. Dabei erweisen
sich Matrizen als geeignete Hilfsmittel und Rechenwerkzeuge.
Definition 3.1.1 (Lineare Gleichungssysteme). Ein lineares Gleichungssystem
uĚber dem KoĚrper K hat die Form
a11 x1
a21 x1
..
.

+ a12 x2
+ a22 x2
..
.

+ ...
+ ...

am1 x1 + am2 x2 + . . .
67

+ a1n xn
+ a2n xn
..
.

= b1
= b2
..
.

+ amn xn = bm

(3.1)

68

Mathematik fuĚr Informatiker

M. Skutella

wobei alle Koeffizienten aij und bi aus K sind (fuĚr i = 1, . . . , m und j = 1, . . . , n).
Gesucht sind dann Werte x1 , x2 , . . . , xn â K, die (3.1) erfuĚllen.
Die LoĚsungsmenge des linearen Gleichungssystems (3.1) ist die Menge

L := (x1 , x2 , . . . , xn ) â K n | x1 , x2 , . . . , xn erfuĚllen (3.1) .
Beispiele.
(i) Das lineare Gleichungssystem uĚber Q
x1 + x2 + x3 = 0
x1 + x2 + x3 = 1
besitzt offenbar keine LoĚsung, d.h. die LoĚsungsmenge L ist die leere Menge.
(ii) Das lineare Gleichungssystem uĚber R
x1 + 2x2
x1 + 2x2 + 2x3
2x1 + 4x2
3x3

+ x4
+ 3x4
+ 3x4
+ 2x4

=
=
=
=

1
5
5
3

besitzt beispielsweise die LoĚsung x1 = â2, x2 = 0, x3 = â1, x4 = 3.
Eine weitere LoĚsung ist x1 = 0, x2 = â1, x3 = â1, x4 = 3. Die gesamte
LoĚsungsmenge L dieses linearen Gleichungssystems werden wir weiter unten
bestimmen.

3.1.1

Das GauĂâsche Eliminationsverfahren

Grundlegend fuĚr die systematische LoĚsung linearer Gleichungssysteme ist das
folgende einfache Lemma.
Lemma 3.1.2. Die LoĚsungsmenge eines linearen Gleichungssystems uĚber K aĚndert
sich nicht, wenn man
(i) zwei Gleichungen vertauscht;
(ii) das c-fache einer Gleichung zu einer anderen addiert (c â K);
(iii) eine Gleichung mit c â K \ {0} multipliziert.
Beweis. Behauptung (i) ist klar. Um (ii) zu zeigen, muss man sich nur klar machen, dass fuĚr c, w, x, y, z â K gilt:
(w = x

â§

y = z)

ââ

(w = x

â§

y + c Âˇ w = z + c Âˇ x) .

Teil (iii) folgt schlieĂlich aus der Tatsache, dass fuĚr x, y â K und c â K \ {0}
gilt:
x = y ââ c Âˇ x = c Âˇ y .
Damit ist der Beweis abgeschlossen.



Kapiel 3: Lineare Algebra

M. Skutella

69

Der GauĂâsche Algorithmus (auch GauĂâsches Eliminationsverfahren genannt)
benutzt die Regeln aus Lemma 3.1.2 sukzessive, um ein gegebenes lineares Gleichungssystem in ein anderes zu uĚberfuĚhren, bei dem man die LoĚsung direkt ablesen kann.
Beispiel. Wir betrachten noch einmal das Beispiel von oben, also das folgende
lineare Gleichungssystem uĚber R:
x1 + 2x2
x1 + 2x2 + 2x3
2x1 + 4x2
3x3

+ x4
+ 3x4
+ 3x4
+ 2x4

=
=
=
=

1
5
5
3

Addiert man das (â1)-fache der ersten Gleichung zur zweiten Gleichung und
das (â2)-fache der ersten Gleichung zur dritten, so erhaĚlt man:
x1 + 2x2

+ x4
+ 2x4
x4
+ 2x4

2x3
3x3

=
=
=
=

1
4
3
3

Multipliziert man jetzt die zweite Gleichung mit 1/2 und addiert danach das (â3)fache der zweiten Gleichung zur vierten, so erhaĚlt man:
x1 + 2x2
x3

+
+

x4
x4
x4
âx4

=
1
=
2
=
3
= â3

Addiert man schlieĂlich die dritte Gleichung zur vierten und das (â1)-fache der
dritten Gleichung zur ersten und zur zweiten, so erhaĚlt man:
x1 + 2x2
x3

= â2
= â1
x4 =
3
0 =
0

Daraus liest man jetzt sofort die folgende LoĚsungsmenge des linearen Gleichungssystems ab:
L = {(x1 , x2 , â1, 3) â R4 | x1 + 2x2 = â2}
= {(â2 â 2x2 , x2 , â1, 3) | x2 â R} .
Bevor wir das GauĂâsche Eliminationsverfahren in voller Allgemeinheit betrachten, fuĚhren wir zunaĚchst den Begriff der Matrix ein.

70

Mathematik fuĚr Informatiker

Definition 3.1.3 (Matrizen). Es
Schema der Form
ďŁŤ
a11
ďŁŹ a21
ďŁŹ
ďŁŹ ..
ďŁ­ .
am1

M. Skutella

sei (K, +, Âˇ) ein KoĚrper und m, n â N. Ein
a12
a22
..
.

ÂˇÂˇÂˇ
ÂˇÂˇÂˇ

ďŁś
a1n
a2n ďŁˇ
ďŁˇ
.. ďŁˇ
. ďŁ¸

am2 Âˇ Âˇ Âˇ amn

mit aij â K fuĚr alle i â {1, 2, . . . , m} und j â {1, 2, . . . , n} heiĂt eine Matrix,
genauer eine m Ă n Matrix uĚber K. Dabei bezeichnet m die Anzahl der Zeilen der
Matrix und n die Anzahl der Spalten. Der erste Index des Eintrages aij gibt dann
die Zeilennummer des Eintrages an und der zweite Index die Spaltennummer.
Die Menge aller m Ă n Matrizen uĚber dem KoĚrper K wird mit K mĂn bezeichnet.
Definition 3.1.4 (Koeffizientenmatrix eines linearen Gleichungssystems). Die
Koeffizientenmatrix des linearen Gleichungssystems uĚber K
a11 x1
a21 x1
..
.

+ a12 x2
+ a22 x2
..
.

+ ...
+ ...

am1 x1 + am2 x2 + . . .

+ a1n xn
+ a2n xn
..
.

= b1
= b2
..
.

(3.2)

+ amn xn = bm

ist die Matrix
ďŁŤ

a11
ďŁŹ a21
ďŁŹ
ďŁŹ ..
ďŁ­ .

a12
a22
..
.

ÂˇÂˇÂˇ
ÂˇÂˇÂˇ

ďŁś
a1n
a2n ďŁˇ
ďŁˇ
.. ďŁˇ
. ďŁ¸

â

K mĂn .

am1 am2 Âˇ Âˇ Âˇ amn

Die erweiterte Matrix des linearen Gleichungssystems (3.2) ist die Matrix
ďŁś
ďŁŤ
a11 a12 Âˇ Âˇ Âˇ a1n b1
ďŁŹ a21 a22 Âˇ Âˇ Âˇ a2n b2 ďŁˇ
ďŁŹ
ďŁˇ
mĂ(n+1)
.
(3.3)
ďŁŹ ..
..
..
.. ďŁˇ â K
ďŁ­ .
.
.
. ďŁ¸
am1 am2 Âˇ Âˇ Âˇ amn bm
Definition 3.1.5 (Elementare Zeilenumformungen). Elementare Zeilenumformungen auf K mĂn sind Abbildungen der folgenden Form (fuĚr 1 â¤ k, ` â¤ m):
(i) Vk,` : K mĂn â K mĂn : Vertausche k-te und `-te Zeile.â
â
mĂn
mĂn
(ii) Ak,` (c) : K
âK
fuĚr c â K: Addiere das c-Fache der k-ten Zeile
â
zur `-ten Zeile.â

Kapiel 3: Lineare Algebra

M. Skutella

71

(iii) Mk (c) : K mĂn â K mĂn fuĚr c â K \ {0}: Multipliziere die k-te Zeile mit c.â
â
Durch elementare Zeilenumformungen kann man eine beliebige m Ă n Matrix auf sogenannte Stufenform bringen. Wir demonstrieren das zunaĚchst anhand
eines kleinen Beispiels.
Beispiel. Wir betrachten die erweiterte Matrix des linearen Gleichungssystems
mit vier Variablen und vier Zeilen von oben.
ďŁś
ďŁŤ
ďŁś
ďŁŤ
1 2 0 1 1 A1,2 (â1) 1 2 0 1 1
ďŁŹ1 2 2 3 5ďŁˇ A1,3 (â2) ďŁŹ0 0 2 2 4ďŁˇ
ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ
ďŁ­2 4 0 3 5ďŁ¸ ââ ďŁ­0 0 0 1 3ďŁ¸
0 0 3 2 3
0 0 3 2 3
M2 (1/2)
A2,4 (â3)

ââ

ďŁŤ

1
ďŁŹ0
ďŁŹ
ďŁ­0
0

2
0
0
0

ďŁś A3,1 (â1)
0 1
1
A3,2 (â1)
ďŁˇ
1 1
2 ďŁˇ A3,4 (1)
ââ
0 1
3ďŁ¸
0 â1 â3

ďŁŤ

1
ďŁŹ 0
ďŁŹ
ďŁ­ 0
0

2
0
0
0

0
1
0
0

ďŁś
0 â2
0 â1 ďŁˇ
ďŁˇ
1 3 ďŁ¸
0 0

Die nach der letzten Umformung entstandene Matrix hat Stufenform.
Definition 3.1.6. [Stufenform] Eine Matrix A â
sie wie folgt aussieht:
ďŁŤ
0ÂˇÂˇÂˇ0 1 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇâ 0
ďŁŹ 0ÂˇÂˇÂˇ0 0 ÂˇÂˇÂˇ 0 1 âÂˇÂˇÂˇâ 0
ďŁŹ
ďŁŹ
A = ďŁŹ 0ÂˇÂˇÂˇ0 0 ÂˇÂˇÂˇ 0 0 ÂˇÂˇÂˇ 0 1
ďŁŹ 0ÂˇÂˇÂˇ0 0 ÂˇÂˇÂˇ 0 0 ÂˇÂˇÂˇ 0 0
ďŁ­
..
..
..
..
..
..
.
.
.
.
.
.

K mĂn hat Stufenform, wenn
âÂˇÂˇÂˇâ
âÂˇÂˇÂˇâ
âÂˇÂˇÂˇâ
ÂˇÂˇÂˇ 0
..
.

0
0
0
1
..
.

âÂˇÂˇÂˇ
âÂˇÂˇÂˇ
âÂˇÂˇÂˇ
âÂˇÂˇÂˇ
..
.

ďŁś
ďŁˇ
ďŁˇ
ďŁˇ
ďŁˇ .
ďŁˇ
ďŁ¸

Dabei deuten die â-EintraĚge an, dass an diesen Stellen beliebige Skalare aus K
stehen duĚrfen.
Satz 3.1.7 (Stufenform). Jede Matrix A â K mĂn kann man durch elementare
Zeilenumformungen auf Stufenform bringen.
Beweis. Der Beweis des Satzes wird durch Induktion uĚber die Anzahl der Zeilen m
gefuĚhrt. Induktionsanfang: FuĚr m = 1 ist A = (a11 , a12 , . . . , a1n ). Sind alle a1i = 0
(1 â¤ i â¤ n), so ist A bereits in Stufenform. Wir koĚnnen also annehmen, dass nicht
alle a1i gleich Null sind. Es sei j1 := min{j | a1j 6= 0}. Wenden wir auf A die
Umformung M1 (aâ1
1j1 ) an, so erhaĚlt man die Matrix (0, . . . , 0, 1, â, . . . , â), die in
Stufenform ist. (Dabei steht die Eins an der j1 -ten Stelle.)
Induktionsschluss: Wir nehmen an, dass die Behauptung fuĚr ein beliebiges
aber fest gewaĚhltes m gilt. Wir betrachten jetzt eine Matrix A â K (m+1)Ăn .
EnthaĚlt die Matrix nur Nullen, so ist sie bereits in Stufenform. Andernfalls sei
j1 := min{j | âi : aij 6= 0} .

72

Mathematik fuĚr Informatiker

M. Skutella

Dann ist j1 also der kleinste Index einer Spalte, in der es einen von Null verschiedenen Eintrag aij1 gibt.
ďŁś
ďŁŤ
0ÂˇÂˇÂˇ0 â âÂˇÂˇÂˇâ
..
.. ďŁˇ
ďŁŹ ..
.
. ďŁˇ
ďŁŹ .
ďŁˇ
ďŁŹ
ďŁŹ0 Âˇ Âˇ Âˇ 0 â â Âˇ Âˇ Âˇ âďŁˇ
ďŁˇ
ďŁŹ
ďŁŹ0 Âˇ Âˇ Âˇ 0 aij1 â Âˇ Âˇ Âˇ âďŁˇ
ďŁˇ
ďŁŹ
ďŁŹ0 Âˇ Âˇ Âˇ 0 â â Âˇ Âˇ Âˇ âďŁˇ
ďŁŹ .
..
.. ďŁˇ
ďŁ­ ..
.
. ďŁ¸
0ÂˇÂˇÂˇ0 â âÂˇÂˇÂˇâ
Wende jetzt die elementare Zeilenumformung Mi (aâ1
ij1 ) und dann Ai,k (âakj1 ) fuĚr
alle k 6= i an. Wendet man dann noch die elementare Zeilenumformung Vi,1 an,
so erhaĚlt man eine Matrix der Form
ďŁŤ
ďŁś
0ÂˇÂˇÂˇ0 1 âÂˇÂˇÂˇâ
ďŁŹ0 Âˇ Âˇ Âˇ 0 0 â Âˇ Âˇ Âˇ âďŁˇ
ďŁŹ
ďŁˇ
(3.4)
ďŁŹ ..
..
.. ďŁˇ
ďŁ­ .
.
. ďŁ¸
0ÂˇÂˇÂˇ0 0 âÂˇÂˇÂˇâ
Es sei jetzt B â K mĂn die Matrix, die aus den letzten m Zeilen in (3.4) besteht.
Nach Induktionsannahme kann man B durch elementare Zeilenumformungen auf
Stufenform bringen. Eliminiert man dann noch die EintraĚge in der ersten Zeile,
die oberhalb der Stufen stehen, so erhaĚlt man damit aus (3.4) eine Matrix in
Stufenform.

Zur Illustration betrachten wir ein weiteres Beispiel.
Beispiel. Wir betrachten das folgende lineare Gleichungssystem uĚber dem endlichen KoĚrper mit sieben Elementen Z7 :
x3 = 4
3x1 + 6x2 + 6x3 = 2
x1 + 4x2
= 4
Um das Gleichungssystem zu loĚsen, stellen wir die erweiterte Matrix auf und
bringen sie durch elementare Zeilenumformungen auf Stufenform:
ďŁś
ďŁŤ
ďŁś
0 0 1 4
3 6 6 2 M1 (5)
V1,2
A (6)
ďŁ­3 6 6 2ďŁ¸ ââ
ďŁ­0 0 1 4ďŁ¸ 1,3
ââ
1 4 0 4
1 4 0 4
ďŁŤ

ďŁś
1 2 2 3 M2 (4)
V2,3
A2,1 (5)
ââ ďŁ­0 2 5 1ďŁ¸ ââ
0 0 1 4
ďŁŤ

ďŁŤ

ďŁś
1 2 2 3
ďŁ­0 0 1 4ďŁ¸
0 2 5 1

ďŁś
1 0 4 2 A3,1 (3)
A (1)
ďŁ­0 1 6 4ďŁ¸ 3,2
ââ
0 0 1 4
ďŁŤ

ďŁŤ

ďŁś
1 0 0 0
ďŁ­0 1 0 1ďŁ¸
0 0 1 4

Kapiel 3: Lineare Algebra

M. Skutella

73

Die letzte Matrix entspricht dem umgeformten linearen Gleichungssystem:
x1 = 0
x2 = 1
x3 = 4
Die eindeutige LoĚsung des linearen Gleichungssystems ist also x1 = 0, x2 = 1,
x3 = 4 und die LoĚsungsmenge ist damit einelementig.
Wir wissen jetzt also, dass man die erweiterte m Ă (n + 1) Matrix A (siehe (3.3)) eines gegebenen linearen Gleichungssystems (3.2) mit m Gleichungen
und n Unbekannten durch elementare Zeilenumformungen in Stufenform bringen
kann. Diese Matrix A0 in Stufenform entspricht nach Lemma 3.1.2 wieder einem
linearen Gleichungssystem, das zu dem gegebenen aĚquivalent ist.
Wir nehmen an, dass die Stufen in den Spalten j1 < j2 < Âˇ Âˇ Âˇ < jr auftreten;
die Spalte ji , i = 1, . . . , r, ist also die Spalte von A0 , in der die i-te Zeile den ersten
Eintrag ungleich Null (genauer gesagt: eine Eins) enthaĚlt. Wir unterscheiden nun
zwei FaĚlle. Ist jr = n+1, dann lautet die r-te Gleichung des umgeformten linearen
Gleichungssystems
0x1 + 0x2 + . . . + 0xn = 1 ,
so dass das Gleichungssystem offenbar keine LoĚsung besitzt.
Andernfalls (wenn jr â¤ n) lautet das umgeformte Gleichungssystem:
n
X

xj1 +

a01j xj = a01,n+1

j=j1 +1
j6=j2 ,...,jr

n
X

xj2 +

a02j xj = a02,n+1

j=j2 +1
j6=j3 ,...,jr

..
.
xjr +

..
.
n
X

..
.

a0rj xj = a0r,n+1

j=jr +1

0 = 0
..
..
.
.
0 = 0
Alle xi auĂer xj1 , . . . , xjr sind frei waĚhlbar; aus deren Wahl ergeben sich dann die

74

Mathematik fuĚr Informatiker

M. Skutella

restlichen xj1 , . . . , xjr wie folgt:
xj1 :=

a01,n+1

â

n
X

a01j xj

j=j1 +1
j6=j2 ,...,jr

xj2 :=

a02,n+1

â

n
X

a02j xj

j=j2 +1
j6=j3 ,...,jr

..
.

..
.

xjr :=

a0r,n+1

..
.
â

n
X

a0rj xj

j=jr +1

Damit haben wir also eine Beschreibung der LoĚsungsmenge des linearen Gleichungssystems.
Insbesondere ist das lineare Gleichungssystem genau dann eindeutig loĚsbar,
wenn {j1 , . . . , jr } = {1, . . . , n}, also falls r = n gilt. Da die Anzahl der Stufen r
durch die Anzahl der Zeilen m beschraĚnkt ist, muss also n â¤ m sein, falls das
lineare Gleichungssystem eindeutig loĚsbar ist.
Korollar 3.1.8. Falls das lineare Gleichungssystem (3.2) eine eindeutige LoĚsung
besitzt, so gilt n â¤ m.
Beispiel. Wir betrachten das folgende lineare Gleichungssystem uĚber dem endlichen KoĚrper mit drei Elementen Z3 :
x1 + 2x2 +
2x1 +
Wir formen die
ďŁŤ
1
ďŁ­0
2

x2

x3 + x4 + 2x5 = 1
2x3 + x4 + 2x5 = 2
+ x4
= 1

erweiterte Matrix in Stufenform um:
ďŁś
ďŁŤ
ďŁś
2 1 1 2 1 A13 (1) 1 2 1 1 2 1
M2 (2)
0 2 1 2 2ďŁ¸ ââ ďŁ­0 0 1 2 1 1ďŁ¸
1 0 1 0 1
0 0 1 2 2 2

A21 (2)
A23 (2)

ďŁś
ďŁŤ
ďŁś
1 2 0 2 1 0 A31 (2)
1 2 0 2 0 2
A32 (2)
ââ ďŁ­0 0 1 2 1 1ďŁ¸ ââ ďŁ­ 0 0 1 2 0 0 ďŁ¸
0 0 0 0 1 1
0 0 0 0 1 1
ďŁŤ

Das zugehoĚrige umgeformte lineare Gleichungssystem ist
x1 + 2x2

+ 2x4
x3 + 2x4
x5

= 2
= 0
= 1

Kapiel 3: Lineare Algebra

M. Skutella

75

Die LoĚsungsmenge ist also

L = (2 + x2 + x4 , x2 , x4 , x4 , 1) | x2 , x4 â Z3

.

Die Anzahl der verschiedenen LoĚsungen ist also 9.
Definition 3.1.9 (Homogene lineare Gleichungssysteme). Das lineare Gleichungssystem (3.2) heiĂt homogen, wenn b1 = b2 = Âˇ Âˇ Âˇ = bm = 0. Ein homogenes lineares
Gleichungssystem hat immer eine LoĚsung, naĚmlich x1 = x2 = Âˇ Âˇ Âˇ = xn = 0. Diese
LoĚsung (x1 , . . . , xn ) = (0, . . . , 0) heiĂt triviale LoĚsung.
Korollar 3.1.10. Ist m = n und hat das homogene lineare Gleichungssystem
a11 x1
a21 x1
..
.

+ a12 x2
+ a22 x2
..
.

+ ...
+ ...

am1 x1 + am2 x2 + . . .

+ a1n xn
+ a2n xn
..
.

= 0
= 0
..
.

+ amn xn = 0

nur die triviale LoĚsung, so hat (3.2) fuĚr jede rechte Seite b1 , . . . , bm eine eindeutig
bestimmte LoĚsung.
Beweis. Wir betrachten die erweiterte Matrix des homogenen linearen Gleichungssystems:
ďŁŤ
ďŁś
a11 a12 Âˇ Âˇ Âˇ a1m 0
ďŁŹ a21 a22 Âˇ Âˇ Âˇ a2m 0ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ ..
..
..
.. ďŁˇ .
.
.
ďŁ­ .
.
.
.
.ďŁ¸
am1 am2 Âˇ Âˇ Âˇ amm 0
Da das homogene lineare Gleichungssystem nach Voraussetzung eine eindeutige LoĚsung besitzt, muss die durch elementare Zeilenumformungen entstehende
Matrix in Stufenform wie folgt aussehen:
ďŁŤ
ďŁś
1 0 ÂˇÂˇÂˇ 0 0
.. .. ďŁˇ
ďŁŹ
. .ďŁˇ
ďŁŹ0 1
ďŁŹ.
ďŁˇ .
.
. . 0 ... ďŁ¸
ďŁ­ ..
0 ÂˇÂˇÂˇ 0 1 0
Bringt man durch dieselben elementaren Zeilenumformungen die erweiterte Matrix
ďŁŤ
ďŁś
a11 a12 Âˇ Âˇ Âˇ a1m b1
ďŁŹ a21 a22 Âˇ Âˇ Âˇ a2m b2 ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ ..
..
..
.. ďŁˇ
.
.
ďŁ­ .
.
.
.
. ďŁ¸
am1 am2 Âˇ Âˇ Âˇ amm bm

76

Mathematik fuĚr Informatiker

M. Skutella

auf Stufenform, so muss diese also wie folgt aussehen (mit b01 , . . . , b0m â K):
ďŁŤ

1

ďŁŹ
ďŁŹ0
ďŁŹ.
ďŁ­ ..
0

ďŁś
Âˇ Âˇ Âˇ 0 b01
.. 0 ďŁˇ
1
. b2 ďŁˇ
. ďŁˇ .
...
0 .. ďŁ¸
Âˇ Âˇ Âˇ 0 1 b0m
0

Damit ist also (x1 , . . . , xm ) = (b01 , . . . , b0m ) die eindeutige LoĚsung des linearen
Gleichungssystems mit rechter Seite b1 , . . . , bm .


3.1.2

Matrizenrechnung

Auf der Menge der m Ă n Matrizen uĚber einem KoĚrper K definieren wir eine
Addition und eine skalare Multiplikation mit Elementen aus dem KoĚrper K.
Definition 3.1.11 (Matrixaddition und Multiplikation mit Skalaren). Es seien m, n â N und A, B â K mĂn . FuĚr i = 1, . . . , m und j = 1, . . . , n bezeichnen
wir den Eintrag in der i-ten Zeile und j-ten Spalte der Matrix A mit Aij . Analog
seien Bij die EintraĚge der Matrix B. Wir definieren eine VerknuĚpfung (Addition)
+â auf K mĂn wie folgt:
â
(A + B)ij := Aij + Bij

fuĚr i = 1, . . . , m und j = 1, . . . , n.

Man erhaĚlt also die EintraĚge der Matrix A + B â K mĂn durch Addition der EintraĚge der Matrizen A und B. Weiterhin definieren wir die skalare Multiplikation
Âˇâ wie folgt. FuĚr s â K und A â K mĂn sei
â
(s Âˇ A)ij := s Âˇ Aij

fuĚr i = 1, . . . , m und j = 1, . . . , n.

Beispiel. Es sei K = R der KoĚrper der
Matrizen uĚber R:



1 2 3
0 1
+
4 5 6
1 â1

reellen Zahlen. Wir betrachten 2 Ă 3



0
1 3 3
=
,
1
5 4 7






1 2 3
2 4 6
2Âˇ
=
.
4 5 6
8 10 12
Das lineare Gleichungssystem
a11 x1
a21 x1
..
.

+ a12 x2
+ a22 x2
..
.

+ ...
+ ...

am1 x1 + am2 x2 + . . .

+ a1n xn
+ a2n xn
..
.

= b1
= b2
..
.

+ amn xn = bm

Kapiel 3: Lineare Algebra

M. Skutella

77

koĚnnen wir jetzt alternativ wie folgt schreiben:
ďŁŤ ďŁś
ďŁŤ
ďŁś
ďŁŤ
ďŁś
ďŁś
b1
a1n
a12
a11
ďŁŹ b2 ďŁˇ
ďŁŹ a2n ďŁˇ
ďŁŹ a22 ďŁˇ
ďŁŹ a21 ďŁˇ
ďŁŹ ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ
ďŁˇ
x1 Âˇ ďŁŹ .. ďŁˇ + x2 Âˇ ďŁŹ .. ďŁˇ + Âˇ Âˇ Âˇ + xn Âˇ ďŁŹ .. ďŁˇ = ďŁŹ .. ďŁˇ .
ďŁ­ . ďŁ¸
ďŁ­ . ďŁ¸
ďŁ­ . ďŁ¸
ďŁ­ . ďŁ¸
bm
amn
am2
am1
ďŁŤ

Noch kuĚrzer schreibt man dafuĚr
ďŁŤ ďŁś
ďŁŤ ďŁś
ďŁŤ
ďŁś
b1
x1
a11 a12 Âˇ Âˇ Âˇ a1n
ďŁŹ b2 ďŁˇ
ďŁŹ x2 ďŁˇ
ďŁŹ a21 a22 Âˇ Âˇ Âˇ a2n ďŁˇ
ďŁŹ ďŁˇ
ďŁŹ ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ ..
..
.. ďŁˇ Âˇ ďŁŹ .. ďŁˇ = ďŁŹ .. ďŁˇ .
ďŁ­ . ďŁ¸
ďŁ­.ďŁ¸
ďŁ­ .
.
. ďŁ¸
bm
xn
am1 am2 Âˇ Âˇ Âˇ amn
Letztere Schreibweise erklaĚrt sich durch die folgende allgemeine Definition der
Matrixmultiplikation.
Definition 3.1.12 (Matrixmultiplikation). Es seien `, m, n â N und A â K mĂn ,
B â K nĂ` . Dann ist das Produkt A Âˇ B â K mĂ` wie folgt definiert:
(A Âˇ B)ij := Ai1 Âˇ B1j + Ai2 Âˇ B2j + Âˇ Âˇ Âˇ + Ain Âˇ Bnj =

n
X

Aik Âˇ Bkj .

k=1

Zur Berechnung des Eintrages in der Zeile i und Spalte j der Produktmatrix AÂˇB
benoĚtigt man also die gesamte Zeile i von A sowie die gesamte Spalte j von B.
Bemerkung. Man beachte, dass das Produkt zweier Matrizen A und B nur dann
definiert ist, wenn die Spaltenzahl von A gleich der Zeilenzahl von B ist.
Beispiel. Wir betrachten Matrizen uĚber dem KoĚrper der rationalen Zahlen Q:




ďŁŤ ďŁś

 


1
1
Âˇ
1
+
2
Âˇ
1
+
3
Âˇ
(â1)
0
1 2 3
=
,
Âˇ ďŁ­1ďŁ¸ =
4 Âˇ 1 + 5 Âˇ 1 + 6 Âˇ (â1)
3
4 5 6
â1
ďŁŤ
ďŁś



1 0 0
0
2
â3
1 2 3
.
Âˇ ďŁ­1 1 0ďŁ¸ =
3 5 â6
4 5 6
â1 0 â1

Lemma 3.1.13 (Distributivgesetz der Matrixrechnung). Ist A â K mĂn und B, C â
K nĂq , dann gilt
A Âˇ (B + C) = A Âˇ B + A Âˇ C .

78

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Nach Definition der Matrixmultiplikation und -addition gilt fuĚr 1 â¤ i â¤
m und 1 â¤ j â¤ q:
n
n
X
X

A Âˇ (B + C) ij =
Aik Âˇ (B + C)kj =
Aik Âˇ (Bkj + Ckj )
k=1

=

n
X

(Aik Âˇ Bkj + Aik Âˇ Ckj ) =

k=1

k=1
n
X

n
X

k=1

k=1

Aik Âˇ Bkj +

Aik Âˇ Ckj

= (A Âˇ B)ij + (A Âˇ C)ij = (A Âˇ B + A Âˇ C)ij .
Damit ist die Behauptung bewiesen.



Satz 3.1.14 (Ring der n Ă n Matrizen). Die Menge K nĂn der n Ă n Matrizen
uĚber einem KoĚrper K bilden zusammen mit der oben definierten Addition und
Multiplikation einen nicht-kommutativen Ring mit Eins.
Beweisskizze. Es ist leicht zu sehen, dass (K nĂn , +) eine kommutative Gruppe
ist. Das neutrale Element der Addition (Nullelement) ist die Nullmatrix, deren
EintraĚge alle Null sind. Man kann nachrechnen, dass die Matrixmultiplikation
auf K nĂn assoziativ ist und gemeinsam mit der Addition das Distributivgesetz
erfuĚllt (siehe Lemma 3.1.13). Das neutrale Element der Matrixmultiplikation
ist die Einheitsmatrix En , die Einsen auf der Diagonalen und sonst nur Nullen
enthaĚlt:
ďŁŤ
ďŁś
1 0 ÂˇÂˇÂˇ 0
. . . .. ďŁˇ
ďŁŹ
.ďŁˇ
ďŁŹ0 1
En := ďŁŹ . .
ďŁˇ â K nĂn .
.
. . 0ďŁ¸
ďŁ­ .. . .
0 ÂˇÂˇÂˇ 0 1
Wir uĚberlassen alle weiteren Beweisdetails dem Leser.



Wir zeigen anhand eines einfachen Beispiels, dass die Matrixmultiplikation
auf K nĂn nicht kommutativ ist.
Beispiel. Es gilt







1 0
0 1
0 1
Âˇ
=
,
0 0
0 0
0 0








0 1
1 0
0 0
Âˇ
=
.
0 0
0 0
0 0

umgekehrt jedoch

Kapiel 3: Lineare Algebra

3.2

M. Skutella

79

VektorraĚume

In diesem Abschnitt beschaĚftigen wir uns mit VektorraĚumen uĚber einem beliebigen KoĚrper K. VektorraĚume bilden die zentrale Struktur in der linearen Algebra.
Es stellt sich heraus, dass beispielsweise die LoĚsungsmengen der im vorherigen
Abschnitt diskutierten linearen Gleichungssysteme uĚber K mit n Unbekannten
einen engen Bezug zu sogenannten TeilraĚumen des Vektorraums K n aufweisen.
Neben der Definition und Beschreibung von VektorraĚumen diskutieren wir weitere wichtige Konzepte in diesem Zusammenhang. Dazu gehoĚren Linearkombinationen, Erzeugendensysteme, die lineare AbhaĚngigkeit von Vektoren, Basen von
VektorraĚumen und schlieĂlich der Dimensionsbegriff.

3.2.1

Definition

Wir beginnen mit einer axiomatischen Definition des Begriffs Vektorraum.
Definition 3.2.1 (K-VektorraĚume). Es sei (K, +, Âˇ) ein KoĚrper. Ein K-Vektorraum
ist eine Menge V zusammen mit Abbildungen
+: V ĂV âV
Âˇ: K ĂV âV

(v, w) 7â v + w ,
(s, v) 7â s Âˇ v ,

fuĚr die die folgenden Regeln gelten:
(i) (V, +) ist kommutative Gruppe; das neutrale Element der Addition ist der
Nullvektor 0. Das inverse Element zu v wird mit âv bezeichnet.
(ii) 1Âˇv = v fuĚr alle v â V . (Dabei bezeichnet 1 das Einselement des KoĚrpers K.)
(iii) (s Âˇ s0 ) Âˇ v = s Âˇ (s0 Âˇ v) fuĚr alle s, s0 â K, v â V .
(iv) (s + s0 ) Âˇ v = (s Âˇ v) + (s0 Âˇ v) fuĚr alle s, s0 â K, v â V .
(v) s Âˇ (v + w) = (s Âˇ v) + (s Âˇ w) fuĚr alle s â K, v, w â V .
Die Elemente von V heiĂen Vektoren 1 . Ist (K, +, Âˇ) kein KoĚrper sondern nur
ein Ring mit Eins, so spricht man statt von einem K-Vektorraum von einem
K-Modul.
Beispiele.
(i) FuĚr m, n â N ist die Menge K mĂn der m Ă n Matrizen uĚber K mit der
Matrixaddition und der Skalarmultiplikation (siehe Definition 3.1.11) ein KVektorraum.
1

Zur besseren Unterscheidung von Skalaren drucken wir Vektoren meistens in Fettschrift.

80

Mathematik fuĚr Informatiker

M. Skutella

(ii) Als Spezialfall von (i) ist K n := K nĂ1 mit Addition und Skalarmultiplikation ein K-Vektorraum. Addition und Skalarmultiplikation sehen in diesem
Spezialfall wie folgt aus:
ďŁŤ
ďŁś
ďŁŤ ďŁś
ďŁŤ
ďŁś
ďŁŤ ďŁś ďŁŤ ďŁś
s Âˇ x1
x1
x1 + y1
y1
x1
ďŁŹ s Âˇ x2 ďŁˇ
ďŁŹ x2 ďŁˇ
ďŁŹ x2 + y2 ďŁˇ
ďŁŹ x2 ďŁˇ ďŁŹ y2 ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ ďŁˇ ďŁŹ ďŁˇ
ďŁŹ .. ďŁˇ + ďŁŹ .. ďŁˇ = ďŁŹ .. ďŁˇ , s Âˇ ďŁŹ .. ďŁˇ = ďŁŹ .. ďŁˇ .
ďŁ­ . ďŁ¸
ďŁ­.ďŁ¸
ďŁ­ . ďŁ¸
ďŁ­.ďŁ¸ ďŁ­.ďŁ¸
s Âˇ xn
xn
xn + yn
yn
xn
(iii) FuĚr K = R und n = 2 kann man sich den Vektorraum R2 als Ebene mit
uĚblicher Vektoraddition und skalarer Multiplikation
vorstellen. Wir veran
schaulichen das fuĚr die beiden Vektoren x = xx12 und y = yy12 :

x+y

x2 + y2
y
y2

3
2

Âˇ x2
x2

3
2

x
y1 x1

3
2

Âˇ x1

Âˇx

x1 + y1

Entsprechend kann man den Vektorraum R3 mit dem uns gut vertrauten
dreidimensionalen Raum assoziieren.
(iv) Es sei M eine beliebige Menge und K ein beliebiger KoĚrper. Dann wird die
Menge K M der Abbildungen von M nach K mit der folgenden Addition
und Skalarmultiplikation zu einem Vektorraum. FuĚr f, g â K M und s â K
definieren wir
(f + g)(x) := f (x) + g(x)
(s Âˇ f )(x) := s Âˇ f (x)

fuĚr alle x â M ,
fuĚr alle x â M .

Der Nullvektor dieses Vektorraums ist die Nullabbildung, d.h. x 7â 0 fuĚr
alle x â M .
(v) Es sei wie im letzten Beispiel M eine Menge und K ein KoĚrper. Dann ist
die Menge
K (M ) := {f : M â K | f (x) 6= 0 nur fuĚr endlich viele x â M }

Kapiel 3: Lineare Algebra

M. Skutella

81

mit der im letzten Beispiel definierten Addition und Skalarmultiplikation ein
K-Vektorraum. Dazu beachte man, dass fuĚr f, g â K (M ) gilt, dass auch f +
g â K (M ) . Das bedeutet, dass K (M ) abgeschlossen ist unter der uĚblichen
Addition von Funktionen. Dasselbe gilt fuĚr die Skalarmultiplikation.
Wir halten die folgenden allgemeinguĚltigen Rechenregeln in VektorraĚumen als
Lemma fest.
Lemma 3.2.2 (Rechenregeln in VektorraĚumen). Es sei (K, +, Âˇ) ein KoĚrper
und (V, +, Âˇ) ein K-Vektorraum. Dann gilt:
(i) 0 Âˇ v = 0 fuĚr alle v â V .
(ii) s Âˇ 0 = 0 fuĚr alle s â K.
(iii) FuĚr s â K und v â V gilt: s Âˇ v = 0

ââ

(s = 0 â¨ v = 0) .

(iv) (âs) Âˇ v = â(s Âˇ v) fuĚr alle s â K, v â V .
Beweis. Zu (i):
0 Âˇ v = 0 Âˇ v + 0 = 0 Âˇ v + (0 Âˇ v + (â(0 Âˇ v)))
= (0 Âˇ v + 0 Âˇ v) + (â(0 Âˇ v)) = (0 + 0) Âˇ v + (â(0 Âˇ v))
= 0 Âˇ v + (â(0 Âˇ v)) = 0 .
Zu (ii):
s Âˇ 0 = s Âˇ 0 + 0 = s Âˇ 0 + (s Âˇ 0 + (â(s Âˇ 0)))
= (s Âˇ 0 + s Âˇ 0) + (â(s Âˇ 0)) = s Âˇ (0 + 0) + (â(s Âˇ 0))
= s Âˇ 0 + (â(s Âˇ 0)) = 0 .
Zu (iii): Die Implikation â=â folgt offenbar aus (i) und (ii). Wir muĚssen also
â
noch die Implikation =ââ zeigen. Es sei also sÂˇv = 0. Wir nehmen an, dass s 6= 0
â
gilt (andernfalls sind wir fertig) und muĚssen zeigen, dass dann v = 0:
v = 1 Âˇ v = (sâ1 Âˇ s) Âˇ v = sâ1 Âˇ (s Âˇ v) = sâ1 Âˇ 0 = 0 .
Zu (iv):
(âs) Âˇ v = (âs) Âˇ v + 0 = (âs) Âˇ v + (s Âˇ v + (â(s Âˇ v)))
= (âs + s) Âˇ v + (â(s Âˇ v)) = 0 Âˇ v + (â(s Âˇ v)) = â (s Âˇ v) .
Damit ist der Beweis abgeschlossen.



82

3.2.2

Mathematik fuĚr Informatiker

M. Skutella

TeilraĚume

AĚhnlich wie wir bei Gruppen und Ringen Untergruppen und Unterringe eingefuĚhrt haben, kann man auch bei VektorraĚumen Teilmengen betrachten, die
selbst wieder VektorraĚume sind.
Definition 3.2.3 (TeilraĚume). Es sei (K, +, Âˇ) ein KoĚrper und (V, +, Âˇ) ein KVektorraum. Ist U â V mit
(i) U 6= â,
(ii) v, w â U

(v + w) â U ,

=â

(iii) s â K, v â U

=â

(s Âˇ v) â U ,

dann bildet U einen Teilraum oder Untervektorraum von V .
Bemerkung. Man uĚberzeugt sich leicht von der Tatsache, dass ein Teilraum U
eines K-Vektorraumes (V, +, Âˇ) zusammen mit der EinschraĚnkung der Addition +|U ĂU und Skalarmultiplikation Âˇ|KĂU selbst K-Vektorraum ist.
Lemma 3.2.4 (Charakterisierung von TeilraĚumen). Es sei (V, +, Âˇ) ein K-Vektorraum und U â V . Die Teilmenge U ist genau dann ein Teilraum von V , wenn
die folgenden beiden Bedingungen erfuĚllt sind:
(i) 0 â U ,
(ii) s â K, v, w â U

((s Âˇ v) + w) â U .

=â

Beweis. Ist U ein Teilraum von V , so gibt es ein Element v â U und es gilt 0 =
(0 Âˇ v) â U , also (i). Ist s â K und v, w â U , so gilt (s Âˇ v) â U und damit
auch ((s Âˇ v) + w) â U , also (ii).
Gelten umgekehrt die Eigenschaften (i) und (ii), so ist U 6= â, da 0 â U .
FuĚr v, w â V gilt v + w = (1 Âˇ v) + w â U . SchlieĂlich gilt fuĚr s â K und v â U ,
dass s Âˇ v = (s Âˇ v) + 0 â U . Nach Definition 3.2.3 ist U damit also ein Teilraum
von V .

Beispiele.
(i) Die Teilmenge {0} von V und V selbst sind TeilraĚume von V . Man nennt
sie auch die trivialen TeilraĚume. FuĚr v 6= 0 ist {v} kein Teilraum von V .
(ii) Es sei
ďŁŤ

a11
ďŁŹ a21
ďŁŹ
A := ďŁŹ ..
ďŁ­ .

a12
a22
..
.

ÂˇÂˇÂˇ
ÂˇÂˇÂˇ

ďŁś
a1n
a2n ďŁˇ
ďŁˇ
mĂn
.. ďŁˇ â K
ďŁ¸
.

am1 am2 Âˇ Âˇ Âˇ amn

Kapiel 3: Lineare Algebra

M. Skutella

83

und U := {x â K n | A Âˇ x = 0} â K n die LoĚsungsmenge des homogenen
linearen Gleichungssystems
a11 x1
a21 x1
..
.

+ a12 x2
+ a22 x2
..
.

+ ...
+ ...

am1 x1 + am2 x2 + . . .

+ a1n xn
+ a2n xn
..
.

= 0
= 0
..
.

+ amn xn = 0

Dann ist U ein Teilraum von K n .
(iii) Es sei A â K mĂn wie im letzten Beispiel und b â K m \ {0}. Die LoĚsungsmenge U 0 := {x â K n | A Âˇ x = b} des inhomogenen linearen Gleichungssystems A Âˇ x = b ist kein Teilraum von K n . Denn offenbar wird Bedingung (i)
aus Lemma 3.2.4 verletzt, da A Âˇ 0 = 0 6= b ist.
(iv) Es sei V = RR der R-Vektorraum der Abbildungen von R nach R. Dann
ist U := {f : R â R | f (x) = f (x + 2Ď)âx â R} ein Teilraum von V (der
Teilraum der 2Ď-periodischen Abbildungen).
Es sei nun a â R. Dann ist auch Ua := {f : R â R | f (a) = 0} ein Teilraum
von V .
Andererseits ist U 0 := {f : R â R | f (0) = 1} kein Teilraum von V , da der
Nullvektor (Nullfunktion) nicht in U 0 enthalten ist.
Auch U 00 := {f : R â R | f (0) = 0 â¨ f (1) = 0} ist kein Teilraum von V ,
denn die Funktion f1 : R â R mit f1 (x) := x und die Funktion f2 : R â R
mit f2 (x) := x â 1 sind beide in U 00 , nicht jedoch ihre Summe f1 + f2 . Man
beachte, dass U 00 die Vereinigung der beiden TeilraĚume U0 und U1 ist. Die
Vereinigung von zwei TeilraĚumen ist also im Allgemeinen kein Teilraum.
Aufgrund ihrer hohen Bedeutung halten wir die in Beispiel (ii) gemachte Beobachtung als Satz fest.
Satz 3.2.5. Ist A â K mĂn , so ist die LoĚsungsmenge U := {x â K n | A Âˇ x =
0} des homogenen linearen Gleichungssystems A Âˇ x = 0 ein Teilraum des KVektorraums K n .
Beweis. Es gilt 0 â U , da A Âˇ 0 = 0. FuĚr s â K und x, y â U gilt
A Âˇ ((s Âˇ x) + y) = s Âˇ (A Âˇ x) + A Âˇ y = s Âˇ 0 + 0 = 0 .
Die Aussage des Satzes folgt also mit Lemma 3.2.4.



Wir diskutieren als NaĚchstes TeilraĚume, die aus anderen TeilraĚumen durch
Schnittbildung und Addition entstehen.

84

Mathematik fuĚr Informatiker

M. Skutella

Lemma 3.2.6. Es sei (V, +, Âˇ) ein K-Vektorraum und U1 , U2 zwei TeilraĚume
von V . Dann sind auch
U1 âŠ U2

und

U1 + U2 := {u1 + u2 | u1 â U1 und u2 â U2 }

TeilraĚume von V . Ist I eine beliebige Indexmenge
und ist fuĚr alle i â I die
T
Menge Ui ein Teilraum von V , so ist auch iâI Ui ein Teilraum von V .
Beweis. Wir beweisen zunaĚchst die letzte Behauptung des Lemmas mit Hilfe
von Lemma
T 3.2.4. Da Ui einT Teilraum von V ist, gilt 0 â Ui fuĚr alle i â I.
Also 0 â iâI Ui . FuĚr x, y â iâI Ui gilt offenbar x, y â Ui fuĚr alle i â I.
T Folglich
gilt fuĚr s â K dann s Âˇ x + y â Ui fuĚr alle i â I und damit s Âˇ x + y â iâI Ui .
Es bleibt zu zeigen, dass U1 +U2 ein Teilraum von V ist. Da 0 â U1 und 0 â U2
gilt 0 = 0 + 0 â U1 + U2 . Es sei nun s â K und x, y â U1 + U2 . Dann gibt
es u1 , u01 â U1 und u2 , u02 â U2 mit x = u1 + u2 und y = u01 + u02 . Damit gilt dann
s Âˇ x + y = s Âˇ (u1 + u2 ) + (u01 + u02 )
= (s Âˇ u1 + u01 ) + (s Âˇ u2 + u02 ) â U1 + U2 .
Damit ist der Beweis fertig.



Beispiel. Es sei V ein K-Vektorraum. FuĚr v â V definieren wir
hvi := {s Âˇ v | s â K} .
Dann ist hvi ein Teilraum von V . Man nennt ihn den von v erzeugten
Teilraum.

x
2
Im R-Vektorraum R kann man sich den von einem Vektor y 6= 0 erzeugten
Teilraum als die
 Punkte auf der eindeutigen Geraden durch den Nullpunkt und
x
den Punkt y vorstellen:

x0
y0

x0



h

y0
y

x
y



x

h

x0
y0



i

x
y



i

Kapiel 3: Lineare Algebra

M. Skutella

85

Dann ist
 
 0
  
 0

x
x
x
x
0
0
h
i+h 0 i =
sÂˇ
+s Âˇ
| s, s â R .
y
y
y
y0
Anschaulich uĚberzeugt man sich leicht davon, dass dieser Teilraum von R2 der
ganze Vektorraum R2 ist.

3.2.3

Linearkombinationen und Erzeugendensysteme

Eine wichtige Rolle im Zusammenhang mit VektorraĚumen und TeilraĚumen spielen
Linearkombinationen von Vektoren. Das sind neue Vektoren, die durch Skalarmultiplikation und Vektoraddition aus gegebenen Vektoren entstehen. Mit Hilfe
dieser Linearkombinationen kann man einen Teilraum von Innen herausâ erzeuâ
gen.
Definition 3.2.7 (Linearkombinationen, Erzeugnisse). Es sei (V, +, Âˇ) ein KVektorraum mit Vektoren u1 , . . . , un â V . Dann heiĂt der Vektor v â V Linearkombination von {u1 , . . . , un }, wenn es s1 , . . . , sn â K gibt mit
v = s1 Âˇ u1 + Âˇ Âˇ Âˇ + sn Âˇ un .
Ist M â V eine Teilmenge von V , so definieren wir das Erzeugnis von M als
hM i := {v â V | v ist Linearkombination endlich vieler Vektoren aus M }
)
( n
X
si Âˇ vi n â N, si â K und vi â M fuĚr i = 1, . . . , n .
=
i=1

Das Erzeugnis der leeren Menge soll nach Definition der triviale Teilraum von V
sein, der nur aus dem Nullvektor besteht, also hâi := {0}.
Lemma 3.2.8. Es sei (V, +, Âˇ) ein K-Vektorraum und M â V eine beliebige
Teilmenge von V . Dann ist das Erzeugnis hM i von M ein Teilraum von V .
Beweis. Ist M = â, so ist nach Definition 0 â hM i. Andernfalls sei v â M ; dann
ist 0 = 0 Âˇ v â hM i. Es seien nun v, v0 â hM i. Dann gilt
v =

n
X

si Âˇ xi

mit n â N, si â K und xi â M fuĚr i = 1, . . . , n,

s0i Âˇ x0i

mit n0 â N, s0i â K und x0i â M fuĚr i = 1, . . . , n0 .

i=1
0

0

v =

n
X
i=1

Folglich gilt fuĚr t â K
0

tÂˇv+v =

n
X
i=1

0

(t Âˇ si ) Âˇ xi +

n
X
i=1

s0i Âˇ x0i .

86

Mathematik fuĚr Informatiker

M. Skutella

Die rechte Seite ist eine Linearkombination endlich vieler Vektoren aus M und
damit in hM i enthalten. Die Behauptung folgt also mit Lemma 3.2.4.

Bemerkung.
(i) FuĚr M â V heiĂt U := hM i auch der von M erzeugte Teilraum von V .
Die Menge M heiĂt Erzeugendensystem von U . Man uĚberzeugt sich leicht
davon, dass U der kleinste Teilraum (bezuĚglich Mengeninklusion) ist, der M
enthaĚlt.
(ii) Ist die Menge M endlich, also M = {v1 , . . . , vn } mit n â N, so sagen wir,
dass U := hM i endlich erzeugt ist. Wir schreiben auch
hM i = h{v1 , . . . , vn }i = hv1 , . . . , vn i
)
( n
X
=
si Âˇ vi si â K fuĚr i = 1, . . . , n .
i=1

Insbesondere schreiben wir fuĚr v â V
hvi = {s Âˇ v | s â K} .
Beispiele.
 1  â1  1 
(i) Es sei V = R2 und M  =
, 1 , 0 . Dann ist hM i = R2 , denn
1
ein beliebiger Vektor xy â R2 kann wie folgt als Linearkombination der
Elemente von M geschrieben werden:
 
 
 
 
x
1
â1
1
= xÂˇ
+ (y â x) Âˇ
+ (y â x) Âˇ
.
y
1
1
0
 
 1
Damit ist 11 , â1
, 0 also ein Erzeugendensystem des Vektorraums R2
1
und R2 ist folglich endlich erzeugt.
  
Bereits die kleinere Menge  11 , 10
ist ein Erzeugendensystem von R2 ,
x
2
da ein beliebiger Vektor y â R geschrieben werden kann als
 
 
 
x
1
1
= yÂˇ
+ (x â y) Âˇ
.
y
1
0
(ii) Wir betrachten den K-Vektorraum K n . FuĚr i = 1, . . . , n sei ei der Vektor,
dessen i-ter Eintrag 1 ist und alle anderen EintraĚge 0, d.h.
ďŁŤ ďŁś
0
ďŁŹ .. ďŁˇ
ďŁŹ.ďŁˇ
ďŁŹ ďŁˇ
(
ďŁŹ0ďŁˇ
1 falls j = i,
ďŁŹ ďŁˇ
ei = ďŁŹ1ďŁˇ â i
(ei )j =
ďŁŹ ďŁˇ
0 sonst.
ďŁŹ0ďŁˇ
ďŁŹ.ďŁˇ
ďŁ­ .. ďŁ¸
0

Kapiel 3: Lineare Algebra

M. Skutella

87

Der Vektor ei heiĂt i-ter Einheitsvektor. Dann ist {e1 , . . . , en } ein Erzeugendensystem von K n , also K n = he1 , . . . , en i, denn
ďŁŤ ďŁś
x1
ďŁŹ .. ďŁˇ
fuĚr alle x1 , . . . , xn â K.
ďŁ­ . ďŁ¸ = x 1 Âˇ e1 + Âˇ Âˇ Âˇ + x n Âˇ en
xn
Folglich ist der Vektorraum K n endlich erzeugt.
(iii) Es sei M eine beliebige Menge. In Verallgemeinerung des letzten Beispiels
definieren wir fuĚr y â M den Einheitsvektor ey â K (M ) durch
(
1 falls x = y,
ey (x) :=
0 sonst.
Dann ist die Menge {ey | y â M } ein Erzeugendensystem von K (M ) . Betrachte eine beliebige Funktion f â K (M ) , die nur an den Stellen y1 , . . . , yn â
M einen Wert ungleich 0 annimmt. Dann gilt
f = f (y1 ) Âˇ ey1 + Âˇ Âˇ Âˇ + f (yn ) Âˇ eyn .
Wir betrachten Erzeugendensysteme, die eine spezielle Eigenschaft erfuĚllen
und Basen genannt werden.
Definition 3.2.9 (Basen). Es sei (V, +, Âˇ) ein K-Vektorraum. Eine Teilmenge M â V heiĂt Basis von V , wenn sich jedes v â V eindeutig als Linearkombination von paarweise verschiedenen Vektoren aus M schreiben laĚsst. AuĂerdem
definieren wir, dass die leere Menge â eine Basis des trivialen K-Vektorraums {0}
ist.
Beispiele.
(i) Es sei (V, +, Âˇ) ein K-Vektorraum. Die endliche Teilmenge
{v1 , . . . , vn } â V
ist Basis von V , wenn v1 , . . . , vn paarweise verschieden sind und es zu jedem u â V genau ein n-Tupel (x1 , . . . , xn ) â K n gibt mit
u = x1 Âˇ v1 + Âˇ Âˇ Âˇ + xn Âˇ Âˇ Âˇ vn .
(ii) Die Menge der Einheitsvektoren {e1 , . . . , en } ist eine Basis des K-Vektorraums K n .

88

Mathematik fuĚr Informatiker

M. Skutella

(iii) Der Nullvektor 0 kann nie Element einer Basis sein, denn
0Âˇ0 = 1Âˇ0 = 0 ,
so dass also die Koeffizienten der Darstellung nicht eindeutig sind.
 â1  1 
1
(iv) Wie wir weiter
oben
beobachtet
haben,
gilt
h
, 1 , 0 i = R2 . Die Men1
 1
1
â1
ge 1 , 1 , 0 ist jedoch keine Basis von R2 , denn
 
 
 
 
â1
1
â1
1
= 0Âˇ
+1Âˇ
+0Âˇ
1
1
1
0
und andererseits


(v) Die Menge



1
1



,

 
 

 
â1
1
â1
1
= 1Âˇ
+0Âˇ
â2Âˇ
.
1
1
1
0
1
0



ist Basis von R2 , denn fuĚr

x
y



â R2 gilt

 
 
 
x
1
1
= yÂˇ
+ (x â y) Âˇ
.
y
1
0
Gilt auch
 
 
 
x
1
1
= aÂˇ
+bÂˇ
y
1
0
fuĚr a, b â R, so muss x = a + b und y = a gelten. Daraus folgt aber a = y
und b = x â y, so dass die Koeffizienten also eindeutig sind.
(vi) Der R-Vektorraum R2 hat unendlich viele Basen. Man uĚberpruĚft leicht,
dass {e1 , c Âˇ e2 } fuĚr alle c â R \ {0} eine Basis von R2 ist.

3.2.4

Lineare AbhaĚngigkeit und lineare UnabhaĚngigkeit

Eine Teilmenge von Vektoren eines K-Vektorraums heiĂt linear abhaĚngig, falls
der davon erzeugte Teilraum bereits schon von einer kleineren Teilmenge erzeugt
wird. Andernfalls heiĂt die Teilmenge linear unabhaĚngig.
Definition 3.2.10 (Lineare UnabhaĚngigkeit). Es sei (V, +, Âˇ) ein K-Vektorraum.
Eine Teilmenge M â V heiĂt linear unabhaĚngig, wenn fuĚr jedes v â M gilt,
dass hM \ {v}i =
6 hM i. Die Teilmenge M heiĂt linear abhaĚngig, wenn M nicht
linear unabhaĚngig ist, das heiĂt
M ist linear abhaĚngig

ââ

âv â M : hM \ {v}i = hM i .

Kapiel 3: Lineare Algebra

M. Skutella

89

Beispiele.
(i) Die leere Menge â ist linear unabhaĚngig.
(ii) Ist 0 â M , so ist M linear abhaĚngig, da hM \ {0}i = hM i.
 
 1
(iii) Die Menge  11 , â1
, 0
ist linear abhaĚngig, weil hM i = R2 aber auch
1
schon hM \ â1
i = R2 .
1
Lemma 3.2.11. Es sei V eine K-Vektorraum und M â V . Die folgenden Aussagen sind aĚquivalent:
(i) M ist linear abhaĚngig.
(ii) Es gibt ein v â M mit v â hM \ {v}i.
Das Lemma sagt also aus, dass es in einer linear abhaĚngigen Teilmenge M ein
Element gibt, das als Linearkombination der anderen Elemente aus M geschrieben
werden kann.
Beweis. (i)=â(ii): Da M linear abhaĚngig ist, gibt es nach Definition ein v â M
mit hM \ {v}i = hM i. Da v â M , gilt v â hM i = hM \ {v}i.
(ii)=â(i): Es sei v â M mit v â hM \ {v}i. Dann ist
v =

n
X

si Âˇ vi

mit si â K und vi â M \ {v} fuĚr i = 1, . . . , n.

(3.5)

i=1

Es sei nun w â hM i, also
w =

m
X

ti Âˇ wi

mit ti â K und wi â M fuĚr i = 1, . . . , m.

(3.6)

i=1

Wir muĚssen zeigen, dass w â hM \ {v}i. Ist v 6= wi fuĚr alle i = 1, . . . , m, dann
sind wir fertig. Andernfalls koĚnnen wir ohne BeschraĚnkung der Allgemeinheit
annehmen, dass v = w1 . Dann gilt wegen (3.6) und (3.5)
w = t1 Âˇ v +

m
X
i=2

ti Âˇ wi =

n
X
i=1

(t1 Âˇ si ) Âˇ vi +

m
X

ti Âˇ wi .

i=2

Damit ist w also Linearkombination endlich vieler Elemente aus M \ {v} und
folglich hM \ {v}i = hM i.

Beispiel. Es sei V = R3 und
ďŁąďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁśďŁź
1
0
0 ďŁ˝
ďŁ˛ 1
ďŁ­1ďŁ¸ , ďŁ­0ďŁ¸ , ďŁ­1ďŁ¸ , ďŁ­0ďŁ¸
M :=
.
ďŁł
ďŁž
0
0
0
1

90

Mathematik fuĚr Informatiker

M. Skutella

Dann ist M linear abhaĚngig, da
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
ďŁŤ ďŁś
0 E
0
1
D 1
ďŁ­1ďŁ¸ â ďŁ­0ďŁ¸ , ďŁ­1ďŁ¸ , ďŁ­0ďŁ¸ .
1
0
0
0
Es gilt auch
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
ďŁŤ ďŁś
0 E
0
1
D 1
ďŁ­0ďŁ¸ â ďŁ­1ďŁ¸ , ďŁ­1ďŁ¸ , ďŁ­0ďŁ¸
1
0
0
0
und
ďŁŤ ďŁś
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
0
1
0 E
D 1
ďŁ­1ďŁ¸ â ďŁ­1ďŁ¸ , ďŁ­0ďŁ¸ , ďŁ­0ďŁ¸ .
0
0
0
1
Man beachte jedoch, dass
ďŁŤ ďŁś
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
0
1
0 E
D 1
ďŁ­0ďŁ¸ 6â ďŁ­1ďŁ¸ , ďŁ­0ďŁ¸ , ďŁ­1ďŁ¸ .
1
0
0
0
In dem folgenden Lemma stellen wir fest, dass eine Teilmenge von Vektoren
genau dann linear abhaĚngig ist, wenn der Nullvektor als nicht-triviale Linearkombination dieser Vektoren geschrieben werden kann.
Lemma 3.2.12. Es sei V eine K-Vektorraum und M â V . Die folgenden Aussagen sind aĚquivalent:
(i) M ist linear abhaĚngig.
(ii) Es gibt paarweise verschiedene Vektoren v1 , . . . , vn â M und zugehoĚrige
Skalare s1 , . . . , sn â K, die nicht alle Null sind, mit
s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn = 0 .
Beweis. (i)=â(ii): Da M linear abhaĚngig ist, gibt es nach Lemma 3.2.11 ein v1 â
M mit v1 â hM \ {v1 }i. Wir unterscheiden zwei FaĚlle. Erster Fall: M \ {v1 } = â.
Da hâi = {0}, gilt dann v1 = 0. Wir setzen n := 1, s1 := 1, so dass gilt s1 Âˇ v1 =
1 Âˇ 0 = 0.
Zweiter Fall: M \ {v1 } =
6 â. Dann ist nach Voraussetzung
v1 = s2 Âˇ v2 + Âˇ Âˇ Âˇ + sn Âˇ vn ,

Kapiel 3: Lineare Algebra

M. Skutella

91

mit v2 , . . . , vn â M \ {v1 } und s2 , . . . , sn â K. Setzen wir s1 := â1 6= 0, dann
gilt also
s1 Âˇ v1 + s2 Âˇ v2 + Âˇ Âˇ Âˇ + sn Âˇ vn = 0 .
(ii)=â(i): Es seien also v1 , . . . , vn â M paarweise verschieden und s1 , . . . , sn â K
nicht alle Null, mit
s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn = 0 .
Durch Umnummerieren koĚnnen wir ohne BeschraĚnkung der Allgemeinheit annehmen, dass s1 6= 0. Dann gilt
â1
v1 = (âsâ1
1 Âˇ s2 ) Âˇ v2 + Âˇ Âˇ Âˇ + (âs1 Âˇ sn ) Âˇ vn â hv2 , . . . , vn i â hM \ {v1 }i .

Nach Lemma 3.2.11 ist M also linear abhaĚngig.



Als unmittelbare Folgerung aus Lemma 3.2.12 erhalten wir das naĚchste Korollar.
Korollar 3.2.13. Es sei V ein K-Vektorraum und M â V . Die folgenden Aussagen sind aĚquivalent:
(i) M ist linear unabhaĚngig.
(ii) FuĚr beliebige, paarweise verschiedene Vektoren v1 , . . . , vn â M und beliebige
Skalare s1 , . . . , sn â K gilt:
s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn = 0

=â

s1 = Âˇ Âˇ Âˇ = sn = 0 .

Bemerkung. Aus dem Korollar folgt insbesondere, dass Teilmengen linear unabhaĚngiger Mengen selbst wieder linear unabhaĚngig sind.
Beispiele.
(i) Es sei V = R3 und
ďŁąďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁśďŁź
1
1 ďŁ˝
ďŁ˛ 1
ďŁ­
ďŁ¸
ďŁ­
ďŁ¸
ďŁ­
1 , 2 , 3ďŁ¸
M :=
.
ďŁž
ďŁł
1
3
5
Um festzstellen, ob M linear abhaĚngig ist, muĚssen wir nach Lemma 3.2.12
uĚberpruĚfen, ob es Skalare x1 , x2 , x3 â R gibt mit (x1 , x2 , x3 ) 6= (0, 0, 0), so
dass
ďŁŤ ďŁś
ďŁŤ ďŁś
ďŁŤ ďŁś
ďŁŤ ďŁś
1
1
1
0
x1 Âˇ ďŁ­1ďŁ¸ + x2 Âˇ ďŁ­2ďŁ¸ + x3 Âˇ ďŁ­3ďŁ¸ = ďŁ­0ďŁ¸ .
1
3
5
0

92

Mathematik fuĚr Informatiker

M. Skutella

In Matrixschreibweise bedeutet das
ďŁś ďŁŤ ďŁś
ďŁŤ
ďŁŤ ďŁś
x1
1 1 1
0
ďŁ­1 2 3ďŁ¸ Âˇ ďŁ­x2 ďŁ¸ = ďŁ­0ďŁ¸ .
1 3 5
x3
0
Um dieses homogene lineare Gleichungssystem zu loĚsen, wenden wir elementare Zeilenumformungen auf die erweiterte Matrix an:
ďŁś
ďŁŤ
ďŁś
ďŁŤ
ďŁŤ
ďŁś
1 1 1 0 A21 (â1)
1 1 1 0 A12 (â1)
1 0 â1 0
(â2)
(â1)
ďŁ­ 0 1 2 0 ďŁ¸ .
ďŁ­0 1 2 0ďŁ¸ A23ââ
ďŁ­1 2 3 0ďŁ¸ A13ââ
0 2 4 0
1 3 5 0
0 0 0 0
Daraus lesen wir die folgende LoĚsungsmenge L des homogenen linearen Gleichungssystems ab:
ďŁź
ďŁąďŁŤ ďŁś
ďŁ˝
ďŁ˛ x1
ďŁ­x2 ďŁ¸ â R3 x1 â x3 = 0 â§ x2 + 2x3 = 0
L =
ďŁž
ďŁł
x3
ďŁąďŁŤ
ďŁś
t
ďŁ˛
ďŁ­â2tďŁ¸
=
ďŁł
t

tâR

ďŁź
ďŁ˝

ďŁŤ
=

D

ďŁž

ďŁś
1 E
ďŁ­â2ďŁ¸ .
1

Eine LoĚsung (x1 , x2 , x3 ) ist also zum Beispiel (1, â2, 1). Folglich ist M linear
abhaĚngig.
(ii) Es sei V = RR der Vektorraum aller Abbildungen von R nach R. Wir
betrachten die Teilmenge M := {sin, cos} und fragen uns, ob M linear abhaĚngig oder linear unabhaĚngig ist. Dazu muĚssen wir feststellen, ob
es (s1 , s2 ) 6= (0, 0) gibt mit
s1 Âˇ sin + s2 Âˇ cos = 0 (= Nullfunktion).
Das heiĂt, fuĚr alle x â R muĚsste gelten, dass
s1 Âˇ sin x + s2 Âˇ cos x = 0 .
Setzen wir in diese Gleichung beispielsweise x = 0 ein, so erhalten wir
s1 Âˇ 0 + s2 Âˇ 1 = 0 ,
also s2 = 0. Setzen wir andererseits x = Ď/2 ein, so ergibt sich
s1 Âˇ 1 + s2 Âˇ 0 = 0 ,
also s1 = 0. Folglich ist M also linear unabhaĚngig.

Kapiel 3: Lineare Algebra

3.2.5

M. Skutella

93

Basen

Wir beschaĚftigen uns im Folgenden naĚher mit Basen von VektorraĚumen. ZunaĚchst
beweisen wir einige alternative Charakterisierungen von Basen.
Lemma 3.2.14 (Charakterisierung von Basen). Es sei (V, +, Âˇ) ein K-Vektorraum
und M â V . Dann sind die folgenden Aussagen aĚquivalent:
(i) M ist Basis von V .
(ii) M ist linear unabhaĚngiges Erzeugendensystem von V .
(iii) M ist inklusionsminimales Erzeugendensystem von V , d.h.
hM i = V

und

hM \ {u}i =
6 V

fuĚr alle u â M .

(iv) M ist eine inklusionsmaximale linear unabhaĚngige Teilmenge von V , d.h. M
ist linear unabhaĚngig aber M âŞ {v} ist fuĚr jedes v â V \ M linear abhaĚngig.
Beweis. Wir beweisen das Lemma mittels eines Ringschlusses:
(i)=â(ii): Da M Basis ist, ist M nach Definition insbesondere ein Erzeugendensystem. Wir muĚssen nur noch zeigen, dass M linear unabhaĚngig ist. Dazu
betrachten wir v1 , . . . , vn â M paarweise verschieden und s1 , . . . , sn â K mit
s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn = 0 = 0 Âˇ v1 + Âˇ Âˇ Âˇ + 0 Âˇ vn .
Da M eine Basis ist, folgt aus der Eindeutigkeit der Darstellung des Nullvektors 0
als Linearkombination paarweise verschiedener Vektoren aus M , dass s1 = Âˇ Âˇ Âˇ =
sn = 0. Folglich ist M wegen Korollar 3.2.13 linear unabhaĚngig.
(ii)=â(iii): Da M ein Erzeugendensystem von V ist, gilt hM i = V . Da M
linear unabhaĚngig ist, gilt nach Definition hM \ {u}i =
6 hM i = V fuĚr alle u â M .
(iii)=â(iv): Nach Voraussetzung ist hM \{u}i =
6 V = hM i fuĚr alle u â M , so
dass M nach Definition linear unabhaĚngig ist. Es bleibt zu zeigen, dass M âŞ {v}
fuĚr alle v â V \ M linear abhaĚngig ist. WaĚre M âŞ {v} fuĚr ein v â V \ M linear
unabhaĚngig, so folgte daraus nach Definition
hM i = h(M âŞ {v}) \ {v}i 6= V .
Dies ist aber ein Widerspruch, da nach Voraussetzung hM i = V .
(iv)=â(i): Wir zeigen zunaĚchst, dass hM i = V , d.h. jeder Vektor v â V kann
als Linearkombination endlich vieler Vektoren aus M geschrieben werden. Das ist
klar, falls v â M . Es sei also im Folgenden v â V \ M . Dann ist nach Voraussetzung M âŞ{v} linear abhaĚngig. Wegen Lemma 3.2.12 gibt es dann s, s1 , . . . , sn â K
nicht alle Null und v1 , . . . , vn â M mit
s Âˇ v + s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn = 0 .

94

Mathematik fuĚr Informatiker

M. Skutella

Da M linear unabhaĚngig ist, muss s 6= 0 gelten. Dann gilt
v = â (sâ1 s1 ) Âˇ v1 â Âˇ Âˇ Âˇ â (sâ1 sn ) Âˇ vn â hM i .
Es bleibt zu zeigen, dass jeder Vektor v â V eine eindeutige Darstellung als Linearkombination endlich vieler paarweise verschiedener Vektoren aus M besitzt.
Es sei also
v = s1 v1 + Âˇ Âˇ Âˇ + sn vn

und

v = t1 w1 + Âˇ Âˇ Âˇ + tm wm

(3.7)

mit s1 , . . . , sn , t1 , . . . , tm â K und v1 , . . . , vn , w1 , . . . , wm â M . Durch Umbenennen der Vektoren erhaĚlt man {v1 , . . . , vn , w1 , . . . , wm } = {x1 , . . . , xq } â M ,
wobei die xi paarweise verschieden gewaĚhlt sind. Somit koĚnnen wir (3.7) wie folgt
schreiben:
v = s01 x1 + Âˇ Âˇ Âˇ + s0q xq

und

v = t01 x1 + Âˇ Âˇ Âˇ + t0q xq .

Durch Subtraktion der beiden AusdruĚcke erhaĚlt man
0 = (s01 â t01 )x1 + Âˇ Âˇ Âˇ + (s0q â t0q )xq .
Da M linear unabhaĚngig ist gilt also s0i = t0i fuĚr i = 1, . . . , q. Damit sind also die
beiden Darstellungen von v in (3.7) identisch.

Schon weiter oben haben wir uĚber endlich erzeugte VektorraĚume gesprochen.
Der VollstaĚndigkeit halber reichen wir eine formale Definition dieses Begriffs nach.
Definition 3.2.15 (Endlich erzeugte VektorraĚume). Es sei V ein K-Vektorraum.
Gibt es eine endliche Teilmenge M â V mit V = hM i, so ist V endlich erzeugt.
Wir haben bislang nur an speziellen Beispielen gesehen, dass Basen von VektorraĚumen tatsaĚchlich existieren koĚnnen. Der folgende Satz belegt, dass das kein
Zufall ist.
Satz 3.2.16 (Existenz von Basen). Jeder endlich erzeugte K-Vektorraum besitzt
eine Basis.
Beweis. Es sei V ein K-Vektorraum mit V = hv1 , . . . , vn i. Wir zeigen mittels
Induktion uĚber n, dass V eine Basis besitzt. Induktionsanfang: n = 0 also V =
hâi = {0}. Dann ist â nach Definition eine Basis von V .
Induktionsschluss: Die Behauptung sei fuĚr ein beliebiges aber fest gewaĚhltes n â N0 wahr. Es sei jetzt V = hv1 , . . . , vn+1 i. Ist die Menge {v1 , . . . , vn+1 }
linear unabhaĚngig, so bildet sie nach Lemma 3.2.14 eine Basis von V . Andernfalls
gibt es ein i â {1, . . . , n + 1} mit
V = hv1 , . . . , vn+1 i = hv1 , . . . , viâ1 , vi+1 , . . . , vn+1 i .
Der Vektorraum V wird also von n Vektoren erzeugt und besitzt daher nach
Induktionsannahme eine Basis.


Kapiel 3: Lineare Algebra

M. Skutella

95

Man kann sogar zeigen, dass jeder beliebige Vektorraum eine Basis besitzt.
Der Beweis, auf den wir hier nicht naĚher eingehen, beruht auf dem Lemma von
Zorn.
Aus dem Beweis von Satz 3.2.16 folgt das naĚchste Korollar.
Korollar 3.2.17. Jedes endliche Erzeugendensystem eines Vektorraums enthaĚlt
eine Basis.
Wir wenden uns jetzt kurz dem Problem zu, fuĚr einen endlich erzeugten Vektorraum eine Basis algorithmisch zu konstruieren. Der Algorithmus beruht auf
dem folgenden Lemma.
Lemma 3.2.18. Es sei V ein K-Vektorraum und v1 , . . . , vn â V .
(i) FuĚr i 6= j und s â K gilt
hv1 , . . . , vj , . . . , vn i = hv1 , . . . , vj + svi , . . . , vn i .
(ii) FuĚr i â {1, . . . , n} und t â K \ {0} gilt
hv1 , . . . , vi , . . . , vn i = hv1 , . . . , tvi , . . . , vn i .
(iii) hv1 , . . . , vn i = hv1 , . . . , vn , 0i .
Beweis. Klar.



Wir erlaĚutern anhand eines Beispiels, wie man mit Hilfe des Lemmas zu einem
gegebenen endlich erzeugten Vektorraum eine Basis konstruieren kann.
Beispiel. Es sei K = R und
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
1
1 E
D 1
ďŁ­
ďŁ¸
ďŁ­
ďŁ¸
ďŁ­
1 , 3 , 6 ďŁ¸ = hv1 , v2 , v3 i .
V :=
1
5
11
Wegen Lemma 3.2.18 (i) ist dann
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
0
0 E
D 1
ďŁ­
ďŁ¸
ďŁ­
ďŁ¸
ďŁ­
1 , 2 , 5 ďŁ¸ = hv10 , v20 , v30 i .
V = hv1 , v2 â v1 , v3 â v1 i =
1
4
10
Durch Anwenden von Lemma 3.2.18 (i), (ii) und (iii) bekommt man
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
ďŁŤ ďŁś ďŁŤ ďŁś
0
0 E
0 E
D 1
D 1
0
0 1 0
5 0
ďŁ­
ďŁ­
ďŁ¸
ďŁ­
ďŁ¸
ďŁ­
ďŁ¸
ďŁ¸
ďŁ­
1 , 1 , 0
1 , 1ďŁ¸ .
V = hv1 , 2 v2 , v3 â 2 v2 i =
=
1
2
0
1
2
Da die letzten beiden Vektoren linear unabhaĚngig sind, bilden sie also eine Basis
von V .

96

Mathematik fuĚr Informatiker

M. Skutella

Wie man feststellen kann, haben wir in diesem Beispiel im Wesentlichen den
GauĂâschen Algorithmus auf die Spalten der durch die erzeugenden Vektoren gebildeten Matrix angewendet. Lemma 3.2.18 besagt, dass die dabei verwendeten
elementaren Spaltenumformungen die Eigenschaft erhalten, dass die Spaltenvektoren den Vektorraum erzeugen.

3.2.6

Dimension

Ziel dieses Unterabschnitts ist es zu zeigen, dass alle Basen eines Vektorraums dieselbe KardinalitaĚt besitzen, die dann auch Dimension des Vektorraums genannt
wird.
Im letzten Unterabschnitt haben wir gezeigt, dass jedes endliche Erzeugendensystem eines Vektorraums V eine Basis von V enthaĚlt. Der folgende Satz stellt
die umgekehrte Vorgehensweise zur Konstruktion einer Basis dar.
Satz 3.2.19 (BasisergaĚnzungssatz). Es sei V ein endlich erzeugter K-Vektorraum
mit endlichem Erzeugendensystem E â V , also V = hEi. Weiterhin sei M â V
linear unabhaĚngig. Dann gibt es eine Teilmenge E 0 â E, so dass M âŞ E 0 eine
Basis von V ist.
Der Satz sagt also aus, dass man jede linear unabhaĚngige Teilmenge von V
durch Hinzunahme von geeigneten Vektoren aus einem vorgegebenen Erzeugendensystem zu einer Basis von V ergaĚnzen kann.
Beweis. Es sei E 0 â E inklusionsminimal mit der Eigenschaft, dass hE 0 âŞM i = V ,
d.h. h(E 0 \ {v}) âŞ M i 6= V fuĚr alle v â E 0 . Wir zeigen, dass B := E 0 âŞ M eine
Basis von V ist. Nach Konstruktion ist B ein Erzeugendensystem von V . Wegen
Lemma 3.2.14 (ii) muĚssen wir nur noch zeigen, dass B linear unabhaĚngig ist. Es
seien u1 , . . . , un â E 0 und v1 . . . , vm â M . Weiter seien s1 , . . . , sn , t1 , . . . , tm â K
mit
n
m
X
X
si Âˇ ui +
tj Âˇ vj = 0 .
(3.8)
i=1

j=1

Wir zeigen zunaĚchst, dass s1 = Âˇ Âˇ Âˇ = sn = 0. Ist si 6= 0, so ist
ui = â

X

(si

â1

Âˇ sk ) Âˇ uk â

m
X

(si â1 Âˇ tj ) Âˇ vj â h(E 0 \ {ui }) âŞ M i .

j=1

k6=i

Folglich ist V = hE 0 âŞ M i = h(E 0 \ {ui }) âŞ M i im Widerspruch zur MinimalitaĚt
von E 0 . Wir haben also gezeigt, dass s1 = Âˇ Âˇ Âˇ = sn = 0. Damit folgt aus (3.8)
m
X

tj Âˇ vj = 0 .

j=1

Da M linear unabhaĚngig ist, folgt aus Korollar 3.2.13, dass t1 = Âˇ Âˇ Âˇ = tm = 0.
Folglich ist also E 0 âŞ M linear unabhaĚngig (wieder wegen Korollar 3.2.13).


Kapiel 3: Lineare Algebra
Beispiel. Wir betrachten das

1
E :=
0

M. Skutella

97

Erzeugendensystem
 
 
 

0
0 1
0 0
0 0
,
,
,
0
0 0
1 0
0 1

des R-Vektorraums R2Ă2 . Die Menge

 

1 0
0 1
M :=
,
0 1
1 0
ist linear unabhaĚngig und die Obermenge

 
 
 

1 0
0 1
1 0
0 1
B :=
,
,
,
0 1
1 0
0 0
0 0
ist eine Basis von R2Ă2 . Man beachte jedoch, dass

 
 
 

1 0
0 1
1 0
0 0
0
B :=
,
,
,
0 1
1 0
0 0
0 1
keine Basis von R2Ă2 ist, da diese Menge linear abhaĚngig ist (der erste Vektor ist
die Summe der beiden letzten Vektoren).
Der folgende Satz ist ein wichtiger Meilenstein auf unserem Weg, der uns
schlieĂlich zu der Einsicht fuĚhren wird, dass alle Basen eines Vektorraums dieselbe
KardinalitaĚt haben.
Satz 3.2.20 (Austauschsatz von Steinitz). Es sei V ein K-Vektorraum, I eine
beliebige Indexmenge und {v1 , . . . , vn } und {ui | i â I} Basen von V . Dann gibt
es zu jedem i â {1, . . . , n} ein ji â I, so dass
{v1 , . . . , viâ1 , uji , vi+1 , . . . , vn }
eine Basis von V ist.
Beweis. Da die linear unabhaĚngige Menge {v1 , . . . , viâ1 , vi+1 , . . . , vn } keine inklusionsmaximale linear unabhaĚngige Menge ist, ist sie auch keine Basis, also
nach Lemma 3.2.14 (ii)
hv1 , . . . , viâ1 , vi+1 , . . . , vn i 6= V .
Folglich gibt es also ein ji â I mit
uji 6â hv1 , . . . , viâ1 , vi+1 , . . . , vn i .

(3.9)

Wir zeigen, dass B := {v1 , . . . , viâ1 , uji , vi+1 , . . . , vn } eine Basis von V ist.
ZunaĚchst zeigen wir, dass B linear unabhaĚngig ist. Es seien
s1 , . . . , siâ1 , t, si+1 , . . . , sn â K

98

Mathematik fuĚr Informatiker

M. Skutella

mit
s1 v1 + Âˇ Âˇ Âˇ + siâ1 viâ1 + tuji + si+1 vi+1 + Âˇ Âˇ Âˇ + sn vn = 0 .
Dann ist t = 0 wegen (3.9). Da die Menge {v1 , . . . , viâ1 , vi+1 , . . . , vn } linear
unabhaĚngig ist, gilt dann auch s1 = Âˇ Âˇ Âˇ = siâ1 = si+1 = Âˇ Âˇ Âˇ = sn = 0. Aus
Korollar 3.2.13 folgt also, dass B linear unabhaĚngig ist.
Nach Satz 3.2.19 kann man B zu einer Basis ergaĚnzen, das heiĂt es gibt E 0 â
E = {v1 , . . . , vn }, so dass B âŞ E 0 eine Basis von V ist. Ist vi 6â E 0 , so ist B âŞ
E 0 = B und wir sind fertig. Andernfalls ist B âŞ E 0 = {v1 , . . . , vn , uji } Basis.
Da {v1 , . . . , vn } Basis und damit inkusionsmaximale linear unabhaĚngige Teilmenge ist, gilt uji â {v1 , . . . , vn }. Folglich ist B = B âŞ E 0 Basis.

Der folgende Satz enthaĚlt das wichtigste Resultat dieses Unterabschnitts und
fuĚhrt uns schlieĂlich zum Begriff der Dimension.
Satz 3.2.21. Es sei V ein K-Vektorraum und B = {v1 , . . . , vn } eine Basis von V
mit n paarweise verschiedenen Elementen, d.h. |B| = n. Dann gilt:
(i) Ist B 0 eine beliebige Basis von V , so ist |B 0 | = n.
(ii) Ist M â V linear unabhaĚngig, so ist |M | â¤ n.
(iii) Ist M â V linear unabhaĚngig und |M | = n, so ist M Basis von V .
Definition 3.2.22 (Dimension eines Vektorraums). In der in Satz 3.2.21 beschriebenen Situation heiĂt n die Dimension des Vektorraums V ; wir schreiben dim V = n. Man sagt dann auch, dass V endlich dimensional ist. Besitzt
ein Vektorraum V keine endliche Basis, so ist seine Dimension unendlich, also dim V = â. Man sagt dann auch, dass V unendlich dimensional ist.
Bemerkung. Es folgt aus Korollar 3.2.17, dass jeder endlich erzeugte Vektorraum endlich dimensional ist.
Beweis von Satz 3.2.21. Zu (i): Es sei B 0 = {wi | i â I} Basis von V . Wir
beweisen zunaĚchst mittels vollstaĚndiger Induktion uĚber k, dass es zu jedem 0 â¤
k â¤ n Indizes j1 , . . . , jk â I gibt, so dass die Menge
{wj1 , . . . , wjk , vk+1 , . . . , vn }
eine Basis von V ist. Induktionsanfang: FuĚr k = 0 ist die Aussage klar, da die
Menge {v1 , . . . , vn } nach Voraussetzung Basis von V ist. Induktionsschluss: Die
Aussage gelte fuĚr ein beliebiges, fest gewaĚhltes k. Wir wenden den Austauschsatz
von Steinitz (Satz 3.2.20) auf die beiden Basen
{wj1 , . . . , wjk , vk+1 , . . . , vn } und {wi | i â I}

Kapiel 3: Lineare Algebra

M. Skutella

99

an. Der Austauschsatz besagt, dass es einen Index jk+1 â I gibt, so dass die
Menge {wj1 , . . . , wjk+1 , vk+2 , . . . , vn } eine Basis von V ist. Damit ist der Induktionsbeweis fertig.
FuĚr k = n erhalten wir aus der bewiesenen Behauptung also Indizes j1 , . . . , jn â
I, so dass {wj1 , . . . , wjn } Basis von V ist. Nach Lemma 3.2.14 (iv) ist {wj1 , . . . , wjn }
also eine inklusionsmaximale linear unabhaĚngige Teilmenge von V . Da auch die
Obermenge {wi | i â I} linear unabhaĚngig ist, folgt also {j1 , . . . , jn } = I und
damit |B 0 | = n.
Zu (ii): Es sei M â V linear unabhaĚngig. Da man M nach Satz 3.2.19 zu
einer Basis ergaĚnzen kann und da jede Basis nach (i) genau n Elemente enthaĚlt,
folgt also |M | â¤ n.
Zu (iii): Ist |M | = n und M linear unabhaĚngig, so ist M selbst eine Basis,
da M nach Satz 3.2.19 zu einer n-elementigen Basis ergaĚnzt werden kann.

Beispiele.
(i) Die Dimension des K-Vektorraums K n ist n, da beispielsweise die Menge
der Einheitsvektoren {e1 , . . . , en } eine Basis von K n bildet.
(ii) Die Dimension des K-Vektorraums aller m Ă n Matrizen K mĂn ist m Âˇ n.
Man uĚberzeugt sich leicht davon, dass die Menge
{Eij | 1 â¤ i â¤ m und 1 â¤ j â¤ n}
eine Basis von K mĂn ist. Dabei bezeichnet Eij die m Ă n Matrix, deren
Eintrag in der i-ten Zeile und j-ten Spalte eine Eins ist und die sonst nur
Null-EintraĚge hat.
(iii) Es sei K = R und
ďŁŤ ďŁś ďŁŤ ďŁś ďŁŤ ďŁś
1
1 E
D 1
V := ďŁ­1ďŁ¸ , ďŁ­3ďŁ¸ , ďŁ­ 6 ďŁ¸ .
1
5
11
Wie weiter oben schon gezeigt wurde, ist dim V = 2.
(iv) Es sei M eine beliebige unendliche Menge. Dann ist die Dimension des KVektorraums K (M ) unendlich. Wir geben eine Basis von K (M ) an, die aus
unendlich vielen Elementen besteht. Wie in dem Beispiel vor Definition 3.2.9
betrachten wir fuĚr x â M die Funktion ex â K (M ) mit
(
1 falls x = y,
ex (y) :=
0 sonst.
Dann ist B := {ex | x â M } eine Basis von K (M ) . Wir haben in dem
Beispiel vor Definition 3.2.9 schon gezeigt, dass B den Vektorraum K (M )

100

Mathematik fuĚr Informatiker

M. Skutella

erzeugt. Es seien ex1 , . . . , exn â B paarweise verschieden und s1 , . . . , sn â K
mit
s 1 Âˇ e x1 + Âˇ Âˇ Âˇ + s n Âˇ e xn = 0 .
Dann gilt insbesondere fuĚr i = 1, . . . , n, dass
si = (s1 Âˇ ex1 + Âˇ Âˇ Âˇ + sn Âˇ exn )(xi ) = 0 .
Folglich ist B linear unabhaĚngig.
Die Eigenschaft eines Vektorraums, endlich dimensional zu sein, vererbt sich
an alle seine TeilraĚume.
Korollar 3.2.23. Ist V ein endlich dimensionaler K-Vektorraum und U ein
Teilraum von V , dann ist auch U endlich dimensional und es gilt dim U â¤ dim V .
Ist dim U = dim V , so ist U = V .
Beweis. Ist dim V = n, so sind je n + 1 Vektoren aus V linear abhaĚngig. Insbesondere sind je n + 1 Vektoren aus U linear abhaĚngig, so dass eine Basis von U
hoĚchstens n Vektoren enthaĚlt, d.h. dim U â¤ n.
Ist dim U = n, so besitzt U eine Basis B mit |B| = n. Dann ist B eine
inklusionsmaximale linear unabhaĚngige Teilmenge von V und damit Basis von V .
Folglich ist U = V .

Satz 3.2.24 (Dimensionsformel fuĚr UntervektorraĚume). Es sei V ein endlich
erzeugter K-Vektorraum und U1 , U2 TeilraĚume von V . Dann ist
dim U1 + dim U2 = dim(U1 + U2 ) + dim(U1 âŠ U2 ) .
Beweis. Es sei B = {u1 , . . . , ud } eine Basis von U1 âŠ U2 , also insbesondere
dim(U1 âŠ U2 ) = d. Dann kann man B nach Satz 3.2.19 zu einer Basis von U1
beziehungsweise von U2 ergaĚnzen. Es seien also
B1 = {u1 , . . . , ud , v1 , . . . , vm }
eine Basis von U1 (also dim U1 = d + m) und
B2 = {u1 , . . . , ud , w1 , . . . , wn }
eine Basis von U2 (also dim U2 = d + n). Dann gilt
dim U1 + dim U2 = dim(U1 âŠ U2 ) + (d + m + n) .
Es bleibt zu zeigen, dass dim(U1 + U2 ) = d + m + n. Wir zeigen, dass
C := {u1 , . . . , ud , v1 , . . . , vm , w1 , . . . , wn } â U1 âŞ U2 â U1 + U2

Kapiel 3: Lineare Algebra

M. Skutella

101

eine Basis von U1 + U2 mit d + m + n paarweise verschiedenen Vektoren ist. Wir
uĚberzeugen uns zunaĚchst davon, dass C den Teilraum U1 +U2 erzeugt, also hCi =
U1 + U2 . Es sei x â U1 + U2 , das heiĂt x = x1 + x2 mit x1 â U1 und x2 â U2 .
Dann gibt es s1 , . . . , sd , t1 , . . . , tm â K mit
x1 =

d
X

si Âˇ ui +

i=1

m
X

tj Âˇ vj ,

j=1

weil B1 eine Basis von U1 ist. Analog gibt es s01 , . . . , s0d , r1 , . . . , rn â K mit
x2 =

d
X

s0i

Âˇ ui +

i=1

n
X

rk Âˇ w k ,

k=1

weil B2 eine Basis von U2 ist. Dann ist
x = x1 + x2 =

d
X

(si +

s0i )

Âˇ ui +

i=1

m
X

tj Âˇ vj +

j=1

n
X

rk Âˇ wk â hCi ,

k=1

also hCi = U1 + U2 .
Es bleibt zu zeigen, dass C linear unabhaĚngig ist. Dazu betrachten wir Skalare s1 , . . . , sd , t1 , . . . , tm , r1 , . . . , rn â K mit
d
X

si Âˇ ui +

m
X

tj Âˇ vj +

j=1

i=1

n
X

rk Âˇ w k = 0 .

k=1

Dann gilt
y :=

d
X

si Âˇ ui +

m
X

i=1

|

tj Âˇ vj = â

j=1

n
X

rk Âˇ wk â U1 âŠ U2 .

(3.10)

k=1

{z

|

}

âU1

{z

âU2

}

Da B eine Basis des Teilraums U1 âŠ U2 ist, gibt es eindeutig bestimmte Koeffizienten s01 , . . . , s0d â K mit
y =

d
X

s0i Âˇ ui .

i=1

Aus (3.10) und (3.11) folgt, dass
d
X
i=1

s0i Âˇ ui +

n
X
k=1

rk Âˇ w k = 0 .

(3.11)

102

Mathematik fuĚr Informatiker

M. Skutella

Da B2 = {u1 , . . . , ud , w1 , . . . , wn } linear unabhaĚngig ist, folgt s01 = Âˇ Âˇ Âˇ = s0d = 0
und r1 = Âˇ Âˇ Âˇ = rn = 0. Eingesetzt in (3.10) ergibt das
d
X
i=1

si Âˇ ui +

m
X

tj Âˇ vj = 0 .

j=1

Da B1 = {u1 , . . . , ud , v1 , . . . , vm } linear unabhaĚngig ist, folgt schlieĂlich s1 =
Âˇ Âˇ Âˇ = sd = 0 und t1 = Âˇ Âˇ Âˇ = tm = 0. Folglich sind die Vektoren in C paarweise
verschieden und linear unabhaĚngig.

Beispiel. Es sei V ein dreidimensionaler K-Vektorraum und U1 6= U2 zwei verschiedene TeilraĚume von V mit dim U1 = dim U2 = 2. Dann muss dim(U1 âŠ U2 ) =
1 gelten, denn fuĚr dim(U1 + U2 ) kommt nur 2 oder 3 in Betracht. WaĚre dim(U1 +
U2 ) = 2 = dim Ui (i = 1, 2), dann waĚre U1 = U1 + U2 = U2 im Widerspruch zur
Voraussetzung U1 6= U2 .

3.2.7

Eine Anwendung: Endliche KoĚrper

Wir diskutieren in diesem Abschnitt einige interessante Eigenschaften endlicher
KoĚrper, die wir mit Hilfe der Theorie der VektorraĚume herleiten. Dazu benoĚtigen
wir zunaĚchst den folgenden Satz.
Satz 3.2.25. Es sei K ein KoĚrper mit q Elementen und V ein K-Vektorraum
mit dim V = n. Dann ist |V | = q n .
Beweis. Es sei B = {v1 , . . . , vn } eine Basis von V . Dann laĚsst sich jeder Vektor u â V eindeutig schreiben als
u = s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn
mit s1 , . . . , sn â K. Da es fuĚr jedes der si , i = 1, . . . , n, genau q MoĚglichkeiten
gibt, existieren insgesamt also genau q n solcher n-Tupel (s1 , . . . , sn ). Folglich ist
also |V | = q n .

Das folgende Lemma dient als Vorbereitung fuĚr die Definition der Charakteristik eines KoĚrpers, die wir danach vorstellen.
Lemma 3.2.26. Zu einem endlichen KoĚrper K gibt es eine natuĚrliche Zahl p â N
mit
p Âˇ 1 := 1| + 1 +{zÂˇ Âˇ Âˇ + 1} = 0 .
p Summanden

Hier bezeichnet 1 das Einselement und 0 das Nullelement aus K.

Kapiel 3: Lineare Algebra

M. Skutella

103

Beweis. Da K endlich ist, ist auch die Teilmenge {n Âˇ 1 | n â N} endlich. Folglich
gibt es natuĚrliche Zahlen n1 < n2 mit n1 Âˇ 1 = n2 Âˇ 1. Wie man leicht sieht, folgt
daraus aber (n2 â n1 ) Âˇ 1 = 0.

Mit der Charakteristik eines KoĚrpers bezeichnet man jetzt die kleinste Zahl p,
die die Eigenschaft aus dem Lemma besitzt.
Definition 3.2.27 (Charakteristik eines KoĚrpers). Ist K ein beliebiger KoĚrper,
so heiĂt die kleinste natuĚrliche Zahl p mit
p Âˇ 1 := 1| + 1 +{zÂˇ Âˇ Âˇ + 1} = 0
p Summanden

die Charakteristik von K, in Zeichen char K = p. Gibt es keine solche natuĚrliche
Zahl p, so ist die Charakteristik von K gleich null.
Beispiele.
(i) char R = 0
(ii) char Q = 0
(iii) char Z2 = 2
(iv) char Zp = p
Es stellt sich heraus, dass die Charakteristik eines KoĚrpers keine beliebige
natuĚrliche Zahl sein kann.
Satz 3.2.28. Die Charakteristik eines KoĚrpers K ist null oder eine Primzahl.
Beweis. Es sei K ein KoĚrper mit char K = p 6= 0. Dann ist p > 1. Wir nehmen
im Widerspruch zur Behauptung an, dass p keine Primzahl ist. Dann gibt es zwei
natuĚrliche Zahlen 1 < p1 , p2 < p mit p = p1 Âˇ p2 . Man uĚberpruĚft leicht, dass dann
0 = p Âˇ 1 = 1| + 1 +{zÂˇ Âˇ Âˇ + 1}
p Summanden

= (1| + 1 +{zÂˇ Âˇ Âˇ + 1}) Âˇ (1| + 1 +{zÂˇ Âˇ Âˇ + 1}) = (p1 Âˇ 1) Âˇ (p2 Âˇ 1) .
p1 Summanden

p2 Summanden

Folglich gilt p1 Âˇ 1 = 0 oder p2 Âˇ 1 = 0 im Widerspruch zur MinimalitaĚt von p. 
Damit folgt insbesondere fuĚr endliche KoĚrper, dass die Charakteristik eine
Primzahl sein muss.
Korollar 3.2.29. Ist K ein endlicher KoĚrper, so ist char K eine Primzahl.

104

Mathematik fuĚr Informatiker

M. Skutella

Wir moĚchten im Folgenden herausfinden, welcher Zusammenhang zwischen
der MaĚchtigkeit eines endlichen KoĚrpers und seiner Charakteristik besteht.
Satz 3.2.30. Es sei K ein endlicher KoĚrper mit Charakteristik p. Dann ist K0 :=
{0, 1, 1+1, . . . , (pâ1)Âˇ1} mit der EinschraĚnkung der Addition und Multiplikation
von K ein KoĚrper, also ein TeilkoĚrper.
Beweis. Nachrechnen.



Bemerkung. Ist K ein KoĚrper und K0 â K ein TeilkoĚrper, so kann man K
als K0 -Vektorraum auffassen.
Beispiele.
(i) Der KoĚrper der komplexen Zahlen C = {a + bi | a, b â R kann als RVektorraum mit Basis {1, i} aufgefasst werden.
(ii) Die reellen Zahlen R bilden einen Q-Vektorraum.
(iii) Z5 ist kein TeilkoĚrper von Z7 , weil die Addition in Z5 sich von der Addition
in Z7 unterscheidet.
Mit den gesammelten Einsichten koĚnnen wir jetzt das folgende wichtige Resultat uĚber die KardinalitaĚt endlicher KoĚrper beweisen.
Satz 3.2.31. Ist K ein endlicher KoĚrper mit Charakteristik p, so gibt es ein n â
N mit |K| = pn .
Beweis. Nach Satz 3.2.30 ist K0 = {0, 1, 1 + 1, . . . , (p â 1) Âˇ 1} ein TeilkoĚrper
mit |K0 | = p und K kann als (endlich dimensionaler) K0 -Vektorraum betrachtet
werden. Die Behauptung folgt also aus Satz 3.2.25.

Folglich gibt es beispielsweise keinen KoĚrper mit 6 Elementen. Wir geben noch
den folgenden Satz ohne Beweis an.
Satz 3.2.32. Zu jeder Primzahlpotenz pn gibt es einen KoĚrper mit pn Elementen.
Beispiel. Als Beispiel stellen wir einen KoĚrper mit 4 Elementen vor. Die Menge


 
 
 

0 0
1 0
0 1
1 1
,
,
,
â Z2Ă2
2
0 0
0 1
1 1
1 0

bildet mit der Matrixaddition und -multiplikation einen KoĚrper mit 4 Elementen.

Kapiel 3: Lineare Algebra

3.3

M. Skutella

105

Lineare Abbildungen und Matrizen

Bereits in Kapitel 2 haben wir uns kurz mit Homomorphismen von Gruppen
und Ringen beschaĚftigt. Homomorphismen sind Abbildungen, die mit den VerknuĚpfungen der zugrundeliegenden Struktur (also Gruppen oder Ringen) vertraĚglich sind. In diesem Abschnitt beschaĚftigen wir uns mit Homomorphismen
auf VektorraĚumen, die auch lineare Abbildungen genannt werden. Wie wir sehen
werden, besteht ein enger Zusammenhang zwischen diesen linearen Abbildungen
und Matrizen beziehungsweise linearen Gleichungssystemen.

3.3.1

Lineare Abbildungen

Im letzten Abschnitt hatten wir den Begriff der Basis eines Vektorraums ausfuĚhrlich diskutiert. Dabei handelt es sich um eine linear unabhaĚngige Menge von Vektoren, die den zugrundeliegenden Vektorraum erzeugen. Geben wir einer solchen
Menge eine Ordnung, so erhalten wir eine sogenannte Basisfolge.
Definition 3.3.1 (Basisfolgen). Es sei V ein K-Vektorraum und B = (v1 , . . . , vn ) â
V n . Dann heiĂt B Basisfolge oder geordnete Basis, wenn {v1 , . . . , vn } Basis von V
ist und die Vektoren v1 , . . . , vn paarweise verschieden sind (also |{v1 , . . . , vn }| =
n).
Beispiel. In dem R-Vektorraum R3 sind B1 = (e1 , e2 , e3 ) und B2 = (e2 , e1 , e3 )
zwei unterschiedliche Basisfolgen. Man beachte, dass B1 6= B2 aber {e1 , e2 , e3 } =
{e2 , e1 , e3 } gilt.
Bemerkung. Ist B = (v1 , . . . , vn ) â V n eine Basisfolge des Vektorraums V , so
folgt aus der Definition von Basen (Definition 3.2.9), dass es zu jedem Vektor v â
V eindeutige Koeffizienten (s1 , . . . , sn ) â K n gibt mit
v = s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn .
Ordnen wir dem Vektor v â V diese Koeffizienten zu, so erhalten wir eine Abbildung
cB : V â K n ,
ďŁŤ ďŁś
s1
ďŁŹ .. ďŁˇ
v 7â ďŁ­ . ďŁ¸ .
sn
Man uĚberzeugt sich leicht davon, dass fuĚr alle v, v0 â V und s â K gilt:
cB (v + v0 ) = cB (v) + cB (v0 )
und
cB (s Âˇ v) = s Âˇ cB (v) .

106

Mathematik fuĚr Informatiker

M. Skutella

Aufgrund der beiden genannten Eigenschaften der Abbildung cB nennt man
sie linear oder Vektorraumhomomorphismus. Wir definieren diese Begriffe nun in
voller Allgemeinheit.
Definition 3.3.2 (Lineare Abbildungen, Vektorraumhomomorphismen). Es seien V und W zwei K-VektorraĚume und Ď : V â W eine Abbildung. Dann heiĂt Ď
linear oder Vektorraumhomomorphismus, falls
Ď(v + v0 ) = Ď(v) + Ď(v0 )

fuĚr alle v, v0 â V

und
Ď(s Âˇ v) = s Âˇ Ď(v)

fuĚr alle s â K und v â V .

Ein Vektorraumhomomorphismus ist also eine Abbildung zwischen zwei KVektorraĚumen, die mit der Vektoraddition und mit der skalaren Multiplikation
vertraĚglich ist. Damit haben wir also die in Kapitel 2 Abschnitt 2.2.4 eingefuĚhrte
Definition von Gruppen- und Ringhomomorphismen in analoger Weise auf KVektorraĚume ausgedehnt.
Bemerkung. Sind V und W zwei K-VektorraĚume und Ď : V â W eine lineare
Abbildung, so ist Ď(0) = 0. Denn:
Ď(0) = Ď(0 Âˇ 0) = 0 Âˇ Ď(0) = 0 .
(Diese Tatsache folgt auch schon daraus, dass eine lineare Abbildung Ď : V â
W nach Definition ein Gruppenhomomorphismus von der Gruppe (V, +) in die
Gruppe (W, +) ist.)
Im Folgenden geben wir eine kompaktere Charakterisierung linearer Abbildungen an, indem wir die beiden in Definition 3.3.2 geforderten Eigenschaften zu
einer Eigenschaft zusammenfassen. (Dazu vergleiche man auch Definition 3.2.3
fuĚr TeilraĚume und die entsprechende Charakterisierung in Lemma 3.2.4).
Korollar 3.3.3 (Charakterisierung linearer Abbildungen). Es seien V und W
zwei K-VektorraĚume und Ď : V â W eine Abbildung. Die Abbildung Ď ist genau
dann linear, wenn
Ď(s Âˇ v + v0 ) = s Âˇ Ď(v) + Ď(v0 )

fuĚr alle s â K und v, v0 â V .

Den Beweis diese Korollars fuĚhrt man analog zu dem Beweis des oben erwaĚhnten Lemmas 3.2.4.
Beispiele.
(i) Sind V und W zwei K-VektorraĚume, dann ist die Abbildung Ď : V â W
mit Ď(v) := 0 fuĚr alle v â V linear, also ein Vektorraumhomomorphismus.

Kapiel 3: Lineare Algebra

M. Skutella

107

(ii) Es sei V der R-Vektorraum aller differenzierbarer Funktionen von R nach R,
also
V := {f : R â R | f ist differenzierbar} ,
und f 0 bezeichne die Ableitung der Funktion f â V . Dann ist die durch f 7â
f 0 definierte Abbildung von V nach RR linear. Dies folgt sofort aus den
bekannten Ableitungsregeln fuĚr Funktionen.
(iii) Es sei V ein K-Vektorraum und c â K ein Skalar. Dann ist die Abbildung
Ďc : V â V
v 7â c Âˇ v
linear. Denn
Ďc (s Âˇ v + v0 ) = c Âˇ (s Âˇ v + v0 ) = s Âˇ (c Âˇ v) + c Âˇ v0 = s Âˇ Ďc (v) + Ďc (v0 )
fuĚr alle s â K und v, v0 â V .
(iv) Es sei V = W = K und Ď : V â W linear. Setzen wir c := Ď(1) â K, so ist
Ď(x) = Ď(x Âˇ 1) = x Âˇ Ď(1) = x Âˇ c

fuĚr alle x â K.

Folglich ist Ď = Ďc (siehe letztes Beispiel) und insbesondere ist die lineare
Abbildung Ď durch Angabe von Ď(1) eindeutig bestimmt.
Lemma 3.3.4. Es seien U , V und W drei K-VektorraĚume. Sind Ď : U â V
und Ď : V â W lineare Abbildungen, so ist die HintereinanderausfuĚhrung
ĎâŚĎ : U âW
v 7â Ď(Ď(v))
ebenfalls eine lineare Abbildung.
Beweis. FuĚr s â K und v, v0 â U gilt
(Ď âŚ Ď)(s Âˇ v + v0 ) =
=
=
=

Ď(Ď(s Âˇ v + v0 ))
Ď(s Âˇ Ď(v) + Ď(v0 ))
s Âˇ Ď(Ď(v)) + Ď(Ď(v0 ))
s Âˇ (Ď âŚ Ď)(v) + (Ď âŚ Ď)(v0 ) .

Die Behauptung folgt also aus Korollar 3.3.3.



Der folgende Satz liefert eine ErklaĚrung fuĚr die in Beispiel (iv) gemachte
Beobachtung in einem allgemeinen Kontext.

108

Mathematik fuĚr Informatiker

M. Skutella

Satz 3.3.5. Es seien V und W zwei K-VektorraĚume, (v1 , . . . , vn ) â V n eine
Basisfolge von V und (w1 , . . . , wn ) â W n . Dann gibt es genau eine lineare Abbildung Ď : V â W mit
Ď(vi ) = wi

fuĚr i = 1, . . . , n.

(3.12)

Der Satz besagt also, dass eine lineare Abbildung durch Angabe der Bildwerte
auf einer Basis des Ursprungsvektorraums V eindeutig bestimmt ist.
Beweis. Wir zeigen zunaĚchst, dass es hoĚchstens eine lineare Abbildung mit der
geforderten Eigenschaft (3.12) gibt. Denn zu v â V gibt es eindeutig bestimmte
Zahlen s1 , . . . , sn â K mit
v = s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn .
Aus (3.12) folgt dann
Ď(v) = Ď(s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn )
= s1 Âˇ Ď(v1 ) + Âˇ Âˇ Âˇ + sn Âˇ Ď(vn )
= s1 Âˇ w 1 + Âˇ Âˇ Âˇ + sn Âˇ w n ,
so dass Ď durch (3.12) also eindeutig bestimmt ist.
Es bleibt zu zeigen, dass eine lineare Abbildung Ď mit der geforderten Eigenschaft (3.12) existiert. Dazu definieren wir fuĚr v â V den Vektor Ď(v) â W
wie folgt. Schreibe v = s1 Âˇ v1 + Âˇ Âˇ Âˇ + sn Âˇ vn mit eindeutig bestimmten Skalaren s1 , . . . , sn â K und setze
Ď(v) := s1 Âˇ w1 + Âˇ Âˇ Âˇ + sn Âˇ wn .
Dann gilt also insbesondere (3.12). Wir muĚssen noch zeigen, dass die dadurch
definierte Abbildung Ď : V â W linear ist. FuĚr v0 â V mit v0 = s01 Âˇv1 +Âˇ Âˇ Âˇ+s0n Âˇvn
und t â K gilt nach Definition

Ď(t Âˇ v + v0 ) = Ď (t Âˇ s1 + s01 ) Âˇ v1 + Âˇ Âˇ Âˇ + (t Âˇ sn + s0n ) Âˇ vn
= (t Âˇ s1 + s01 ) Âˇ w1 + Âˇ Âˇ Âˇ + (t Âˇ sn + s0n ) Âˇ wn
= t Âˇ (s1 Âˇ w1 + Âˇ Âˇ Âˇ + sn Âˇ wn ) + (s01 Âˇ w1 + Âˇ Âˇ Âˇ + s0n Âˇ wn )
= t Âˇ Ď(v) + Ď(v0 ) .
Folglich ist Ď linear und der Beweis abgeschlossen.



Bemerkung. Satz 3.3.5 gilt auch fuĚr den Fall unendlicher Basen, d.h. falls eine
Basisfolge (vi )iâI des Vektorraums V mit einer beliebigen Indexmenge I und
Vektoren (wi )iâI in W gegeben sind.

Kapiel 3: Lineare Algebra

M. Skutella

109

Beispiel. Wir betrachten den R-Vektorraum R2 mit der Basisfolge (e1 , e2 ). Eine
lineare Abbildung Ď : R2 â R2 ist dann eindeutig durch die Bilder
w1 := Ď(e1 )

s1
und w2 := Ď(e2 ) gegeben. FuĚr einen beliebigen Vektor v = s2 â R2 gilt dann
Ď(v) = s1 Âˇ w1 + s2 Âˇ w2 .
w1

e2
w2

s1 Âˇ w1

s1 Âˇ e1

e1

Ď(v)

s2 Âˇ w2
s2 Âˇ e2

v

Das folgende Korollar beleuchtet den engen Zusammenhang zwischen linearen
Abbildungen und Matrizen.
Korollar 3.3.6. Jede lineare Abbildung Ď : K n â K m ist von der Form Ď = ĎA
fuĚr eine Matrix A â K mĂn , wobei
ĎA : K n â K m ,
x 7â A Âˇ x .
Umgekehrt ist jede solche Abbildung ĎA mit A â K mĂn linear.
Beweis. FuĚr A â K mĂn ist die Abbildung ĎA mit A â K mĂn linear, da
A Âˇ (s Âˇ x + x0 ) = s Âˇ (A Âˇ x) + A Âˇ x0
fuĚr alle s â K und x, x0 â K n .
Es sei (e1 , . . . , en ) die Standardbasisfolge des Vektorraums K n . FuĚr eine lineare Abbildung Ď : K n â K m setzen wir
ďŁŤ ďŁś
a1i
ďŁŹ .. ďŁˇ
Ď(ei ) =: ďŁ­ . ďŁ¸ â K m
fuĚr i = 1, . . . , n
ami

110

Mathematik fuĚr Informatiker

M. Skutella

und
ďŁŤ

ďŁś
a11 Âˇ Âˇ Âˇ a1n
ďŁŹ
.. ďŁˇ â K mĂn .
A := ďŁ­ ...
. ďŁ¸
am1 Âˇ Âˇ Âˇ amn
Dann gilt
ďŁŤ

ďŁś
a1i
ďŁŹ ďŁˇ
ĎA (ei ) = A Âˇ ei = ďŁ­ ... ďŁ¸ = Ď(ei )
ami

fuĚr i = 1, . . . , n.

Damit stimmen also die beiden linearen Abbildungen Ď und ĎA auf der Basisfolge (e1 , . . . , en ) uĚberein. Aus Satz 3.3.5 folgt daher Ď = ĎA .


3.3.2

Isomorphismen

In Kapitel 2 Definition 2.2.17 haben wir bereits die Begriffe Monomorphismus,
Epimorphismus und Isomorphismus im Zusammenhang mit Gruppen- und Ringhomomorphismen eingefuĚhrt. Wir verallgemeinern diese Definition im Folgenden
fuĚr Vektorraumhomomorphismen.
Definition 3.3.7 (Monomorphismus, Epimorphismus, Isomorphismus).
(i) Ein injektiver Vektorraumhomomorphismus heiĂt (Vektorraum-) Monomorphismus.
(ii) Ein surjektiver Vektorraumhomomorphismus heiĂt (Vektorraum-) Epimorphismus.
(iii) Ein bijektiver Vektorraumhomomorphismus heiĂt (Vektorraum-) Isomorphismus.
Definition 3.3.8 (Isomorphie). Zwei K-VektorraĚume V und W heiĂen isomorph
(in Zeichen V âź
= W ), falls es einen Vektorraumisomorphismus Ď : V â W gibt.
Satz 3.3.9 (Eigenschaften von Isomorphismen). Es seien U , V und W drei KVektorraĚume.
(i) Ist Ď : U â V ein Isomorphismus, so ist auch die Umkehrabbildung Ďâ1 :
V â U ein Isomorphismus.
(ii) Sind Ď : U â V und Ď : V â W Isomorphismen, so ist auch die HintereinanderausfuĚhrung Ď âŚ Ď : U â W ein Isomorphismus.
(iii) Die Isomorphie âź
=â ist eine AĚquivalenzrelation auf der Menge der Kâ
VektorraĚume.

Kapiel 3: Lineare Algebra

M. Skutella

111

Beweis. Um (i) zu beweisen, genuĚgt es zu zeigen, dass Ďâ1 : V â U eine lineare
Abbildung ist. Es seien s â K und v, v0 â V . Da Ď bijektiv ist, gibt es eindeutige
Vektoren u, u0 â U mit Ď(u) = v und Ď(u0 ) = v0 . Da Ď linear ist, gilt Ď(sÂˇu+u0 ) =
s Âˇ v + v0 . Damit erhaĚlt man
Ďâ1 (s Âˇ v + v0 ) = s Âˇ u + u0 = s Âˇ Ďâ1 (v) + Ďâ1 (v0 ) .
Aussage (ii) ist klar, da die Abbildung Ď âŚ Ď wegen Lemma 1.3.8 c) aus
Kapitel 1 bijektiv und wegen Lemma 3.3.4 linear ist.
Um Aussage (iii) zu beweisen, muss man zeigen, dass die Relation reflexiv, symmetrisch und transitiv ist. Die ReflexivitaĚt ist klar, da fuĚr einen KVektorraum V die identische Abbildung idV : V â V ein Isomorphismus ist. Die
Symmetrie folgt aus (i) und die TransitivitaĚt aus (ii).

Satz 3.3.10. Je zwei endlich dimensionale K-VektorraĚume derselben Dimension n sind isomorph.
Beweis. Es sei V ein beliebiger K-Vektorraum der endlichen Dimension n. Dann
hat V eine Basisfolge B = (v1 , . . . , vn ) und die Abbildung cB : V â K n ist
ein
Pn Homomorphismus. Da jeder Vektor v â V eine eindeutige Darstellung v =
mit s1 , . . . , sn â K besitzt, ist cB injektiv. Da fuĚr alle s1 , . . . , sn â K
i=1 si Âˇ vi P
der Vektor ni=1 si Âˇ vi in V liegt, ist cB surjektiv.
Wir haben also gezeigt, dass jeder n-dimensionale K-Vektorraum isomorph
zu K n ist. Die Behauptung folgt also aus Satz 3.3.9 (iii).


3.3.3

Kern und Bild

Analog zu den entsprechenden Definitionen fuĚr Gruppenhomomorphismen in Kapitel 2 Abschnitt 2.2.4 definieren wir Kern und Bild einer linearen Abbildung
zwischen K-VektorraĚumen.
Definition 3.3.11 (Kern und Bild einer linearen Abbildung). Es seien V und W
zwei K-VektorraĚume und Ď : V â W eine lineare Abbildung. Dann ist
Kern(Ď) := {v â V | Ď(v) = 0} â V
und
Bild(Ď) := {Ď(v) | v â V } = Ď(V ) â W .
Beispiel. Wir betrachten den R-Vektorraum V = W = R2 und die lineare
Abbildung Ď : V â W mit



  
 x 
xây
1 â1
x
Ď
:=
=
Âˇ
.
y
yâx
â1 1
y

112

Mathematik fuĚr Informatiker

M. Skutella

Dann ist
 
x
Kern(Ď) =
â R2
y


D1E
xây =0 â§ yâx=0
=
1

und
 
a
Bild(Ď) =
â R2
b


b = âa

D 1 E
=
.
â1

Kern(Ď)

Bild(Ď)

Satz 3.3.12. Es seien V und W zwei K-VektorraĚume und Ď : V â W eine
lineare Abbildung. Dann gilt:
(i) Kern(Ď) ist Teilraum von V und
Kern(Ď) = {0}

ââ

Ď injektiv (Monomorphismus).

(ii) Bild(Ď) ist Teilraum von W und
Bild(Ď) = W

ââ

Ď surjektiv (Epimorphismus).

Ist V = hv1 , . . . , vn i, so ist Bild(Ď) = hĎ(v1 ), . . . , Ď(vn )i.
(iii) Ist V endlich dimensional, so ist
dim V = dim Kern(Ď) + dim Bild(Ď) .
Beweis. Zu (i): Da Ď(0) = 0 ist 0 â Kern(Ď). Es seien s â K und v, w â Kern(Ď).
Dann gilt
Ď(s Âˇ v + w) = s Âˇ Ď(v) + Ď(w) = s Âˇ 0 + 0 = 0
und damit sÂˇv +w â Kern(Ď). Wegen Lemma 3.2.4 ist Kern(Ď) also ein Teilraum
von V .

Kapiel 3: Lineare Algebra

M. Skutella

113

Ist Ď injektiv, so kann auĂer dem Nullvektor in V kein weiteres Element auf
den Nullvektor in W abgebildet werden. Daher ist Kern(Ď) = {0}.
Ist umgekehrt Kern(Ď) = {0} und v, w â V mit Ď(v) = Ď(w), so ist
Ď(v â w) = Ď(v) â Ď(w) = 0
und folglich v â w â Kern(Ď) = {0}, also v = w.
Zu (ii): Da Ď(0) = 0 ist 0 â Bild(Ď). Es seien s â K und v, w â Bild(Ď),
also v = Ď(v0 ) und w = Ď(w0 ) fuĚr v0 , w0 â V . Dann ist
s Âˇ v + w = s Âˇ Ď(v0 ) + Ď(w0 ) = Ď(s Âˇ v0 + w0 ) â Bild(Ď) .
Wegen Lemma 3.2.4 ist Bild(Ď) also ein Teilraum von W . Die in (ii) behauptete
AĚquivalenz ist klar.
P
Ist V = hv1 , . . . , vn i, so ist V = { ni=1 si Âˇ vi | s1 , . . . , sn â K}. Folglich erhaĚlt
man
Bild(Ď) = {Ď(v) | v â V }
!
)
(
n
X
s1 , . . . , s n â K
=
Ď
si Âˇ vi
i=1

=

( n
X

)
si Âˇ Ď(vi ) s1 , . . . , sn â K

i=1

=

Ď(v1 ), . . . , Ď(vn ) .

Zu (iii): Ist dim V = n, so folgt aus Korollar 3.2.23 dim Kern(Ď) =: d â¤ n,
da Kern(Ď) ein Teilraum von V ist. Wir betrachten eine Basisfolge (v1 , . . . , vd )
von Kern(Ď) und ergaĚnzen sie zu einer Basisfolge (v1, . . . , vd , vd+1 , . . . , vn ) von V .
Es genuĚgt zu zeigen, dass B := Ď(vd+1 ), . . . , Ď(vn ) eine Basisfolge von Bild(Ď)
ist.
ZunaĚchst uĚberzeugt man sich leicht davon, dass B ein (geordnetes) Erzeugendensystem von Bild(Ď) ist, da nach (ii)
Bild(Ď) =

Ď(v1 ), . . . , Ď(vn )

=

0, . . . , 0, Ď(vd+1 ), . . . , Ď(vn )

=

Ď(vd+1 ), . . . , Ď(vn ) .

Es bleibt zu zeigen, dass die Vektoren in B paarweise verschieden und linear
unabhaĚngig sind. Dazu betrachten wir sd+1 , . . . , sn â K mit
!
n
n
X
X
0 =
si Âˇ Ď(vi ) = Ď
si Âˇ vi .
i=d+1

i=d+1

114
Dann ist

Mathematik fuĚr Informatiker
Pn

i=d+1

M. Skutella

si Âˇ vi â Kern Ď = hv1 , . . . , vd i, also
n
X

si Âˇ vi =

d
X

tj Âˇ vj

j=1

i=d+1

mit t1 , . . . , td â K. Setzt man sj := âtj fuĚr j = 1, . . . , d, so erhaĚlt man
n
X

si Âˇ vi = 0 .

i=1

Da jedoch hv1 , . . . , vn i eine Basisfolge von V und damit linear unabhaĚngig ist,
folgt daraus sd+1 = Âˇ Âˇ Âˇ = sn = 0 (und auch s1 = Âˇ Âˇ Âˇ = sd = 0). Damit ist der
Beweis fertig.

Definition 3.3.13. Es seien V und W zwei K-VektorraĚume und Ď : V â W
eine lineare Abbildung. Der Rang von Ď ist die Dimension von Bild(Ď), also
Rang(Ď) := dim Bild(Ď) .
Korollar 3.3.14. Es seien V und W zwei K-VektorraĚume und Ď : V â W eine
lineare Abbildung. Ist V endlich dimensional, so gilt:
(i) Ď surjektiv ââ Rang(Ď) = dim W ;
(ii) Ď injektiv ââ Rang(Ď) = dim V ;
(iii) Ist dim V = dim W , so gilt: Ď surjektiv ââ Ď injektiv.
Man vergleiche den letzten Teil des Korollars mit der bekannten Tatsache,
dass eine Abbildung zwischen zwei gleichmaĚchtigen endlichen Mengen genau dann
surjektiv ist, wenn sie injektiv ist.
Beweis. Zu (i): Es gilt
Ď surjektiv

ââ
ââ

Bild(Ď) = W
Rang Ď = dim Bild(Ď) = dim W .

Zu (ii): Es gilt
Ď injektiv

ââ
ââ
ââ

Kern(Ď) = {0}
dim Kern(Ď) = 0
dim V = Rang Ď .

Behauptung (iii) folgt aus (i) und (ii).



Das folgende Beispiel zeigt, dass Korollar 3.3.14 (iii) ohne die Voraussetzung,
dass V endlich dimensional ist, nicht wahr ist.

Kapiel 3: Lineare Algebra

M. Skutella

115

Beispiel. Es sei P(R) der R-Vektorraum der reellen Polynomfunktionen, d.h.
)
(
n
X
i
ai x
.
P(R) :=
f : R â R âa0 , . . . , an â R : f (x) =
i=0

Es sei Ď : P(R) â P(R) die lineare Abbildung, die eine Funktion auf ihre Ableitung abbildet, also Ď(f ) = f 0 . Dann ist
Kern(Ď) = {f | âc â R : f (x) = c âx â R} .
Folglich ist Ď nicht injektiv.
Andererseits ist Ď jedoch surjektiv, da jede PolyP
nomfunktion f (x) = ni=0 ai xi eine Stammfunktion
F (x) :=

n
X
ai i+1
x
i
+
1
i=0

besitzt, fuĚr die F 0 = f gilt. Damit ist also Ď(F ) = f und Ď ist surjektiv.
Umgekehrt kann man leicht Beispiele linearer Abbildungen Ď : V â V konstruieren, so dass Ď injektiv jedoch nicht surjektiv ist. Wir uĚberlassen das dem
Leser als UĚbung.
Beispiel. Es sei A eine m Ă n Matrix uĚber dem KoĚrper K, also A â K mĂn und
ĎA : K n â K m ,
x 7â A Âˇ x .
Dann ist Kern(ĎA ) = {x â K n | A Âˇ x = 0} die LoĚsungsmenge des durch die
Matrix A gegebenen homogenen linearen Gleichungssystems A Âˇ x = 0. Wie wir
wissen ist dies ein Teilraum des K-Vektorraums K n . Es gilt
dim Kern(ĎA ) = n â Rang(ĎA ) .
FuĚr b â K m ist die LoĚsungsmenge {x â K n | A Âˇ x = b} des (inhomogenen)
linearen Gleichungssystems A Âˇ x = b das Urbild des Vektors b unter der Abbildung ĎA , also
{x â K n | A Âˇ x = b} = ĎA â1 (b) .

3.3.4

Homomorphiesatz

Aus dem letzten Abschnitt wissen wir, dass der Kern einer linearen Abbildung
von einem K-Vektorraum V in einen K-Vektorraum W , also das Urbild des
Nullvektors aus W , ein Teilraum von V ist. Wie koĚnnen wir uns das Urbild eines
beliebigen Vektors b â W mit b 6= 0 vorstellen? Und es stellt sich eine weitere
Frage: Ist jeder Teilraum U von V der Kern einer linearen Abbildung von V in
einen K-Vektorraum W ? In diesem Abschnitt beschaĚftigen wir uns unter anderem
mit diesen beiden Fragen. Wir beginnen mit einem Beispiel.

116

Mathematik fuĚr Informatiker

M. Skutella

Ďâ1

Bild(Ď)




a
âa

a
Kern(Ď)




a
âa

Abbildung 3.1: Die Urbildmenge eines Vektors unter einer linearen Abbildung.
Beispiel. Es sei Ď : R2 â R2 definiert durch


 
x
xây
7â
y
yâx
Dann ist



 
1
1
Bild(Ď) =
und
Kern(Ď) =
.
â1
1

a
FuĚr einen beliebigen Vektor âa
â Bild(Ď) erhaĚlt man als Urbildmenge
 
 

 
a
x
a
â1
y =xâa
=
+ Kern(Ď) .
Ď
=
âa
y
0
Siehe auch Abbildung 3.1.
Definition 3.3.15. Ist U ein Teilraum des K-Vektorraums V und v0 â V , dann
sei
v0 + U := {v0 + u | u â U } .
Man nennt v0 + U auch die Nebenklasse oder Restklasse von v0 nach U .
Wir koĚnnen jetzt die Urbildmengen unter linearen Abbildungen durch Nebenklassen charakterisieren.
Satz 3.3.16. Es seien V und W zwei K-VektorraĚume, Ď : V â W eine lineare
Abbildung und U := Kern(Ď). Weiter seien v0 â V und w â W mit Ď(v0 ) = w.
Dann ist Ďâ1 (w) = v0 + U .

Kapiel 3: Lineare Algebra

M. Skutella

117

Beweis. Da Ď(v0 ) = w, gilt
Ď(v) = w

ââ
ââ
ââ
ââ
ââ

Ď(v) = Ď(v0 )
Ď(v) â Ď(v0 ) = 0
Ď(v â v0 ) = 0
v â v0 â Kern(Ď)
v â v0 + Kern(Ď) .

Damit ist der Beweis abgeschlossen.



Lemma 3.3.17. Die Menge der Nebenklassen eines Teilraums U des K-Vektorraums V
bilden eine Partition der Menge V .
Beweis. Man uĚberzeugt sich leicht davon, dass die durch
vâźw

:ââ

vâw âU

gegebene binaĚre Relation auf V reflexiv, symmetrisch und transitiv, also eine
AĚquivalenzrelation ist. Die AĚquivalenzklasse von v ist die Nebenklasse v + U .
Nach Satz 1.5.5 bilden die Nebenklassen also eine Partition von V .

Satz 3.3.18 (Restklassenraum, Faktorraum, Quotientenraum). Es sei V ein KVektorraum und U ein Teilraum von V . Weiter sei
V /U := {v + U | v â V }
die Menge der Nebenklassen nach U . Definiert man fuĚr v, w â V und s â K
(v + U ) + (w + U ) := (v + w) + U
und
s Âˇ (v + U ) := (s Âˇ v) + U ,
so wird V /U ein K-Vektorraum, der Restklassenraum, Quotientenraum oder
Faktorraum von V nach U . AuĂerdem ist die Abbildung Ď : V â V /U mit Ď(v) :=
v + U ein Epimorphismus mit Kern(Ď) = U .
Beweis. Wir muĚssen zunaĚchst zeigen, dass die durch
(v + U ) + (w + U ) := (v + w) + U
und
s Âˇ (v + U ) := (s Âˇ v) + U

118

Mathematik fuĚr Informatiker

M. Skutella

definierten Abbildungen wohldefiniert sind. Es seien v, v0 , w, w0 â V mit v + U =
v0 + U und w + U = w0 + U . Wir muĚssen zeigen, dass dann
(v + w) + U = (v0 + w0 ) + U

(s Âˇ v) + U = (s Âˇ v0 ) + U

und

fuĚr alle s â K gilt. Nach Voraussetzung gilt v0 â v â U und w0 â w â U (siehe
auch Lemma 3.3.17). Folglich ist
(v0 + w0 ) â (v + w) = (v0 â v) + (w0 â w) â U
und damit (v + w) + U = (v0 + w0 ) + U . Weiterhin ist
s Âˇ v0 â s Âˇ v = s Âˇ (v0 â v) â U
und damit (s Âˇ v) + U = (s Âˇ v0 ) + U .
Es bleibt also zu zeigen, dass V /U mit der so definierten Addition und Skalarmultiplikation ein Vektorraum ist. Dazu muĚssen die Vektorraumaxiome aus
Definition 3.2.1 erfuĚllt sein. Dies rechnet man leicht nach. Beispielsweise ist der
Nullvektor in V /U gegeben durch 0 + U . Wir lassen den Beweis der restlichen
Vektorraumeigenschaften als UĚbung.
Es bleibt zu zeigen, dass Ď die behaupteten Eigenschaften besitzt. ZunaĚchst
einmal ist Ď linear, da fuĚr v, v0 â V und s â K gilt:
Ď(s Âˇ v + v0 ) = (s Âˇ v + v0 ) + U
= s Âˇ (v + U ) + (v0 + U )
= s Âˇ Ď(v) + Ď(v0 ) .
Offensichtlich ist Ď surjektiv und es gilt Ď(v) = v + U = 0 + U genau dann,
wenn v â U . Folglich ist Kern(Ď) = U .

Der folgende Satz stellt das Hauptresultat dieses Abschnitts dar.
Satz 3.3.19 (Homomorphiesatz fuĚr VektorraĚume). Es seien V und W zwei KVektorraĚume und Ď : V â W eine lineare Abbildung. Dann ist die Abbildung ÎŚ :
V / Kern(Ď) â Bild(Ď) mit

ÎŚ v + Kern(Ď) := Ď(v)
ein Isomorphismus.
Beweis. Die Abbildung ist wohldefiniert, da fuĚr v, v0 â V
v + Kern(Ď) = v0 + Kern(Ď)

ââ
ââ
ââ

v â v0 â Kern(Ď)
Ď(v â v0 ) = 0
Ď(v) = Ď(v0 ) .

Daraus folgt auch sofort, dass ÎŚ injektiv und surjektiv, also bijektiv ist. Die
LinearitaĚt der Abbildung folgt auch direkt aus der Definition.


Kapiel 3: Lineare Algebra

3.3.5

M. Skutella

119

Rang einer Matrix

Nachdem wir im letzten Abschnitt den Rang einer linearen Abbildung definiert
haben, beschaĚftigen wir uns jetzt mit dem Rang von Matrizen.
Definition 3.3.20 (Rang einer Matrix). Zu einer m Ă n Matrix A uĚber dem
KoĚrper K, also A â K mĂn , betrachten wir die zugehoĚrige lineare Abbildung
ĎA : K n â K m ,
x 7â A Âˇ x .
Dann ist der Rang der Matrix A definiert als
Rang(A) := Rang(ĎA ) = dim(Bild(ĎA )) .
Definition 3.3.21 (Spaltenraum, Zeilenraum). Es sei A eine m Ă n Matrix uĚber
dem KoĚrper K, also
ďŁŤ
ďŁś
a11 Âˇ Âˇ Âˇ a1n
ďŁŹ
.. ďŁˇ â K mĂn .
A = ďŁ­ ...
. ďŁ¸
am1 Âˇ Âˇ Âˇ amn
Der Spaltenraum SR(A) ist der Teilvektorraum von K m , der durch die Spalten
von A erzeugt wird, also
ďŁŤ
ďŁś ďŁŤ
ďŁś
ďŁŤ
ďŁś
a12
a1n E
D a11
ďŁŹ
ďŁˇ ďŁŹ
ďŁˇ
ďŁŹ
ďŁˇ
SR(A) := ďŁ­ ... ďŁ¸ , ďŁ­ ... ďŁ¸ , . . . , ďŁ­ ... ďŁ¸ .
am1
am2
amn
Der Zeilenraum ZR(A) ist der Teilvektorraum von K 1Ăn , der durch die Zeilen
von A erzeugt wird, also
ZR(A) :=

(a11 , . . . , a1n ), (a21 , . . . , a2n ), . . . , (am1 , . . . , amn ) .

In dem folgenden Satz charakterisieren wir den Rang einer Matrix auf verschiedene Weisen. Dabei spielen auch elementare Spaltenumformungen eine Rolle,
die voĚllig analog zu den in Definition 3.1.5 betrachteten elementaren Zeilenumformungen definiert sind (ersetze in Definition 3.1.5 uĚberall Zeileâ durch Spalteâ).
â
â
Satz 3.3.22 (Charakterisierung des Rangs einer Matrix). Es sei A eine m Ă n
Matrix uĚber dem KoĚrper K. Dann gilt:
(i) Rang(A) = dim(SR(A)) ;
(ii) Der Rang von A aĚndert sich durch elementare Spaltenumformungen nicht.

120

Mathematik fuĚr Informatiker

M. Skutella

(iii) Der Rang von A aĚndert sich durch elementare Zeilenumformungen nicht.
Beweis. Zu (i): DefinitionsgemaĚĂ ist der Rang der Matrix A die Dimension des
Bildes der linearen Abbildung ĎA : K n â K m . Es sei (e1 , . . . , en ) die Standardbasisfolge von K n . Dann ist
Bild(ĎA ) = hĎ(e1 ), . . . , Ď(en )i
= hA Âˇ e1 , . . . , A Âˇ en i
ďŁŤ
ďŁś
ďŁŤ
ďŁś
a1n E
D a11
ďŁŹ
ďŁˇ
ďŁŹ
ďŁˇ
= ďŁ­ ... ďŁ¸ , . . . , ďŁ­ ... ďŁ¸ = SR(A) .
amn
am1
Behauptung (ii) gilt, da sich der Spaltenraum von A wegen Lemma 3.2.18
durch elementare Spaltenumformungen nicht aĚndert.
Zu (iii): Die Matrix A0 gehe aus A durch elementare Zeilenumformungen hervor. Dann gilt wegen Lemma 3.1.2
Kern(ĎA ) = {x â K n | A Âˇ x = 0} = {x â K n | A0 Âˇ x = 0} = Kern(ĎA0 ) .
Folglich erhaĚlt man


Rang(A) = n â dim Kern(ĎA ) = n â dim Kern(ĎA0 ) = Rang(A0 ) .
Damit ist der Beweis abgeschlossen.



Bemerkung. Man beachte, dass sich durch elementare Zeilenumformungen zwar
der Rang einer Matrix und damit die Dimension des Spaltenraumes nicht aĚndert,
der Spaltenraum sich jedoch sehr wohl aĚndern kann.
Um den Rang einer Matrix A zu berechnen, kann man also sowohl elementare
Zeilen- als auch Spaltenumformungen anwenden. Wir demonstrieren dies anhand
eines Beispiels.
Beispiel. Wir berechnen
ďŁŤ
1 2
ďŁ­2 4
3 6

den Rang der Matrix
ďŁś
3 4 16 15 14 13
7 8 13 14 5 0 ďŁ¸ â R3Ă8 .
9 12 11 10 4 3

Wir wenden zunaĚchst elementare Zeilenumformungen an:
ďŁŤ
ďŁś
1 2 3 4 16 15 14 13
Rang ďŁ­2 4 7 8 13 14 5 0 ďŁ¸
3 6 9 12 11 10 4 3
ďŁŤ
ďŁś
A12 (â2)
1 2 3 4
16 15 14 13
A13 (â3)
â â â â ďŁ¸
=
Rang ďŁ­ 0 0 1 0
0 0 0 0 â37 â â â

Kapiel 3: Lineare Algebra

M. Skutella

Durch elementare Spaltenumformungen
ďŁŤ
1 0
ďŁ­
=
Rang 0 0
0 0
ďŁŤ
1 0
ďŁ­
=
Rang 0 1
0 0

121

erhaĚlt man schlieĂlich
ďŁś
0 0 0 0 0 0
1 0 0 0 0 0ďŁ¸
0 0 1 0 0 0
ďŁś
0 0 0 0 0 0
0 0 0 0 0 0ďŁ¸ = 3 .
1 0 0 0 0 0

Satz 3.3.23. Es sei A eine m Ă n Matrix uĚber dem KoĚrper K. Dann gilt:
(i) Man kann A durch elementare
Form
ďŁŤ
1 0
ďŁŹ
ďŁŹ 0 1
ďŁŹ . .
ďŁŹ .. . .
ďŁŹ
ďŁŹ 0 ÂˇÂˇÂˇ
ďŁŹ
ďŁŹ 0 ÂˇÂˇÂˇ
ďŁŹ
ďŁŹ .
ďŁ­ ..
0 ÂˇÂˇÂˇ

Zeilen- und Spaltenumformungen auf die
ďŁś
0
.. ďŁˇ
. ďŁˇ
ďŁˇ
0 ďŁˇ
ďŁˇ
0 ďŁˇ
ďŁˇ
0 ďŁˇ
ďŁˇ
.. ďŁˇ
. ďŁ¸
0 0 ÂˇÂˇÂˇ 0

ÂˇÂˇÂˇ 0 0 ÂˇÂˇÂˇ
. . .. ..
. . .
..
. 0 0 ÂˇÂˇÂˇ
0 1 0 ÂˇÂˇÂˇ
0 0 0 ÂˇÂˇÂˇ
.. .. ..
. . .
0

mit r Einsen auf der Hauptdiagonalen bringen. Insbesondere erhaĚlt man
dadurch Rang(A) = r.
(ii) Rang(A) = dim(SR(A)) = dim(ZR(A)).
Beweis. Zu (i): Nach Satz 3.1.7 kann man A durch elementare Zeilenumformungen auf Stufenform bringen:
ďŁś
ďŁŤ
0ÂˇÂˇÂˇ0 1 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇ
ďŁŹ 0ÂˇÂˇÂˇ0 0 ÂˇÂˇÂˇ 0 1 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇ ďŁˇ
ďŁˇ
ďŁŹ
ďŁŹ 0ÂˇÂˇÂˇ0 0 ÂˇÂˇÂˇ 0 0 ÂˇÂˇÂˇ 0 1 âÂˇÂˇÂˇâ 0 âÂˇÂˇÂˇ ďŁˇ
0
A := ďŁŹ
ďŁˇ .
ďŁŹ 0ÂˇÂˇÂˇ0 0 ÂˇÂˇÂˇ 0 0 ÂˇÂˇÂˇ 0 0 ÂˇÂˇÂˇ 0 1 âÂˇÂˇÂˇ ďŁˇ
ďŁ­
ďŁ¸
..
..
..
..
..
..
..
.. . .
.
.
.
.
.
.
.
.
.
Durch elementare Spaltenumformungen kann man mit Hilfe der Einsen, die die
Stufen von A0 definieren, die restlichen EintraĚge den entsprechenden Zeilen zu
Nullen machen. Durch Permutation der Spalten erhaĚlt man dann die beschriebene
Form, wobei die Anzahl r der Einsen der Anzahl der Stufen von A0 entspricht.
Zu (ii): Da sich bei elementaren Zeilenumformungen der Zeilenraum einer
Matrix nicht aĚndert, ist ZR(A) = ZR(A0 ). In A0 sind die von null verschiedenen
Zeilenvektoren linear unabhaĚngig. Folglich gilt dim(ZR(A)) = r = dim(SR(A)).


122

Mathematik fuĚr Informatiker

M. Skutella

Wir schlieĂen diesen Abschnitt mit dem folgenden Hauptsatz uĚber lineare
Gleichungssysteme ab.
Satz 3.3.24 (Hauptsatz uĚber lineare Gleichungssysteme). Es sei A â K mĂn
und b â K m .
(i) Die LoĚsungsmenge
L := {x â K n | A Âˇ x = 0}
des homogenen linearen Gleichungssystems A Âˇ x = 0 ist ein Teilraum
von K n mit
dim L = n â Rang(A) .
(ii) Das inhomogene lineare Gleichungssystem A Âˇ x = b ist genau dann loĚsbar,
wenn
Rang(A) = Rang([A, b]) ,
wobei

ďŁŤ

ďŁś
a11 Âˇ Âˇ Âˇ a1n b1
ďŁŹ
..
.. ďŁˇ
[A, b] := ďŁ­ ...
.
.ďŁ¸
am1 Âˇ Âˇ Âˇ amn bm

die erweiterte Matrix des linearen Gleichungssystems A Âˇ x = b ist.
(iii) Ist v â K n mit A Âˇ v = b, so kann die LoĚsungsmenge
Lb := {x â K n | A Âˇ x = b}
geschrieben werden als
Lb = v + L = {v + w â K n | w â L} .
Insbesondere ist das inhomogene lineare Gleichungssystem A Âˇ x = b genau
dann eindeutig loĚsbar, wenn Rang(A) = n und Lb 6= â ist.
Beweis. Aussage (i) folgt aus Satz 3.3.12, denn


dim L = dim Kern(ĎA ) = n â dim Bild(ĎA ) = n â Rang(A) .
Um (ii) zu beweisen stellen wir fest, dass das inhomogene lineare Gleichungssystem A Âˇ x = b genau dann eine LoĚsung besitzt, wenn b â Bild(ĎA ) =
SR(A). Letzteres ist genau dann der Fall, wenn SR(A) = SR([A, b]) und damit Rang(A) = Rang([A, b]) gilt.
Zu (iii): Es sei v â K n mit A Âˇ v = b. Ist x â K n mit A Âˇ x = 0, so ist
A Âˇ (v + x) = A Âˇ v + A Âˇ x = b + 0 = b
und damit v+x â Lb . Wir haben also gezeigt, dass Lb â v+L. Ist umgekehrt y â
Lb , so gilt
A Âˇ (y â v) = A Âˇ y â A Âˇ v = b â b = 0 .
Folglich ist y â v =: x â L und damit y = v + x â v + L. Wir haben also gezeigt,
dass Lb â v + L und daher Lb = v + L .


Kapiel 3: Lineare Algebra

3.3.6

M. Skutella

123

Eine Anwendung: Polynomfunktionen

Satz 3.3.25 (Vandermonde Matrix). Es seien n â N0 und c1 , . . . , cn+1 â K
paarweise verschieden und
ďŁś
ďŁŤ
1 c1
c1 2 Âˇ Âˇ Âˇ c1 n
ďŁŹ1 c 2
c2 2 Âˇ Âˇ Âˇ c2 n ďŁˇ
ďŁˇ
ďŁŹ
(n+1)Ă(n+1)
.
A := ďŁŹ ..
..
..
.. ďŁˇ â K
ďŁ­.
ďŁ¸
.
.
.
1 cn+1 cn+1 2 Âˇ Âˇ Âˇ cn+1 n
Dann gilt Rang(A) = n + 1. Die Matrix A heiĂt auch Vandermonde Matrix.
Beweis. Wir fuĚhren den Beweis durch Induktion uĚber n. Die Behauptung ist klar
fuĚr n = 0 (und auch fuĚr n = 1). Addiert man fuĚr i = n, nâ1, . . . , 1 das (âc1 )-fache
der i-ten Spalte auf die Spalte i + 1, so erhaĚlt man:
ďŁś
ďŁŤ
1
0
0
ÂˇÂˇÂˇ
0
ďŁŹ1 c 2 â c 1
ÂˇÂˇÂˇ
c2 n â c1 c2 nâ1 ďŁˇ
c2 2 â c1 c2
ďŁˇ
ďŁŹ
Rang(A) = Rang ďŁŹ ..
ďŁˇ .
..
..
..
ďŁ­.
ďŁ¸
.
.
.
nâ1
n
2
1 cn+1 â c1 cn+1 â c1 cn+1 Âˇ Âˇ Âˇ cn+1 â c1 cn+1
Addiert man jetzt das (â1)-fache der ersten Zeile auf alle anderen Zeilen und
multipliziert dann fuĚr i = 1, . . . , n + 1 die i-te Zeile mit (ci â c1 )â1 , so erhaĚlt man:
ďŁś
ďŁŤ
1 0 0 ÂˇÂˇÂˇ
0
ďŁŹ0 1 c2 Âˇ Âˇ Âˇ c2 nâ1 ďŁˇ
ďŁˇ
ďŁŹ
Rang(A) = Rang ďŁŹ .. ..
..
.. ďŁˇ .
ďŁ­. .
.
. ďŁ¸
0 1 cn+1 Âˇ Âˇ Âˇ cn+1 nâ1
Jetzt folgt die Behauptung offenbar mit Induktion.



Definition 3.3.26. Es sei K ein KoĚrper. Dann bezeichnen wir mit P(K) den
K-Vektorraum aller Polynomfunktionen von K nach K.
Satz 3.3.27. Es seien a0 , . . . , an â K nicht alle null und f â P(K) die durch
f (x) := a0 + a1 x + Âˇ Âˇ Âˇ + an xn
gegebene Polynomfunktion. Dann besitzt f hoĚchstens n Nullstellen in K.
Beweis. Wir nehmen an, dass c1 , . . . , cn+1 â K paarweise verschiedene Nullstellen
von f sind. Dann ist
ďŁŤ
ďŁś ďŁŤ ďŁś
ďŁŤ ďŁś
1 c1
c1 2 Âˇ Âˇ Âˇ c1 n
a0
0
2
n ďŁˇ ďŁŹ ďŁˇ
ďŁŹ1 c 2
ďŁŹ
ďŁˇ
c
Âˇ
Âˇ
Âˇ
c
a
2
2
ďŁŹ
ďŁˇ ďŁŹ 1ďŁˇ
ďŁŹ0ďŁˇ
ďŁŹ ..
..
..
.. ďŁˇ Âˇ ďŁŹ .. ďŁˇ = ďŁŹ .. ďŁˇ
ďŁ­.
ďŁ­.ďŁ¸
.
.
. ďŁ¸ ďŁ­.ďŁ¸
2
n
1 cn+1 cn+1 Âˇ Âˇ Âˇ cn+1
an
0
und wegen Satz 3.3.25 folgt daraus, dass a0 = Âˇ Âˇ Âˇ = an = 0.



124

Mathematik fuĚr Informatiker

M. Skutella

Satz 3.3.28. FuĚr i â N0 sei pi â P(K) die durch pi (x) := xi gegebene Polynomfunktion. Ist n â N und hat K mindestens n + 1 Elemente, dann ist die
Menge {p0 , p1 , . . . , pn } linear unabhaĚngig.
Beweis. Es seien a0 , . . . , an â K und a0 p0 + a1 p1 + Âˇ Âˇ Âˇ + an pn = 0 die Nullabbildung. Wie im Beweis zu Satz 3.3.27 folgt dann, dass a0 = Âˇ Âˇ Âˇ = an = 0. Folglich
ist die Menge {p0 , p1 , . . . , pn } linear unabhaĚngig.

Korollar 3.3.29. Besitzt der KoĚrper K unendlich viele Elemente, so ist (pi )iâN0
eine Basisfolge des K-Vektorraums P(K). Insbesondere gilt: Sind f und g Polynomfunktionen mit
f (x) =

n
X

ai xi

und

g(x) =

i=0

m
X

bi x i

i=0

wobei an 6= 0 und bm 6= 0, so ist genau dann f = g, wenn n = m und ai = bi
fuĚr i = 0, . . . , n.
Beweis. Die Behauptung folgt direkt aus Satz 3.3.28.



Korollar 3.3.30. Ist K ein endlicher KoĚrper mit q Elementen, so ist (p0 , . . . , pqâ1 )
eine Basisfolge von P(K) und es gilt P(K) = K K . Jede Abbildung von K nach K
ist also eine Polynomfunktion.
Beweis. Nach Satz 3.3.28 ist (p0 , . . . , pqâ1 ) linear unabhaĚngig. Da |K K | = q q ,
folgt aus Satz 3.2.25, dass dim(K K ) = q. Folglich ist (p0 , . . . , pqâ1 ) eine Basisfolge
von K K und damit erst recht auch eine Basisfolge von P(K).


3.3.7

Matrix einer linearen Abbildung

Eine lineare Abbildung zwischen zwei endlich dimensionalen VektorraĚumen kann
durch Angabe von Basisfolgen der VektorraĚume und durch eine Matrix vollstaĚndig
spezifiziert werden.
Definition 3.3.31 (Matrix einer linearen Abbildung). Es seien V und W zwei
K-VektorraĚume und Ď : V â W eine lineare Abbildung. Weiter seien B =
(v1 , . . . , vn ) eine Basisfolge von V und B 0 = (w1 , . . . , wm ) eine Basisfolge von W .
Dann ist nach Satz 3.3.5 die lineare Abbildung Ď durch die Angabe von
Ď(vj ) â W

fuĚr j = 1, . . . , n

vollstaĚndig bestimmt. Der Vektor Ď(vj ) laĚsst sich eindeutig in der Basis B 0 ausdruĚcken:
m
X
Ď(vj ) =
aij Âˇ wi
fuĚr j = 1, . . . , n,
i=1

Kapiel 3: Lineare Algebra

M. Skutella

125

wobei aij â K fuĚr i = 1, . . . , m und j = 1, . . . , n. Die dadurch definierte Matrix (aij ) â K mĂn heiĂt Matrix von Ď bezuĚglich der Basen B und B 0 , in Zeichen
B 0 [Ď]B

= (aij ) â K mĂn .

Beispiele.
(i) Wir betrachten den R-Vektorraum P(R) der Polynomfunktionen von R
nach R und den durch die Funktionen
p0 (x)
p1 (x)
p2 (x)
p3 (x)

:=
:=
:=
:=

x0 = 1 ,
x1 = x ,
x2 ,
x3

aufgespannten Teilraum V := hp0 , p1 , p2 , p3 i der Polynomfunktionen vom
Grad hoĚchstens 3. Wegen Satz 3.3.28 ist B := (p0 , p1 , p2 , p3 ) eine Basisfolge
von V . Wir betrachten die folgende Abbildung Ď : V â V mit
Ď(f )(x) := f (x + 1)

fuĚr alle x â R.

Diese Abbildung ist linear, denn es gilt fuĚr s â R und f, g â V , dass
Ď(s Âˇ f + g)(x) = (s Âˇ f + g)(x + 1)
= s Âˇ f (x + 1) + g(x + 1)
= s Âˇ Ď(f )(x) + Ď(g)(x)
fuĚr alle x â R. Weiter gilt, dass
Ď(p0 )
Ď(p1 )
Ď(p2 )
Ď(p3 )

=
=
=
=

p0 ,
p0 + p1 ,
p0 + 2 Âˇ p1 + p2 ,
p0 + 3 Âˇ p1 + 3 Âˇ p2 + p3 .

Daraus erhaĚlt man die Matrix von Ď bezuĚglich der Basis B:
ďŁś
ďŁŤ
1 1 1 1
ďŁŹ0 1 2 3ďŁˇ
ďŁŹ
ďŁˇ .
B [Ď]B = ďŁ­
0 0 1 3ďŁ¸
0 0 0 1
(ii) Es sei A â K mĂn und ĎA : K n â K m die zugehoĚrige lineare Abbildung
mit ĎA (x) = A Âˇ x. Es seien B = (e1 , . . . , en ) die Standardbasis von K n
und B 0 = (e01 , . . . , e0m ) die Standardbasis von K m . Dann ist
ďŁŤ
ďŁś
a1j
m
X
ďŁŹ .. ďŁˇ
ĎA (ej ) = A Âˇ ej = ďŁ­ . ďŁ¸ =
aij Âˇ e0i
fuĚr j = 1, . . . , n.
i=1
amj

126

Mathematik fuĚr Informatiker

M. Skutella

Folglich ist also
B 0 [ĎA ]B

= A .

Satz 3.3.32. Es seien V und W zwei K-VektorraĚume, B = (v1 , . . . , vn ) eine
Basisfolge von V und B 0 = (w1 , . . . , wm ) eine Basisfolge von W . FuĚr eine lineare
Abbildung Ď : V â W gilt dann

cB 0 Ď(v) =

B 0 [Ď]B

Âˇ cB (v)

fuĚr alle v â V .

Beweis. Nach Definition gilt
= (aij ) â K mĂn ,

B 0 [Ď]B

P
j = 1, . . . , n.
wobei Ď(vj ) = m
i=1 aij wi fuĚr P
Es sei nun v â V mit v = nj=1 sj Âˇ vj , also
ďŁŤ ďŁś
s1
ďŁŹ .. ďŁˇ
cB (v) = ďŁ­ . ďŁ¸
sn
mit s1 , . . . , sn â K. Dann ist
Ď(v) =

n
X

sj Âˇ Ď(vj )

j=1

=

n
X

sj Âˇ

j=1

=

=

m
X
i=1

m
X

n
X

i=1

j=1

n
X
i=1

aij Âˇ wi
!

aij Âˇ sj

Âˇ wi

ďŁŤ

ďŁŤ ďŁśďŁś
s1
ďŁŹ
ďŁŹ .. ďŁˇďŁˇ
ďŁ­(ai1 , . . . , ain ) Âˇ ďŁ­ . ďŁ¸ďŁ¸ Âˇ wi .
sn

Folglich gilt also

cB 0 Ď(v) =

B 0 [Ď]B

Âˇ cB (v) .

Damit ist der Beweis abgeschlossen.
Satz 3.3.32 kann man auch wie folgt formulieren.



Kapiel 3: Lineare Algebra

M. Skutella

127

Korollar 3.3.33. Es seien V und W zwei K-VektorraĚume, B = (v1 , . . . , vn )
eine Basisfolge von V und B 0 = (w1 , . . . , wm ) eine Basisfolge von W . FuĚr eine
lineare Abbildung Ď : V â W gilt dann
cB 0 âŚ Ď = ĎA âŚ cB ,
wobei A :=B 0 [Ď]B .
Als weitere Folgerung koĚnnen wir jetzt eine Aussage uĚber den Rang einer
linearen Abbildung mit Hilfe der ihr zugeordneten Matrix machen.
Korollar 3.3.34. Es seien V und W zwei K-VektorraĚume, B = (v1 , . . . , vn )
eine Basisfolge von V und B 0 = (w1 , . . . , wm ) eine Basisfolge von W . FuĚr eine
lineare Abbildung Ď : V â W gilt dann
Rang(Ď) = Rang(B 0 [Ď]B ) .
Beweis. Es sei A :=B 0 [Ď]B â K mĂn . Nach Definition gilt Rang(Ď) = dim Bild(Ď)
und Rang(A) = dim Bild(ĎA ). Es genuĚgt daher zu zeigen, dass Bild(Ď) âź
= Bild(ĎA ).
m
Dazu betrachten wir den Isomorphismus cB 0 : W â K und zeigen, dass seine
EinschraĚnkung auf Bild(Ď) einen Isomorphismus
 von Bild(Ď) auf Bild(ĎA ) liefert.
Wir muĚssen also nur zeigen, dass cB 0 Bild(Ď) = Bild(ĎA ). Zu ââ: FuĚr v â V
â
gilt wegen Korollar 3.3.33


cB 0 Ď(v) = ĎA cB (v) â Bild(ĎA ) .
Zu ââ: Es sei
â
ďŁŤ

ďŁś
s01
ďŁŹ .. ďŁˇ
ďŁ­ . ďŁ¸ â Bild(ĎA )
s0m

ďŁŤ

ďŁś
ďŁŤ ďŁś
s01
s1
ďŁŹ .. ďŁˇ
ďŁŹ .. ďŁˇ
ďŁ­ . ďŁ¸ = AÂˇďŁ­ . ďŁ¸
s0m
sn

also

mit s1 , . . . , sn â K. Definieren wir v :=

Pn

j=1

sj Âˇ vj , dann gilt

ďŁŤ

ďŁś
s01


ďŁŹ .. ďŁˇ
ďŁ­ . ďŁ¸ = A Âˇ cB (v) = cB 0 Ď(v) â cB 0 Bild(Ď) .
s0m
Damit ist der Beweis abgeschlossen.



Satz 3.3.35. Es seien U , V und W drei endlich-dimensionale K-VektorraĚume
und Ď : U â V und Ď : V â W lineare Abbildungen. Ist B Basisfolge von U , B 0
Basisfolge von V und B 00 Basisfolge von W , so gilt
B 00 [Ď

âŚ Ď]B =

B 00 [Ď]B 0 ÂˇB 0

[Ď]B .

128

Mathematik fuĚr Informatiker

M. Skutella

Dieser Sachverhalt stellt die eigentliche Motivation fuĚr die Definition der Matrixmultiplikation dar.
Beweis. Es sei B = (u1 , . . . , un ), B 0 = (v1 , . . . , vm ) und B 00 = (w1 , . . . , w` ).
Weiter sei B 0 [Ď]B = A = (aij ) â K mĂn und B 00 [Ď]B 0 = C = (cki ) â K `Ăm . Dann
gilt also
Ď(uj ) =

m
X

aij Âˇ vi

und

`
X

Ď(vi ) =

i=1

cki Âˇ wk .

k=1

Damit erhaĚlt man also

(Ď âŚ Ď)(uj ) = Ď Ď(uj )
!
m
X
= Ď
aij Âˇ vi
i=1

=

=

m
X
i=1
m
X

aij Âˇ Ď(vi )
aij Âˇ

i=1

=

`
X

cki Âˇ wk

k=1

m
`
X
X

!
Âˇwk .

cki Âˇ aij

i=1

k=1

|

{z

=(CÂˇA)kj

}

Damit haben wir also gezeigt, dass fuĚr k = 1, . . . , ` und j = 1, . . . , m der Eintrag
in der k-ten Zeile und j-ten Spalte der Matrix B 00 [Ď âŚĎ]B mit dem entsprechenden
Eintrag der Matrix B 00 [Ď]B 0 ÂˇB 0 [Ď]B uĚbereinstimmt.

Beispiel. Wir betrachten noch einmal den R-Vektorraum P(R) der Polynomfunktionen von R nach R und den durch die Funktionen
p0 (x)
p1 (x)
p2 (x)
p3 (x)

:=
:=
:=
:=

x0 = 1 ,
x1 = x ,
x2 ,
x3

aufgespannten Teilraum V := hp0 , p1 , p2 , p3 i der Polynomfunktionen vom Grad
hoĚchstens 3. Wir haben weiter oben festgestellt, dass B := (p0 , p1 , p2 , p3 ) eine
Basisfolge von V ist. Wir betrachten wieder die folgende Abbildung Ď : V â V
mit
Ď(f )(x) := f (x + 1)

fuĚr alle x â R

Kapiel 3: Lineare Algebra

M. Skutella

129

und
ďŁŤ

B [Ď]B

1
ďŁŹ0
= ďŁŹ
ďŁ­0
0

1
1
0
0

1
2
1
0

ďŁś
1
3ďŁˇ
ďŁˇ .
3ďŁ¸
1

Wir betrachten jetzt die Abbildung Ď2 := Ď âŚ Ď : V â V , fuĚr die gilt:

Ď2 (f )(x) = Ď Ď(f ) (x) = Ď(f )(x + 1) = f (x + 2)
fuĚr f â V und x â R. Wegen Satz 3.3.35 gilt
ďŁŤ
1
ďŁŹ
0
2
2
= ďŁŹ
B [Ď ]B = B [Ď]B
ďŁ­0
0

2
1
0
0

ďŁś
4 8
4 12ďŁˇ
ďŁˇ .
1 6ďŁ¸
0 1

Dies stimmt mit der Beobachtung uĚberein, dass fuĚr eine Funktion
f (x) := a0 + a1 Âˇ x + a2 Âˇ x2 + a3 Âˇ x3
mit a0 , a1 , a2 , a3 â R gilt:
f (x + 2) = (a0 + 2a1 + 4a2 + 8a3 )
+(a1 + 4a2 + 12a3 ) Âˇ x
+(a2 + 6a3 ) Âˇ x2
+a3 Âˇ x3 .
Als Korollar aus Satz 3.3.35 koĚnnen wir jetzt leicht beweisen, dass die Matrixmultiplikation assoziativ ist. (Wir hatten das bereits im Beweis von Satz 3.1.14
erwaĚhnt, jedoch nicht explizit bewiesen.)
Korollar 3.3.36. Die Matrixmultiplikation ist assoziativ, d.h. fuĚr A â K mĂn ,
C â K nĂp und D â K pĂq gilt
(A Âˇ C) Âˇ D = A Âˇ (C Âˇ D) .
Beweis. Wir betrachten die linearen Abbildungen
ĎA : K n â K m ,
ĎC : K p â K n ,
ĎD : K q â K p .
In Kapitel 1, Lemma 1.3.9 haben wir festgestellt, dass die Komposition von Abbildungen assoziativ ist, d.h.
(ĎA âŚ ĎC ) âŚ ĎD = ĎA âŚ (ĎC âŚ ĎD ) .
Ist Bi die Standardbasis von K i , so gilt Bm [ĎA ]Bn = A,
Bp [ĎD ]Bq = D. Die Behauptung folgt also mit Satz 3.3.35.

Bn [ĎC ]Bp

= C und


130

3.3.8

Mathematik fuĚr Informatiker

M. Skutella

Basiswechsel

Definition 3.3.37 (Basiswechselmatrix). Es sei V ein K-Vektorraum mit Basisfolgen B = (v1 , . . . , vn ) und B 0 = (v10 , . . . , vn0 ). Dann heiĂt die Matrix Q :=
B 0 [idV ]B Basiswechselmatrix.
Lemma P
3.3.38. Wir betrachten
P die Situation aus Definition 3.3.37. Es sei v â V
mit v = ni=1 si vi und v = ni=1 s0i vi0 , das heiĂt
ďŁŤ ďŁś
ďŁŤ ďŁś
s01
s1
ďŁŹ ďŁˇ
ďŁŹ ďŁˇ
und
cB 0 (v) = ďŁ­ ... ďŁ¸ .
cB (v) = ďŁ­ ... ďŁ¸
s0n
sn
Dann ist cB 0 (v) = Q Âˇ cB (v) und insbesondere vj =

Pn

0
i=1 qij vi

wobei Q = (qij ).

Beweis. Die Behauptung folgt unmittelbar aus Satz 3.3.32, wenn man die spezielle lineare Abbildung Ď = idV betrachtet.

Bemerkung. Wegen Satz 3.3.35 gilt
B 0 [idV ]B

Âˇ B [idV ]B 0 =

B 0 [idV ]B 0

B [idV ]B 0

Âˇ B 0 [idV ]B =

B [idV ]B

= En

und
= En ,

wobei En die n Ă n Einheitsmatrix ist, also
ďŁŤ

1

En

ďŁŹ
ďŁŹ0
:= ďŁŹ .
ďŁ­ ..
0

ďŁś
ÂˇÂˇÂˇ 0
. . . .. ďŁˇ
1
.ďŁˇ
â K nĂn .
... ... ďŁˇ
ďŁ¸
0
ÂˇÂˇÂˇ 0 1
0

Folglich ist B [idV ]B 0 = Qâ1 die zu Q := B 0 [idV ]B inverse Matrix.
Definition 3.3.39 (Invertierbar, inverse Matrix). Sind P, Q â K nĂn mit P Âˇ
Q = Q Âˇ P = En , so nennt man die Matrizen P und Q invertierbar, regulaĚr
oder nicht singulaĚr. Die Matrix P heiĂt dann auch die zu Q inverse Matrix in
Zeichen P = Qâ1 .
Beispiel. Es sei V = R2 ,
   
1
0
B = (e1 , e2 ) =
,
0
1

und

0

B =

(v10 , v20 )

   
1
1
=
,
.
2
â1

Kapiel 3: Lineare Algebra

M. Skutella

131

FuĚr einen Vektor v = ( xx12 ) â V gilt v = x1 e1 +x2 e2 , also cB (v) = ( xx12 ). Um cB 0 (v)
zu berechnen, bestimmen wir zunaĚchst die Basiswechselmatrix Q = B 0 [idV ]B . Es
muss gelten
 
 
 
1
1
1
0
0
+ q21
= e1 = q11 v1 + q21 v2 = q11
â1
2
0
und
 
 
 
1
1
0
0
0
.
+ q22
= e2 = q12 v1 + q22 v2 = q12
â1
2
1
Daraus erhaĚlt man sofort q11 = 1/3, q21 = 2/3, q12 = 1/3 und q22 = â1/3, also
1 1 
3
3
Q =
.
1
2
â
3
3
Folglich ist
1
3
2
3

cB 0 (v) = Q Âˇ cB (v) =

  
1

x1 + 31 x2
x1
3
Âˇ
=
.
2
x2
â 31
x â 31 x2
3 1
1
3

Wie man leicht sieht, ist

P =

B [idV ]B 0

=


1 1
= Qâ1 .
2 â1

Satz 3.3.40. Es seien V und W zwei endlich-dimensionale K-VektorraĚume und Ď :
V â W eine lineare Abbildung. Weiter seien B und B 0 Basisfolgen von V und C
und C 0 Basisfolgen von W . Dann ist
C 0 [Ď]B 0

=

C 0 [idW ]C

Âˇ C [Ď]B Âˇ B [idV ]B 0 .

Beweis. Die Behauptung des Satzes folgt unmittelbar aus Satz 3.3.35, da C 0 [Ď]B 0 =

C 0 [idW âŚĎ âŚ idV ]B 0 .
Beispiel. In Fortsetzung des Beispiels von oben betrachten wir wieder den Vektorraum V = R2 mit den Basisfolgen
   
   
1
1
1
0
0
0
0
B = (e1 , e2 ) =
,
und
B = (v1 , v2 ) =
,
.
0
1
2
â1
Es sei Ď : V â V die durch
 
 1

â 3 x1 + 23 x2
x1
Ď
=
4
x2
x + 31 x2
3 1

132

Mathematik fuĚr Informatiker

M. Skutella

Ď(v) = v10 â v20
v10
v = v10 + v20

v20

Abbildung 3.2: Geometrische Veranschaulichung der Abbildung Ď.
definierte lineare Abbildung. Dann ist
 1
â3
= â 13 e1 + 43 e2
Ď(e1 ) =
4
3

und
2
Ď(e2 ) =

3
1
3

=

2
e
3 1

+ 31 e2 .

Folglich ist

B [Ď]B

=

â 31
4
3

2
3
1
3



und
B 0 [Ď]B 0

Âˇ B [Ď]B Âˇ B [idV ]B 0
1 1   1 2 

â3 3
1 1
3
3
=
Âˇ 4 1 Âˇ
2
â 13
2 â1
3
3
3
 1 1 



1 1
1 0
3
3
Âˇ
=
.
=
0 â1
â 23 13
2 â1

=

B 0 [idV ]B

Anhand dieser Darstellung sieht man leicht, dass Ď geometrisch eine SchraĚgspie1
gelung an der Geraden durch v10 = ( 12 ) in Richtung v20 = ( â1
) ist. Siehe auch
Abbildung 3.2.

3.3.9

Algebra der linearen Abbildungen

Definition 3.3.41 (Endomorphismen). Es seien V und W zwei K-VektorraĚume.
Dann bezeichnen wir die Menge der linearen Abbildungen von V nach W mit
Hom(V, W ) := {Ď : V â W | Ď linear} .

Kapiel 3: Lineare Algebra

M. Skutella

133

Im Spezialfall V = W bezeichnen wir eine lineare Abbildung von V nach V auch
als Endomorphismus und setzen
End(V ) := {Ď : V â V | Ď linear} .
Satz 3.3.42. Es seien V und W zwei K-VektorraĚume.
(i) Die Menge Hom(V, W ) bildet einen Teilraum des K-Vektorraums Abb(V, W )
aller Abbildungen von V nach W .
(ii) Ist dim(V ) = n und dim(W ) = m, so ist Hom(V, W ) âź
= K mĂn . Insbesondere
ist dim(Hom(V, W )) = m Âˇ n.
Beweis. Ad (i): Man kann leicht verifizieren, dass Abb(V, W ) mit der Addition
(f + g)(v) := f (v) + g(v)

fuĚr f, g â Abb(V, W ), v â V ,

und der Skalarmultiplikation
(s Âˇ f )(v) := s Âˇ f (v)

fuĚr f â Abb(V, W ), s â K, v â V

einen K-Vektorraum bildet. Die Teilmenge der linearen Abbildungen Hom(V, W )
bildet einen Teilraum. Die Nullabbildung v 7â 0 ist in Hom(V, W ) enthalten.
AuĂerdem uĚberpruĚft man leicht, dass fuĚr Ď, Ď â Hom(V, W ) und s â K die
Abbildung s Âˇ Ď + Ď linear und daher in Hom(V, W ) enthalten ist.
Ad (ii): Es sei B = (v1 , . . . , vn ) eine Basisfolge von V und C = (w1 , . . . , wm )
einen Basisfolge von W . Wir zeigen, dass fuĚr Ď, Ď â Hom(V, W ) und s â K
C [s

Âˇ Ď + Ď]B = s Âˇ C [Ď]B + C [Ď]B .

Dazu sei
C [Ď]B

= (aij ) ,

C [Ď]B

= (bij )

und

C [s

Âˇ Ď + Ď]B = (cij ) .

Dann ist
m
X

cij wi = (s Âˇ Ď + Ď)(vj ) = s Âˇ Ď(vj ) + Ď(vj )

i=1

= sÂˇ

m
X
i=1

=

m
X
i=1

aij wi +

m
X

bij wi

i=1

(s Âˇ aij + bij )wi

134

Mathematik fuĚr Informatiker

M. Skutella

und folglich cij = s Âˇ aij + bij fuĚr alle i = 1, . . . , m und j = 1, . . . , n. Damit haben
wir also gezeigt, dass die Abbildung
ÂľCB : Hom(V, W ) â K mĂn
Ď 7â C [Ď]B
linear ist. Es bleibt zu zeigen, dass ÂľCB injektiv und surjektiv ist. ZunaĚchst uĚberzeugt man sich leicht davon, dass Kern(ÂľCB ) nur aus der Nullabbildung v 7â 0
besteht. Ist naĚmlich C [Ď]B die Nullmatrix, so folgt daraus sofort Ď(vj ) = 0 fuĚr
alle j = 1, . . . , n. Andererseits ist ÂľCB surjektiv, da man zu einer beliebigen
Matrix (aij ) â K mĂn eine lineare Abbildung Ď : V â W definieren kann durch
Ď(vj ) :=

m
X

aij wi

fuĚr j = 1, . . . , m.

i=1

Dann ist aber C [Ď]B = (aij ). Damit ist der Beweis abgeschlossen.



Satz 3.3.43. Es sei V ein K-Vektorraum.
(i) Die Menge der Endomorphismen End(V ) bildet mit der Addition
(Ď + Ď)(v) := Ď(v) + Ď(v)

fuĚr Ď, Ď â End(V ), v â V

und der Multiplikation
(Ď âŚ Ď)(v) := Ď(Ď(v))

fuĚr Ď, Ď â End(V ), v â V

einen Ring mit Eins.
(ii) Ist dim(V ) = n und B eine Basisfolge von V , dann ist
ÂľB : End(V ) â K nĂn
Ď 7â B [Ď]B
ein Ring-Isomorphismus, das heiĂt ÂľB ist bijektiv mit
ÂľB (Ď + Ď) = ÂľB (Ď) + ÂľB (Ď) und

ÂľB (Ď âŚ Ď) = ÂľB (Ď) Âˇ ÂľB (Ď)

fuĚr Ď, Ď â End(V ).
Beweis. Ad (i): Man uĚberpruĚft leicht, dass End(V ) mit der angegebenen Addition eine kommutative Gruppe und mit der angegebenen Multiplikation ein
Monoid bildet. Das Einselement ist die identische Abbildung. AuĂerdem gilt das
Distributivgesetz, so dass End(V ) also einen Ring mit Eins bildet.

Kapiel 3: Lineare Algebra

M. Skutella

135

Ad (ii): Wie im Beweis von Satz 3.3.42 gezeigt wurde ist die Abildung ÂľB
bijektiv und es gilt
fuĚr Ď, Ď â End(V ).

ÂľB (Ď + Ď) = ÂľB (Ď) + ÂľB (Ď)
AuĂerdem ist nach Satz 3.3.35
ÂľB (Ď âŚ Ď) =

B [Ď

âŚ Ď]B =

B [Ď]B

Âˇ B [Ď]B = ÂľB (Ď) Âˇ ÂľB (Ď) .

Damit ist der Beweis abgeschlossen.



Definition 3.3.44 (K-Algebra). Es sei K ein KoĚrper. Ein Ring R mit Eins, der
gleichzeitig ein K-Vektorraum ist (mit derselben Addition wie im Ring), so dass
auĂerdem noch
s Âˇ (a Âˇ b) = (s Âˇ a) Âˇ b = a Âˇ (s Âˇ b)

fuĚr alle s â K, a, b â R

(3.13)

gilt, heiĂt eine K-Algebra (mit Eins).
Beispiele.
(i) Ist V ein K-Vektorraum, so ist End(V ) eine K-Algebra. Wegen Satz 3.3.42
und Satz 3.3.43 muĚssen wir nur noch zeigen, dass (3.13) gilt. Es seien also s â
K und Ď, Ď â End(V ). Dann gilt fuĚr v â V
(s Âˇ (Ď âŚ Ď))(v) =
=
=
=

s Âˇ ((Ď âŚ Ď)(v))
s Âˇ Ď(Ď(v)) = ((s Âˇ Ď) âŚ Ď)(v)
Ď(s Âˇ Ď(v))
(Ď âŚ (s Âˇ Ď))(v)

Damit haben wir (3.13) gezeigt.
(ii) K nĂn ist eine K-Algebra.
(iii) C ist eine R-Algebra.

3.3.10

Die volle lineare Gruppe

Satz 3.3.45 (Volle lineare Gruppe).
(i) Ist V ein K-Vektorraum, so ist
GL(V ) := {Ď â End(V ) | Ď ist bijektiv}
zusammen mit der VerknuĚpfung von Abbildungen âŚâ eine Gruppe, die volle
â
lineare Gruppe. Die Elemente von GL(V ) heiĂen auch Automorphismen.

136

Mathematik fuĚr Informatiker

M. Skutella

(ii) FuĚr n â N ist
GL(n, K) := {A â K nĂn | A invertierbar} ,
eine Gruppe, die Gruppe der regulaĚren n Ă n Matrizen.
Beweis. Ad (i): Man beachte zunaĚchst, dass die VerknuĚpfung von zwei bijektiven
Abbildungen wieder bijektiv ist. AuĂerdem ist die VerknuĚpfung assoziativ, das
neutrale Element ist idV und zu jedem Ď â GL(V ) ist Ďâ1 wegen Satz 3.3.9 auch
wieder in GL(V ). Teil (ii) beweist man analog.

Lemma 3.3.46. Ist V ein K-Vektorraum mit dim(V ) = n und B eine Basisfolge
von V , so ist
ÂľB : GL(V ) ââ GL(n, K)
Ď 7ââ B [Ď]B
ein Isomorphismus von Gruppen, das heiĂt ÂľB ist bijektiv und
ÂľB (Ď âŚ Ď) = ÂľB (Ď) Âˇ ÂľB (Ď)

fuĚr Ď, Ď â GL(V ).

(3.14)

Beweis. ZunaĚchst einmal ist ÂľB wohldefiniert, da B [Ď]B fuĚr Ď â GL(V ) invertierbar ist, denn
B [Ď]B

Âˇ B [Ďâ1 ]B =

B [Ď

â1

]B Âˇ B [Ď]B =

B [Ď

âŚ Ďâ1 ]B =

B [idV ]B

= En

B [idV ]B

= En .

und
B [Ď

â1

âŚ Ď]B =

Aus dem Beweis zu Satz 3.3.42 folgt, dass ÂľB injektiv ist. AuĂerdem ist ÂľB
surjektiv, da fuĚr A â GL(n, K) gilt, dass ÂľB (ĎA ) = A und ĎA â GL(V ), denn
ĎA âŚ ĎAâ1 = ĎAâ1 âŚ ĎA = idV .
Eigenschaft (3.14) folgt schlieĂlich aus Satz 3.3.35.



Korollar 3.3.47. Es sei V ein K-Vektorraum mit dim(V ) = n, Ď â End(V )
und A â K nĂn . Dann gilt
Ď â GL(V )

ââ

Rang(Ď) = n

A â GL(n, K)

ââ

Rang(A) = n .

und

Kapiel 3: Lineare Algebra

M. Skutella

137

Bemerkung. Ist V ein K-Vektorraum mit dim(V ) > 1, so ist GL(V ) nicht
kommutativ.
Beweis. Es sei B = (v1 , v2 , . . . ) eine Basisfolge von V . Wir definieren zwei Endomorphismen Ď, Ď â End(V ) durch
(
(
vi
fuĚr i 6= 1,
vi
fuĚr i 6= 2,
Ď(vi ) :=
und Ď(vi ) :=
v1 + v2 fuĚr i = 1,
v1 + v2 fuĚr i = 2.
Dann sind Ď und Ď sogar Automorphismen, denn man uĚberpruĚft leicht, dass
(
(
v
fuĚr
i
=
6
1,
vi
fuĚr i 6= 2,
i
Ďâ1 (vi ) :=
und Ď â1 (vi ) :=
v1 â v2 fuĚr i = 1,
v1 â v2 fuĚr i = 2.
Wir zeigen noch, dass Ď âŚ Ď 6= Ď âŚ Ď, denn
(Ď âŚ Ď)(v1 ) = Ď(v1 + v2 ) = 2v1 + v2
und
(Ď âŚ Ď)(v1 ) = Ď(v1 ) = v1 + v2 .
Damit ist der Beweis abgeschlossen.



Wir beschaĚftigen uns im Folgenden mit der Frage, wie man fuĚr eine gegebenen
Matrix A â K nĂn feststellt, ob die inverse Matrix Aâ1 existiert, und diese gegebenenfalls berechnet. Wegen Korollar 3.3.47 kann man die Frage nach er Existenz
auf eine einfache Rangberechnung zuruĚckfuĚhren. Existiert die inverse Matrix Aâ1 ,
so erfuĚllt die j-te Spalte von Aâ1 die Gleichung
A Âˇ x = ej

fuĚr j = 1, . . . , n.

(3.15)

Um Aâ1 zu berechnen, muss man also die n in (3.15) gegebenen linearen Gleichungssysteme loĚsen. Dies kann man simultan mit dem folgenden Verfahren erledigen.
Bemerkung. Es sei A â GL(n, K). Bringt man die n Ă 2n Matrix [A, En ] durch
elementare Zeilenoperationen auf Stufenform, so erhaĚlt man eine n Ă 2n Matrix der Form [En , X], wobei X = Aâ1 . Ist A nicht regulaĚr, so laĚsst sich die
Matrix [A, En ] durch elementare Zeilenoperationen nicht in diese Form bringen.
Beispiel. Es sei
ďŁŤ
ďŁś
1 1 1
A := ďŁ­0 1 1ďŁ¸ â R3Ă3 .
1 1 3

138

Mathematik fuĚr Informatiker

Dann erhaĚlt man:
ďŁŤ
1 1 1
ďŁ­0 1 1
1 1 3
ďŁŤ
M3 (1/2)
1 0 0
A2,1 (â1)
ďŁ­
0 1 1
ââ
0 0 1

ďŁś
ďŁŤ
1 1
1 0 0
A1,3 (â1)
ďŁ¸
ďŁ­
0 1
0 1 0
ââ
0 0
0 0 1
ďŁś
1
â1 0
A3,2 (â1)
0
1
0 ďŁ¸ ââ
â1/2 0 1/2

M. Skutella

1 1
1 0
2 â1
ďŁŤ
1 0
ďŁ­0 1
0 0

ďŁś
0 0
1 0ďŁ¸
0 1
ďŁś
0
1
â1
0
0 1/2
1 â1/2ďŁ¸
1 â1/2 0
1/2

Folglich ist
ďŁŤ

Aâ1

ďŁś
1
â1
0
1 â1/2ďŁ¸ .
= ďŁ­ 1/2
â1/2 0
1/2

Man kann die Beobachtung aus der letzten Bemerkung wie folgt verallgemeinern.
Bemerkung. Es seien A â GL(n, K) und C â K nĂn gegeben und eine Matrix X â K nĂn mit A Âˇ X = C gesucht, d.h. X = Aâ1 Âˇ C. Bringt man die n Ă 2n
Matrix [A, C] durch elementare Zeilenoperationen auf Stufenform, so erhaĚlt man
eine n Ă 2n Matrix der Form [En , X] mit dem gesuchten X â K nĂn .
Wir liefern im Folgenden eine BegruĚndung des in den beiden letzten Bemerkungen beschriebenen Verfahrens und gleichzeitig eine neue Interpretation von
elementaren Zeilenoperationen.
Satz 3.3.48. Ist Îľ : K nĂn â K nĂn eine elementare Zeilenoperation und sind A, B â
K nĂn , so ist
Îľ(A Âˇ B) = Îľ(A) Âˇ B .
Beweis. Es sei A = (aij ), B = (bij ) und A Âˇ B = (cij ), also
cij =

n
X

aik bkj .

k=1

Ist Îľ die Vertauschung der Zeilen i und `, also Îľ = Vi,` , so ist
n
X

Îľ(A Âˇ B) ij = c`j =
a`k bkj =

Îľ(A) Âˇ B


ij

.

k=1

Auf diese Art zeigt man, dass in diesem Fall Îľ(A Âˇ B) = Îľ(A) Âˇ B. Noch einfacher
liegt der Fall, wenn Îľ die Multiplikation einer Zeile mit einer Konstante s ist,
also Îľ = Mi (s), denn
s Âˇ cij =

n
X
k=1

(s Âˇ aik )bkj .

Kapiel 3: Lineare Algebra

M. Skutella

139

Ist schlieĂlich Îľ = Ai,` (s), so gilt
cij + sc`j =

X

k = 1n (aik + s Âˇ a`k )bkj .

Damit ist der Beweis abgeschlossen.



Wir koĚnnen jetzt eine exakte BegruĚndung fuĚr die Bemerkung zur Berechnung
der inversen Matrix nachliefern. Sind Îľ1 , . . . , Îľm elementare Zeilenoperationen mit
(Îľm âŚ Âˇ Âˇ Âˇ âŚ Îľ1 )(A) = En ,
so folgt mit Satz 3.3.48, dass
(Îľm âŚ Âˇ Âˇ Âˇ âŚ Îľ1 )(En ) = (Îľm âŚ Âˇ Âˇ Âˇ âŚ Îľ1 )(A Âˇ Aâ1 )
= (Îľm âŚ Âˇ Âˇ Âˇ âŚ Îľ1 )(A) Âˇ Aâ1
= En Âˇ Aâ1 = Aâ1 .
Definition 3.3.49 (Elementarmatrizen). Es sei n â N, i, j â {1, . . . , n} mit i 6= j
und s â K \ {0}.
(i) Die Elementarmatrix Vi,j â GL(n, K) entsteht aus der Einheitsmatrix En
durch Vertauschen der i-ten und j-ten Zeile.
(ii) Die Elementarmatrix Mi (s) â GL(n, K) entsteht aus der Einheitsmatrix En
durch Multiplikation der i-ten Zeile mit s.
(iii) Die Elementarmatrix Ai,j (s) â GL(n, K) entsteht aus der Einheitsmatrix En durch Addition des s-fachen der i-ten Zeile zur j-ten Zeile.
Bemerkung. Eine elementare Zeilenumformung von A â K nĂn entspricht der
Multiplikation von A von links mit der entsprechenden Elementarmatrix.
Lemma 3.3.50. Die inverse Matrix einer Elementarmatrix ist selbst eine Elementarmatrix.
Beweis. Man uĚberpruĚft leicht, dass
Vi,j â1 = Vi,j ,

Mi (s)â1 = Mi (sâ1 ) ,

Ai,j (s)â1 = Ai,j (âs) .

Daraus folgt offenbar die Behauptung.



Satz 3.3.51. Jede Matrix A â GL(n, K) ist ein Produkt von Elementarmatrizen.
Beweis. Da man A durch elementare Zeilenumformungen in die Einheitsmatrix
umformen kann, gibt es nach der Bemerkung oben Elementarmatrizen N1 , . . . , Nm
mit
Nm Âˇ Âˇ Âˇ Âˇ Âˇ N1 Âˇ A = En .
Folglich ist
A = N1 â1 Âˇ Âˇ Âˇ Âˇ Âˇ Nm â1 .
Wegen Lemma 3.3.50 ist A also ein Produkt von Elementarmatrizen.



140

Mathematik fuĚr Informatiker

3.4

M. Skutella

Determinanten

3.4.1

Alternierende Multilinearformen

Definition 3.4.1. Es sei V ein K-Vektorraum und n âĽ 2. Eine Abbildung
Ď : |V Ă Âˇ{z
Âˇ Âˇ Ă V} ââ K
n mal

heiĂt n-Multilinearform, wenn fuĚr jedes i â {1, . . . , n} und alle v1 , . . . , viâ1 , vi+1 , . . . , vn
die durch
v 7ââ Ď(v1 , . . . , viâ1 , v, vi+1 , . . . , vn )
gegebene Abbildung von V nach K linear ist, das heiĂt
Ď(v1 , . . . , viâ1 , s Âˇ v, vi+1 , . . . , vn ) = s Âˇ Ď(v1 , . . . , viâ1 , v, vi+1 , . . . , vn )
und
Ď(v1 , . . . , viâ1 , v + v0 , vi+1 , . . . , vn ) =
Ď(v1 , . . . , viâ1 , v, vi+1 , . . . , vn ) + Ď(v1 , . . . , viâ1 , v0 , vi+1 , . . . , vn )
fuĚr alle v, v0 â V und s â K.
Beweis.



Kapitel 4
Analysis
In diesem Kapitel geben wir eine EinfuĚhrung in die grundlegenden Themen der
Analysis. Wir beginnen mit der Behandlung von Konvergenzbetrachtungen bei
Folgen und Reihen, wenden uns dann stetigen Funktionen zu, um danach die Differenzialrechnung zu behandeln. Darauf folgt ein Abschnitt uĚber Integralrechnung
und zum Schluss noch eine kurze EinfuĚhrung in Differentialgleichungen.

4.1
4.1.1

Folgen und Reihen
Die VollstaĚndigkeit der reellen Zahlen

Definition 4.1.1 (Anordnungsaxiome). Ein KoĚrper K heiĂt angeordnet, wenn
es in ihm eine Teilmenge P (den Positivbereich) gibt, der die folgenden Eigenschaften besitzt:
(i) K ist disjunkte Vereinigung der Mengen P , {0} und âP := {x â K | âx â
P }.
(ii) FuĚr x, y â P gilt: x + y â P und x Âˇ y â P .
Die Elemente aus P heiĂen dann positiv und die Elementeaus âP negativ.
Beispiel. Die KoĚrper Q und R sind angeordnet. Der Positivbereich besteht aus
den positiven (rationalen bzw. reellen) Zahlen.
In einem angeordneten KoĚrper koĚnnen wir die bekannte Ordnungsrelation â¤â
â
wie folgt definieren.
Lemma 4.1.2 (Ordnungsrelation â¤). Es sei K ein angeordneter KoĚrper mit
Positivbereich P . Dann wird durch
xâ¤y

:ââ

y â x â P âŞ {0}

fuĚr x, y â K eine totale Ordnung â¤ mit den folgenden Eigenschaften definiert.
FuĚr w, x, y, z â K gilt:
141

142

Mathematik fuĚr Informatiker

M. Skutella

(i) Ist x â¤ y und w â¤ z, dann gilt x + w â¤ y + z.
(ii) Ist x â¤ y und 0 â¤ z, so ist x Âˇ z â¤ y Âˇ z;
ist x â¤ y und z â¤ 0, so ist y Âˇ z â¤ x Âˇ z.
(iii) Falls x â¤ y, dann ist ây â¤ âx.
(iv) Ist x 6= 0 und 0 â¤ x â¤ y, so ist 0 â¤ y â1 â¤ xâ1 .
Beweis. Wir zeigen lediglich, dass â¤ die Eigenschaften einer Ordnungsrelation
(siehe Definition 1.5.7 in Kapitel 1) besitzt. Die weiteren Eigenschaften kann
man leicht durch Nachrechnen uĚberpruĚfen.
ReflexivitaĚt: FuĚr x â K gilt nach Definition x â¤ x, da x â x = 0.
Antisymmetrie: Wir betrachten zwei Elemente x, y â K mit x â¤ y. Ist x 6= y,
so gilt also y â x â P und daher x â y = â(y â x) â âP , so dass also y 6â¤ x.
TransitivitaĚt: Es seien x, y, z â K mit x â¤ y und y â¤ z. Dann gilt also y â
x, z â y â P . Folglich ist auch z â x = (z â y) + (y â x) â P und damit x â¤ z. 
Wir verwenden neben dem Relationssymbol â¤â natuĚrlich auch die bekannten
â
Symbole âĽâ (x âĽ y :â y â¤ x), <â (x < y :â x â¤ y â§ x 6= y) und >â
â
â
â
(x > y :â y < x).
Bemerkung.
(i) Ist K ein angeordneter KoĚrper und x â K, so ist x2 âĽ 0. Man sieht dies
leicht mit Hilfe einer Fallunterscheidung: Ist x âĽ 0, so ist die Behauptung
nach Definition klar. Ist x < 0, so ist âx > 0 und daher x2 = (âx) Âˇ (âx) =
x2 âĽ 0.
(ii) Damit wissen wir jetzt insbesondere, dass die komplexen Zahlen C keinen
angeordneten KoĚrper bilden, da 1 = 1 Âˇ 1 und â1 = i Âˇ i andernfalls beide
positiv, also in P sein muĚssten. Dies widerspricht aber der Tatsache, dass P
und âP disjunkt sein muĚssen.
(iii) Wir betrachten einen angeordneten KoĚrper K und die beiden ausgezeichneten Elemente 0, 1 â K. Da 1 = 1 Âˇ 1 > 0, gilt
1 < 1 + 1 < 1 + 1 + 1 < 1 + 1 + 1 + 1 < . . . < 1| + 1 +{zÂˇ Âˇ Âˇ + 1} .
n-mal

Damit sind diese Zahlen also alle verschieden und wir koĚnnen sie mit der
Menge der natuĚrlichen Zahlen N identifizieren. Daraus kann man leicht folgern, dass auch alle ganzen Zahlen Z und sogar alle rationalen Zahlen Q
in K enthalten sein muĚssen. Folglich ist Q der kleinste angeordnete KoĚrper.
Insbesondere koĚnnen endliche KoĚrper nicht angeordnet sein.

Kapiel 4: Analysis

M. Skutella

143

Wir werden im Folgenden sehen, dass auch die reellen Zahlen R einen ausgezeichneten angeordneten KoĚrper darstellen. Dazu benoĚtigen wir das sogenannte
VollstaĚndigkeitsaxiom. (Wir erinnern hier an Definition 1.5.8 aus Kapitel 1).
Definition 4.1.3 (VollstaĚndigkeitsaxiom). Ein angeordneter KoĚrper K heiĂt
vollstaĚndig, wenn in ihm jede Teilmenge M â K, die eine obere Schranke x â K
besitzt (also y â¤ x fuĚr alle y â M ), auch ein Supremum besitzt.
Wir stellen im Folgenden zunaĚchst fest, dass der KoĚrper der rationalen Zahlen Q nicht vollstaĚndig ist. Dazu zeigen wir zunaĚchst, dass sich Q tatsaĚchlich
von R unterscheidet. Das bedeutet, dass es reelle Zahlen gibt, die nicht als Bruch
zweier ganzer Zahlen, also nicht als rationale Zahl geschrieben werden koĚnnen.
â
Lemma 4.1.4. Die Gleichung X 2 â 2 = 0 besitzt in Q keine LoĚsung, d.h. 2 ist
keine rationale Zahl.
2
Beweis. Im Widerspruch zur Behauptung nehmen wir an, dass pq = 2 mit p â
Z und q â N. Dann ist folglich
p2 = 2 Âˇ q 2 .
In der eindeutigen Primfaktorzerlegung der natuĚrlichen Zahl p2 kommt jeder
Primfaktor mit gerader HaĚufigkeit vor. In der eindeutigen Primfaktorzerlegung
der Zahl 2 Âˇ q 2 kommt der Primfaktor 2 jedoch ungerade oft vor. Dies ist ein
Widerspruch.

â
Wir wissen jetzt, dass 2 keine rationale Zahl ist. Das bedeutet, dass die
Menge der rationalen Zahlen die reelle Zahlengerade
nicht vollstaĚndig uĚberdeckt,
â
sondern LuĚcken wie etwa an der Stelle 2 auftreten koĚnnen. Andererseits kann
man leicht zeigen, dass die rationalen Zahlen dichtâ auf der reellen Achse liegen,
â
d.h. dass es keine groĚĂerenâ LuĚcken gibt.
â
Lemma 4.1.5. Sind a, b â R mit a < b, so gibt es eine rationale Zahl
mit a < pq < b.
Beweis. Es sei q :=
a =



2
bâa



p
q

âQ

â N und p := da Âˇ qe + 1 â Z. Dann ist

aÂˇq
p
aÂˇq+2
2
<
<
â¤ a+ 2 = b .
q
q
q
bâa


Wir koĚnnen jetzt zeigen, dass Q nicht vollstaĚndig ist.
Satz 4.1.6. Der angeordnete KoĚrper der rationalen Zahlen Q ist nicht vollstaĚndig.

144

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Wir betrachten die Teilmenge M := {x â Q â
| x2 â¤ 2}. WuĚrden wir
die entsprechende Teilmenge von Râbetrachten, so waĚre 2 sowohl Maximum als
auch Supremum dieser Menge. Da 2 wegen Lemma 4.1.4 jedoch keine rationale
Zahl ist, besitzt â
M kein Supremum. Denn angenommen r â Q waĚre Supremum
von M . Ist r < 2, dann gibt es nach Lemma â
4.1.5 ein r0 â M mit r0 > r, so
dass r keine obere Schranke ist. Folglich
ist r > 2. Dann gibt es aber wiederum
â
00
nach Lemma 4.1.5 ein r â Q mit 2 < r00 < r. Folglich ist r00 eine obere Schranke
und r kann folglich nicht die kleinste obere Schranke sein.

Im Gegensatz dazu ist der KoĚrper der reellen Zahlen R vollstaĚndig, was eine
ausgezeichnete Eigenschaft von R darstellt. Wir geben den folgenden Satz ohne
Beweis an.
Satz 4.1.7. Der KoĚrper der reellen Zahlen R ist der einzige vollstaĚndige angeordnete KoĚrper.

4.1.2

Folgen

Definition 4.1.8 (Folgen). Es sei M eine beliebige Menge. Eine Folge in M ist
eine Abbildung Ď : N â M mit
n 7â an = Ď(n) â M

fuĚr n â N.

Wir bezeichnen eine solche Folge mit (an )nâN oder einfach nur mit (an ).
Manchmal beginnen Folgen nicht bei n = 1 sondern bei n = 0 oder einer
anderen Zahl n â Z. Dann haben wir also streng genommen eine Abbildung
von {n â Z | n âĽ n0 } nach M . Wir schreiben die Folge dann als (an )nâN0
beziehungsweise (an )nâĽn0 .
Beispiele.
(i) Ist an = a fuĚr alle n â N, so sprechen wir von der konstanten Folge (an ).
(ii) FuĚr i â C ist (in )nâN die Folge: i, â1, âi, 1, i, â1, âi, 1, . . .
(iii) ( n1 )nâN ist die Folge: 1, 12 , 13 , 41 , 15 , 61 , 17 ,. . .
(iv) ( n12 )nâN ist die Folge: 1, 14 , 19 ,

1
, 1 , 1 , 1 ,. . .
16 25 36 49

(v) Die Folge der Fibonacci-Zahlen (siehe auch Kapitel 2, Abschnitt 2.1.3) ist
rekursiv definiert durch a0 := 0, a1 := 1 und an := anâ1 + anâ2 fuĚr n âĽ 2,
also: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144,. . .
(vi) Wir betrachten die rekursiv definierte Folge (an )nâN mit a1 := 1 und an+1 :=
an
+ a1n fuĚr n â N, also: 1, 1.5, 1.416666 . . . , 1.414215 . . . , 1.414213 . . . ,
2
. . . Aufgrund der angegebenen
â Folgenglieder liegt der Verdacht nahe, dass
sich diese Folge dem Wert 2 annaĚhert.

Kapiel 4: Analysis

M. Skutella

145

Definition 4.1.9 (Konvergenz von Folgen). Es sei (an )nâN eine Folge von komplexen (oder reellen) Zahlen an â C. Die Folge konvergiert gegen den Grenzwert a â C, in Zeichen limnââ an = a, wenn gilt:
âÎľ > 0 ân0 â N ân > n0 :

|an â a| < Îľ .

Die Folge (an ) heiĂt konvergent (man sagt dann auch, dass die Folge konvergiert),
falls es einen Grenzwert gibt, gegen den sie konvergiert. Falls die Folge (an ) nicht
konvergiert, dann divergiert sie und heiĂt divergent.
Bemerkung.
(i) Eine Folge, die gegen den Grenzwert 0 konvergiert, heiĂt auch Nullfolge.
(ii) Eine Folge komplexer Zahlen (an )nâN ist nach Definition genau dann eine
Nullfolge, wenn die relle Folge (|an |)nâN eine Nullfolge ist.
(iii) Eine Folge (an )nâN konvergiert genau dann gegen den Grenzwert a, wenn
die Folge (an â a)nâN eine Nullfolge ist.
(iv) Konvergiert die Folge (an ) gegen den Grenzwert a = limnââ an , so schreiben
wir auch
an â a fuĚr n â â .
(v) FuĚr Îľ > 0 und a â C nennen wir die Menge {x â C | |a â x| < Îľ} â C auch
Îľ-Umgebung von a (analog in R). Konvergiert eine Folge (an ) gegen den
Grenzwert a, so bedeutet das also, dass in jeder Îľ-Umgebung (mit Îľ > 0)
von a fast alle Folgenglieder von (an ) liegen. Dabei bedeutet fast alleâ
â
genau gesagt alle auĂer endlich vielenâ.
â
Beispiele.
(i) Die Folge ( n1 )nâN konvergiert gegen
 1  den Grenzwert 0, denn: WaĚhle zu einem
beliebigen Îľ > 0 die Zahl n0 = Îľ , so dass fuĚr n âĽ n0 gilt:
1
1
an â¤ an0 =  1  â¤ 1 = Îľ .
Îľ

Îľ

n
(ii) Man kann leicht zeigen, dass die Folge ( n+1
)nâN gegen den Grenzwert 1
konvergiert.

(iii) Die komplexe Folge (in )nâN divergiert.

146

Mathematik fuĚr Informatiker

M. Skutella

(iv) Die Folge ( 2nn )nâN konvergiert gegen den Grenzwert 0. Mit vollstaĚndiger
Induktion kann man naĚmlich zeigen, dass 2n âĽ n2 fuĚr n âĽ 4. Folglich gilt
n
1
n
â0 â¤ 2 =
n
2
n
n

fuĚr n âĽ 4.

 
WaĚhlen wir also zu einem beliebigen Îľ > 0 die Zahl n0 = max 1Îľ , 4 , so
ist das Konvergenzkriterium erfuĚllt.
(v) FuĚr a â C betrachten wir die Folge (an )nâN . Man kann zeigen, dass (an )
fuĚr |a| âĽ 1 und a 6= 1 divergent ist. FuĚr den Fall a = 1 ist die Folge (an )
konstant und konvergiert folglich gegen 1. Ist |a| < 1, so konvergiert die
Folge (an ) gegen 0.
(vi) Wir betrachten noch einmal die rekursiv definierte Folge (an )nâN mit a1 := 1
und an+1 := a2n + a1n fuĚr n â N. Wie weiter oben vermutet, konvergiert
â
diese Folge gegen den Grenzwert 2. Man kann mit vollstaĚndiger Induktion
leicht zeigen, dass 1 â¤ an â¤ 2 fuĚr alle n â N. Weiterhin kann man leicht
nachrechnen, dass
â
â
â
â
|an â 2|
1
â¤ |an â 2| Âˇ .
|an+1 â 2| = |an â 2| Âˇ
2an
2
Folglich gilt nach Induktion
â

1
,
2n
so dass man zu beliebigem Îľ > 0 die Zahl n0 einfach so waĚhlen kann,
dass 2n10 < Îľ. Dann gilt
â
1
1
fuĚr alle n âĽ n0 .
|an â 2| â¤ n â¤ n0 < Îľ
2
2
|an â

2| â¤

Satz 4.1.10 (Eindeutigkeit des Grenzwerts). Es sei (an )nâN eine konvergente
Folge mit an â C. Dann ist der Grenzwert a der Folge eindeutig bestimmt.
Beweis. Im Widerspruch zur Behauptung nehmen wir an, dass die Folge sowohl
gegen a als auch gegen a0 6= a konvergiert. WaĚhlt man 0 < Îľ < (a â a0 )/2, dann
gibt es ein n0 â N, so dass
|an â a| < Îľ

fuĚr n âĽ n0 .

AuĂerdem gibt es ein n00 â N, so dass
|an â a0 | < Îľ

fuĚr n âĽ n00 .

Folglich gilt fuĚr n âĽ max{n0 , n00 }:
|a â a0 | â¤ |a â an | + |an â a0 | < 2Îľ < |a â a0 | ,
was ein Widerspruch ist.



Kapiel 4: Analysis

M. Skutella

147

Definition 4.1.11. Es sei (an )nâN eine reelle Zahlenfolge.
(i) Die Folge (an ) geht gegen â, in Zeichen limnââ an = â, falls fuĚr alle r > 0
ein n0 â N existiert, so dass an > r fuĚr alle n âĽ n0 ist.
(ii) Die Folge (an ) geht gegen ââ, in Zeichen limnââ an = ââ, falls fuĚr alle r <
0 ein n0 â N existiert, so dass an < r fuĚr alle n âĽ n0 ist.
(iii) Die Folge (an ) heiĂt nach oben (unten) beschraĚnkt, falls die Menge {an |
n â N} eine obere (untere) Schranke in R besitzt. Die Folge (an ) heiĂt
beschraĚnkt, falls sie nach oben und nach unten beschraĚnkt ist.
(iv) Die Folge (an ) heiĂt monoton wachsend (monoton fallend), wenn fuĚr alle n â
N gilt, dass an+1 âĽ an (an+1 â¤ an ). Ist zusaĚtzlich an+1 6= an fuĚr alle n â N,
so nennen wir die Folge streng monoton wachsend (fallend). Eine Folge heiĂt
(streng) monoton, wenn sie (streng) monoton wachsend oder fallend ist.
Lemma 4.1.12. Jede konvergente Folge reeller Zahlen ist beschraĚnkt.
Beweis. Es sei (an )nâN eine konvergente Folge reeller Zahlen mit Grenzwert a.
Dann gibt es ein n0 â N, so dass an â¤ a + 1 fuĚr alle n âĽ n0 . Dann ist (an ) nach
oben beschraĚnkt durch max{a + 1, a1 , a2 , . . . , an0 â1 }. Analog kann man zeigen,
dass (an ) nach unten beschraĚnkt ist.

Umgekehrt ist jede beschraĚnkte reelle Zahlenfolge konvergent, falls sie monoton ist.
Lemma 4.1.13. Es sei (an )nâN eine nach oben (unten) beschraĚnkte, monoton
wachsende (fallende) Folge reeller Zahlen. Dann ist (an ) konvergent mit Grenzwert sup{an | n â N} ( inf{an | n â N}).
Beweis. Wir zeigen, dass die monoton wachsende Folge (an ) gegen a := sup{an |
n â N} konvergiert. Es sei Îľ > 0 beliebig. Da a Supremum der Menge {an | n â N}
ist, gibt es ein n0 â N mit an0 > a â Îľ. Da (an ) monoton wachsend ist gilt dann
|an â a| = a â an < Îľ

fuĚr alle n âĽ n0 .

Folglich konvergiert (an ) gegen a. Die geklammerte Version des Lemmas beweist
man analog.

Bemerkung. Man beachte, dass
 die Monotonie der Folge in Lemma 4.1.13 essenziell ist. Denn die Folge (â1)n nâN ist zwar beschraĚnkt jedoch nicht konvergent.
Satz 4.1.14 (Vergleichskriterium). Es seien (an ), (bn ) und (cn ) reelle Zahlenfolgen mit an â¤ bn â¤ cn fuĚr alle n â N.
(i) Ist b â R mit limnââ an = limnââ cn = b, so ist limnââ bn = b.

148

Mathematik fuĚr Informatiker

M. Skutella

(ii) Ist limnââ an = â, so ist auch limnââ bn = â.
(iii) Ist limnââ cn = ââ, so ist auch limnââ bn = ââ.
Beweis. Wir beweisen beispielhaft Teil (i). Die Beweise der restlichen Aussagen
funktionieren aĚhnlich. Es sei Îľ > 0; dann gibt es n0 , n00 â N mit
|an â b| < Îľ

fuĚr alle n âĽ n0

|cn â b| < Îľ

fuĚr alle n âĽ n00 .

und

Folglich gilt
b â Îľ < an â¤ bn â¤ c n â¤ b + Îľ

fuĚr alle n âĽ max{n0 , n00 }.

Damit konvergiert (bn ) gegen den Grenzwert b.


Beispiel. Wir betrachten die Folge n12 nâN . Da 0 â¤ n12 â¤ n1 fuĚr alle n â N,


konvergiert n12 wie die konstante Folge (0)nâN und die Folge n1 nâN gegen 0.
Korollar 4.1.15. Es seien (an ) und (bn ) reelle Zahlenfolgen. Ist (an ) eine Nullfolge und (bn ) beschraĚnkt, so ist die Folge (an Âˇ bn )nâN eine Nullfolge.
Beweis. Da (bn ) beschraĚnkt ist, gibt es ein B > 0 mit |bn | â¤ B fuĚr alle n â
N. Folglich gilt 0 â¤ |an Âˇ bn | â¤ B Âˇ |an | fuĚr alle n â N. Da sowohl (0)nâN als
auch (B Âˇ |an |)nâN gegen 0 konvergieren, ist (an Âˇ bn ) nach Satz 4.1.14 (i) also eine
Nullfolge.

Lemma 4.1.16. Es seien (an ) und (bn ) reelle Zahlenfolgen mit an â¤ bn fuĚr
alle n â N. Sind (an ) und (bn ) konvergent, so gilt limnââ an â¤ limnââ bn .
Beweis. Es sei a := limnââ an und b := limnââ bn . Im Widerspruch zur Behauptung nehmen wir an, dass b < a. Es sei Îľ := (a â b)/2. Dann gibt es ein n0 â N
mit an > a â Îľ fuĚr alle n âĽ n0 und ein n00 â N mit bn < b + Îľ fuĚr alle n âĽ n00 .
Folglich gilt fuĚr n âĽ max{n0 , n00 }, dass
b n < b + Îľ = a â Îľ < an .
Das ist ein Widerspruch zur Voraussetzung.



Bemerkung. Sind (an ) und (bn ) reelle, konvergente Zahlenfolgen mit an < bn fuĚr
alle n â N, so folgt
 daraus nicht
 notwendig, dass limnââ1 an <1 limnââ bn . Zum
1
1
Beispiel sind n+1 nâN und n nâN zwei Nullfolgen mit n+1 < n fuĚr alle n â N.
Satz 4.1.17. Es seien (an )nâN und (bn )nâN konvergente komplexe Zahlenfolgen, a := limnââ an und b := limnââ bn . Dann gilt:

Kapiel 4: Analysis

M. Skutella

149

(i) Die Folge (an Âą bn ) ist konvergent mit limnââ (an Âą bn ) = a Âą b.
(ii) Die Folge (an Âˇ bn ) ist konvergent mit limnââ (an Âˇ bn ) = a Âˇ b.
(iii) Ist c â C, so ist die Folge (c Âˇ an ) konvergent mit limnââ (c Âˇ an ) = c Âˇ a.
(iv) Ist b 6= 0, so gibt es ein n0 â N, so dass bn 6= 0 fuĚr alle n âĽ n0 .
Dann sind auch die Folgen b1n und abnn konvergent mit limnââ b1n = 1b

und limnââ abnn = ab .
(v) Die Folge (|an |)nâN ist konvergent mit limnââ |an | = |a|.
(vi) Die komplexe Folge (an )nâN ist genau dann konvergent,
wenn die beiden

reellen Zahlenfolgen Re(an ) nâN und Im(an ) nâN konvergieren. In diesem
Fall gilt limnââ an = limnââ Re(an ) + i Âˇ limnââ Im(an ).
Beweis. Wir beweisen beispielhaft den ersten Teil des Satzes. Es sei Îľ > 0 beliebig
gewaĚhlt. Dann gibt es zu Îľ0 := Îľ/2 > 0 Zahlen n0 , n00 â N mit
|an â a| < Îľ0

fuĚr alle n âĽ n0

|bn â b| < Îľ0

fuĚr alle n âĽ n00 .

und

Folglich gilt fuĚr alle n âĽ max{n0 , n00 }:
|(an Âą bn ) â (a Âą b)| = |(an â a) Âą (bn â b)|
â¤ |an â a| + |bn â b|
< Îľ0 + Îľ0 = Îľ .
Die weiteren Teile des Satzes beweist man aĚhnlich.

2 â2n+1
Beispiel. Wir betrachten die Folge 3n5n
2 +88n+1001 nâN . Da
5 â n2 + n12
5n2 â 2n + 1
=
,
3n2 + 88n + 1001
3 + 88
+ 1001
n
n2
liefert Satz 4.1.17
limnââ (5) â limnââ ( n2 ) + limnââ ( n12 )
5n2 â 2n + 1
=
lim
nââ 3n2 + 88n + 1001
limnââ (3) + limnââ ( 88
) + limnââ ( 1001
)
n
n2
5 limnââ (1) â 2 limnââ ( n1 ) + limnââ ( n12 )
=
3 limnââ (1) + 88 limnââ ( n1 ) + 1001 limnââ ( n12 )
=

5â2Âˇ0+0
3 + 88 Âˇ 0 + 1001 Âˇ 0

=

5
.
3



150

Mathematik fuĚr Informatiker

M. Skutella

Wir geben schlieĂlich ohne Beweis ein beruĚhmtes Konvergenzkriterium von
Cauchy an.
Satz 4.1.18 (Konvergenzkriterium von Cauchy). Eine Folge komplexer Zahlen (an )nâN ist genau dann konvergent, wenn
âÎľ > 0 ân0 â N âp, q âĽ n0 :

|ap â aq | < Îľ .

Definition 4.1.19 (Teilfolgen, HaĚufungswerte). Es sei (an )nâN eine Folge komplexer Zahlen.
(i) Ist (mn )nâN eine streng monoton wachsende Folge natuĚrlicher Zahlen, so
heiĂt die Folge (amn )nâN Teilfolge von (an ).
(ii) Eine Zahl a â C heiĂt HaĚufungswert von (an ), falls es eine Teilfolge von (an )
gibt, die gegen a konvergiert.
Beispiele.
(i) Jede Folge ist Teilfolge von sich selbst. Insbesondere ist der Grenzwert einer
konvergenten Folge auch HaĚufungswert der Folge.
(ii) Die Folge komplexer Zahlen (in )nâN besitzt unter anderem die vier Teilfolgen (i4n+1 )nâN , (i4n+2 )nâN , (i4n+3 )nâN und (i4n+4 )nâN , die alle vier konstant
sind und insbesondere gegen die Grenzwerte i, â1, âi und 1 konvergieren.
Diese vier Zahlen sind also HaĚufungswerte der Folge (in )nâN .
Wir stellen zum Schluss dieses Abschnitts uĚber Folgen einen beruĚhmten Satz
vor (ohne Beweis).
Satz 4.1.20 (Satz von Bolzano & WeierstraĂ). Jede beschraĚnkte Folge besitzt
eine konvergente Teilfolge. Insbesondere besitzt also jede beschraĚnkte Folge einen
HaĚufungswert.

4.1.3

Reihen

Reihen sind spezielle Folgen, die durch Aufsummieren von Folgen entstehen.
Definition 4.1.21 (Reihen).
Es sei (ak )kâN eine Folge komplexer Zahlen. Dann
Pâ
bezeichnet die Reihe k=1 ak die Folge
!
n
X
(sn )nâN :=
ak
.
k=1

nâN

Konvergiert diese Folge (snP
) gegen den Grenzwert a, so konvergiert die Reihe und
der Grenzwert a wird mit â
k=1 ak bezeichnet. Divergiert die Folge
Pn (sn ), so sagt
man auch, dass die Reihe divergiert. Das n-te Folgenglied sn = k=1 ak wird nte Partialsumme genannt und die Folge (sn ) wird auch Folge der Partialsummen
genannt.

Kapiel 4: Analysis

M. Skutella

151

Bemerkung.
P
(i) Man beachte, dass mit â
k=1 ak zunaĚchst keine (komplexe) Zahl identifiziert wird, sondern lediglich die spezielle
P Zahlenfolge (sn ). Nur wenn diese
Zahlenfolge konvergiert, bezeichnet â
k=1 ak gleichzeitig den Grenzwert.
(ii) AĚhnlich wie bei Folgen muĚssen auch Reihen nicht mit dem Index k = 1
beginnen.
P Jede andere ganze Zahl n0 â Z istPhier denkbar. Wir schreiben
dann kâĽn0 ak . FuĚr nP
0 , n1 â Z ist die Reihe
kâĽn0 ak genau dann konvergent, wenn die Reihe kâĽn1 ak konvergiert.
(iii) Jede Folge (sn )nâN kann als Reihe geschrieben werden. Man setzt einfach
a1 := s1 und ak+1 := sk+1 â sk fuĚr k â N. Dann ist
n
X

sn =

ak

fuĚr alle n â N.

k=1

Beispiele.
P
1
(i) Die harmonische Reiheâ â
k=1 k ist nicht konvergent. Wir zeigen, dass die
â
zugehoĚrige Folge der Partialsummen gegen
P2m 1undendlich geht. Dazu betrachten wir fuĚr m â N die Partialsumme k=1 k . Es gilt
m

2
X
1
k=1

k

= 1+

p

2
X

m
X

p=1 k=2pâ1 +1

âĽ 1+
= 1+
= 1+

p

m
X

2
X

p=1 k=2pâ1 +1
m
X
p=1

1
k
1
2p

1
2

m
.
2

Folglich gibt es zu jedem
r > 0 ein n0 â N (waĚhle naĚmlich n0 := 2m
P
n
mit 1 + m2 > r), so dass k=1 k1 > r fuĚr alle n âĽ n0 .
P
1
(ii) Die Reihe â
k=1 k2 ist konvergent. Da die Folge der Partialsummen monoton steigend ist, genuĚgt es nach Lemma 4.1.13 zu zeigen, dass diese Folge

152

Mathematik fuĚr Informatiker

M. Skutella

beschraĚnkt ist. FuĚr alle n â N gilt:
n
n
X
X
1
1
â¤ 1+
2
k
k Âˇ (k â 1)
k=1
k=2

n 
X
1
1
= 1+
â
kâ1 k
k=2


1
= 1+ 1â
n
< 2 .

P
Ď2
1
Man kann zeigen, dass der Grenzwert der Folge gleich â
k=1 k2 = 6 ist.
Pâ k
P
1
k
(iii) FuĚr q â C mit |q| < 1 ist die Reihe â
k=0 q konvergent mit
k=0 q = 1âq .
Denn wir haben in Kapitel 2, Lemma 2.1.3 gezeigt (beachte, dass der dort
gefuĚhrte Beweis auch fuĚr komplexe Zahlen q funktioniert), dass fuĚr die n-te
Partialsumme gilt:
sn =

n
X

qk =

k=0

1 â q n+1
.
1âq

Wie wir weiter oben festgestellt haben, ist limnââ q n = 0. Folglich gilt
â
X
k=0

qk =

lim sn =

nââ

1 â q Âˇ limnââ q n
1
=
.
1âq
1âq

Der folgende Satz ist eine direkte UĚbertragung von Satz 4.1.18 fuĚr Reihen.
Satz 4.1.22 (Cauchy-Kriterium
fuĚr Reihen). Es sei (an )nâN eine Folge komplexer
P
Zahlen. Die Reihe â
a
konvergiert
genau dann, wenn
k=1 k
âÎľ > 0 ân0 â N âp âĽ n âĽ n0 :

p
X

ak

< Îľ .

k=n

Beispiele.
(i) Mit Hilfe von Satz 4.1.22 koĚnnen
jetzt noch einmal sehr einfach zeigen,
Pâ wir
1
dass die harmonische Reihe k=1 k divergent ist. Denn fuĚr alle n â N gilt
2n
X
1
âĽ
k
k=n+1

Folglich kann es fuĚr Îľ =

1
2

2n
X
1
1
=
.
2n
2
k=n+1

das in Satz 4.1.22 geforderte n0 â N nicht geben.

Kapiel 4: Analysis

M. Skutella

153

(ii) Genauso
mit Hilfe von Satz 4.1.22 zeigen, dass die Reihen
Pâ kann man
k
und k=1 (â1) nicht konvergieren.

Pâ

k=1

ik

Mit Satz 4.1.22 erhaĚlt man sofort das folgende notwendige Kriterium fuĚr die
Konvergenz einer Reihe.
Lemma
P 4.1.23. Es sei (an )nâN eine Folge komplexer Zahlen. Konvergiert die
Reihe â
k=1 ak , so ist die Folge (an ) eine Nullfolge.
P
Beweis. Konvergiert die Reihe â
k=1 ak , so ist das Cauchy-Kriterium aus Satz 4.1.22
erfuĚllt. Zu einem beliebigen Îľ > 0 gibt es also ein n0 â N, so dass fuĚr alle n âĽ n0
gilt (setze p := n):
|an â 0| = |an | =

n
X

ak

< Îľ .

k=n

Folglich ist (an ) eine Nullfolge.



Bemerkung. Die Bedingung, dass (an ) eine Nullfolge sein
Pâmuss ist notwendig,
jedoch nicht hinreichend
 Reihe k=1 ak . Denn die harPâ 1 fuĚr die Konvergenz der
1
monische Reihe k=1 k ist divergent, obwohl n nâN eine Nullfolge ist.
Aus unserem Wissen uĚber die Konvergenz von Folgen aus Lemma 4.1.13
koĚnnen wir sofort das folgende Kriterium fuĚr die Konvergenz einer Reihe mit
nicht-negativen Summanden ableiten.
Korollar 4.1.24. Ist (an )nâN eine
Pâ Folge nicht-negativer reeller Zahlen, dann konvergiert die zugehoĚrige Reihe k=1 ak genau dann, wenn die Folge der Partialsummen nach oben beschraĚnkt ist.
Definition 4.1.25 (Absolute Konvergenz).
Es sei (an )nâN eine Folge komplexer
Pâ
Zahlen.
k=1 ak heiĂt absolut konvergent, falls die ReiPâ Die zugehoĚrige Reihe
he k=1 |ak | konvergiert.
Satz 4.1.26. Jede absolut konvergente Reihe ist konvergent.
Beweis. Da wegen der Dreiecksungleichung fuĚr alle p âĽ n gilt, dass
p
X
k=n

ak

â¤

p
X

|ak | ,

k=n

folgt die Behauptung unmittelbar aus dem Cauchy-Kriterium in Satz 4.1.22. 
Das folgende Majorantenkriterium ist nuĚtzlich, da man damit die (absolute)
Konvergenz einer Reihe auf die Konvergenz einer anderen (einfacheren) Reihe
zuruĚckfuĚhren kann.

154

Mathematik fuĚr Informatiker

M. Skutella

Satz 4.1.27 (Majoranten- und Minorantenkriterium). Es seien (an )nâN und (bn )nâN
Folgen komplexer Zahlen.
P
(i) Ist â
k=1 bk absolut konvergent und gibt
Pâes eine reelle Zahl c > 0 mit |an | â¤
c Âˇ |bn | fuĚr alle n â N, dann ist auch k=1 ak absolut konvergent.
Pâ
(ii) Ist
k=1 bk nicht absolut konvergent und gibt es eine
Pâreelle Zahl c > 0
mit |an | âĽ c Âˇ |bn | fuĚr alle n â N, dann ist auch
k=1 ak nicht absolut
konvergent.
Beweis. Zu (i): Wegen Korollar
Pâdass die Folge der
Pâ 4.1.24 genuĚgt es zu zeigen,
Partialsummen der Reihe
|a
|
beschraĚnkt
ist.
Da
k
k=1
k=1 |bk | konvergiert,
ist die Folge der Partialsummen dieser Reihe nach Lemma 4.1.12 durch eine
Zahl B > 0 beschraĚnkt. Folglich gilt fuĚr alle n â N:
n
X

|ak | â¤

n
X

c Âˇ |bk | = c Âˇ

k=1

k=1

n
X

|bk | â¤ c Âˇ B .

k=1

Teil (ii) beweist man analog.



Beispiele.
(i) Die Reihe

Pâ

k!
k=1 kk

ist absolut konvergent. Es gilt

2
k!
1 Âˇ 2 Âˇ 3ÂˇÂˇÂˇk
=
fuĚr k âĽ 2.
â¤ 2
k
k
k Âˇ k Âˇ kÂˇÂˇÂˇk
k
P
2
Folglich ist die Reihe â
k=1 k2 eine absolut konvergente Majorante.
Pâ 1
P
1
(ii) Ist 0 < p < 1, so divergiert die Reihe â
k=1 k eine divergente
k=1 kp , da
Minorante ist.
Das folgende Quotientenkriterium erhaĚlt man durch Anwendung des Majorantenkriteriums mit einer geometrischen Reihe als Vergleichsreihe.
Satz 4.1.28 (Quotientenkriterium). Es sei (an )nâN eine Folge komplexer Zahlen.
(i) Gibt esPein q < 1, so dass |an+1 | â¤ q Âˇ |an | fuĚr alle n â N, dann ist die
Reihe â
k=1 ak absolut konvergent.
P
(ii) Gilt |an | > 0 und |an+1 | âĽ |an | fuĚr alle n â N, dann ist die Reihe â
k=1 ak
nicht absolut konvergent.
Beweis. Zu (i): Mit vollstaĚndiger Induktion kann man leicht zeigen, dass
|an | â¤ q nâ1 Âˇ |a1 |

fuĚr alle n â N.

Kapiel 4: Analysis

M. Skutella

155

Folglich gilt fuĚr die n-te Partialsumme
n
X

|ak | â¤ |a1 | Âˇ

k=1

n
X

q kâ1 = |a1 | Âˇ

nâ1
X

q k = |a1 | Âˇ

k=0

k=1

1 â qn
|a1 |
â¤
.
1âq
1âq

Die Folge der Partialsummen ist also beschraĚnkt, so dass die Reihe nach Korollar 4.1.24 absolut konvergiert.
Zu (ii): Mit vollstaĚndiger Induktion folgt, dass |an | âĽ |a1 | > 0 fuĚr
Palle n â N.
Nach dem Minorantenkriterium aus Satz 4.1.27 (ii) ist die Reihe â
k=1 ak also
nicht absolut konvergent.

Beispiele.
P
zk
(i) FuĚr z â C ist die Reihe â
k=0 k! absolut konvergent. Dies folgt aus dem
Quotientenkriterium in Satz 4.1.28, da
|z|
|z|n
|z|n+1
=
Âˇ
(n + 1)!
n + 1 n!
Folglich ist die Bedingung aus dem Quotientenkriterium fuĚr alle n âĽ |z|
erfuĚllt. Da die ersten n Summanden keinen Einfluss auf die Konvergenz der
Reihe haben, ist die Behauptung damit gezeigt.
P
1
(ii) Obwohl die Reihe â
k=1 k2 absolut konvergent ist (siehe oben), kann man
das nicht einfach mit dem Quotientenkriterium beweisen. Es gilt zwar
1
(n+1)2
1
n2


=

n
n+1

2
< 1 ,

doch es gibt kein q < 1, so dass der Quotient fuĚr alle n â N durch q nach
oben beschraĚnkt ist.
AĚhnlich wie das Quotientenkriterium erhaĚlt man auch das folgende Wurzelkriterium.
Satz 4.1.29 (Wurzelkriterium). Es sei (an )nâN eine Folge komplexer Zahlen.
p
n
(i) Gibt
es
ein
q
<
1,
so
dass
|an | â¤ q fuĚr alle n â N, dann ist die ReiPâ
he k=1 ak absolut konvergent.
p
P
(ii) Gilt n |an | âĽ 1 fuĚr alle n â N, dann ist die Reihe â
k=1 ak nicht absolut
konvergent.
Beweis.
(i) folgt aus dem Majorantenkriterium in Satz 4.1.27 (i),
Pâ Behauptung
k
da k=1 q absolut konvergent P
ist. Behauptung (ii) folgt aus dem Minorantenk
kriterium in Satz 4.1.27 (ii), da â

k=1 1 divergent ist.

156

Mathematik fuĚr Informatiker

M. Skutella

Beispiel. Es sei (an )nâN die durch
(
2ân falls n gerade,
an :=
3ân falls n ungerade,
P
definierte Folge. Dann ist die Reihe â
k=1 ak nach dem Wurzelkriterium absolut
konvergent. Es gilt naĚmlich
(
1
â
falls n gerade,
2
n
an :=
1
falls n ungerade.
3
Folglich ist

â
n

an â¤

1
2

< 1 fuĚr alle n â N.

Bemerkung. Satz 4.1.28 und Satz 4.1.29 gelten auch noch, wenn man fuĚr alâ
le n â Nâ durch fuĚr fast alle n â Nâ ersetzt (mit der Bedeutung: fuĚr alle auĂer
â
â
endlich vielen n â Nâ).
Definition 4.1.30 (Alternierende Reihen).
Es sei (an )nâN eine Folge reeller ZahP
len. Wir nennen die zugehoĚrige Reihe â
a
k=1 k alternierend, wenn die Folgenglieder abwechselnd positiv und negativ sind.
P
Pâ (â1)k
k
Beispiel. Die Reihen â
sind alternierend.
k=1 (â1) und
k=1
k
Pâ
Satz 4.1.31 (Leibniz-Kriterium). Es sei k=1 ak eine alternierende Reihe. Ist
die P
Folge (|an |)nâN eine monoton fallende Nullfolge, dann konvergiert die Reihe â
k=1 ak .
Beweis. Wir nehmen ohne BeschraĚnkung der Allgemeinheit an, dass a1 < 0 (den
Fall a1 > 0 kann man voĚllig analog behandeln). Dann gibt es eine Folge von
nicht-negativen rellen Zahlen (bn )nâN mit an = (â1)n Âˇ bn fuĚr alle n â N. Die
Folge (bn ) ist nachP
Voraussetzung einePmonoton fallende Nullfolge. FuĚr die Partialsummen sn := nk=1 an der Reihe â
k=1 ak gilt also
s2n+2 â s2n = b2n+2 â b2n+1 â¤ 0 ,
s2n+3 â s2n+1 = â b2n+3 + b2n+2 âĽ 0

(4.1)
(4.2)

und
s2n â s2n+1 = b2n+1 âĽ 0

(4.3)

fuĚr alle n â N. Folglich ist die Teilfolge (s2n )nâN wegen (4.1) monoton fallend
und die Teilfolge (s2n+1 )nâN ist wegen (4.2) monoton wachsend. AuĂerdem gilt
wegen (4.3), dass s2n âĽ s2n+1 fuĚr alle n â N. Da (bn ) eine Nullfolge ist, gibt es zu
jedem Îľ > 0 ein n0 â N mit
0 â¤ s2n â s2n+1 < Îľ

fuĚr alle n mit 2n âĽ n0 .

Kapiel 4: Analysis

M. Skutella

157

WirPzeigen jetzt mit Hilfe des Cauchy-Kriterium in Satz 4.1.22, dass die Reihe â
k=1 ak konvergiert. Dazu genuĚgt es zu zeigen, dass
p
X

ak

< Îľ

fuĚr alle p âĽ n > n0 .

(4.4)

k=n

Wir nehmen im Folgenden an, dass p = 2q gerade und n = 2m + 1 ungerade ist
(die anderen drei FaĚlle kann man analog behandeln). Dann gilt
p
X

ak

=

k=n

2q
X

ak

= s2m â s2q

wegen (4.1),

â¤ s2m â s2q+1
â¤ s2m â s2m+1
< Îľ

wegen (4.3),
wegen (4.2),
wegen (4.4).

k=2m+1

Damit ist der Beweis abgeschlossen.
Beispiel. Die sogenannte Leibniz-Reihe
konvergent.


Pâ

k=1

(â1)k
k

ist nach dem Leibniz-Kriterium

Zum Schluss dieses Abschnitts geben wir noch zwei interessante Resultate
uĚber absolut konvergente Reihen ohne Beweis an. ZunaĚchst benoĚtigen wir jedoch
die folgende Definition der Umordnung einer Folge.
Definition 4.1.32 (Umordnung einer Folge). Es sei (an )nâN eine Folge komplexer Zahlen und Ď : N â N eine bijektive Abbildung. Dann nennt man die
Folge (aĎ(n) )nâN eine Umordnung von (an ).
Satz 4.1.33.
Es sei (an )nâN eine Folge komplexer Zahlen, so dass die zugehoĚrige
P
Reihe â
a
k=1 k absolut konvergent ist. Ist Ď : N â N eine bijektive
Pâ Abbildung,
so ist die zu der umgeordneten Folge (aĎ(n) )nâN gehoĚrende Reihe k=1 aĎ(k) auch
absolut konvergent und die Grenzwerte der beiden Reihen stimmen uĚberein.
Bemerkung. Satz 4.1.33 gilt nicht, wenn man absolut konvergentâ durch konâ
â
vergentâ ersetzt. Durch Umordnung kann aus einer konvergenten Reihe, die nicht
absolut konvergent ist, sowohl eine divergente Reihe als auch eine konvergente
Reihe mit verschiedenem Grenzwert entstehen.
Pâ
Pâ
Satz 4.1.34 (Cauchy-Produkt). Es seien
Pn k=0 ak und k=0 bk absolut konvergente
k=0 ak bnâk . Dann konvergiert die ReiP Reihen. FuĚr n â N0 sei cn :=
c
absolut
und
es
gilt
he â
n=0 n
!
!
!
â
n
â
â
â
X
X
X
X
X
ak bnâk
=
cn =
ak Âˇ
bk
.
n=0

k=0

n=0

k=0

k=0

158

4.1.4

Mathematik fuĚr Informatiker

M. Skutella

Potenzreihen

Wir betrachten in diesem Abschnitt Reihen, die von einer komplexen Variablen z
abhaĚngen, sogenannte Potenzreihen.
Definition 4.1.35 (Potenzreihen). Es sei (an )nâN0 eine Folge komplexer Zahlen
und z0 â C. Dann betrachten wir fuĚr beliebige z â C die Potenzreihe
â
X

ak (z â z0 )k .

k=0

Die komplexe Zahl z0 heiĂt Entwicklungspunkt der Potenzreihe.
Bemerkung. Wir werden im Folgenden fast nur Potenzreihen mit dem Entwicklungspunkt z0 = 0 betrachten. Wir koĚnnen das ohne BeschraĚnkung der Allgemeinheit tun, da man immer durch einen Variablenwechsel von z auf z â z0
uĚbergehen kann.
Beispiele.
P
k
(i) Wir koĚnnen fuĚr z â C die geometrische Reihe â
k=0 z als spezielle Potenzreihe mit an := 1 fuĚr alle n â N0 und z0 := 0 auffassen. Wie wir weiter
oben gezeigt haben, konvergiert diese Potenzreihe fuĚr |z| < 1 und divergiert
fuĚr |z| > 1.
(ii) FuĚr beliebiges z0 â C konvergiert die Potenzreihe
(siehe oben).

Pâ

k=0

(zâz0 )k
k!

fuĚr alle z â C

(iii) FuĚrPden Entwicklungspunkt z = z0 konvergiert eine beliebige Potenzreik
he â
k=0 ak (z â z0 ) immer gegen den Wert a0 .
Lemma 4.1.36.
(an )nâN0 eine Folge komplexer Zahlen. Konvergiert die
Pâ Es sei
k
Potenzreihe
k=0 ak z fuĚr ein z = z1 â C, dann konvergiert sie absolut fuĚr
alle z â C mit |z| < |z1 |.
Beweis. Wegen Lemma 4.1.23 ist (an z1n )nâN0 eine Nullfolge. Folglich gibt es ein c >
0 mit |an z1n | â¤ c fuĚr alle n â N0 . Es sei nun z â C mit |z| < |z1 | und q := zz1 < 1.
Dann gilt
 n
n
z
z
n
n
|an z | =
Âˇ an z1 â¤ c Âˇ
= c Âˇ qn .
z1
z1
Aufgrund des Majorantenkriteriums ist die Reihe
gent.

Pâ

k=0

ak z k also absolut konver

Kapiel 4: Analysis

M. Skutella

159

Definition 4.1.37 (Konvergenzbereich,
Konvergenzradius). Es sei (an )nâN0 eine
Pâ
k
Folge komplexer Zahlen und k=0 ak z die zugehoĚrige Potenzreihe. Dann nennt
man die Menge
)
(
â
X
k
ak z konvergiert
C :=
zâC
k=0

den Konvergenzbereich der Potenzreihe. AuĂerdem nennt man
Ď := sup{|z| | z â K}
den Konvergenzradius der Potenzreihe.
Bemerkung. Da 0 im Konvergenzbereich jeder Potenzreihe liegt, ist der Konvergenzradius Ď immer nicht-negativ. Ist der Konvergenzradius unendlich groĂ,
so konvergiert die Potenzreihe wegen Lemma 4.1.36 fuĚr alle z â C.
Pâ
k
Satz 4.1.38. Es sei (an )nâN0 eine Folge komplexer Zahlen und
k=0 ak z die
zugehoĚrige Potenzreihe mit Konvergenzradius Ď. Dann gilt
(i) Die Potenzreihe ist fuĚr alle z â C mit |z| < Ď absolut konvergent.
(ii) Die Potenzreihe ist fuĚr alle z â C mit |z| > Ď divergent.
Beweis. Zu (i): Es sei z â C mit |z| < Ď. Dann gibt es nach Definition von Ď
ein z1 â C mit |z| < |z1 | < Ď, so dass z1 im Konvergenzbereich der Potenzreihe liegt. Die Behauptung folgt dann sofort mit Lemma 4.1.36. Teil (ii) folgt
unmittelbar aus der Definition des Konvergenzradius Ď.

Bemerkung.
(i) Satz 4.1.38 kann man wie folgt zusammenfassen. FuĚr den Konvergenzbereich C und den Konvergenzradius Ď einer Potenzreihe gilt
{z â C | |z| < Ď} â C â {z â C | |z| â¤ Ď} .
(ii) Betrachtet man in der Situation von Satz 4.1.38 ein z â C mit |z| = Ď, so
kann man keine allgemeinguĚltige Aussage bezuĚglich der Konvergenz oder
Divergenz der Potenzreihe im Punkt z machen. Wir illustrieren dies im
Folgenden anhand einiger Beispiele.
Beispiele.
P
k
(i) Der Konvergenzradius der geometrischen Reihe â
k=0 z ist Ď = 1. Die geometrische Reihe divergiert jedoch fuĚr alle z â C mit |z| = Ď, da die zugehoĚrige Folge (z n )nâN0 offenbar keine Nullfolge ist.

160

Mathematik fuĚr Informatiker

M. Skutella

P
zk
(ii) Wir betrachten die Potenzreihe â
k=1 k . FuĚr z = â1 erhaĚlt man die konvergente Leibnizreihe und fuĚr z = 1 die divergente harmonische Reihe. Daraus
kann man wegen Satz 4.1.38 bereits schlieĂen, dass der Konvergenzradius
dieser Potenzreihe Ď = 1 ist. Insbesondere liegt hier offenbar kein einheitliches Konvergenzverhalten der Punkte z â C mit |z| = Ď vor.
P
zk
(iii) Wir werden spaĚter zeigen, dass die Potenzreihe â
k=1 k2 den Konvergenzradius Ď = 1 hat. Da die Potenzreihe fuĚr z = 1 absolut konvergent ist, folgt
aus dem Majorantenkriterium, dass sie fuĚr alle z â C mit |z| = Ď absolut
konvergiert.
Zur konkreten Berechnung des Konvergenzradius einer Potenzreihe kann man
das Quotienten- oder das Wurzelkriterium aus dem letzten Abschnitt verwenden.
Die folgenden SaĚtze praĚzisieren diese Einsicht.
Pâ
Satz 4.1.39. Es sei (an )nâN0 eine Folge komplexer Zahlen und
z k die
k=0 akp
zugehoĚrige Potenzreihe mit Konvergenzradius Ď. FuĚr n â N0 sei bn := n |an |.
Dann gilt:
(i) Geht die Folge (bn )nâN0 gegen unendlich, so ist Ď = 0.
(ii) Konvergiert (bn )nâN0 gegen den Grenzwert b > 0, so ist Ď = 1b .
(iii) Ist (bn )nâN0 eine Nullfolge, so ist Ď = â.
p
Beweis. Wir beweisen nur (ii). Ist limnââ n |an | = limnââ bn = b, so ist
lim

nââ

p
n
|an z n | =

p
p
lim (|z| n |an |) = |z| Âˇ lim n |an | = |z| Âˇ b .

nââ

nââ

Ist also |z| < 1b , so ist die Potenzreihe wegen Satz 4.1.29 (i) absolut konvergent.
Ist |z| > 1b , so ist die Potenzreihe wegen Satz 4.1.29 (ii) divergent. Folglich ist
der Konvergenzradius der Potenzreihe Ď = 1b . Die beiden anderen Aussagen des
Satzes beweist man analog.

Satz 4.1.40.
(an )nâN0 eine Folge komplexer Zahlen mit an 6= 0 fuĚr alle n â
P Es sei
k
N0 und â
a
z
die
zugehoĚrige Potenzreihe mit Konvergenzradius Ď. FuĚr n â
k=0 k
|an+1 |
N0 sei bn := |an | . Dann gilt:
(i) Geht die Folge (bn )nâN0 gegen unendlich, so ist Ď = 0.
(ii) Konvergiert (bn )nâN0 gegen den Grenzwert b > 0, so ist Ď = 1b .
(iii) Ist (bn )nâN0 eine Nullfolge, so ist Ď = â.

Kapiel 4: Analysis

M. Skutella

Beweis. Wir beweisen wieder nur (ii). Ist limnââ
|an+1 z n+1 |
=
nââ
|an z n |
lim

lim (|z|

nââ

161
|an+1 |
|an |

= limnââ bn = b, so ist

|an+1 |
|an+1 |
) = |z| Âˇ lim
= |z| Âˇ b .
nââ |an |
|an |

Ist also |z| < 1b , so ist die Potenzreihe wegen Satz 4.1.28 (i) absolut konvergent.
Ist |z| > 1b , so ist die Potenzreihe wegen Satz 4.1.28 (ii) divergent. Folglich ist
der Konvergenzradius der Potenzreihe Ď = 1b . Die beiden anderen Aussagen des
Satzes beweist man analog.

Pâ
Beispiele. Wir betrachten die Potenzreihe k=0 ak z k .
|
|
n
(i) Ist an = n1 fuĚr n â N, dann ist |a|an+1
= n+1
und die Folge ( |a|an+1
)nâN
n|
n|
konvergiert gegen 1. Nach Satz 4.1.40 ist der Konvergenzradius der Potenzreihe Ď = 11 = 1 (wie bereits weiter oben festgestellt). Dasselbe Ergebnis
kann man prinzipiell auch mit dem Wurzelkriterium (Satz 4.1.39) erhalten.

(ii) Ist an =

1
n2

fuĚr n â N, dann ist
|an+1 |
n2
1
= 2
=
2
|an |
n + 2n + 1
1+ n +

1
n2

|
)nâN konvergiert folglich gegen 1. Nach Satz 4.1.40 ist
und die Folge ( |a|an+1
n|
der Konvergenzradius der Potenzreihe Ď = 11 = 1.
p
p
(iii) Ist an = nn , so ist n |an | = n und die Folge ( n |an |)nâN geht gegen unendlich. Folglich ist der Konvergenzradius der Potenzreihe Ď = 0 und der
Konvergenzbereich besteht folglich nur aus dem Nullpunkt.
|
|
n!
1
(iv) Ist an = n!1 , so ist |a|an+1
= (n+1)!
= n+1
und die Folge ( |a|an+1
)nâN ist eine
n|
n|
Nullfolge. Folglich ist der Konvergenzradius der Potenzreihe unendlich und
die Potenzreihe konvergiert fuĚr alle z â C.

Die im letzten Beispiel betrachtete Potenzreihe spielt eine besondere Rolle,
da sie als Funktion aufgefasst die bekannte Exponentialfunktion definiert. Wir
beschaĚftigen uns im folgenden Abschnitt naĚher mit dieser Funktion.

4.1.5

Exponentialfunktion und Logarithmus

Wir fuĚhren zunaĚchst die Eulerâsche Zahl e als Grenzwert einer Folge ein. Als
technisches Hilfsmittel benoĚtigen wir dabei die Bernoulli-Ungleichung und die
Binomialformel.
Lemma 4.1.41 (Bernoulli-Ungleichung). Ist x â R mit x âĽ â1, so gilt fuĚr
alle n â N0
(1 + x)n âĽ 1 + n Âˇ x .

162

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Wir zeigen die Behauptung mitels vollstaĚndiger Induktion. Induktionsanfang: Die Behauptung ist offenbar wahr fuĚr n = 0, da (1 + x)0 = 1 = 1 + 0 Âˇ x
fuĚr alle x â R. Induktionsschluss: Wir nehmen an, dass die Behauptung fuĚr ein
beliebiges, fest gewaĚhltes n â N0 . Dann gilt
(1 + x)n+1 =
âĽ
=
âĽ

(1 + x)n Âˇ (1 + x)
(1 + n Âˇ x) Âˇ (1 + x) nach Induktionsannahme und da x âĽ â1,
1 + (n + 1) Âˇ x + x2
1 + (n + 1) Âˇ x
da x2 âĽ 0.

Damit ist der Beweis abgeschlossen.



Lemma 4.1.42 (Binomialformel). Es seien x, y â C und n â N. Dann gilt
n  
X
n k nâk
n
(x + y) =
x y
,
k
k=0

n
wobei der Binomialkoeffizient k wie folgt definiert ist:
 
n
n!
n Âˇ (n â 1) Âˇ Âˇ Âˇ Âˇ Âˇ (n â k + 2) Âˇ (n â k + 1)
=
=
.
k
k! Âˇ (n â k)!
k Âˇ (k â 1) Âˇ Âˇ Âˇ Âˇ Âˇ 2 Âˇ 1
Beweis. VollstaĚndige Induktion uĚber n.



1 n
n

konverSatz 4.1.43 (Eulerâsche Zahl e). Die Folge (an )nâN mit an := 1 +
giert. Der Grenzwert wird mit e bezeichnet und Eulerâsche Zahl genannt.
Beweis. Wir zeigen, dass die Folge (an ) monoton steigend und beschraĚnkt ist.
Um die Monotonie zu zeigen, betrachten wir den Quotienten an+1
und zeigen,
an
dass er immer groĚĂer als 1 ist. Denn es gilt
n+1
1
1 + n+1
an+1
n
=
an
1 + n1
=

(n+2)n+1
(n+1)n+1
(n+1)n
nn


n
n+2
(n + 2) Âˇ n
=
Âˇ
n+1
(n + 1)2

 
n
1
1
=
1+
Âˇ 1â
n+1
(n + 1)2

 

1
n
âĽ
1+
Âˇ 1â
n+1
(n + 1)2
1
n
n
= 1+
â
â
2
n + 1 (n + 1)
(n + 1)3
1
= 1+
(n + 1)3

wegen Lemma 4.1.41,

Kapiel 4: Analysis

M. Skutella

163

Es bleibt also zu zeigen, dass die Folge (an ) beschraĚnkt ist. Es gilt

n
n  
X
1
n 1
an =
1+
=
.
n
k nk
k=0
Es gilt
 
n
1
n Âˇ (n â 1) Âˇ Âˇ Âˇ Âˇ Âˇ (n â k + 2) Âˇ (n â k + 1)
Âˇ k =
k
n
k! Âˇ nk
nâk+1
1 n nâ1
Âˇ Âˇ
Âˇ ÂˇÂˇÂˇ Âˇ
.
=
k! n
n
n

1
FuĚr k âĽ 1 gilt daher nk Âˇ n1k â¤ k!1 â¤ 2kâ1
. Folglich gilt
n  
n
â  k
X
X
X
n 1
1
1
â¤ 1+
< 1+
an = 1 + 1 +
= 3 .
k
kâ1
k n
2
2
k=2
k=1
k=0
Damit ist der Beweis fertig.



Bemerkung. Aus dem
Beweis von Satz 4.1.43 folgt, dass e â¤ 3. Andererseits

1 2
gilt e âĽ a2 = 1 + 2 = 94 . Genauer gesagt ist e ungefaĚhr 2.718282.
P
1
Lemma 4.1.44. Die Reihe â
k=0 k! konvergiert gegen den Grenzwert e.
n
fuĚr alle n â P
N, so dass e nach Definition der
Beweis. Es sei an := 1 + n1
Grenzwert
Folge (an ) ist. Weiter sei sn := nk=0 k!1 die n-te Partialsumme der
Pâ der
Reihe k=0 k!1 . Dann ist die Folge (sn ) monoton steigend und wir muĚssen zeigen,
dass siegegen e konvergiert. Bereits im Beweis von Satz 4.1.43 haben wir gezeigt,
dass nk Âˇ n1k â¤ k!1 . Daraus folgt
n

n
n  
X
X
1
n 1
1
â¤
=
= sn .
an =
1+
k
n
k
n
k!
k=0
k=0
Es bleibt also zu zeigen, dass die Folge (sn ) nach oben durch e beschraĚnkt ist.
Dann folgt aus dem Vergleichskriterium in Satz 4.1.14 (i), dass sie gegen den
Grenzwert e konvergiert.
Aus dem Beweis von Satz 4.1.43 folgt, dass fuĚr m âĽ n gilt:
m  
X
m 1
am =
k mk
k=0
m
X
1 m mâ1
mâk+1
=
Âˇ
Âˇ
Âˇ ÂˇÂˇÂˇ Âˇ
k! m
m
m
k=0

âĽ

n
X
1 m mâ1
mâk+1
Âˇ
Âˇ
Âˇ ÂˇÂˇÂˇ Âˇ
=: bm .
k!
m
m
m
k=0

164

Mathematik fuĚr Informatiker

M. Skutella

Mit Satz 4.1.17 und Lemma 4.1.16 folgt, dass
n
X
1
sn =
= lim bm â¤ lim am â¤ e
mââ
mââ
k!
k=0

fuĚr alle n â N.

Damit ist der Beweis abgeschlossen.



Wir definieren jetzt die Exponentialfunktion als spezielle Potenzreihe.
Definition 4.1.45 (Exponentialfunktion). Die Exponentialfunktion exp : C â C
ist definiert durch
â
X
zk
exp(z) :=
fuĚr alle z â C.
k!
k=0
Bemerkung.
(i) Es gilt exp(0) =

Pâ

0k
k=0 k!

= 1 und exp(1) =

Pâ

1k
k=0 k!

= e.

(ii) Die Exponentialfunktion besitzt eine sehr spezielle Eigenschaft, die im Zusammenhang mit der beschreibung von Wachstumsprozessen in der Natur
von groĂer Bedeutung ist. Es sei f (0) = 1 der Bestand einer Population zum
Zeitpunkt 0 und f (t) der Bestand zu einem spaĚteren Zeitpunkt t âĽ 0. Wenn
sich jedes Individuum der Population zum Zeitpunkt t weiter so vermehrt,
wie das erste Individuum zum Zeitpunkt null, so ist die Population nach
weiteren s Zeiteinheiten auf die GroĚĂe f (s + t) = f (s) Âˇ f (t) angewachsen.
Man interessiert sich daher fuĚr Funktionen f : C â C, die die folgende
Funktionalgleichung erfuĚllen:
f (x + y) = f (x) Âˇ f (y)

fuĚr alle x, y â C.

(4.5)

Lemma 4.1.46. FuĚr die Exponentialfunktion exp : C â C gilt
exp(x + y) = exp(x) Âˇ exp(y)

fuĚr alle x, y â C.

Beweis. Der Beweis basiert im Wesentlichen auf Satz 4.1.34 uĚber das CauchyProdukt. FuĚr x, y â C gilt:
!
!
â
â
X
X
xk
xk
exp(x) Âˇ exp(y) =
Âˇ
k!
k!
k=0
k=0
â X
n
X
xk

y nâk
k! (n â k)!
n=0 k=0
 
â X
n
X
1
n
Âˇ
Âˇ xk Âˇ y nâk
=
n!
k
n=0 k=0
=

=

Âˇ

â
X
(x + y)n
n=0

n!

= exp(x + y) .

Kapiel 4: Analysis

M. Skutella

165

Damit ist die Behauptung bewiesen.



Bemerkung. FuĚr c â C erfuĚllt auch die Funktion f : C â C mit f (z) :=
exp(c Âˇ z) die Funktionalgleichung (4.5). Man kann zeigen, dass jede Funktion f ,
die (4.5) erfuĚllt, von dieser Form fuĚr ein c â C ist. Insbesondere ist exp die einzige
Funktion, die (4.5) erfuĚllt und an der Stelle 1 gleich e ist.
Wir halten im folgenden Lemma einige weitere Eigenschaften der Exponentialfunktion fest.
Lemma 4.1.47. FuĚr die Exponentialfunktion exp gilt:
(i) exp(z) 6= 0 fuĚr alle z â C.
(ii) exp(âz) =

1
exp(z)

fuĚr alle z â C.

(iii) exp(x) â R>0 fuĚr alle x â R.
(iv) exp(x) < exp(y) fuĚr alle x, y â R mit x < y, d.h. exp ist auf R streng
monoton wachsend.
Beweis. Nach Lemma 4.1.46 gilt
1 = exp(0) = exp(z â z) = exp(z) Âˇ exp(âz)

fuĚr alle z â C.

Daraus folgen sofort Behauptung (i) und (ii).
Zu (iii): Aus der Definition der Exponentialfunktion folgt unmittelbar, dass
exp(x) â R fuĚr alle x â R. AuĂerdem ist exp(x) âĽ 0 fuĚr alle x â R, da exp(x) =
exp( x2 )2 . Die Tatsache, dass sogar exp(x) > 0 folgt dann unmittelbar aus (i).
Zu (iv): Da
exp(y) = exp(x) Âˇ exp(y â x)

und

exp(x) > 0 ,

bleibt zu zeigen, dass exp(r) > 1 fuĚr r > 0. Dies folgt aus der Definition der
Exponentialfunktion, da
exp(r) =

â
X
rk
k=0

k!

âĽ 1+r > 1 .

Dabei erhaĚlt man die erste Ungleichung durch Weglassen aller Summanden mit
Index k âĽ 2.

Satz 4.1.48. FuĚr jede rationale Zahl q â Q gilt exp(q) = eq .

166

Mathematik fuĚr Informatiker

M. Skutella

Beweis. ZunaĚchst kann man leicht durch vollstaĚndige Induktion zeigen, dass
exp(n) = en fuĚr alle n â N0 . Im Induktionsschritt wendet man die Funktionalgleichung aus Lemma 4.1.46 an. Wir betrachten nun ein m â N:
!
 
 m
m
m
m
Y
X
1
1
1
e = exp
exp
= exp
=
= exp
.
m
m
m
m
k=1
k=1
Folglich ist exp( m1 ) die m-te Wurzel aus e, also
 
â
1
1
exp
= m e = em .
m
Folglich gilt fuĚr jede positive rationale Zahl
exp

n
m


= exp

1
m

n
,
m

dass

=

em

n

1

n

n

= em .

Wegen Lemma 4.1.47 (ii) gilt dann fuĚr negative rationale Zahlen
 n â1
 n
= exp
=
exp â
m
m

n

em

â1

n

= eâ m .

Damit ist der Satz bewiesen.



Bemerkung. Aufgrund von Satz 4.1.48 definiert man fuĚr beliebige komplexe
Zahlen z â C:
ez := exp(z) .
Wie wir in Lemma 4.1.47 gesehen haben, ist die EinschraĚnkung der Exponentialfunktion auf die reellen Zahlen monoton steigend und damit insbesondere
injektiv. Man kann sogar zeigen, dass sie bijektiv ist.
Satz 4.1.49. Die EinschraĚnkung der Exponentialfunktion auf die Menge der reellen Zahlen (expR : R â R>0 ) definiert eine bijektive Abbildung von R nach R>0 .
Zur Vereinfachung der Notation bezeichnen wir die Funktion expR : R â R>0
im Folgenden oft auch einfach nur mit exp.
Definition 4.1.50 (NatuĚrlicher Logarithmus). Die Umkehrfunktion der reellen
Exponentialfunktion exp : R â R>0 ist der natuĚrliche Logarithmus, der mit ln :
R>0 â R bezeichnet wird. Es ist also
ln(x) = y

ââ

x = ey = exp(y) .

Wir beweisen zunaĚchst einige Eigenschaften des natuĚrlichen Logarithmus.

Kapiel 4: Analysis

M. Skutella

167

Lemma 4.1.51. FuĚr den natuĚrlichen Logarithmus ln : R>0 â R gilt:
(i) ln(x) < ln(y) fuĚr alle 0 < x < y.
(ii) ln(x Âˇ y) = ln(x) + ln(y) fuĚr alle x, y â R>0 .
(iii) ln(1/x) = â ln(x) fuĚr alle x â R>0 .
(iv) ln(1) = 0.
Beweis. Eigenschaft (i) folgt aus Lemma 4.1.47 (iv). Eigenschaft (ii) folgt aus
Lemma 4.1.46. Eigenschaft (iii) folgt aus (ii). Und (iv) folgt schlieĂlich aus der
Tatsache, dass exp(0) = 1.

Mit Hilfe der Exponentialfunktion und des natuĚrlichen Logarithmus koĚnnen
wir jetzt beliebige komplexe Potenzen reeller Zahlen definieren.
Definition 4.1.52. Es sei a â R > 0 und z â C. Dann definieren wir
az := ezÂˇln(a) = exp(z Âˇ ln(a)) .
Wir nennen die durch z 7â az definierte Funktion von C nach C auch Exponentialfunktion zur Basis a und bezeichnen sie mit expa . Es gilt also
expa (z) = az = exp(z ln(a))

fuĚr alle z â C.

Aus den Eigenschaften der Exponentialfunktion exp folgen sofort die folgenden Eigenschaften von expa .
Lemma 4.1.53. Es sei a â R>0 . Dann gilt:
(i) expa erfuĚllt die Funktionalgleichung (4.5).
(ii) Die EinschraĚnkung von expa auf die reellen Zahlen ist streng monoton wachsend, falls a > 1, und streng monoton fallend, falls a < 1; fuĚr a = 1 ist sie
konstant gleich 1.
(iii) FuĚr a 6= 1 liefert expa eine Bijektion zwischen R und R>0 .
Bemerkung. Es seien a, b â R>0 . Man kann leicht zeigen, dass
(ax )y = axÂˇy

fuĚr alle x, y â R.

AuĂerdem gilt
az Âˇ bz = (a Âˇ b)z

fuĚr alle z â C.

Aufgrund der letzten Behauptung in Lemma 4.1.53 besitzt expa eine Umkehrfunktion von R>0 nach R â den Logarithmus zur Basis a.

168

Mathematik fuĚr Informatiker

M. Skutella

Definition 4.1.54 (Logarithmus zur Basis a). Es sei a â R>0 \ {1}. Dann nennt
man die Umkehrabbildung der EinschraĚnkung von expa auf die reellen Zahlen
die Logarithmusfunktion zur Basis a und bezeichnet sie mit loga : R>0 â R.
(Insbesondere ist ln = loge .)
Lemma 4.1.55. Es sei a â R>0 \ {1} und x > 0. dann gilt
loga (x) =

ln(x)
.
ln(a)

Beweis. Es gilt
ln(x)/ ln(a)

a


= expa

ln(x)
ln(a)




= exp ln(x) = x .


4.1.6

Landau-Symbole

In diesem Abschnitt wollen wir verschiedene Folgen miteinander vergleichen. Als
Motivation dient uns dabei die folgende Problematik, die bei der Analyse von
Algorithmen auftritt. Die Laufzeit (i.e., Anzahl der benoĚtigten elementaren Rechenschritte) eines Algorithmus haĚngt in aller Regel von der LaĚnge n der Eingabe
(i.e., Anzahl der Bits oder Bytes, aus denen die Eingabe besteht) ab. Betrachten wir beispielsweise den Euklidischen Algorithmus aus Kapitel 2, so ist intuitiv
klar, dass die Anzahl der dabei benoĚtigten elementaren Rechenoperationen umso groĚĂer sein wird, je groĚĂer die Zahlen sind, die der Algorithmus als Eingabe
erhaĚlt. Bezeichnet man die maximal moĚgliche Anzahl der elementaren Rechenschritte, die ein zu analysierender Algorithmus fuĚr eine Eingabe der LaĚnge n â N
durchfuĚhren muss, mit fn , so hat man dadurch eine Folge (fn )nâN definiert, die
das Laufzeitverhalten des Algorithmus beschreibt. Andererseits interessiert man
sich natuĚrlich nicht fuĚr die exakte Definition dieser Folge, sondern eigentlich nur
fuĚr deren asymptotisches Verhalten fuĚr wachsende Werte n. Man ist beispielsweise
an Aussagen der folgenden Form interessiert:
â˘ Die Laufzeit des Algorithmus ist ungefaĚhr proportional zur GroĚĂe der Eingabe (man sagt dann auch, dass die Laufzeit des Algorithmus linear mit
der LaĚnge der Eingabe waĚchst).
â˘ Die Laufzeit des Algorithmus waĚchst ungefaĚhr quadratisch in der EingabelaĚnge n, d.h. die Laufzeit ist ungefaĚhr proportional zu n2 .
â˘ Die Laufzeit des Algorithmus waĚchst mindestens exponentiell in der EingabelaĚnge n, d.h. die Laufzeit waĚchst beispielsweise wie 2n .

Kapiel 4: Analysis

M. Skutella

169

â˘ Die Laufzeit des Algorithmus ist durch ein Polynom in der EingabelaĚnge
beschraĚnkt, d.h. die Laufzeit ist fuĚr alle n â N durch p(n) beschraĚnkt,
wobei p eine beliebige Polynomfunktion ist.
Bei allen diesen Aussagen kommt es uns nicht auf konstante Faktoren an. Es ist
beispielsweise nicht so interessant, ob sich die Laufzeit eines Algorithmus wie n
oder wie 2n verhaĚlt â in beiden FaĚllen spricht man einfach nur von linearer Laufzeit. Viel interessanter ist die Frage, ob die Laufzeit proportional zu n, zu n log n
oder zu n2 waĚchst. Solche Betrachtungen werden durch die sogenannten LandauSymbole formalisiert. Sie dienen dazu, verschiedene Folgen miteinander zu vergleichen, wobei konstante Faktoren wegabstrahiert werden.
Definition 4.1.56 (Landau-Symbole). Es sei g = (gn ) â RN>0 eine Folge positiver
reeller Zahlen.
(i) Die Menge O(g) (sprich: GroĂ O von gâ) enthaĚlt alle Folgen positiver reller
â
Zahlen, die punktweise hoĚchstens um einen konstanten Faktor groĚĂer als g
sind, d.h.:
O(g) := {f = (fn ) â RN>0 | âc > 0 : fn â¤ c Âˇ gn fuĚr alle n â N} .
Ist f â O(g), so sagt man auch, dass f hoĚchstens so schnell wie g waĚchst.
(ii) Die Menge âŚ(g) (sprich: GroĂ Omega von gâ) enthaĚlt alle Folgen positiver
â
reller Zahlen, die punktweise hoĚchstens um einen konstanten Faktor kleiner
als g sind, d.h.:
âŚ(g) := {f = (fn ) â RN>0 | âc > 0 : fn âĽ c Âˇ gn fuĚr alle n â N} .
Ist f â âŚ(g), so sagt man auch, dass f mindestens so schnell wie g waĚchst.
(iii) Die Menge Î¸(g) (sprich: Theta von gâ) enthaĚlt alle Folgen positiver relâ
ler Zahlen, die punktweise hoĚchstens um einen konstanten Faktor von g
abweichen, d.h.:
Î¸(g) := {f = (fn ) â RN>0 | âc âĽ 1 :

1
c

Âˇ gn â¤ fn â¤ c Âˇ gn ân â N} .

Ist f â Î¸(g), so sagt man auch, dass f genau so schnell wie g waĚchst.
(iv) Die Menge o(g) (sprich: Klein o von gâ) enthaĚlt alle Folgen positiver reller
â
Zahlen, die asymptotisch um mehr als nur einen konstanten Faktor kleiner
als g sind, d.h.:
o(g) := {f = (fn ) â RN>0 | âc > 0 ân0 â N : fn â¤ c Âˇ gn ân âĽ n0 } .
Ist f â o(g), so sagt man auch, dass f langsamer als g waĚchst.

170

Mathematik fuĚr Informatiker

M. Skutella

(v) Die Menge Ď(g) (sprich: Klein omega von gâ) enthaĚlt alle Folgen positiver
â
reller Zahlen, die asymptotisch um mehr als nur einen konstanten Faktor
groĚĂer als g sind, d.h.:
Ď(g) := {f = (fn ) â RN>0 | âc > 0 ân0 â N : fn âĽ c Âˇ gn ân âĽ n0 } .
Ist f â Ď(g), so sagt man auch, dass f schneller als g waĚchst.
Beispiele.
(i) Ist fn =

Pd

k=0

ak nk mit a0 , . . . , ad â R und ad > 0, so ist f â Î¸(nd ).

(ii) Wir bezeichnen mit 1 = (1)nâN die konstante Folge, deren Folgeglieder alle 1
sind. Dann ist f â O(1) genau dann, wenn f beschraĚnkt ist.

gilt nicht,
(iii) Ist f â O n1 , soist f eine Nullfolge. Die umgekehrte Richtung

da die Folge â1n zwar eine Nullfolge ist, jedoch in Ď n1 liegt.
(iv) Es gilt
ÂˇÂˇÂˇ â O

1
1
â O
â O(1) â O(n) â O(n2 ) â Âˇ Âˇ Âˇ
2
n
n

(v) Ist f = (exp(n))nâN und d â N beliebig, so ist f â Ď(nd ). Denn es gilt
fuĚr n â N:
exp(n) âĽ

nd+1
n
=
Âˇ nd
(d + 1)!
(d + 1)!

WaĚhle man also zu einem beliebigen c > 0 die Zahl n0 := c Âˇ (d + 1)!, dann
gilt fuĚr alle n âĽ n0 , dass exp(n) âĽ nd .
Wir haben damit gezeigt, dass die Exponentialfunktion schneller als jede
Polynomfunktion waĚchst.
â
(vi) Ist f = (ln(n))nâN und d â N beliebig, so ist f â o( d n). Dies zeigt man
analog zu der Behauptung in (v).
Es gilt also, dass die Logarithmusfunktion langsamer als jede Wurzelfunktion waĚchst.
Bemerkung.
(i) Aus der Definition der Landau-Symbole folgen sofort die folgenden AĚquivalenzen:
f â O(g)
f â o(g)

ââ
ââ

f â Î¸(g)

ââ

g â âŚ(f ) ,
g â Ď(f ) ,

f â O(g) und f â âŚ(g) .

Kapiel 4: Analysis

M. Skutella

171

(ii) Mit den Landau-Symbolen O, âŚ, Î¸, o und Ď verhaĚlt es sich also aĚhnlich wie
mit den bekannten Vergleichsrelationen â¤, âĽ, =, < und >. Dabei gelten
die folgenden anschaulichen Entsprechungen:
f â O(g)
f â âŚ(g)
f â Î¸(g)
f â o(g)
f â Ď(g)

f â¤ gâ ,
â
f âĽ gâ ,
â
f = gâ ,
â
f < gâ ,
â
f > gâ .
â
Dabei sind die rechten Seiten natuĚrlich nicht wirklich woĚrtlich zu nehmen.
bedeutet
bedeutet
bedeutet
bedeutet
bedeutet

(iii) Alternativ haĚtte man auch die folgenden zu Definition 4.1.56 aĚquivalenten
Definitionen angeben koĚnnen:


O(g) = f = (fn ) â RN>0 | fgnn nâN ist beschraĚnkt ,


o(g) = f = (fn ) â RN>0 | fgnn nâN ist Nullfolge .
(iv) Man verwendet uĚblicherweise die folgenden Sprechweisen:
â˘ Ist f â Î¸(1), so ist f konstantâ.
â
â˘ Ist f â Î¸(n), so waĚchst f linear.
â˘ Ist f â Î¸(n2 ), so waĚchst f quadratisch.
â˘ Ist f â Î¸(n3 ), so waĚchst f kubisch.
â˘ Ist f â O(nk ) fuĚr ein k â N, so ist f polynomial beschraĚnkt.
â˘ Ist f â Ď(cn ) fuĚr ein c > 1, so waĚchst f exponentiell.
â˘ Ist f â Î¸(log n), so waĚchst f logarithmisch.

4.2

Stetige Funktionen

Abbildungen von einer Teilmenge der reellen Zahlen R in eine Teilmenge der reellen Zahlen nennt man auch (reelle) Funktionen. Ebenso nennt man Abbildungen
von einer Teilmenge der komplexen Zahlen C in eine Teilmenge der komplexen
Zahlen (komplexe) Funktionen. Wir diskutieren in diesem Abschnitt den Begriff
der Stetigkeit von Funktionen. Anschaulich gesprochen heiĂt eine Funktion stetig, wenn sie keine Sprungstellen besitzt. Bei reellen Funktionen ist das im Wesentlichen gleichbedeutend damit, dass der Graph der Funktion ohne Absetzen
des Stifts gezeichnet werden kann. (Wir geben zwei Beispiele in Abbildung 4.1.)
Etwas praĚziser gefasst bedeutet das, dass sich bei geringfuĚgiger AĚnderung des
eingesetzten Wertes auch der Funktionswert nur geringfuĚgig aĚndert.
Im Folgenden bezeichne K immer den KoĚrper der reellen oder komplexen
Zahlen, also K â {R, C}.

172

Mathematik fuĚr Informatiker

1,5

1,5

1

1

0,5

0,5

0

0,5

1

1,5

2

2,5

3

3,5

4

4,5

0

0,5

-0,5

-0,5

-1

-1

-1,5

-1,5

(a)

M. Skutella

1

1,5

2

2,5

3

3,5

4

4,5

(b)

Abbildung 4.1: Der Graph einer unstetigen reellen Funktion mit Sprungstelle in
(a) und der Graph einer stetigen reellen Funktion in (b).

4.2.1

BeruĚhrungspunkte

Bevor wir den Begriff der Stetigkeit formal definieren koĚnnen, benoĚtigen wir
zunaĚchst einen Begriff aus der Topologie.
Definition 4.2.1 (BeruĚhrungspunkt). Es sei D â K. Ein Element x0 â K heiĂt
BeruĚhrungspunkt von D, wenn es eine Folge (xn )nâN mit xn â D fuĚr alle n â N
gibt, so dass limnââ xn = x0 .
Beispiele.
(i) Jedes Element x0 â D ist BeruĚhrungspunkt von D, da x0 Grenzwert der
konstanten Folge (xn )nâN mit xn := x0 fuĚr alle n â N ist.
(ii) Der Punkt x0 = 2 ist BeruĚhrungspunkt der Menge D = R\{2}, da beispielsweise die durch xn := 2 + n1 fuĚr alle n â N gegebene Folge von Elementen
aus D gegen 2 konvergiert.
(iii) Alle Punkte auf dem komplexen Einheitskreis {z â C | |z| = 1} sind
BeruĚhrungspunkte der offenen Kreisscheibe {z â C | |z| < 1}, da fuĚr z0 â C
mit |z0 | = 1 die durch zn = (1â n1 )z0 gegebene komplexe Zahlenfolge gegen z0
konvergiert. Man kann zeigen, dass alle Punkte auĂerhalb des Einheitskreises keine BeruĚhrungspunkte sind.
Man kann den Begriff des BeruĚhrungspunktes alternativ auch wie folgt charakterisieren.
Lemma 4.2.2. Es sei D â K. Dann ist x0 â K genau dann ein BeruĚhrungspunkt
von D, wenn es zu jedem Îľ > 0 ein x â D mit |x0 â x| < Îľ gibt.
Beweis. Es sei x0 ein BeruĚhrungspunkt von D und (xn )nâN mit xn â D eine
Folge mit limnââ xn = x0 . Dann gibt es nach Definition 4.1.9 zu jedem Îľ > 0

Kapiel 4: Analysis

M. Skutella

173

ein n0 â N mit |x0 â xn | < Îľ fuĚr alle n âĽ n0 . Insbesondere gilt also xn0 â D
und |x0 â xn0 | < Îľ.
Um die andere Richtung zu beweisen nehmen wir nun an, dass es zu jedem Îľ >
0 ein x â D mit |x0 â x| < Îľ gibt. Wir definieren eine Folge (xn )nâN wie folgt:
FuĚr n â N waĚhlen wir ein beliebiges xn â D mit |x0 â xn | < n1 . Man sieht leicht,
dass dann limnââ xn = x0 gilt, so dass x0 BeruĚhrungspunkt von D ist.

Beispiele.
(i) Wir betrachten die Teilmenge
D := {z â C | 0 < Re(z) â¤ 1 und Im(z) = 0} â C .
AuĂer den Elementen in D ist der einzige BeruĚhrungspunkt von D der Nullpunkt. Dass 0 tatsaĚchlich ein BeruĚhrungspunkt ist sieht man beispielsweise
anhand der Nullfolge n1 nâN , deren Folgeglieder alle in D liegen.
Betrachten wir jedoch einen Punkt z0 = a+bi â C\(DâŞ{0}), dann gilt a 6= 0
oder b 6= 0. Ist b 6= 0, dann gibt es keinen Punkt z â D mit |z0 â z| < |b|, so
dass z0 kein BeruĚhrungspunkt von D sein kann. Ist b = 0, so ist entweder a <
0 oder a > 1. Im ersten Fall gibt es kein z â D mit |z0 âz| < âa; im zweiten
Fall gibt es kein z â D mit |z0 â z| < a â 1. In beiden FaĚllen ist also z0 kein
BeruĚhrungspunkt.
(ii) Jede reelle Zahl ist BeruĚhrungspunkt der Menge der rationalen Zahlen Q.
Dies folgt unmittelbar aus Lemma 4.2.2 und Lemma 4.1.5.

4.2.2

Grenzwerte von Funktionen

Als naĚchstes definieren wir den Grenzwert oder Limes einer Funktion in einem
BeruĚhrungspunkt ihres Definitionsbereichs.
Definition 4.2.3 (Grenzwert, Limes einer Funktion). Es sei D â K, x0 ein
BeruĚhrungspunkt von D und f : D â K eine Funktion. Weiter sei y0 â K
(falls K = R erlauben wir auch y0 = â und y0 = ââ).
(i) Man sagt, dass f in x0 den Grenzwert y0 hat (in Zeichen: limxâx0 f (x) =
y0 ), falls fuĚr alle Folgen (xn )nâN mit xn â D und limnââ xn = x0 gilt,
dass limnââ f (xn ) = y0 .
(ii) Ist K der KoĚrper der reellen Zahlen R und ist der Definitionsbereich D nach
oben unbeschraĚnkt, so ist limxââ f (x) = y0 , falls fuĚr alle Folgen (xn )nâN
mit xn â D und limnââ xn = â gilt, dass limnââ f (xn ) = y0 .
(iii) Ist K = R und ist der Definitionsbereich D nach unten unbeschraĚnkt,
so ist limxâââ f (x) = y0 , falls fuĚr alle Folgen (xn )nâN mit xn â D und
limnââ xn = ââ gilt, dass limnââ f (xn ) = y0 .

174

Mathematik fuĚr Informatiker

M. Skutella

Bemerkung.
(i) Ist x0 â D und besitzt die Funktion f : D â K einen Grenzwert in x0 , so
muss dieser gleich f (x0 ) sein. Denn eine moĚglich Folge (xn )nâN mit xn â D
und limnââ xn = x0 ist die durch xn = x0 fuĚr alle n â N definierte konstante
Folge. FuĚr diese gilt offenbar limnââ f (xn ) = f (x0 ).
(ii) Ist K = R und limxâx0 f (x) = â (oder limxâx0 f (x) = ââ), so besitzt f
in x0 streng genommen keinen Grenzwert. Man sagt in diesem Fall nur,
dass f fuĚr x â x0 gegen unendlich (oder minus unendlich) geht und nennt â
(oder ââ) den uneigentlichen Grenzwert von f in x0 .
Beispiele.
(i) Es sei f : C â C definiert durch f (z) := z 2 â 2z + 3i. Dann existiert der
Grenzwert von f in jedem Punkt z0 â C. Es sei naĚmlich (zn )nâN eine Folge
mit limnââ zn = z0 . Dann ist wegen Satz 4.1.17
lim (zn 2 ) + lim (â2zn ) + lim (3i)
nââ
nââ

2
=
lim zn â 2 lim zn + 3i

lim f (zn ) =

nââ

=

nââ

nââ
z0 2 â 2z0

nââ

+ 3i = f (z0 ) .

(ii) Dieselbe Argumentation wie im letzten Beispiel kann man auf eine beliebige
Polynomfunktion f : K â K anwenden, um zu zeigen, dass diese in jedem
beliebigen Punkt z0 â K den Grenzwert f (z0 ) hat.
(iii) Es sei D := C \ {3} und f : D â C die durch
f (z) :=

z2 â 9
zâ3

definierte Funktion. Dann ist 3 ein BeruĚhrungspunkt von D und die Funktion f hat in 3 den Grenzwert 6. Denn es gilt
f (z) =

z2 â 9
(z â 3)(z + 3)
=
= z+3
zâ3
zâ3

fuĚr z 6= 3.

Damit folgt wie im letzten Beispiel, dass limzâ3 f (z) = 6.
(iv) Wir betrachten die Signum-Funktion sgn : R â R mit
ďŁą
ďŁ´
falls x > 0,
ďŁ˛1
sgn(x) =
0
falls x = 0,
ďŁ´
ďŁł
â1 falls x < 0.

Kapiel 4: Analysis

M. Skutella

175

Diese Funktion besitzt im Punkt 0 keinen Grenzwert. Dazu betrachten wir
zwei Folgen (xn )nâN und (yn )nâN , die beide gegen
0 konvergieren, so dass

jedoch die Folgen sgn(xn ) nâN und sgn(yn ) nâN gegen unterschiedliche
Grenzwerte konvergieren. Dazu sei xn := n1 und yn := â n1 fuĚr n â N. Dann
ist nach Definition sgn(xn ) = 1 und sgn(yn ) = â1 fuĚr alle n â N. Folglich
gilt also limnââ sgn(xn ) = 1 und limnââ sgn(yn ) = â1.
Man kann sogar noch eine weitere Folge (zn )nâN mit limnââ zn = 0 und
limnââ sgn(zn ) = 0 finden, naĚmlich zn := 0 fuĚr alle n â N.

Es gibt auch Nullfolgen (an )nâN , so dass die zugehoĚrige Folge sgn(an ) nâN

nicht konvergiert. Betrachte beispielsweise die Folge (â1)n n1 nâN , fuĚr die
(

1
falls n gerade,
n1
n
sgn((â1) n = (â1) =
â1 falls n ungerade,
gilt.
(v) Wir betrachten die Funktion f : R \ {0} â R mit f (x) := x1 . Dann
ist limxââ f (x) = 0 und auch limxâââ f (x) =
 0. Der Grenzwert im Punkt 0
1
existiert jedoch nicht. FuĚr die Nullfolge n nâN geht die zugehoĚrige Fol
ge f ( n1 ) nâN gegen unendlich, weil f ( n1 ) = n fuĚr alle n â N. FuĚr die Null

folge â n1 nâN geht die zugehoĚrige Folge f (â n1 ) nâN jedoch gegen ââ.
(vi) FuĚr die Funktion f : R \ {0} â R mit f (x) := x12 gilt limxâ0 f (x) = â.
Um das zu beweisen, betrachten wir eine beliebige Nullfolge (xn )nâN . Wir
muĚssen zeigen, dass es zu jedem r > 0 ein n0 â N gibt mit f (xn ) > r fuĚr
alle n âĽ n0 . Da (xn ) eine Nullfolge ist, gibt es ein n0 â N mit xn < â1r fuĚr
alle n âĽ n0 . Folglich ist f (xn ) = xn1 2 > r fuĚr alle n âĽ n0 .
(vii) Wir betrachten die Dirichletâsche Funktion f : R â R mit
(
1 falls x â Q,
f (x) :=
0 falls x â R \ Q.
Diese Funktion besitzt in keinem Punkt x0 â R einen Grenzwert. Wir
erlaĚutern das beispielhaft
fuĚr den
â Punkt x0 = 0. Dazuâbetrachten wir die

beiden Nullfolgen n1 nâN und n2 nâN . Da n1 â Q und n2 6â Q, konvergiert
die erste Folge gegen 1 und die zweite gegen 0.
Bemerkung. Um zu zeigen, dass der Grenzwert einer Funktion in einem Punkt x0
nicht existiert, genuĚgt es, zwei gegen x0 konvergente Folgen zu finden, so dass
die zugehoĚrigen Funktionswerte gegen unterschiedliche Grenzwerte konvergieren.
Alternativ reicht es auch, eine einzelne gegen x0 konvergente Folge aufzuzeigen,
deren Funktionswerte nicht konvergieren. Es scheint jedoch viel schwieriger zu

176

Mathematik fuĚr Informatiker

M. Skutella

zeigen, dass der Grenzwert einer Funktion in einem Punkte x0 tatsaĚchlich existiert, da man dazu laut Definition alle gegen x0 konvergenten Folgen betrachten
muss. Abhilfe verschafft hier die folgende alternative Charakterisierung.
Lemma 4.2.4. [Îľ-Î´-Kriterium fuĚr Grenzwert einer Funktion] Es sei D â K, x0
ein BeruĚhrungspunkt von D und f : D â K eine Funktion. Dann besitzt f in x0
genau dann den Grenzwert y0 â K, wenn es zu jedem Îľ > 0 ein Î´ > 0 gibt, so
dass fuĚr alle x â D mit |x0 â x| < Î´ stets |y0 â f (x)| < Îľ gilt.
Beweis. Wir zeigen zunaĚchst, dass das Îľ-Î´-Kriterium hinreichend fuĚr die Existenz
des Grenzwertes ist. Wir nehmen also an, dass es zu jedem Îľ > 0 ein Î´ > 0
gibt, so dass fuĚr alle x â D mit |x0 â x| < Î´ stets |y0 â f (x)| < Îľ gilt. Es sei
nun (xn )nâN eine beliebige Folge mit xn â D und limnââ xn = x0 . Wir betrachten
ein beliebiges Îľ > 0 und das zugehoĚrige Î´ > 0. Da die Folge (xn )nâN gegen x0
konvergiert, gibt es ein
 n0 â N mit |x0 â xn | < Î´ fuĚr alle n âĽ n0 . Betrachten wir
jetzt die Folge f (xn ) nâN , dann gilt also |y0 â f (xn )| < Îľ fuĚr alle n âĽ n0 . Folglich

konvergiert f (xn ) nâN gegen y0 .
Wir beweisen noch die Notwendigkeit des Kriteriums. Dazu nehmen wir an,
dass es nicht erfuĚllt ist und zeigen, dass f dann nicht den Grenzwert y0 besitzen
kann. Es sei also Îľ > 0, so dass es fuĚr jedes Î´ > 0 ein x â D mit |x0 â x| < Î´
und |y0 âf (x)| > Îľ gibt. Wir konstruieren eine gegen x0 konvergente Folge (xn )nâN
wie folgt: FuĚr jedes n â N waĚhlen wir eine xn â D mit |x0 â xn | < n1 und |y0 â
f (xn )| > Îľ. Dann konvergiert
die Folge (xn )nâN offenbar gegen x0 , die Folge

der Funktionswerte f (xn ) nâN jedoch nicht gegen y0 , da |y0 â f (xn )| > Îľ fuĚr
alle n â N.

Um die Existenz des Grenzwertes einer Funktion in einem Punkt x0 zu zeigen,
sind die Rechenregeln fuĚr konvergente Folgen aus Satz 4.1.17 oft nuĚtzlich. Wir
formulieren sie hier neu fuĚr Grenzwerte von Funktionen.
Satz 4.2.5. Es sei D â K, x0 eine BeruĚhrungspunkt von D und f, g : D â K
zwei Funktionen mit limxâx0 f (x) = y0 â K und limxâx0 g(x) = z0 â K. Dann
gilt:

(i) limxâx0 f (x) Âą g(x) = y0 Âą z0 .

(ii) limxâx0 f (x) Âˇ g(x) = y0 Âˇ z0 .

(iii) FuĚr Îť â K ist limxâx0 Îť Âˇ f (x) = Îť Âˇ y0 .

(iv) Ist z0 6= 0, so ist limxâx0 f (x)/g(x) = y0 /z0 .
(v) limxâx0 |f (x)| = |y0 |.
(vi) Ist K = C, so gilt genau dann limxâx0 f (x) = y0 , wenn


lim Re f (x) = Re(y0 )
und
lim Im f (x) = Im(y0 ) .
xâx0

xâx0

Kapiel 4: Analysis

M. Skutella

177

Bemerkung. In Satz 4.2.5 (iv) betrachtet man streng genommen die Funktion h : D0 â K mit h(x) := f (x)/g(x), deren Definitionsbereich durch D0 = {x â
D | g(x) 6= 0} gegeben ist. Man kann zeigen, dass x0 auch ein BeruĚhrungspunkt
von D0 ist.
Beispiel. Wir betrachten die Funktion h : C \ {3} â C mit
h(z) :=

z2 + z + 1
.
zâ3

Dann existiert fuĚr z0 6= 3 der Grenzwert von h in z0 und es gilt limzâz0 h(z) =
h(z0 ).
Satz 4.2.6. Es seien D, E â K, x0 ein BeruĚhrungspunkt von D und f : D â
E mit limxâx0f (x) = y0 . Ist g : E â K mit limyây0 g(y) = z0 , dann ist
limxâx0 g f (x) = z0 .
Beweis. Wir betrachten eine beliebige Folge (x
 n )nâN mit xn â D und limnââ xn =
x0 . Dann ist f (xn ) â E und die Folge f (xn ) nâN konvergiert nach Voraussetzung
gegen y0 . (Insbesondere ist also
 y0 ein BeruĚhrungspunkt von E.)Da limyây0 g(y) =
z0 , gilt also limnââ g f (xn ) = z0 . Folglich ist limxâx0 g f (x) = z0 .

Als naĚchstes betrachten wir fuĚr den Spezialfall reeller Funktionen noch sogenannte rechtsseitige und linksseitige Grenzwerte.
Definition 4.2.7 (Rechtsseitiger und linksseitiger Grenzwert). Es sei D â R, x0
ein BeruĚhrungspunkt von D und f : D â R eine reelle Funktion. Weiter sei y0 â
R âŞ {â, ââ}.
(i) Man sagt, dass f in x0 den rechtsseitigen Grenzwert y0 hat (in Zeichen:
limxâx0 + f (x) = y0 ), falls fuĚr alle Folgen (xn )nâN mit xn â D, xn > x0
und limnââ xn = x0 gilt, dass limnââ f (xn ) = y0 .
(ii) Man sagt, dass f in x0 den linksseitigen Grenzwert y0 hat (in Zeichen:
limxâx0 â f (x) = y0 ), falls fuĚr alle Folgen (xn )nâN mit xn â D, xn < x0
und limnââ xn = x0 gilt, dass limnââ f (xn ) = y0 .
Bemerkung. Ist y0 â {â, ââ}, so spricht man wieder nur von uneigentlichen
(rechtsseitigen oder linksseitigen) Grenzwerten.
Beispiel. Die Signumfunktion besitzt an der Stelle 0 den rechtsseitigen Grenzwert limxâ0+ sgn(x) = 1 und den linksseitigen Grenzwert limxâ0â sgn(x) = â1.
Man beachte jedoch, dass keiner dieser Grenzwerte dem tatsaĚchlichen Funktionswert sgn(0) = 0 entspricht.

178

Mathematik fuĚr Informatiker

4.2.3

M. Skutella

Stetigkeit

Wir koĚnnen jetzt den Begriff der Stetigkeit formal definieren.
Definition 4.2.8. [Stetigkeit] Es sei D â K und f : D â K eine Funktion.
(i) Die Funktion f heiĂt stetig in x0 â D, falls ihr Grenzwert in x0 existiert
(also limxâx0 f (x) = f (x0 )).
(ii) Die Funktion f heiĂt rechtsseitig (linksseitig) stetig in x0 â D, falls gilt,
dass limxâx0 + f (x) = f (x0 ) (limxâx0 â f (x) = f (x0 )).
(iii) Die Funktion f heiĂt stetig, falls sie in allen Punkten x0 â D stetig ist.
(iv) Ist x0 â K\D ein BeruĚhrungspunkt von D und existiert der Grenzwert von f
in x0 , so heiĂt f stetig ergaĚnzbar in x0 . Die Funktion fÂŻ : D âŞ {x0 } â K mit
(
f (x)
falls x â D,
fÂŻ(x) =
0
limx0 âx0 f (x ) falls x = x0 ,
heiĂt stetige ErgaĚnzung von f in x0 .
Beispiele.
(i) Wie schon weiter oben bemerkt, existiert der Grenwert einer (reellen oder
komplexen) Polynomfunktion in jedem Punkt von K. Folglich sind Polynomfunktionen also stetig.
(ii) Die Funktion f : R â R mit f (x) := dxe (hier bezeichnet dxe die kleinste
ganze Zahl, die groĚĂer oder gleich x ist, also dxe := min{n â Z | x â¤ n})
ist in allen Punkten x0 â R linksseitig stetig, jedoch in keinem ganzzahligen
Punkt x0 â Z rechtsseitig stetig. Wir beweisen nur letztere Behauptung.
FuĚr x0 â Z betrachten wir die Folge (xn )nâN mit xn := x0 + n1 fuĚr alle n â N.
Dann gilt dxn e = x0 + 1 und daher limnââ dxn e = x0 + 1 6= dx0 e.
(iii) Sei D := C\{3} und f : D â C die durch f (z) := (z 2 â9)/(z â3) definierte
Funktion. Wie weiter oben gezeigt wurde, ist f im Punkt 3 stetig ergaĚnzbar
(mit Funktionswert 6).
Mit Hilfe der Definition 4.2.8 koĚnnen wir jetzt Satz 4.2.5 wie folgt formulieren.
Korollar 4.2.9. Es sei D â K, x0 eine BeruĚhrungspunkt von D und f, g : D â
K zwei Funktionen, die in x0 stetig (falls x0 â D) beziehungsweise stetig ergaĚnzbar
(falls x0 6â D) sind. Dann gilt:
(i) Die auf D definierten Funktionen f Âą g, f Âˇ g, Îť Âˇ f (fuĚr beliebiges Îť â K)
und |f | sind stetig (ergaĚnzbar) in x0 .

Kapiel 4: Analysis

M. Skutella

179

(ii) Ist limxâx0 g(x) 6= 0, so ist die auf {x â D | g(x) 6= 0} definierte Funktion f /g stetig (ergaĚnzbar) in x0 .
(iii) Ist K = C, so ist die Funktion f : D â C genau dann stetig (ergaĚnzbar)
in x0 , wenn die beiden Funktion Re(f ), Im(f ) : D â R stetig (ergaĚnzbar)
in x0 sind.
Bemerkung. Als Spezialfall von Korollar 4.2.9 (ii) koĚnnen wir festhalten, dass
die Funktion x 7â 1/f (x) stetig im Punkt x0 ist, falls die Funktion f in x0 stetig
ist und limxâx0 f (x) 6= 0.
Beispiel. Es seien f, g : K â K Polynomfunktionen und D := {x â K | g(x) 6=
0}. Dann ist die gebrochen rationale Funktion h : D â K mit h(x) := f (x)/g(x)
stetig.
Das naĚchste Korollar ist eine unmittelbare Folgerung aus Satz 4.2.6.
Korollar 4.2.10. Es seien D, E â K, x0 ein BeruĚhrungspunkt von D und f :
D â E stetig (ergaĚnzbar) in x0 . Ist die Funktion g : E â K stetig (ergaĚnzbar)
in dem Punkt limxâx0 f (x), so ist auch die Komposition g âŚ f : D â K stetig
(ergaĚnzbar) in x0 .
Wir geben das folgende Resultat ohne Beweis an.
Satz 4.2.11. Es seien a, b â R âŞ {ââ, â} mit a < b und I â R ein Intervall
der Form1 [a, b], (a, b], [a, b) oder (a, b). Ist f : I â M mit M â R eine bijektive
stetige Funktion, so ist auch die Umkehrabbildung f â1 : M â I stetig.
Beispiele.
(i) Die Abbildung f : [0, â) â [0, â) mit f (x) = x2 ist stetig und streng
monoton steigend und damit bijektiv. Folglich ist die
â Umkehrabbildung
(Wurzelfunktion) f â1 : [0, â) â [0, â) mit f â1 (x) = x auch stetig.
(ii) In Verallgemeinerung des letzten Beispiels betrachten wir fuĚr beliebiges n â
N die bijektive, stetige Abbildung f : [0, â) â [0, â) mit f (x) = xn . Die
Umkehrfunktion von
â f ist offenbar die Funktion, die ein x â [0, â) auf
seine n-te Wurzel n x abbildet. Diese Funktion ist nach Satz 4.2.11 also
auch stetig.
Aus dem Îľ-Î´-Kriterium in Lemma 4.2.4 koĚnnen wir die folgende alternative
Charakterisierung von Stetigkeit folgern.
Korollar 4.2.12. Es sei D â K und x0 â D. Eine Funktion f : D â K ist genau
dann stetig in x0 , wenn es fuĚr alle Îľ > 0 ein Î´ > 0 gibt, so dass fuĚr alle x â D
mit |x0 â x| < Î´ folgt, dass |f (x0 ) â f (x)| < Îľ.
1

Wir verwenden hier die folgende Konvention: [a, b] := {x â R | a â¤ x â¤ b}, (a, b] := {x â
R | a < x â¤ b}, [a, b) := {x â R | a â¤ x < b} und (a, b) := {x â R | a < x < b}.

180

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Folgt unmittelbar aus Lemma 4.2.4.



Bemerkung. Wir stellen fest, dass Stetigkeit im Punkt x0 eine lokale Eigenschaft
einer Funktion f ist, die nur von dem Verhalten von f in unmittelbarer Umgebung
von x0 abhaĚngt.
Wir fuĚhren im Folgenden noch zwei weitere, staĚrkere Stetigkeitsbegriffe ein,
die im Gegensatz zur gewoĚhnlichen Stetigkeit nicht mehr nur lokal sondern global
definiert sind.
Definition 4.2.13 (GleichmaĚĂige Stetigkeit). Es sei D â K. Eine Funktion f :
D â K heiĂt gleichmaĚĂig stetig auf D, falls es zu jedem Îľ > 0 ein Î´ > 0 gibt, so
dass fuĚr alle x, y â D mit |x â y| < Î´ folgt, dass |f (x) â f (y)| < Îľ.
Bemerkung. Aus Definition 4.2.13 und Korollar 4.2.12 folgt, dass jede gleichmaĚĂig stetige Funktion insbesondere stetig ist.
Beispiele.
â
(i) Die Wurzelfunktion f : [0, â) â R mit f (x) := x ist gleichmaĚĂig stetig.
WaĚhlt man zu einem gegebenen Îľ > 0 das zugehoĚrige Î´ := Îľ2 , dann gilt fuĚr
alle x, y âĽ 0 mit |x â y| < Î´, dass
p
â
â
â
|x â y| < Î´ â¤ Îľ .
|f (x) â f (y)| = | x â y| â¤
FuĚr die erste Ungleichung haben wir die folgende AbschaĚtzung verwendet:
FuĚr x âĽ y âĽ 0 gilt
â
â
â
xâ y â¤ xây .
Diese Ungleichung ist genau dann erfuĚllt, wenn die durch Quadrieren beider
Seiten entstehende Ungleichung erfuĚllt ist (das liegt daran, dass die Funktion z 7â z 2 streng monoton wachsend2 auf [0, â) ist):
â â
x+yâ2 x y â¤ xây .
â
â
Diese Ungleichung ist erfuĚllt, da x âĽ y gilt.
(ii) Die Funktion f : [0, â) â R mit f (x) = x2 ist nicht gleichmaĚĂig stetig.
Denn andernfalls muĚsste es zu Îľ = 1 ein Î´ > 0 geben, so dass x2 â y 2 < 1
fuĚr alle x âĽ y âĽ 0 mit x â y < Î´. Dies fuĚhrt zu dem folgenden Widerspruch,
wenn wir y = 1/Î´ und x = y + Î´/2 waĚhlen:
x2 â y 2 = (x + y)(x â y) = (2/Î´ + Î´/2)Î´/2 = 1 + Î´ 2 /4 > 1 .
2

AĚhnlich wie bei Folgen definiert man die Begriffe (streng) monoton wachsend bzw. fallend
auch fuĚr reelle Funktionen. Ist D â R und f : D â R, dann heiĂt f monoton wachsend,
falls f (x) â¤ f (y) fuĚr alle x, y â D mit x â¤ y. Die Funktion heiĂt streng monoton wachsend,
falls man â¤â durch <â ersetzen kann. Die Funktion f heiĂt (streng) monoton fallend, falls âf
â
â
(streng) monoton wachsend ist.

Kapiel 4: Analysis

M. Skutella

181

Bemerkung. Anhand der beiden Beispiele sieht man, dass Satz 4.2.11 nicht
mehr gilt, wenn wir Stetigkeit durch gleichmaĚĂige Stetigkeit ersetzen.
Definition 4.2.14 (Lipschitz-Stetigkeit). Es sei D â K. Eine Funktion f : D â
K heiĂt Lipschitz-stetig auf D, falls es eine Konstante L âĽ 0 gibt, so dass fuĚr
alle x, y â D gilt, dass |f (x) â f (y)| â¤ L Âˇ |x â y|. Dann heiĂt L LipschitzKonstante. Ist f Lipschitz-stetig mit Lipschitz-Konstante L < 1, so nennt man f
auch eine Kontraktion.
Beispiele.
(i) FuĚr a, b â C ist die komplexe Funktion f : C â C mit f (z) := a Âˇ z + b
Lipschitz-stetig mit Lipschitz-Konstante L := |a|. Denn es gilt fuĚr x, y â C,
dass
|f (x) â f (y)| = |(a Âˇ x + b) â (a Âˇ y + b)| = |a| Âˇ |x â y| .
â
(ii) Die Wurzelfunktion f : [0, â) â R mit f (x) := x ist nicht Lipschitzstetig. Widerspruchsbeweis: Angenommen f ist Lipschitz-stetig mit Lipschitz-Konstante L > 0. WaĚhle x := 4/(16L2 ) und y := 1/(16L2 ), dann
gilt
â
|x â y|
â
| x â y| = â
â =
x+ y

4
L
3

Âˇ |x â y| > L Âˇ |x â y| .

Lemma 4.2.15. Es sei D â K. Eine Lipschitz-stetige Funktion f : D â K ist
insbesondere gleichmaĚĂig stetig.
Beweis. Es sei f : D â K eine Lipschitz-stetige Funktion mit zugehoĚriger
Lipschitz-Konstante L > 0. WaĚhlt man zu einem beliebigen Îľ > 0 dann Î´ = Îľ/L,
so gilt fuĚr beliebige x, y â D mit |x â y| < Î´, dass
|f (x) â f (y)| â¤ L Âˇ |x â y| < L Âˇ Î´ = Îľ .
Damit ist der Beweis abgeschlossen

4.2.4



Elementare Funktionen: exp, ln, cos, sin, tan etc.

Wir gehen in diesem Abschnitt noch einmal auf die Exponentialfunktion und
dazu verwandte Funktionen ein. Wir beginnen mit der Feststellung, dass die
Exponentialfunktion stetig ist.
Satz 4.2.16. Die Exponentialfunktion exp : C â C ist stetig.

182

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Wir beweisen zunaĚchst, dass exp im Nullpunkt stetig ist. Dazu betrachten wir eine beliebige Nullfolge (zn )nâN und zeigen, dass limnââ exp(zn ) =
exp(0) = 1 ist. FuĚr |zn | < 1 gilt:
0 â¤ | exp(zn ) â 1| =

â
X
zn k
k=1

â¤

k!

â
X
|zn |k
k=1

k!

â¤

â
X

|zn |k =

k=1

|zn |
.
1 â |zn |

Da limnââ zn = 0, konvergiert auch die rechte Seite dieser Ungleichung gegen 0
(wegen Satz 4.1.17). Folglich gilt limnââ | exp(zn ) â 1| = 0 und damit auch
limnââ exp(zn ) = 1.
Damit koĚnnen wir jetzt leicht zeigen, dass exp auch in jedem beliebigen
Punkt z0 â C stetig ist. Dazu betrachten wir eine Folge (zn )nâN mit limnââ zn =
z0 . Das bedeutet, dass limnââ (zn â z0 ) = 0. Folglich gilt wegen Lemma 4.1.46

lim exp(zn ) = lim exp(z0 ) Âˇ exp(zn â z0 )
nââ

nââ

= exp(z0 ) Âˇ lim exp(zn â z0 )
nââ

= exp(z0 ) Âˇ 1 = exp(z0 ) .
Damit ist der Beweis abgeschlossen.



Satz 4.2.16 folgt auch aus einem allgemeinen Stetigkeitsresultat uĚber Potenzreihen, das wir hier ohne Beweis angeben.
P
k
Satz 4.2.17 (Stetigkeit von Potenzreihen). Es sei â
k=0 ak z eine Potenzreihe
mit Konvergenzradius Ď > 0. Wir betrachten die zugehoĚrige komplexe Funktion
f : {z â C | |z| < Ď} â C

mit

f (z) :=

â
X

ak z k .

k=0

Dann ist die Funktion f stetig.
Da die EinschraĚnkung einer stetigen Funktion auf eine Teilmenge ihres Definitionsbereichs immer noch stetig ist (dies folgt sofort aus der Definition der
Stetigkeit oder alternativ aus Korollar 4.2.12), ist auch die reelle Exponentialfunktion expR stetig. Folglich ist auch die Logarithmusfunktion stetig.
Korollar 4.2.18. Der natuĚrliche Logarithmus ln : R>0 â R ist stetig.
Beweis. Folgt aus Satz 4.2.16 und Satz 4.2.11.



Wie wir schon in Abschnitt 4.1.6 erwaĚhnt haben, waĚchst die Exponentialfunktion schneller als jede Polynomfunktion und die Logarithmusfunktion waĚchst
langsamer als die n-te Wurzel fuĚr alle n â N.

Kapiel 4: Analysis

M. Skutella

183

Lemma 4.2.19. Es sei p : R â R eine beliebige Polynomfunktion. Dann gilt
p(x)
= 0 .
xââ exp(x)
lim

FuĚr beliebiges n â N gilt
ln(x)
lim â
= 0 .
xââ n x
Beweis. Siehe Beispiel nach Definition 4.1.56 und UĚbung.



Mit Hilfe der Exponentialfunktion koĚnnen wir die trigonometrischen Funktionen Sinus (sin) und Cosinus (cos) einfuĚhren. Dazu benoĚtigen wir zunaĚchst die
folgende Eigenschaft.
Lemma 4.2.20. Die Exponentialfunktion exp : C â C besitzt die folgenden
Eigenschaften:
(i) exp(zĚ) = exp(z) fuĚr alle z â C.
(ii) | exp(x + iy)| = exp(x) fuĚr alle x, y â R. Insbesondere ist | exp(iy)| = 1 fuĚr
alle y â R.
Beweis. Teil (i) folgt im Wesentlichen aus Satz 4.1.17 (vi). FuĚr (ii) genuĚgt es zu
zeigen, dass | exp(iy)| = 1 fuĚr alle y â R. Denn daraus folgt
| exp(x + iy)| = | exp(x) Âˇ exp(iy)| = | exp(x)| Âˇ | exp(iy)| = | exp(x)|
fuĚr alle x, y â R. Wegen Lemma 2.3.6 (iii) gilt
| exp(iy)|2 = exp(iy) Âˇ exp(iy)
=
=
=
=
Damit ist der Beweis abgeschlossen.

exp(iy) Âˇ exp(iy)
exp(iy) Âˇ exp(âiy)
exp(iy â iy)
exp(0) = 1 .


Bemerkung. Aus Lemma 4.2.20 (ii) folgt insbesondere, dass die komplexe Zahl
exp(iy) fuĚr y â R auf dem komplexen Einheitskreis liegt. Man kann zeigen,
dass exp(iy) genau einmal entgegen dem Uhrzeigersinn um den Einheitskreis
wandert, wenn man y von 0 bis 2Ď erhoĚht. Die komplexe Zahl exp(iĎ) mit Ď â R
schlieĂt also mit der positiven reellen Achse den Winkel Ď ein (siehe Abbil
dung 4.2). Insbesondere gilt exp(i2Ď) = exp(0) = 1 und folglich exp i(Ď+2Ďk) =
exp(iĎ) fuĚr alle Ď â R und k â Z.

184

Mathematik fuĚr Informatiker

M. Skutella

Im

i

exp(iĎ)

Ď
Re
â1

1

âi

Abbildung 4.2: Das Verhalten der Funktion Ď 7â exp(iĎ) fuĚr Ď â [0, 2Ď].
Lemma 4.2.21. Die Funktion f : R â C mit f (Ď) := exp(iĎ) ist 2Ď-periodisch,
das heiĂt

exp i(Ď + 2Ď) = exp(iĎ)
fuĚr alle Ď â R.
Betrachtet man Abbildung 4.2, so sieht man sehr leicht, dass der Realteil
der komplexen Zahl exp(iĎ) dem Cosinus des Winkels Ď und der ImaginaĚrteil
dem Sinus des Winkels Ď entspricht. Da wir die Cosinus- und die Sinus-Funktion
bislang nicht formal definiert haben, holen wir das an dieser Stelle nach.
Definition 4.2.22 (Cosinus und Sinus). FuĚr Ď â R definieren wir


cos(Ď) := Re exp(iĎ)
und
sin(Ď) := Im exp(iĎ) .
Die dadurch definierten Funktionen cos : R â R und sin : R â R nennt man
Cosinus- und Sinus-Funktion.
Aus den Eigenschaften der Exponentialfunktion kann man die folgenden Eigenschaften von cos und sin herleiten.
Satz 4.2.23 (Eigenschaften von Cosinus und Sinus).
(i) Cosinus und Sinus sind 2Ď-periodisch und es gilt fuĚr alle k â Z:


cos 2kĎ = sin 2kĎ + Ď/2 = 1 ,


cos kĎ + Ď/2 = sin kĎ = 0 ,


cos (2k + 1)Ď = sin 2kĎ + 3Ď/2 = â 1 .
AuĂerdem ist cos(Ď) = sin(Ď + Ď/2) fuĚr alle Ď â R.

Kapiel 4: Analysis

M. Skutella

185

(ii) Cosinus und Sinus sind stetige Funktionen.
2
2
(iii) cos(x) + sin(x) = 1 fuĚr alle x â R.
(iv) cos(x + y) = cos(x) cos(y) â sin(x) sin(y) fuĚr alle x, y â R.
(v) sin(x + y) = sin(x) cos(y) + cos(x) sin(y) fuĚr alle x, y â R.
Die Gleichungen in (iv) und (v) bezeichnet man auch als Additionstheoreme fuĚr
Cosinus und Sinus.
Beweis. Die Eigenschaften in (i) folgen unmittelbar aus den oben besprochenen
Eigenschaften der Funktion Ď 7â exp(iĎ). Teil (ii) folgt aus Korollar 4.2.9 (iii).
Teil (iii) gilt, da fuĚr x â R
2
2
2
2
+ Im exp(iĎ)
cos(x) + sin(x) = Re exp(iĎ)
= | exp(iĎ)|2 = 1
wegen Lemma 4.2.20 (ii). Die Additionstheoreme in (iv) und (v) erhaĚlt man wie
folgt. FuĚr x, y â R ist einerseits

exp i(x + y) = exp(ix) Âˇ exp(iy)


= cos(x) + i sin(x) Âˇ cos(y) + i sin(y)

= cos(x) cos(y) â sin(x) sin(y)

+ i sin(x) cos(y) + cos(x) sin(y)
Andererseits ist

exp i(x + y) = cos(x + y) + i sin(x + y) .
Vergleicht man Real- und ImaginaĚrteile der beiden AusdruĚcke, so erhaĚlt man
daraus (iv) und (v).

Satz 4.2.24 (Reihenentwicklung von cos und sin). Die Funktionen cos und sin
lassen sich wie folgt als Potenzreihen darstellen. Es gilt
cos(x) = 1 â

â
X
x2 x4 x6 x8
(â1)k 2k
+
â
+
â ÂˇÂˇÂˇ =
x
2!
4!
6!
8!
(2k)!
k=0

sin(x) = x â

â
X
x3 x5 x7 x9
(â1)k 2k+1
+
â
+
â ÂˇÂˇÂˇ =
x
.
3!
5!
7!
9!
(2k
+
1)!
k=0

und

186

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Nach Definition der Exponentialfunktion ist
exp(ix) =

â
X
(ix)k

k!

k=0

.

Wegen Satz 4.1.17 (vi) gilt dann


â
X

(ix)k
cos(x) = Re exp(ix) =
Re
k!
k=0
und


â
X

(ix)k
.
sin(x) = Im exp(ix) =
Im
k!
k=0
FuĚr k â N0 ist

Re

(ix)k
k!



(ix)k
k!



(
=

(â1)k/2 k
x
k!

0

falls k gerade,
falls k ungerade,

(
0

falls k gerade,

und

Im

=

(â1)(kâ1)/2 k
x
k!

falls k ungerade.

Daraus folgt die Behauptung.



Wir erwaĚhnen schlieĂlich noch eine Eigenschaft von Cosinus und Sinus ohne
Beweis.
Lemma 4.2.25. Die EinschraĚnkung der Cosinus-Funktion auf das Intervall [0, Ď]
definiert eine Bijektion zwischen [0, Ď] und [â1, 1]. Analog dazu definiert die EinschraĚnkung der Sinus-Funktion auf [âĎ/2, Ď/2] eine Bijektion zwischen dem Intervall [âĎ/2, Ď/2] und [â1, 1].
Die Umkehrfunktionen von Cosinus und Sinus heiĂen Arcuscosinus und Arcussinus und werden im Folgenden definiert.
Definition 4.2.26 (Arcuscosinus und Arcussinus). Die Umkehrfunktionen der
in Lemma 4.2.25 betrachteten EinschraĚnkungen von Cosinus und Sinus werden
Arcuscosinus und Arcussinus genannt und wie folgt bezeichnet:
arccos : [â1, 1] â [0, Ď]

und

arcsin : [â1, 1] â [âĎ/2, Ď/2] .

SchlieĂlich definieren wir noch die Funktionen Tangens und Cotangens.

Kapiel 4: Analysis

M. Skutella

187

Definition 4.2.27 (Tangens, Cotangens). FuĚr x â R \ {Ď/2 + kĎ | k â Z} ist
die Tangens-Funktion definiert als
tan(x) :=

sin(x)
.
cos(x)

FuĚr x â R \ {kĎ | k â Z} ist die Cotangens-Funktion definiert als
cot(x) :=

4.2.5

cos(x)
.
sin(x)

Nullstellensatz und Zwischenwertsatz

Wir zeigen in diesem Abschnitt einige wichtige Eigenschaften stetiger Funktionen. ZunaĚchst beschaĚftigen wir uns mit dem Nullstellensatz, der unter gewissen
Bedingungen die Existenz einer Nullstelle garantiert.
Satz 4.2.28 (Nullstellensatz). Es seien a, b â R mit a < b und f : [a, b] â R
eine stetige Funktion. Haben f (a) und f (b) verschiedene Vorzeichen, dann gibt
es ein x â [a, b] mit f (x) = 0. Wir nennen x Nullstelle von f .
Der Satz ist relativ einleuchtend, wenn man sich vor Augen fuĚhrt, dass man
den Graphen der stetigen Funktion f ohne Absetzen des Stiftes zeichnen koĚnnen
muss. Da naĚmlich f (a) und f (b) verschiedene Vorzeichen haben, muss man beim
Zeichnen offenbar (mindestens) einmal die horizontale x-Achse uĚberqueren. An
der Stelle, an der der Graph die x-Achse beruĚhrt, liegt dann eine Nullstelle von f
vor. Wir fuĚhren im Folgenden einen formalen Beweis, der auf dem wichtigen
Prinzip der Intervallschachtelung beruht.
Beweis. Wir betrachten den Fall, dass f (a) < 0 und f (b) > 0. Der dazu symmetrische Fall kann voĚllig analog behandelt werden. Wir definieren rekursiv eine
Folge von Intervallen [an , bn ] fuĚr alle n â N0 mit den folgenden Eigenschaften:
(i) f (an ) â¤ 0 und f (bn ) âĽ 0 fuĚr alle n â N0 ;
(ii) [an , bn ] â [an+1 , bn+1 ] fuĚr alle n â N0 ;
(iii) bn â an = (b â a)/2n fuĚr alle n â N0 .
Dazu setzen wir a0 := a und b0 := b. Zu gegebenem an und bn betrachten
wir den

Mittelpunkt (an + bn )/2 des Intervalls [an , bn ]. Gilt f (an + bn )/2 â¤ 0, so setzen
wir an+1 := (an + bn )/2 und bn+1 := bn . Anderfalls, wenn f (an + bn )/2 > 0,
setzen wir an+1 := an und bn+1 := (an + bn )/2. Man kann mit vollstaĚndiger
Induktion leicht zeigen, dass dann die Eigenschaften (i), (ii) und (iii) erfuĚllt sind.
Wegen (ii) ist die Folge (an )nâN monoton wachsend und die Folge (bn )nâN ist
monoton fallend. AuĂerdem sind beide Folgen beschraĚnkt und daher konvergent.
Wegen (iii) ist die Folge (bn âan )nâN eine Nullfolge, so dass also x := limnââ an =
limnââ bn â [a, b]. Weil f stetig ist, gilt dann f (x) = limnââ f (an ) = limnââ f (bn ).
Wegen (i) gilt f (x) â¤ 0 und f (x) âĽ 0 also f (x) = 0.


188

Mathematik fuĚr Informatiker

M. Skutella

Das folgende Korollar stellt eine wichtige Anwendung des Nullstellensatzes
dar.
Korollar 4.2.29. Ist p ein Polynom uĚber R mit ungeradem Grad, so besitzt die
zugehoĚrige reelle Polynomfunktion x 7â p(x) eine Nullstelle.
Beweis. Siehe UĚbung.



Als naĚchstes stellen wir den Zwischenwertsatz vor, der unmittelbar aus dem
oben besprochenen Nullstellensatz folgt.
Satz 4.2.30 (Zwischenwertsatz). Es seien a, b â R mit a < b und f : [a, b] â R
eine stetige Funktion. Ist f (a) â¤ y â¤ f (b) oder f (a) âĽ y âĽ f (b), dann gibt es
ein x â [a, b] mit f (x) = y.
Beweis. Wir betrachten die Funktion g[a, b] â R mit g(z) := f (z) â y. Da f
stetig ist, ist auch g stetig und besitzt nach Satz 4.2.28 eine Nullstelle x â [a, b].
Dann gilt f (x) = g(x) + y = y.

Eine Konsequenz des Zwischenwertsatzes ist das folgende Resultat uĚber injektive Funktionen.
Korollar 4.2.31. Es sei I â R ein Intervall und f : I â R eine stetige Funktion.
Dann ist f genau dann injektiv, wenn f streng monoton wachsend oder fallend
ist.
Beweis. Ist f streng monoton wachsend oder fallend, so ist f nach Definition
injektiv.
Wir nehmen im Folgenden im Widerspruch zur Behauptung an, dass f injektiv
jedoch weder streng monoton wachsend noch fallend ist. Dann gibt es x1 , x2 , x3 â
I mit x1 < x2 < x3 und
f (x1 ) < f (x2 ) â§ f (x2 ) > f (x3 )

oder

f (x1 ) > f (x2 ) â§ f (x2 ) < f (x3 ) .

Wir beschraĚnken uns im Folgenden auf ersteren Fall; der zweite Fall kann voĚllig
analog behandelt werden. Wir waĚhlen y â R mit max{f (x1 ), f (x3 )} < y < f (x2 ).
Nach Satz 4.2.30 gibt es dann ein x â [x1 , x2 ] und ein x0 â [x2 , x3 ] mit f (x) =
y = f (x0 ). Da f (x2 ) > y gilt x 6= x2 6= x0 und daher x < x0 . Folglich ist f im
Widerspruch zur Annahme nicht injektiv.

Wir geben schlieĂlich noch den folgenden Satz ohne Beweis an.
Satz 4.2.32. Es seien a, b â R mit a < b und f : [a, b] â R eine stetige Funktion.
Dann gibt es y, z â [a, b] mit
f (y) = max{f (x) | x â [a, b]}
und
f (z) = min{f (x) | x â [a, b]} .

Kapiel 4: Analysis

M. Skutella

189

Bemerkung. Die Aussage von Satz 4.2.32 gilt nicht mehr, falls wir ein Intervall
der Form (a, b], [a, b) oder (a, b) betrachten. Ein Gegenbeispiel ist hier die Funktion f : (0, 1] â R mit f (x) := 1/x, die offenbar unbeschraĚnkt ist und daher kein
Maximum annimmt.
Bemerkung. In allen in diesem Abschnitt vorgestellten Resultaten ist die Voraussetzung der Stetigkeit der Funktion f unabdingbar. Man kann zu jedem dieser
Resultate leicht Beispiele unstetiger Funktionen konstruieren, fuĚr die das entsprechende Resultat nicht gilt. Wir lassen das als UĚbungsaufgabe.

4.3

Differenzialrechnung

Wir beschaĚftigen uns in diesem Abschnitt mit der Differenzialrechnung von (reellen) Funktionen. Im Folgenden bezeichnet K wieder den KoĚrper der reellen oder
komplexen Zahlen, also K â {R, C}.

4.3.1

Differenzierbarkeit und Ableitung von Funktionen

Wir betrachten eine reelle Funktion f . Wenn wir uns den Graphen von f vornehmen, haben wir eine gute Vorstellung davon, was es bedeuten soll, dass eine
Funktion an einer stelle x0 glattâ ist. Anschaulich gesprochen meinen wir daâ
mit, dass der Graph der Funktion an dieser Stelle keine Eckeâ aufweist. Etwas
â
mathematischer formuliert heiĂt das, dass die Funktion f an der Stelle x0 eine
Tangente besitzt, die sich an die Funktion anschmiegtâ.
â
Wie fasst man diese Vorstellung in eine formale Definition? Wir koĚnnen uns
dem Begriff der Tangente einer Funktion mit Hilfe des Begriffs der Sekante
naĚhern.
Definition 4.3.1 (Sekante, Steigung). Es sei D â R und f : D â R eine reelle
Funktion. Sind x0 , x â
 D mit x0 6=x, dann heiĂt die eindeutige Gerade durch
die Punkte x0 , f (x0 ) und x, f (x) Sekante des Graphen der Funktion f . Die
Steigung der Sekante ist durch den Ausdruck
f (x) â f (x0 )
x â x0
gegeben. Dieser Ausdruck wird auch Differenzenquotient genannt.
Anschaulich gesprochen erhaĚlt man die Tangente der Funktion f an der Stelle x0 (falls die Funktion uĚberhaupt eine Tangente an dieser Stelle besitzt), indem
man den Punkt x immer naĚher an den Punkt x0 heranruĚcken laĚsst und dabei die
Sekante betrachtet.
Definition 4.3.2 (Differenzierbarkeit, Ableitung). Es sei D â R und f : D â R
eine reelle Funktion.

190

Mathematik fuĚr Informatiker

M. Skutella

(i) Ist x0 â D und existiert der Grenzwert
lim

xâx0

f (x) â f (x0 )
,
x â x0

(4.6)

so sagt man, dass f in x0 differenzierbar ist. In diesem Fall bezeichnet man
den Grenzwert (4.6) mit f 0 (x0 ) und nennt ihn die Ableitung von f an der
Stelle x0 .
(ii) Ist die Funktion f an jeder Stelle x0 â D differenzierbar, so heiĂt f differenzierbar. In diesem Fall nennt man die Funktion
f0 : D â R

mit

x 7â f 0 (x)

die Ableitung von f .
Bemerkung.
(i) Existiert die Ableitung von f an der Stelle x0 , so wird die Tangente von f
in x0 durch die Funktion x 7â f (x0 ) + f 0 (x0 ) Âˇ (x â x0 ) beschrieben.
(ii) Eine notwendige Voraussetzung fuĚr die Existenz des Grenzwertes (4.6) ist,
dass x0 ein BeruĚhrungspunkt von D \ {x0 } ist. Das heiĂt, dass x0 kein
isolierter Punkt des Definitionsbereichs D sein kann. Dies entspricht auch
unserer Anschauung, nach der eine reelle Funktion in einem isolierten Punkt
ihres Definitionsbereichs keine Tangente besitzt.
(iii) Den Grenzwert (4.6) kann man, falls er existiert, alternativ auch wie folgt
schreiben:
f (x0 + h) â f (x0 )
.
hâ0
h

f 0 (x0 ) = lim

(iv) Definition 4.3.2 kann unmittelbar auf den Fall komplexwertiger Funktionen f : D â C mit D â R erweitert werden. In diesem Fall ist auch f 0 eine
komplexwertige Funktion.
(v) Die Ableitung von f an der Stelle x0 wird manchmal auch mit
zeichnet.

df
(x0 )
dx

be-

Der folgende Satz stellt eine alternative Charakterisierung der Differenzierbarkeit einer Funktion f dar. Diese Charakterisierung ist durch die in der Bemerkung
diskutierte Tangentenfunktion x 7â f (x0 ) + f 0 (x0 ) Âˇ (x â x0 ) motiviert.
Satz 4.3.3. Es sei D â R und f : D â K eine Funktion. Weiter seien x0 â D
und s â K. Dann sind die beiden folgenden Aussagen aĚquivalent:
(i) Die Funktion f ist in x0 differenzierbar mit Ableitung f 0 (x0 ) = s.

Kapiel 4: Analysis

M. Skutella

191

(ii) Es gibt eine Funktion Ď : D â K mit limxâx0 Ď(x) = 0 und
f (x) = f (x0 ) + s Âˇ (x â x0 ) + Ď(x) Âˇ (x â x0 )

fuĚr alle x â D.

Beweis. Gilt (ii), so ist der Differenzenquotient gegeben durch
f (x) â f (x0 )
= s + Ď(x) .
x â x0
Folglich existiert die Ableitung von f in x0 und es gilt
lim

xâx0

f (x) â f (x0 )
= s + lim Ď(x) = s .
xâx0
x â x0

Ist umgekehrt f in x0 differenzierbar mit f 0 (x0 ) = s, so koĚnnen wir die Funktion Ď : D â K wie folgt definieren:
(
f (x)âf (x0 )
â s fuĚr x â D \ {x0 },
xâx0
Ď(x) :=
0
fuĚr x = x0 .
Dann gilt limxâx0 Ď(x) = 0, da limxâx0
ist (ii) erfuĚllt.

f (x)âf (x0 )
xâx0

= s, und nach Definition von Ď


Beispiel. Die Funktion f : R â R mit f (x) := (x + 1)2 ist differenzierbar und es
gilt f 0 (x0 ) = 2x0 + 2 fuĚr alle x0 â R. Dies folgt unmittelbar aus Satz 4.3.3, denn
man kann f fuĚr jedes beliebige x0 â R wie folgt schreiben:
f (x) = (x + 1)2
= (x0 + 1)2 + (2x0 + 2) Âˇ (x â x0 ) + (x â x0 ) Âˇ (x â x0 )
fuĚr alle x â R. Setzt man also Ď(x) := x â x0 , so ist die Bedingung aus
Satz 4.3.3 (ii) erfuĚllt.
Eine wichtige Konsequenz von Satz 4.3.3 ist, dass aus der Differenzierbarkeit
von f in x0 insbesondere die Stetigkeit von f in x0 folgt.
Satz 4.3.4. Es sei D â R und f : D â K eine Funktion. Ist x0 â D und ist f
in x0 differenzierbar, so ist f in x0 auch stetig.
Beweis. Ist f in x0 differenzierbar, so gilt nach Satz 4.3.3

lim f (x) = f (x0 ) + f 0 (x0 ) Âˇ lim (x â x0 ) + lim Ď(x) Âˇ (x â x0 )

xâx0

xâx0

xâx0

= f (x0 ) .
Folglich ist f in x0 stetig.



192

Mathematik fuĚr Informatiker

M. Skutella

Bemerkung. Die Umkehrung von Satz 4.3.4 gilt im Allgemeinen nicht. Ein Gegenbeispiel ist die Betragsfunktion x 7â |x|, die im Punkt 0 zwar stetig, jedoch
nicht differenzierbar ist. Denn es gilt
lim+

xâ0

|x| â |0|
= 1
xâ0

und

limâ

xâ0

|x| â |0|
= â1 .
xâ0

Folglich existiert der Grenzwert des Differenzenquotienten an der Stelle 0 nicht.
Beispiele.
(i) Ist c â C, so ist die konstante Funktion f : R â C mit f (x) = c fuĚr
alle x â R differenzierbar und die Ableitung ist uĚberall null.
(ii) Sind a, b â C und ist f : R â C mit f (x) = a Âˇ x + b, so ist
f 0 (x0 ) =

lim

xâx0

f (x) â f (x0 )
=
x â x0

lim

xâx0

a Âˇ (x â x0 )
= a
x â x0

fuĚr alle x0 â R. Insbesondere ist f differenzierbar.
(iii) Ist n â N und f : R â R mit f (x) = xn fuĚr alle x â R, so ist f differenzierbar und es gilt f 0 (x) = n Âˇ xnâ1 fuĚr alle x â R. Denn wegen Lemma 4.1.42
gilt
 k nâk
Pn
n  
n
X
â xn
n kâ1 nâk
(x + h)n â xn
k=0 k h x
=
=
h x
.
h
h
k
k=1
Folglich ist
(x + h)n â xn
=
lim
hâ0
h

 
n nâ1
x
= n Âˇ xnâ1 .
1

Satz 4.3.5. Die reelle Exponentialfunktion exp : R â R ist differenzierbar und
es gilt exp0 = exp.
Beweis. Wir zeigen zunaĚchst, dass die reelle Exponentialfunktion an der Stelle 0
differenzierbar ist und exp0 (0) = exp(0) = 1 gilt. Dazu betrachten wir fuĚr x 6= 0
den Differenzenquotienten
â
â
â
X
X
1 X xk
xkâ1
xkâ1
exp(x) â exp(0)
â1 =
â1 =
â1 =
.
xâ0
x k=1 k!
k!
k!
k=1
k=2

Es genuĚgt also zu zeigen, dass
lim

xâ0

â
X
xkâ1
k=2

k!

= 0 .

Kapiel 4: Analysis

M. Skutella

193

Dies folgt, da fuĚr x mit |x| < 1 gilt, dass
â
X
xkâ1

0 â¤

k=2

k!

â¤

â
X
|x|kâ1
k=2

k!

â¤

â
X

|x|kâ1 =

â
X

|x|` =

`=1

k=2

|x|
.
1 â |x|

Wir zeigen schlieĂlich noch, dass exp0 (x) = exp(x) auch fuĚr x 6= 0 gilt. Dies
folgt jetzt unmittelbar, da
exp(h) â exp(0)
exp(x + h) â exp(x)
= exp(x) Âˇ
h
h
und daher
exp(x + h) â exp(x)
exp(h) â exp(0)
= exp(x) Âˇ lim
hâ0
hâ0
h
h
0
= exp(x) Âˇ exp (0) = exp(x) Âˇ 1 .
lim

Damit ist der Beweis abgeschlossen.



In Verallgemeinerung von Satz 4.3.5 kann man das folgende Resultat zeigen.
Korollar 4.3.6. FuĚr c â C ist die Funktion f : R â C mit f (x) := exp(c Âˇ x)
differenzierbar mit Ableitung f 0 (x) = c Âˇ f (x) = c Âˇ exp(c Âˇ x).
Satz 4.3.5 folgt auch aus einem allgemeinen Differenzierbarkeitsresultat uĚber
Potenzreihen, das wir hier ohne Beweis angeben.
P
k
Satz 4.3.7 (Differenzierbarkeit von Potenzreihen). Es sei â
k=0 ak z eine Potenzreihe mit Konvergenzradius Ď > 0. Wir betrachten die komplexwertige Funktion
f : (âĎ, Ď) â C

mit

f (x) :=

â
X

ak xk .

k=0

Dann ist die Funktion f differenzierbar. Die Potenzreihe
den Konvergenzradius Ď und es gilt
0

f (x) =

â
X

kak xkâ1

Pâ

k=1

kak z kâ1 hat auch

fuĚr alle x â (âĎ, Ď).

k=1

4.3.2

Ableitungsregeln

Wir geben in diesem Abschnitt die wichtigsten Ableitungsregeln an, die sich bei
der Bestimmung der Ableitung von Funktionen als nuĚtzlich erweisen.
Satz 4.3.8. Es sei D â R, x0 â D und f, g : D â K zwei Funktionen, die in x0
differenzierbar sind. Weiter seien Îť, Âľ â K. Dann gilt:

194

Mathematik fuĚr Informatiker

M. Skutella

(i) Die Funktion Îť Âˇ f + Âľ Âˇ g : D â K ist in x0 differenzierbar mit
(Îť Âˇ f + Âľ Âˇ g)0 (x0 ) = Îť Âˇ f 0 (x0 ) + Âľ Âˇ g 0 (x0 ) ( LinearitaĚt der Ableitungâ).
â
(ii) Die Funktion f Âˇ g : D â K ist in x0 differenzierbar mit
(f Âˇ g)0 (x0 ) = f 0 (x0 ) Âˇ g(x0 ) + f (x0 ) Âˇ g 0 (x0 ) ( Leibnizâsche Produktregelâ).
â
(iii) Ist g(x0 ) 6= 0, so ist die Funktion f /g in x0 differenzierbar mit
 0
f
f 0 (x0 ) Âˇ g(x0 ) â f (x0 ) Âˇ g 0 (x0 )
(x0 ) =
( Quotientenregelâ).
â
g
g(x0 )2
(iv) Ist D0 â R, y0 â D0 und h : D0 â D eine Funktion mit h(y0 ) = x0 , die in y0
differenzierbar ist. Dann ist die Funktion f âŚh : D0 â K in y0 differenzierbar
mit

(f âŚ h)0 (y0 ) = f 0 h(y0 ) Âˇ h0 (y0 )
( Kettenregelâ).
â
Beweis. Die LinearitaĚt der Ableitung (i) folgt direkt aus der Definition der Ableitung und Satz 4.2.5 (i) und (iii).
Die Produktregel (ii) gilt, da
(f Âˇ g)0 (x0 ) =
=
=
=
=

(f Âˇ g)(x) â (f Âˇ g)(x0 )
xâx0
x â x0
f (x) Âˇ g(x) â f (x0 ) Âˇ g(x0 ) â f (x0 ) Âˇ g(x) + f (x0 ) Âˇ g(x)
lim
xâx0
x â x0


f (x) â f (x0 )
g(x) â g(x0 )
Âˇ g(x) + f (x0 ) Âˇ
lim
xâx0
x â x0
x â x0
f (x) â f (x0 )
g(x) â g(x0 )
lim
Âˇ lim g(x) + f (x0 ) Âˇ lim
xâx0
xâx0
xâx0
x â x0
x â x0
0
0
f (x0 ) Âˇ g(x0 ) + f (x0 ) Âˇ g (x0 ) .
lim

Die Quotientenregel (iii) kann relativ leicht mit Hilfe der Produktregel und der
Kettenregel bewiesen werden. Wir lassen diesen Teil als UĚbung.
Die Kettenregel (iv) kann man beispielsweise mit Hilfe von Satz 4.3.3 beweisen. Wir gehen hier nicht auf die Details des Beweises ein.

Beispiele.
P
(i) Es seien a0 , . . . , ak â C und p : R â C die durch p(x) := ki=0 ai xi gegebene
Polynomfunktion. Dann ist p differenzierbar mit Ableitung p0 (x) =
Pk
iâ1
.
i=1 iai x

Kapiel 4: Analysis

M. Skutella

195

(ii) Nach Korollar 4.3.6 gilt fuĚr die Funktion f : R â C mit f (x) := exp(i Âˇ x),
dass
f 0 (x) = i Âˇ exp(i Âˇ x) = i Âˇ cos(x) + i2 Âˇ sin(x) = â sin(x) + i Âˇ cos(x) .
Andererseits gilt nach Satz 4.3.8 (i), dass
f 0 (x) = (cos +i Âˇ sin)0 (x) = cos0 (x) + i Âˇ sin0 (x) .
Vergleicht man Real- und ImaginaĚrteil der beiden AusdruĚcke, so erhaĚlt
man cos0 = â sin und sin0 = cos.
(iii) FuĚr n â N ist die Funktion f : R\{0} mit f (x) := 1/xn wegen Satz 4.3.8 (iii)
differenzierbar mit Ableitung
f 0 (x) =

0 Âˇ xn â 1 Âˇ n Âˇ xnâ1
n
= â n+1 .
n
2
(x )
x

(iv) Die Tangens-Funktion tan ist wegen Satz 4.3.8 (iii) auf ihrem gesamten
Definitionsbereich differenzierbar und es gilt

0
sin
sin0 (x) cos(x) â sin(x) cos0 (x)
0
tan (x) =
(x) =
cos
cos2 (x)
=

cos2 (x) + sin2 (x)
1
=
.
cos2 (x)
cos2 (x)

(v) Wegen Satz 4.3.8 (iv) ist fuĚr n â N die Funktion f : R â R mit f (x) :=
sinn (x) differenzierbar mit Ableitung
f 0 (x) = n Âˇ sinnâ1 (x) Âˇ cos(x) .
Satz 4.3.9 (Ableitung der Umkehrfunktion). Es sei I â R ein Intervall, x0 â I
und f : I â R eine stetige und streng monotone Funktion, die in x0 differenzierbar ist mit f 0 (x0 ) 6= 0. Dann ist die Umkehrfunktion f â1 : f (I) â I in f (x0 )
differenzierbar und es gilt

(f â1 )0 f (x0 ) =

1
f 0 (x

0)

.

Beweis. Es sei y0 := f (x0 ) und y â f (I). Da f in x0 = f â1 (y0 ) differenzierbar
ist, gibt es nach Satz 4.3.3 eine Funktion Ď : I â R mit limxâx0 Ď(x) = 0, so
dass


y â y0 = f f â1 (y) â f f â1 (y0 )



= f 0 f â1 (y0 ) + Ď f â1 (y) Âˇ f â1 (y) â f â1 (y0 ) .

196

Mathematik fuĚr Informatiker

M. Skutella

Folglich hat der Differenzenquotient von f â1 die folgende Gestalt:
f â1 (y) â f â1 (y0 )
1

 .
= 0 â1
y â y0
f f (y0 ) + Ď f â1 (y)
Daher ist

f â1 (y) â f â1 (y0 )
(f â1 )0 f (x0 ) = lim
yây0
y â y0
= lim

yây0 f 0

=
=

f â1 (y

f0

f â1 (y

f0

f â1 (y

1

1


â1 (y)
0) + Ď f

1


â1 (y)
0 ) + limyây0 Ď f
1
 = 0
.
f (x0 )
0)

Damit ist der Beweis abgeschlossen.



Beispiele.
(i) Die Logarithmus-Funktion ist die Umkehrfunktion der Exponentialfunktion.
Daher ist sie differenzierbar und fuĚr die Ableitung gilt
ln0 (x) =

exp0

1
1
1
 =
 =
x
ln(x)
exp ln(x)

fuĚr alle x â R>0 .
â
(ii) Es sei n â N und f : RâĽ0 â RâĽ0 mit f (x) = n x die n-te Wurzelfunktion.
Da f die Umkehrfunktion von y 7â y n ist, gilt fuĚr x > 0
f 0 (x) =

1
1
1 1/nâ1
â
=
=
Âˇx
.
n
1â1/n
nâ1
nÂˇx
n
n Âˇ ( x)

(iii) Die in Definition 4.2.26 eingefuĚhrte Umkehrfunktion der Sinusfunktion ist
die Funktion arcsin : [â1, 1] â [âĎ/2, Ď/2]. FuĚr x â [â1, 1] gilt
arcsin0 (x) =
Da sin0 = cos und cos(y) =

p

1
 .
sin arcsin(x)
0

1 â sin2 (y) fuĚr y â [âĎ/2, Ď/2], folgt

1
1
= â
.
arcsin0 (x) = q

1 â x2
1 â sin2 arcsin(x)

Kapiel 4: Analysis

M. Skutella

197

Zum Abschluss dieses Abschnittes betrachten wir noch Ableitungen hoĚherer
Ordnung.
Definition 4.3.10. Es sei I â R ein Intervall, x0 â I und f : I â K eine
Funktion.
(i) Die Funktion f heiĂt einmal differenzierbar (in x0 ), falls f (in x0 ) differenzierbar ist. Die Ableitung f 0 (x0 ) bezeichnet man dann auch als erste
Ableitung und schreibt dafuĚr f (1) (x0 ).
(ii) Ist f differenzierbar und ist die erste Ableitung f (1) (in x0 ) differenzierbar, so sagt man, dass f (in x0 ) zweimal differenzierbar ist. Man nennt
dann f (2) (x0 ) := (f (1) )0 (x0 ) die zweite Ableitung von f (in x0 ).
(iii) Es sei n â N. Ist f n-mal differenzierbar und ist die n-te Ableitung f (n)
(in x0 ) differenzierbar, so sagt man, dass f (in x0 ) n + 1-mal differenzierbar
ist. Man nennt dann f (n+1) (x0 ) := (f (n) )0 (x0 ) die (n + 1)-te Ableitung von f
(in x0 ).
(iv) Es sei n â N. Ist f n-mal differenzierbar und ist f (n) stetig, so heiĂt f n-mal
stetig differenzierbar.
(v) Ist f n-mal differenzierbar fuĚr alle n â N, so heiĂt f unendlich oft differenzierbar oder beliebig oft differenzierbar.
Bemerkung. Die zweite Ableitung von f bezeichnet man auch mit f 00 oder
3
die dritte mit f 000 oder ddxf3 , u.s.w.

d2 f
,
dx2

Beispiele.
(i) Wegen exp0 = exp ist die Exponentialfunktion unendlich oft differenzierbar
und es gilt exp(n) = exp fuĚr alle n â N.
(ii) Die durch eine beliebige Potenzreihe mit Konvergenzradius Ď > 0 definierte
Funktion auf dem Intervall (âĎ, Ď) ist nach Satz 4.3.7 unendlich oft differenzierbar.
(iii) Cosinus und Sinus sind unendlich oft differenzierbar. FuĚr n â N gilt

cos(n)

ďŁą
cos
ďŁ´
ďŁ´
ďŁ´
ďŁ˛â sin
=
ďŁ´
â cos
ďŁ´
ďŁ´
ďŁł
sin

falls
falls
falls
falls

n mod 4 = 0,
n mod 4 = 1,
n mod 4 = 2,
n mod 4 = 3,

198

Mathematik fuĚr Informatiker

M. Skutella

und

sin(n)

ďŁą
sin
ďŁ´
ďŁ´
ďŁ´
ďŁ˛cos
=
ďŁ´
â sin
ďŁ´
ďŁ´
ďŁł
â cos

falls
falls
falls
falls

n mod 4 = 0,
n mod 4 = 1,
n mod 4 = 2,
n mod 4 = 3.

(iv) Ist f : R â C eine Polynomfunktion vom Grad k mit
f (x) = ak xk + akâ1 xkâ1 + Âˇ Âˇ Âˇ + a0 ,
so ist f unendlich oft differenzierbar. Die k-te Ableitung f (k) ist konstant,
naĚmlich f (k) (x) = k! Âˇ ak fuĚr alle x â R, und jede hoĚhere Ableitung f (n)
mit n > k ist die Nullfunktion.
(v) Die Logarithmus-Funktion ln : (0, â) â R ist unendlich oft differenzierbar.
Es gilt
ln0 (x) =

1
,
x

ln00 (x) = â

1
,
x2

ln000 (x) =

2
x3

und allgemeiner
ln(n) (x) = (â1)nâ1

(n â 1)!
xn

fuĚr n â N.

(vi) Die Funktion f : R â R mit f (x) = x Âˇ |x| ist differenzierbar. Es gilt
(
(
âx2 fuĚr x < 0,
â2x fuĚr x < 0,
f (x) =
und f 0 (x) =
2
x
fuĚr x âĽ 0,
2x
fuĚr x > 0.
Die Ableitung an der Stelle 0 bestimmen wir mit Hilfe des Differenzenquotienten:
f 0 (0) = lim

xâ0

x|x| â 0
= lim |x| = 0 .
xâ0
xâ0

Es gilt also, dass f 0 (x) = 2|x| fuĚr alle x â R. Folglich ist f sogar stetig
differenzierbar, jedoch nicht zweimal differenzierbar, da f 0 an der Stelle 0
nicht differenzierbar ist.
(vii) Die Funktion f : R â R mit
(
x2 sin(1/x) fuĚr x 6= 0,
f (x) :=
0
fuĚr x = 0,
ist differenzierbar, jedoch nicht stetig differenzierbar. Wir lassen den Beweis
als UĚbung.

Kapiel 4: Analysis

M. Skutella

199

Bemerkung. Im Herbst 1972 verkuĚndete PraĚsident Nixon, die Beschleuniâ
gungsrate der Inflation nehme ab. Dies war das erste Mal, dass ein amtierender PraĚsident zugunsten seiner Wiederwahl die dritte Ableitung ins Feld fuĚhrte.â
(Zitat des Mathematikers Hugo Rossi)

4.3.3

MittelwertsaĚtze und Extrema

Wir gehen in diesem Abschnitt zunaĚchst auf die NuĚtzlichkeit der Differenzierbarkeit bei der LoĚsung von Extremwertaufgaben ein.
Definition 4.3.11 (Globale und lokale Extremwerte). Es sei D â R, x0 â D
und f : D â R eine reelle Funktion.
(i) x0 heiĂt globales Maximum von f , wenn f (x) â¤ f (x0 ) fuĚr alle x â D.
(ii) x0 heiĂt lokales Maximum von f , wenn es ein Îľ > 0 gibt mit f (x) â¤ f (x0 )
fuĚr alle x â D mit |x â x0 | < Îľ.
Globale und lokale Minima werden analog definiert, indem man â¤â durch âĽâ
â
â
ersetzt. Ein (globales oder lokales) Maximum oder Minimum heiĂt auch (globales
oder lokales) Extremum.
Bemerkung. Ein globales Maximum (Minimum) ist immer auch ein lokales Maximum (Minimum).
Wir zeigen zunaĚchst das folgende notwendige Kriterium fuĚr lokale Extrema
einer differenzierbaren Funktion.
Lemma 4.3.12. Es seien a â R âŞ {ââ}, b â R âŞ {â}, a < x0 < b und f :
(a, b) â R eine in x0 differenzierbare Funktion. Ist x0 ein lokales Extremum
von f , so ist f 0 (x0 ) = 0.
Beweis. Wir nehmen im Folgenden an, dass x0 ein lokales Minimum ist. Den
Fall eines lokalen Maximums kann man voĚllig analog behandeln. Es sei Îľ > 0
mit a < x0 â Îľ < x0 + Îľ < b und f (x) âĽ f (x0 ) fuĚr alle x mit |x â x0 | < Îľ. Dann
gilt fuĚr den Differenzenquotienten
(
f (x) â f (x0 ) âĽ 0 falls x > x0 ,
x â x0
â¤ 0 falls x < x0 .
Folglich ist der rechtsseitige Grenzwert des Differenzenquotienten nicht-negativ
und der linksseitige Grenzwert ist nicht-positiv. Daher muss der Grenzwert f 0 (x0 )
gleich null sein.

Bemerkung. Die Umkehrung der Aussage von Lemma 4.3.12 gilt im Allgemeinen nicht. Die Funktion x 7â x3 besitzt an der Stelle x0 = 0 offenbar kein lokales
Extremum. Ihre Ableitung ist dort aber null.

200

Mathematik fuĚr Informatiker

M. Skutella

Wir werden sehen, dass die Umkehrung der Aussage von Lemma 4.3.12 jedoch unter gewissen Zusatzbedingungen gilt. Dazu benoĚtigen wir zunaĚchst den
Mittelwertsatz.
Satz 4.3.13 (Mittelwertsatz der Differentialrechnung). Es seien a, b â R mit a <
b und f : [a, b] â R eine stetige Funktion, die in jedem Punkt x â (a, b) differenzierbar ist. Dann gibt es ein x0 â (a, b) mit
f (b) â f (a)
= f 0 (x0 ) .
bâa
Bevor wir den Mittelwertsatz beweisen, formulieren wir zunaĚchst ein einfaches
Korollar, das unter dem Namen Satz von Rolleâ bekannt ist.
â
Korollar 4.3.14 (Satz von Rolle). Es seien a, b â R und f : [a, b] â R eine
stetige Funktion, die in jedem Punkt x â (a, b) differenzierbar ist. Ist f (a) = f (b),
so gibt es ein x0 â (a, b) mit f 0 (x0 ) = 0.
Beweis von Satz 4.3.13. Wir beweisen zunaĚchst den Spezialfall aus Korollar 4.3.14.
Ist f konstant, so ist f 0 (x) = 0 fuĚr alle x â [a, b]. Andernfalls besitzt f gemaĚĂ
Satz 4.2.32 ein globales Maximum x0 und ein globales Minimum x1 . Da f nicht
konstant ist, muss mindestens einer der beiden Funktionswerte f (x0 ) und f (x1 )
von f (a) = f (b) verschieden sein. Dann gilt also x0 â (a, b) oder x1 â (a, b). AuĂerdem ist die Ableitung an dieser Stelle nach Lemma 4.3.12 gleich null. Damit
ist der Satz von Rolle bewiesen.
Der allgemeine Mittelwertsatz folgt jetzt sofort daraus, wenn man die Funktion h : [a, b] â R mit
h(x) := f (x) â

f (b) â f (a)
(x â a)
bâa

betrachtet. Denn offenbar gilt
h(a) = h(b) = f (a)

und

Damit ist der Beweis abgeschlossen.

h0 (x) = f 0 (x) â

f (b) â f (a)
.
bâa


Als Konsequenz aus dem Mittelwertsatz koĚnnen wir das folgende Monotoniekriterium formulieren.
Lemma 4.3.15 (Monotoniekriterien). Es seien a â R âŞ {ââ}, b â R âŞ {â}
und f : (a, b) â R eine differenzierbare Funktion.
(i) Es gilt genau dann f 0 (x) âĽ 0 (f 0 (x) â¤ 0) fuĚr alle x â (a, b), wenn f monoton
wachsend (fallend) ist.

Kapiel 4: Analysis

M. Skutella

201

(ii) Ist f 0 (x) > 0 (f 0 (x) < 0) fuĚr alle x â (a, b), so ist f streng monoton
wachsend (fallend).
(iii) Es gilt genau dann f 0 (x) = 0 fuĚr alle x â (a, b), wenn f konstant ist.
Beweisskizze. FuĚr (i) bis (iii) folgt die Implikation ââ unmittelbar aus dem
â
Mittelwertsatz 4.3.13. Die Implikation ââ in (i) und (iii) folgt direkt aus der
â
Definition der Ableitung mit Hilfe des Differenzenquotienten.

Korollar 4.3.16. Es seien a â R âŞ {ââ}, b â R âŞ {â} und f, g : (a, b) â R
zwei differenzierbare Funktionen mit f 0 (x) = g 0 (x) fuĚr alle x â (a, b). Dann gibt
es ein c â R mit f (x) = g(x) + c fuĚr alle x â (a, b).
Beweis. Die Ableitung der Funktion f â g ist nach Voraussetzung uĚberall null,
so dass f â g nach Lemma 4.3.15 (iii) konstant ist.

Auch das naĚchste Korollar folgt direkt aus Lemma 4.3.15.
Korollar 4.3.17. Es seien a â R âŞ {ââ}, b â R âŞ {â} und f : (a, b) â R eine
differenzierbare Funktion. Weiter seien Îą, Î˛, x0 â R mit a â¤ Îą < x0 < Î˛ â¤ b
und f 0 (x0 ) = 0. Gilt f 0 (x) âĽ 0 (f 0 (x) â¤ 0) fuĚr alle x â (Îą, x0 ) und f 0 (x) â¤ 0
(f 0 (x) âĽ 0) fuĚr alle x â (x0 , Î˛), so hat f in x0 ein lokales Maximum (Minimum).
Ist f zweimal differenzierbar, so erhaĚlt man ein einfacheres Kriterium.
Satz 4.3.18. Es seien a â R âŞ {ââ}, b â R âŞ {â} und f : (a, b) â R.
Weiter sei x0 â (a, b) und f sei in x0 zweimal differenzierbar. Ist f 0 (x0 ) = 0
und f 00 (x0 ) < 0 (f 00 (x0 ) > 0), so besitzt f in x0 ein lokales Maximum (Minimum).
Beweis. Es sei f 0 (x0 ) = 0 und f 00 (x0 ) < 0. Nach Definition der zweiten Ableitung
gilt
0 > f 00 (x0 ) =

lim

xâx0

f 0 (x) â f 0 (x0 )
=
x â x0

lim

xâx0

f 0 (x)
,
x â x0

so dass also f 0 (x)/(x â x0 ) < 0 in einer kleinen Umgebung von x0 . Folglich sind
die Voraussetzungen von Korollar 4.3.17 erfuĚllt und x0 ist ein lokales Maximum.
Der Beweis fuĚr den Fall eines lokalen Minimums funktioniert voĚllig analog.

Beispiele.
(i) Es seien a, b, c â R mit a 6= 0 und f (x) := ax2 +bx+c eine Polynomfunktion
vom Grad zwei. Dann besitzt die Ableitung f 0 (x) = 2ax + b eine eindeutige
Nullstelle bei x0 = âb/(2a). Ist a > 0 (a < 0), so gilt f 0 (x) < 0 (f 0 (x) > 0)
fuĚr x < x0 und f 0 (x) > 0 (f 0 (x) < 0) fuĚr x > x0 . Folglich ist x0 nach
Korollar 4.3.17 ein lokales Minimum (Maximum) von f . Noch einfacher
erkennt man das mit Hilfe von Satz 4.3.18, da f 00 (x0 ) = 2a. Man kann sich
uĚberlegen, dass x0 sogar ein globales Minimum (Maximum) von f ist.

202

Mathematik fuĚr Informatiker

M. Skutella


(ii) Wir betrachten die Funktion f : (0, â) â R mit f (x) := xx = exp x ln(x) .
Dann ist
0


f 0 (x) = x ln(x) exp x ln(x) = ln(x) + 1 xx
und
f 00 (x) =

2
1 x
x + ln(x) + 1 xx .
x

Die einzige Nullstelle von f 0 ist 1/e und es gilt f 00 (1/e) > 0. Folglich ist 1/e
ein lokales (und sogar das globale) Minimum.
Zum Abschluss dieses Abschnittes stellen wir die Regeln von de LâHoĚpital vor.
Dazu benoĚtigen wir zunaĚchst den folgenden verallgemeinerten Mittelwertsatz.
Satz 4.3.19 (Verallgemeinerter Mittelwertsatz). Es seien a, b â R mit a < b
und f, g : [a, b] â R zwei stetige Funktion, die in jedem Punkt x â (a, b) differenzierbar sind. Weiter gelte g 0 (x) 6= 0 fuĚr alle x â (a, b). Dann gibt es ein x0 â (a, b)
mit
f 0 (x0 )
f (b) â f (a)
= 0
.
g(b) â g(a)
g (x0 )
Bemerkung. Setzt man g(x) := x in Satz 4.3.19, so erhaĚlt man den bereits
bekannten Mittelwertsatz 4.3.13.
Beweis. Es sei h : [a, b] â R mit
h(x) := f (x) â


f (b) â f (a)
g(x) â g(a) .
g(b) â g(a)

Nach Definition ist h stetig und in jedem Punkt x â (a, b) differenzierbar. AuĂerdem ist h(a) = h(b) = f (a). Folglich gibt es nach Korollar 4.3.14 ein x0 â (a, b)
mit h0 (x0 ) = 0. Da
h0 (x) = f 0 (x) â

f (b) â f (a) 0
g (x)
g(b) â g(a)

folgt die Behauptung.



Satz 4.3.20 (Regeln von de LâHoĚpital). Es seien a, b â R mit a < b und f, g :
(a, b] â R zwei differenzierbare Funktion mit g(x) 6= 0 und g 0 (x) 6= 0 fuĚr alle x â
(a, b].
(i) Gilt limxâa f (x) = limxâa
 g(x) = 0 und existiert der (uneigentliche) Grenz0
0
wert limxâa f (x)/g (x) â R âŞ {ââ, â}, so gilt
f (x)
f 0 (x)
= lim 0
.
xâa g(x)
xâa g (x)
lim

Kapiel 4: Analysis

M. Skutella

203

(ii) Gilt limxâa f (x) = Âąâ und limxâa g(x)
 = Âąâ und existiert der (uneigent0
0
liche) Grenzwert limxâa f (x)/g (x) â R âŞ {ââ, â}, so gilt
f 0 (x)
f (x)
= lim 0
.
xâa g (x)
xâa g(x)
lim

Bemerkung. Der Satz gilt natuĚrlich auch, wenn wir das Intervall (a, b] durch [b, a)
(fuĚr b < a) ersetzen. AuĂerdem gilt er auch fuĚr den Fall, dass a = ââ bzw. a =
+â ist.
Beweisskizze. Wir beweisen nur (i): Nach Voraussetzung kann man f und g
durch f (a) = g(a) = 0 stetig ergaĚnzen. Nach Satz 4.3.19 gibt es dann zu jedem x â (a, b) ein x0 â (a, x) mit
f (x)
f (x) â f (a)
f 0 (x0 )
.
=
= 0
g(x)
g(x) â g(a)
g (x0 )
Lassen wir nun x gegen a konvergieren, so konvergiert auch x0 gegen a, so dass
f (x)
=
xâa g(x)
lim

f 0 (x0 )
.
x0 âa g 0 (x0 )
lim


Beispiele.
â
(i) Es seien f (x) = x2 und g(x) = x2 +â1 â 1 fuĚr x âĽ 0. Dann ist f (0) =
g(0) = 0 und f 0 (x) = 2x, g 0 (x) = 2x/(2 x2 + 1). Es gilt
â
f 0 (x)
=
lim
2
x2 + 1 = 2
xâ0
xâ0 g 0 (x)
lim

und daher auch
lim

xâ0

f (x)
= 2 .
g(x)

(ii) Wir betrachten noch einmal f und g aus dem letzten Beispiel. Offenbar
gilt limxââ f (x) = â und limxââ g(x) = â. Da
â
f 0 (x)
lim 0
= lim 2 x2 + 1 = â ,
xââ g (x)
xââ
folgt auch
f (x)
= â .
xââ g(x)
lim

204

Mathematik fuĚr Informatiker

M. Skutella

(iii) Es sei f (x) = sin(x) und g(x) = x fuĚr x â R. Dann gilt f (0) = g(0) =
0, f 0 (x) = cos(x) und g 0 (x) = 1. Folglich ist
sin(x)
cos(x)
= lim
= 1 .
xâ0
xâ0
x
1
lim

(iv) Es sei f (x) = exp(x) â exp(âx) und g(x) = sin(x) fuĚr x â R. Dann
gilt f (0) = g(0) = 0, f 0 (x) = exp(x) + exp(âx) und g 0 (x) = cos(x). Folglich
ist
ex â eâx
ex + eâx
= lim
= 2 .
xâ0 sin(x)
xâ0 cos(x)
lim

(v) Bei der Berechnung des Grenzwertes limxâ0 x ln(x) fuĚhrt es nicht zum Ziel,
die Regel von de LâHoĚpital auf die beiden Funktionen f (x) = x und g(x) =
1/ ln(x) anzuwenden. Denn es gilt f 0 (x) = 1 und g 0 (x) = â1/(x ln2 (x)), so
dass f 0 (x)/g 0 (x) = âx ln2 (x). UĚber den Grenzwert des letzten Terms fuĚr x
gegen 0 kann man wieder keine direkte Aussage treffen.
Setzt man jedoch f (x) = ln(x) und g(x) = 1/x, so erhaĚlt man f 0 (x) = 1/x
und g 0 (x) = â1/x2 und daher
lim x ln(x) =

xâ0

lim

xâ0

1
x

â x12

= lim âx = 0 .
xâ0

(vi) Man kann die Regel von de LâHoĚpital auch rekursiv anwenden, wie das
folgende Beispiel zeigt. FuĚr n â N gilt
ex
ex
ex
=
lim
=
lim
xââ n Âˇ xnâ1
xââ n(n â 1) Âˇ xnâ2
xââ xn
ex
= Âˇ Âˇ Âˇ = lim
= â .
xââ n!
lim

Die dadurch getroffene Aussage, dass die Exponentialfunktion schneller als
jede Polynomfunktion waĚchst, hatten wir schon fruĚher kennengelernt.
(vii) Auch der folgende Grenzwert ist uns eigentlich schon bekannt.FuĚr n â N ist
1
ln(x)
x
= lim 1 1/nâ1 = lim
lim â
xââ x
xââ n x
xââ
n

4.3.4

1
n

1
â
n

x

= 0 .

Taylorreihen

Bei der EinfuĚhrung der Differentialrechnung haben wir die Interpretation der
Ableitung als Steigung der Tangente der Funktion genutzt. Man kann sagen, dass

Kapiel 4: Analysis

M. Skutella

205

die Tangente an eine Funktion f in der Stelle x0 die Funktion in einer Umgebung
von x0 approximiert. Die Tangente ist durch die folgende Funktion g gegeben:
g(x) := f (x0 ) + f 0 (x0 ) Âˇ (x â x0 ) .
In Satz 4.3.3 haben wir gezeigt, dass fuĚr den Fehlerterm f (x) â g(x) gilt, dass er
sich besser verhaĚlt als (x â x0 ), das heiĂt
lim

xâx0

f (x) â g(x)
= 0 .
x â x0

Ist die Funktion f an der Stelle x0 mehr als einmal differenzierbar, so kann man
versuchen, mit Hilfe hoĚherer Ableitungen eine bessere Approximation von f in
einer Umgebung von x0 zu bekommen.
Definition 4.3.21 (Taylorpolynom). Es sei D â R, x0 â D und f : D â K eine
Funktion, die an der Stelle x0 mindestens n-mal differenzierbar ist fuĚr ein n â N.
Dann heiĂt das Polynom
Tf,n (x, x0 ) :=

n
X
f (i) (x0 )
i=0

i!

(x â x0 )i

n-tes Taylorpolynom von f mit Entwicklungspunkt x0 .
Bemerkung. Das erste Taylorpolynom Tf,1 (x, x0 ) beschreibt offenbar die Tangente an f im Punkt x0 .
Beispiel. Es sei f (x) = sin(x). Das erste Taylorpolynom von sin mit Entwicklungspunkt 0 ist
Tsin,1 (x, 0) = sin(0) + sin0 (0)x = x .
Da sin00 (0) = â sin(0) = 0, stimmt das zweite mit dem ersten Taylorpolynom
uĚberein, also Tsin,2 (x, 0) = Tsin,1 (x, 0) = x fuĚr alle x â R. FuĚr das dritte Taylorpolynom gilt
Tsin,3 (x, 0) = x â 16 x3 .
Allgemeiner gilt fuĚr das (2n + 1)-te Taylorpolynom
n
X
(â1)k 2k+1
Tsin,2n+1 (x, 0) =
x
.
(2k + 1)!
k=0

Man beachte, dass es sich hierbei um die ersten n + 1 Summanden der Reihenentwicklung der Sinus-Funktion handelt (siehe Satz 4.2.24).

206

Mathematik fuĚr Informatiker

M. Skutella

Lemma 4.3.22. Es sei D â R, x0 â D und f : D â K eine Funktion, die an
der Stelle x0 n-mal differenzierbar ist fuĚr ein n â N. Dann ist das Taylorpolynom Tf,n (x, x0 ) die einzige Polynomfunktion p : D â K vom Grad hoĚchstens n
mit p(k) (x0 ) = f (k) (x0 ) fuĚr k = 0, . . . , n.
Beweis. Man rechnet leicht nach, dass das Taylorpolynom Tf,n (x, x0 ) aufgrund
seiner Definition die geforderte Eigenschaft besitzt.
Um die Eindeutigkeit
zu beweisen, betrachten wir die Basisfolge 1, xâx0 , (xâ

x0 )2 , . . . , (x â x0 )n des Vektorraums aller Polynome vom Grad hoĚchstens n. Es
sei p ein Polynom vom grad hoĚchstens n mit der geforderten Eigenschaft. Wir
koĚnnen p schreiben als
p(x) =

n
X

ai (x â x0 )i

mit a0 , . . . , an â K.

i=0

Nach Voraussetzung gilt dann fuĚr k = 0, . . . , n
f (k) (x0 ) = p(k) (x0 ) = k! Âˇ ak ,
so dass ak = f (k) (x0 )/k!. Folglich stimmt p mit dem Taylorpolynom uĚberein. 
Der folgende Satz von Taylor liefert eine genaue Beschreibung der Abweichung
zwischen einer Funktion f und ihrem Taylorpolynom. Mit Hilfe dieses Satzes kann
man also abschaĚtzen, wie groĂ der Fehler ist, den man in Kauf nimmt, wenn man
statt einer (komplizierten) Funktion ihr Taylorpolynom auswertet.
Satz 4.3.23 (Satz von Taylor). Es sei n â N, a < b und f : [a, b] â R eine n-mal
stetig differenzierbare Funktion, die auf dem offenen Intervall (a, b) mindestens
(n + 1)-mal differenzierbar ist. Dann gibt es zu jedem x â (a, b] ein y â (a, x) mit
f (x) = Tf,n (x, a) +

f (n+1) (y)
(x â a)n+1 .
(n + 1)!

(4.7)

Den zweiten Summanden auf der rechten Seite von (4.7) nennt man Restglied.
Beweis. Wir betrachten die Funktion g : (a, b) â R mit
g(z) := f (z) â Tf,n (z, a) â

f (x) â Tf,n (x, a)
Âˇ (z â a)n+1 .
(x â a)n+1

Dann ist g mindestens (n + 1)-mal differenzierbar und, da die Polynomfunktion z 7â Tf,n (z, a) hoĚchstens den Grad n besitzt, gilt
g (n+1) (z) = f (n+1) (z) â

f (x) â Tf,n (x, a)
Âˇ (n + 1)! .
(x â a)n+1

(4.8)

Kapiel 4: Analysis

M. Skutella

207

Wegen Lemma 4.3.22 gilt g(a) = g 0 (a) = Âˇ Âˇ Âˇ = g (n) (a) = 0; auĂerdem gilt g(x) =
0. Nach Korollar 4.3.14 (Satz von Rolle) gibt es also ein x1 â (a, x) mit g 0 (x1 ) =
0 = g 0 (a). Wendet man den Satz von Rolle ein zweites mal an, so erhaĚlt man
ein x2 â (a, x1 ) mit g 00 (x2 ) = 0 = g 00 (a). Nach weiteren n â 1 Anwendungen des
Satzes erhaĚlt man schlieĂlich ein y = xn+1 â (a, xn ) â (a, x) mit g (n+1) (y) = 0.
Wegen (4.8) folgt daraus die Behauptung des Satzes.

Bemerkung. Der Satz gilt natuĚrlich analog fuĚr den Fall, dass wir ein Intervall [b, a] links des Entwicklungspunktes a betrachten.
Beispiel. In Fortsetzung des Beispiels von oben betrachten wir nochmal die
Sinusfunktion. Nach dem Satz von Taylor gilt fuĚr n â N0
| sin(x) â Tsin,2n+1 (x, 0) | â¤

|x|2n+2
,
(2n + 2)!

da | sin2n+2 (y)| = | sin(y)| â¤ 1. Wenn man also sin(1/2) bis auf 12 Nachkommastellen genau berechnen moĚchte, kann man dazu das Taylorpolynom Tsin,11 (x, 0)
auswerten, da
| sin(1/2) â Tsin,11 (1/2, 0) | â¤

1/212
â¤ 5.1 Âˇ 10â13 .
12!

Definition 4.3.24 (Taylor-Reihen). Es seien a, b â R mit a < b und f : (a, b) â
R eine unendlich oft differenzierbare Funktion. Dann heiĂt fuĚr x0 â (a, b) die
Reihe
Tf (x, x0 ) :=

â
X
f (k) (x0 )
k=0

k!

(x â x0 )k

die Taylor-Reihe von f mit Entwicklungspunkt x0 .
Bemerkung. Wie weiter oben bemerkt, stimmt die Taylor-Reihe der SinusFunktion mit Entwicklungspunkt 0 mit der Sinusfunktion uĚberein. Leider verhaĚlt
sich die Taylor-Reihe nicht immer so gut. Es gibt Funktionen, deren Taylorreihen
den Konvergenzradius null haben. Bei anderen Funktionen hat die Taylor-Reihe
zwar einen positiven Konvergenzradius, konvergiert jedoch nicht gegen die zu
Grunde liegende Funktion.
Definition 4.3.25 (Analytische Funktionen). Es seien a, b â R mit a < b und f :
(a, b) â R eine unendlich oft differenzierbare Funktion. Dann heiĂt f analytisch
im Punkt x0 â (a, b), falls es ein Îľ > 0 gibt, so dass sich f auf dem Intervall (x0 â
Îľ, x0 +Îľ) als Potenzreihe darstellen laĚsst; das heiĂt es gibt eine reelle Folge (an )nâN0
mit
f (x) =

â
X
k=0

ak (x â x0 )k

fuĚr x â (x0 â Îľ, x0 + Îľ).

208

Mathematik fuĚr Informatiker

M. Skutella

3

x
Abbildung 4.3: Der Graph der Funktion f (x, y) = â 300
â cos(y).

Zum Abschluss dieses Abschnitts erwaĚhnen wir noch den folgenden Satz ohne
Beweis.
Satz 4.3.26. Es seien a, b, x0 â R mit a < x0 < b und f : (a, b) â R eine
in x0 analytische Funktion. Dann ist die entsprechende Potenzreihe aus Definition 4.3.25 gleich der Taylor-Reihe von f mit Entwicklungspunkt x0 .

4.3.5

Funktionen mehrerer VeraĚnderlicher

Wir gehen in diesem Abschnitt kurz auf Funktionen mehrerer reeller VeraĚnderlicher ein und diskutieren insbesondere die Verallgemeinerung des Differenzierbarkeitsbegriffs auf diese Klasse von Funktionen. Ein Beispiel einer solchen Funktion
ist die Abbildung f : R2 â R mit
f (x, y) := â

x3
â cos(y) .
300

Der Graph dieser Funktion ist in Abbildung 4.3 dargestellt.
Definition 4.3.27 (Partielle Ableitung). Es sei n â N, i â {1, . . . , n} und f :
Rn â R eine Funktion. FuĚr fest gewaĚhlte x1 , . . . , xiâ1 , xi+1 , . . . , xn â R ist die
zu f gehoĚrende i-te partielle Funktion fi : R â R gegeben durch
fi (xi ) := f (x1 , . . . , xiâ1 , xi , xi+1 , . . . , xn ) .

Kapiel 4: Analysis

M. Skutella

209

Ist fi an der Stelle xi â R differenzierbar, so heiĂt fi0 (xi ) die partielle Ableitung
von f nach xi an der Stelle x = (x1 , . . . , xn ) oder die i-te partielle Ableitung von f
an der Stelle x = (x1 , . . . , xn ). Man verwendet dann auch die Bezeichnungen
fi0 (xi ) =

âf
â
(x) =
f (x) .
âxi
âxi

Die Funktion f heiĂt partiell differenzierbar an der Stelle x, falls die i-te partielle
Ableitung von f an der Stelle x fuĚr alle i = 1, . . . , n existiert. In diesem Fall heiĂt
der Vektor


âf
âf
grad f (x) :=
(x), . . . ,
(x)
âx1
âxn
der Gradient von f an der Stelle x. Ist f an jeder Stelle x â Rn partiell differenzierbar, so nennt man f partiell differenzierbar.
Beispiele.
(i) Die Funktion f : R2 â R mit f (x, y) = x2 + y 2 ist partiell differenzierbar
und besitzt die partiellen Ableitungen
âf
(x, y) = 2x
âx

und

âf
(x, y) = 2y .
ây

Folglich ist grad f (x, y) = (2x, 2y).
(ii) Die Funktion f : R3 â R mit f (x, y, z) = x2 Âˇ sin(y) + x Âˇ ez ist partiell
differenzierbar und besitzt die partiellen Ableitungen
âf
(x, y, z) = 2x sin(y) + ez ,
âx
âf
(x, y, z) = x2 Âˇ cos(y) ,
ây
âf
(x, y, z) = x Âˇ ez .
âz
Folglich ist grad f (x, y, z) =


2x sin(y) + ez , x2 Âˇ cos(y), x Âˇ ez .

Bemerkung. Der Gradient einer Funktion f : Rn â R gibt die Richtung des
steilsten Anstieges der Funktion an.
Beispiele.
(i) Es sei f (x, y) = (x2 + y 2 )/7 â 1. Dann gibt grad f (x, y) = (2x/7, 2y/7) die
Richtung des steilsten Anstieges von f im Punkt (x, y) an. Den steilsten
Anstieg in (x, y) findet man also immer, wenn man sich vom Ursprung des
Koordinatensystems wegbewegt. Siehe auch Abbildung 4.4.

210

Mathematik fuĚr Informatiker

M. Skutella

Abbildung 4.4: Der Graph der Funktion f (x, y) = (x2 + y 2 )/7 â 1.

Abbildung 4.5: Der Graph der Funktion f (x, y) = x2 â y 2 .

Kapiel 4: Analysis

M. Skutella

211

(ii) Es sei f (x, y) = x2 â y 2 . Dann ist grad f (0, 0) = (0, 0), da die Funktion im
Nullpunkt ebenâ ist, also keinen Anstieg besitzt. Siehe auch Abbildung 4.5.
â
Definition 4.3.28 (Lokale Extrema). Es sei f : Rn â R und x â Rn . Dann ist x
ein lokales Maximum (Minimum), falls es ein Îľ > 0 gibt, so dass f (x) âĽ f (y)
(f (x) â¤ f (y)) fuĚr alle y â Rn mit |x â y| < Îľ. Hierbei bezeichnet |x â y| den
euklidischen Abstand von x = (x1 , . . . , xn ) und y = (y1 , . . . , yn ), also
p
|x â y| = (x1 â y1 )2 + Âˇ Âˇ Âˇ + (xn â yn )2 .
Wir koĚnnen Lemma 4.3.12 fuĚr den Fall von Funktionen mehrerer VeraĚnderlicher wie folgt verallgemeinern.
Lemma 4.3.29. Es sei f : Rn â R und x â Rn . Ist x ein lokales Extremum
von f und ist f an der Stelle x partiell differenzierbar, so ist grad f (x) = 0.
Beweis. Ist x ein lokales Extremum von f , so ist x insbesondere ein lokales Extremum der partiellen Funktionen f1 , . . . , fn . Damit folgt die Behauptung aus
Lemma 4.3.12.

Bemerkung. Das Beispiel der in Abbildung 4.5 dargestellten Funktion zeigt,
dass ein Punkt x (in dem Beispiel der Nullpunkt), der ein lokales Extremum aller
partiellen Funktionen f1 , . . . , fn ist, nicht notwendigerweise ein lokales Extremum
von f sein muss.
Wir benoĚtigen also, wie im eindimensionalen Fall, noch ein hinreichendes Kriterium fuĚr die Existenz eines lokalen Extremums.
âf
Bemerkung. Die partiellen Ableitungen âx
(i = 1, ..., n) einer Funktion
i
f : Rn â R sind selbst wieder Abbildungen von Rn nach R und unter UmstaĚnden
ebenfalls partiell differenzierbar. Man bezeichnet ihre partiellen Ableitungen
â2f
âf
= âxâ j ( âx
) dann als zweite partielle Ableitungen von f .
âxj âxi
i

Ist die zu untersuchende Funktion zweimal stetig partiell differenzierbar, so
kann man oft mit den folgenden Hilfsmitteln Aussagen uĚber lokale Extrema treffen.
Definition 4.3.30. Ist f : Rn â R in x â Rn zweimal stetig partiell differenzierbar, so bilden die zweiten partiellen Ableitungen von f die Hesse-Matrix
ďŁŤ â2f
ďŁś
2f
(x) Âˇ Âˇ Âˇ âxâ1 âx
(x)
âx1 âx1
n
ďŁŹ
ďŁˇ
..
..
...
Hf (x) := ďŁ­
ďŁ¸
.
.
â2f
(x)
âxn âx1

von f im Punkt a.

ÂˇÂˇÂˇ

â2f
(x)
âxn âxn

212

Mathematik fuĚr Informatiker

M. Skutella

Beispiele.
(i) Die Funktion f : R2 â R, f (x, y) := x2 + y 2 hat die partiellen Ableitungen
âf
(x, y) = 2x und âf
(x, y) = 2y. Die zweiten partiellen Ableitungen lauten
âx
ây
also
0=

2
â2f
â
â
(2x) = 2 = ây
(2y) = ââyf2 (x, y)
(x, y) = âx
âx2
â2f
â
(2y) = âxây
(x, y). Die Hesse-Matrix von f
âx


Hf (x, y) =

und

â2f
(x, y)
âyâx

=

â
(2x)
ây

=

hat somit die Gestalt


2 0
.
0 2

(ii) Die Hesse-Matrix der Funktion f : R3 â R, f (x, y, z) := x2 Âˇ sin(y) + x Âˇ ez
hat die Gestalt
ďŁŤ
ďŁś
2 sin(y) 2x cos(y) ez
Hf (x, y, z) = ďŁ­2x cos(y) âx2 sin(y) 0 ďŁ¸ .
ez
0
xez
Die Hesse-Matrizen in obigen Beispielen sind offenbar symmetrisch. Dies ist
kein Zufall, wie der naĚchste Satz zeigt, den wir ohne Beweis angeben.
Satz 4.3.31 (Satz von Schwarz). Es sei f : Rn â R eine zweimal stetig partiell
differenzierbare Funktion. Dann gilt fuĚr alle i, j = 1, ..., n:
â2f
â2f
=
.
âxi âxj
âxj âxi
Es spielt unter den Voraussetzungen des Satzes also keine Rolle, ob man f
zuerst nach xi oder nach xj ableitet; die Voraussetzung der zweimaligen partiellen
Differenzierbarkeit ist dabei wesentlich. Der Satz liefert nun unmittelbar
Korollar 4.3.32. Es sei f : Rn â R eine zweimal stetig partiell differenzierbare
Funktion. Dann ist die Hesse-Matrix Hf von f symmetrisch.
Mit der Hesse-Matrix kann man eine Funktion nun auf lokale Extrema untersuchen. Dies ist jedoch nicht immer ganz einfach und wir gehen auf den allgemeinen Fall nicht weiter ein. Im zweidimensionalen Fall gibt es aber ein einfaches
Kriterium, welches wir ohne Beweis zitieren. Vorweg jedoch noch eine


a b
Definition 4.3.33 (Determinante). FuĚr eine beliebige 2Ă2-Matrix A =
â
c d
C2Ă2 definieren wir die Determinante von A durch det A := a Âˇ d â b Âˇ c.
Bemerkung. Man kann die Determinante fuĚr quadratische Matrizen beliebiger
GroĚĂe definieren. Da fuĚr uns im Folgenden nur 2 Ă 2-Matrizen von Interesse sind,
beschraĚnken wir uns auf diesen Fall.

Kapiel 4: Analysis

M. Skutella

213

Satz 4.3.34. Es sei f : R2 â R eine zweimal stetig partiell differenzierbare
Funktion. Im Punkt x â R2 sei grad f (x) = 0. Dann gilt:
(i) Ist det Hf (x) > 0 und
Maximum.

â2f
(x)
âx1 2

< 0, so besitzt f im Punkt x ein lokales

(ii) Ist det Hf (x) > 0 und
Minimum.

â2f
(x)
âx1 2

> 0, so besitzt f im Punkt x ein lokales

(iii) Ist det Hf (x) < 0, so besitzt f im Punkt x kein lokales Extremum.
(iv) Ist det Hf (x) = 0, so macht der Satz keine Aussage.

4.4

Integralrechnung

Wir motivieren den folgenden Abschnitt klassisch durch den Wunsch, den FlaĚcheninhalt A der FlaĚche F zu berechnen, die zwischen dem Graphen einer gegebenen
Funktion f : [a, b] â R und der x-Achse eingeschlossenen wird. Wir betrachten
als Beispiel
â den Halbkreis vom Radius r > 0, gegeben durch f : [âr, r] â R mit
f (x) := r2 â x2 .
y

y

r

âr

r

r

x

âr

Abbildung 4.6: Approximation der FlaĚche F fuĚr f (x) =

r

â

x

r 2 â x2 .

Ein approximativer Ansatz ist nun, wie in Abbildung 4.6, das Intervall [âr, r]
zu unterteilen und die FlaĚche durch RechtecksflaĚchen anzunaĚhern (von oben oder
von unten). Es ist intuitiv klar, dass die Approximation durch die Wahl einer
feineren Unterteilung von [âr, r] verbessert werden kann.
Wir formalisieren diese Idee nun und weisen fuĚr stetige Funktionen nach, dass
der oben heuristisch beschriebene Prozess zum Erfolg fuĚhrt. Danach stellen wir
mit dem Hauptsatz der Differential- und Integralrechnung den Zusammenhang
zu den vorigen Abschnitten her.

214

4.4.1

Mathematik fuĚr Informatiker

M. Skutella

Das Integral einer Treppenfunktion

Die folgenden Definitionen sind elementargeometrisch motiviert und haben ihren Ursprung in den oben genannten RechtecksflaĚchen unter dem Graphen einer
Funktion.
Definition 4.4.1. Ist n â Nâ , so nennt man eine endliche Folge x0 , x1 , ..., xn mit
a = x0 < x1 < Âˇ Âˇ Âˇ < xnâ1 < xn = b eine Zerlegung des Intervalls [a, b] â R.
Eine Abbildung Ď : [a, b] â R heiĂt Treppenfunktion, falls es eine Zerlegung x0 , ..., xn des Intervalls [a, b] so gibt, dass Ď auf allen offenen Teilintervallen
(xi , xi+1 ), i = 0, ..., n â 1, konstant ist, das heiĂt
âi = 0, ..., n â 1 âci â R ây â (xi , xi+1 ) : Ď(y) = ci .
Die Menge aller Treppenfunktionen auf [a, b] bezeichnen wir mit T[a,b] .
Bemerkung. Eine Treppenfunktion Ď ist auch an den Zerlegungspunkten xi
definiert. Wir beachten die Funktionswerte dort aber nicht weiter, weil sie bei
der noch folgenden Definition des Integrals keine Rolle spielen.
ďŁą
1
ďŁ´
ďŁ˛1 fuĚr x â [0, 2 ]
Beispiel. Die Funktion Ď : [0, 1] â R mit Ď(x) := 2 fuĚr x â ( 12 , 43 ] ist eine
ďŁ´
ďŁł
1 fuĚr x â ( 34 , 1]
Treppenfunktion auf [0, 1].
Lemma 4.4.2. Die Menge T[a,b] bildet einen R-Vektorraum.
Beweis. Die Menge T[a,b] ist nicht leer, da offenbar jede auf [a, b] konstante Funktion eine Treppenfunktion auf [a, b] ist. Seien nun Îť â R und Ď, Ď â T[a,b] beliebig.
Da Ď und Ď Treppenfunktionen sind, gibt es per Definition Zerlegungen x0 , ..., xn
und y0 , ..., ym von [a, b], so dass Ď auf den offenen Teilintervallen (xi , xi+1 ) und Ď
auf den offenen Teilintervallen (yj , yj+1 ) konstant ist, fuĚr alle i = 0, ..., n â 1 und
j = 0, ..., m â 1.
Die Funktion ÎťĎ ist auf den offenen Teilintervallen (xi , xi+1 ) natuĚrlich ebenfalls konstant, so dass ÎťĎ â T[a,b] . FuĚr die Funktion Ď + Ď sortiert man die
Vereinigung der Zerlegungspunkte x0 , ..., xn , y0 , ..., ym der GroĚĂe nach und erhaĚlt
somit eine neue Zerlegung z0 , ..., zk (k â¤ m + n) von [a, b], auf deren Teilintervallen beide Funktionen Ď und Ď konstant sind. Folglich ist auch Ď + Ď â T[a,b] .

Definition 4.4.3 (Integral einer Treppenfunktion). Es sei Ď â T[a,b] bzgl. der
Zerlegung x0 , ..., xn und Îži â (xi , xi+1 ), fuĚr alle i = 0, ..., n â 1. Dann definieren
Rb
wir das Integral Ď(x) dx von Ď uĚber [a, b] durch die reelle Zahl
a

Zb
Ď(x) dx :=
a

nâ1
X
k=0

Ď(Îžk )(xk+1 â xk ) .

Kapiel 4: Analysis

M. Skutella

215

Bemerkung. Die Terme |Ď(Îži )|(xi+1 â xi ) entsprechen der FlaĚche des Rechtecks
mit Grundseite [xi , xi+1 ] und HoĚhe |Ď(Îži )|, fuĚr alle i = 0, ..., n â 1. Dies macht
deutlich, wieso dies eine Formalisierung der zu Anfang beschriebenen
Idee ist.
Rb
Wir schreiben im Folgenden der Einfachheit halber manchmal a Ď anstelle von
Rb
Ď(x) dx.
a

Lemma 4.4.4. Das Integral fuĚr Treppenfunktionen ist wohldefiniert, d.h. es
haĚngt nicht von der gewaĚhlten Zerlegung ab.
Beweisskizze. Zum Beweis startet man mit zwei beliebigen Zerlegungen x0 , ..., xn
und y0 , ..., ym von [a, b] und Punkten Îži â (xi , xi+1 ), Îśj â (yj , yj+1 ), i = 0, ..., n, j =
0, ..., m. Wegen x0 = a = y0 gilt Ď(Îž0 ) = Ď(Îś0 ). Ist nun y1 = x1 , so koĚnnen wir die
Argumentation mit x1 und y1 fortsetzen. Andernfalls gilt x1 > y1 oder x1 < y1 .
Ohne EinschraĚnkung sei x1 > y1 . Dann ist (x0 , x1 ) âŠ (y1 , y2 ) 6= â und es folgt
Ď(Îś0 ) = Ď(Îž0 ) = Ď(Îś1 ). Damit gilt Ď(Îś0 )(y1 â y0 ) + Ď(Îś1 )(y2 â y1 ) = Ď(Îś0 )(y2 â y0 ).
Man kann also den Zerlegungspunkt y1 aus der Zerlegung entfernen und yi0 := yi+1
setzen (i > 0). Gilt nun y10 = y2 = x1 oder y10 < x1 , so koĚnnen wir wie oben argumentieren. Ist x1 < y10 , so erhalten wir analog Ď(Îž0 ) = Ď(Îž1 ) und wir koĚnnen
den Zerlegungspunkt x1 aus der Zerlegung entfernen. Da es nur endlich viele
Zerlegungspunkte gibt und xn = b = ym gilt, erhaĚlt man so die Behauptung. 
Das Integral fuĚr Treppenfunktionen hat die folgenden Eigenschaften.
Lemma 4.4.5.

Rb

: T[a,b] â R ist ein monotones R-lineares Funktional auf dem

a

R-Vektorraum T[a,b] , d.h. fuĚr Ď, Ď â T[a,b] und Îť â R gilt:
(i)

Rb

Rb

(Ď + Ď) =

a

(ii)

Rb
a

a

(ÎťĎ) = Îť

Rb

Ď+

Rb

Ď

a

Ď

a

(iii) Ist Ď(x) â¤ Ď(x) fuĚr alle x â [a, b], so gilt

Rb
a

Ďâ¤

Rb

Ď .

a

Beweis. Die Aussage ii) folgt sofort aus der Definition des Integrals. FuĚr i) und iii)
genuĚgt es, die Abbildungen Ď und Ď auf einer Zerlegung von [a, b] zu betrachten,
bezuĚglich welcher beide Funktionen Treppenfunktionen sind.

Wir haben bisher nur erreicht, dass wir den Inhalt der RechtecksflaĚchen unter
einem Graphen berechnen koĚnnen. Deshalb werden wir nun unser Integral durch
den Approximations-Gedanken auf eine groĚĂere Klasse von Funktionen ausdehnen.

216

Mathematik fuĚr Informatiker

M. Skutella

Definition 4.4.6. Es sei f : [a, b] â R eine beschraĚnkte Funktion. Dann ist das
Oberintegral von f uĚber [a, b] definiert durch
ďŁą b
ďŁź
ďŁ˛Z
ďŁ˝
Intba (f ) := inf
Ď(x) dx Ď â T[a,b] , Ď âĽ f
.
ďŁł
ďŁž
a

Das Unterintegral von f uĚber [a, b] definiert durch
ďŁą b
ďŁź
ďŁ˛Z
ďŁ˝
intba (f ) := sup
Ď(x) dx Ď â T[a,b] , Ď â¤ f
.
ďŁł
ďŁž
a

Man koĚnnte etwas informell sagen, dass der Graph einer Funktion durch das
Ober- und Unterintegral gewissermaĂen eingeschachteltâ wird. Es stellt sich nun
â
die Frage, ob dieses Konzept uĚberhaupt sinnvoll ist. Das folgende Lemma gibt
darauf die Antwort.
Lemma 4.4.7. FuĚr eine beschraĚnkte Funktion f : [a, b] â R existieren stets
Ober- und Unterintegral.
Beweis. Da f beschraĚnkt ist, existieren m, M â R mit m â¤ f (x) â¤ M fuĚr alle x â
[a, b]. Die konstanten Funktionen const(m) und const(M ) sind Treppenfunktionen
auf [a, b] und es gilt const(m) â¤ f â¤ const(M ).
Rb
Rb
Wegen const(m) = m(b â a) und const(M ) = M (b â a) sind die Mengen
a

ďŁą b
ďŁ˛Z
ďŁł

a

a

Ď Ď â T[a,b] , Ď âĽ f

ďŁź
ďŁ˝

und

ďŁž

ďŁą b
ďŁ˛Z
ďŁł

Ď Ď â T[a,b] , Ď â¤ f

ďŁź
ďŁ˝
ďŁž

a

gemaĚĂ Lemma 4.4.5 nach unten bzw. oben beschraĚnkt.



Nachdem wir uns nun von der Existenz der Ober- und Unterintegrale fuĚr
beschraĚnkte Funktionen uĚberzeugt haben, wollen wir spezifizieren, wann diese
auch das gewuĚnschte Ergebnis liefern.
Definition 4.4.8 (Riemann-integrierbare Funktion). Eine beschraĚnkte Funktion
f : [a, b] â R heiĂt Riemann-integrierbar uĚber [a, b], falls intba (f ) = Intba (f ) gilt.
Rb
FuĚr eine Riemann-integrierbare Funktion f : [a, b] â R heiĂt f (x) dx := intba (f )
a

das Riemann-Integral von f uĚber [a, b].
Stimmen Ober- und Unterintegral nicht uĚberein, so hilft das oben beschriebene Konzept bei der gewuĚnschten Berechnung nicht. Wir sagen dann, dass die
besagte Funktion nicht Riemann-integrierbar ist. Der Nachweis der RiemannIntegrierbarkeit einer gegebenen Funktion f ist nicht immer ganz einfach. Das
folgende Lemma ist dabei oft sehr hilfreich.

Kapiel 4: Analysis

M. Skutella

217

Lemma 4.4.9. Es sei f : [a, b] â R eine beschraĚnkte Funktion. Dann sind die
folgenden Aussagen aĚquivalent:
(i) f ist Riemann-integrierbar.
(ii) Zu beliebigem Îľ > 0 gibt es Treppenfunktionen Ď, Ď â T[a,b] mit Ď â¤ f â¤ Ď
Rb
Rb
und a Ď â a Ď < Îľ.
Beweis. (i)â(ii)â: Sei f Riemann-integrierbar und Îľ > 0 beliebig. Nach DefiniRâb
tion gilt f = intba (f ) = Intba (f ) und zu 2Îľ gibt es Treppenfunktionen Ď, Ď â T[a,b]
a

mit Ď â¤ f â¤ Ď und

Rb

Ďâ

Rb
a

a

f < 2Îľ ,

Rb
a

fâ

Rb
a

Ď < 2Îľ . Es folgt

Rb
a

Ďâ

Rb

Ď < Îľ.

a

(ii)â(i)â: Es sei Îľ > 0 beliebig. Dann gibt es nach (ii) Treppenfunktionen
â
Rb
Rb
Ď, Ď â T[a,b] mit Ď â¤ f â¤ Ď und Ď â Ď < Îľ. Per Definition des Ober- und
a

a

Unterintegrals gilt
Zb
a

Ď â¤ intba (f ) â¤ Intba (f ) â¤

Zb
Ď
a

und es folgt sofort Intba (f ) â intba (f ) < Îľ. Da Îľ > 0 beliebig gewaĚhlt war, folgt die
Behauptung.

Wir werden im naĚchsten Abschnitt zeigen, dass jede stetige Funktion Riemannintegrierbar ist.

4.4.2

Riemann-integrierbare Funktionen

Mit Hilfe der folgenden Definition werden wir die Klasse der Riemann-integrierbaren
Funktionen naĚher klassifizieren.
Definition 4.4.10. Eine Funktion f : [a, b] â R heiĂt gleichmaĚĂig durch Treppenfunktionen approximierbar, wenn es zu beliebigem Îľ > 0 zwei Treppenfunktionen Ď, Ď â T[a,b] gibt, mit Ď â¤ f â¤ Ď und Ď(x) â Ď(x) < Îľ, fuĚr alle x â [a, b].
Bemerkung. Wir haĚtten auch etwas allgemeiner den Begriff gleichmaĚĂige Konâ
vergenzâ definieren koĚnnen. Dabei wird verlangt, dass ab einem geeignetem Index n0 alle Folgenglieder fn einer Funktionenfolge (fn )nâN im Îľ-Schlauch um
ihre Grenzfunktion f liegen. Es gilt dann also fuĚr alle x â [a, b] und n âĽ n0 :
|f (x) â fn (x)| < Îľ. Die gleichmaĚĂige Konvergenz ist ein sehr viel staĚrkerer Begriff
als die punktweise Konvergenz einer Funktionenfolge. Wir werden diese Allgemeinheit im Folgenden jedoch nicht benoĚtigen und beschraĚnken uns daher auf
die obige Definition.

218

Mathematik fuĚr Informatiker

M. Skutella

Lemma 4.4.11. Jede gleichmaĚĂig durch Treppenfunktionen approximierbare Funktion f : [a, b] â R ist Riemann-integrierbar auf [a, b].
Îľ
Beweis. Es sei Îľ > 0 beliebig. Dann gibt es zu Îľ0 := bâa
zwei Treppenfunktionen
0
Ď, Ď â T[a,b] mit Ď â¤ f â¤ Ď und Ď(x) â Ď(x) < Îľ fuĚr alle x â [a, b]. Es gilt

Zb

Zb
Ďâ

a

Zb
(Ď â Ď) â¤

Ď =
a

Zb

a

Îľ0 = Îľ0 (b â a) = Îľ .

a

Lemma 4.4.9 liefert somit die Behauptung.



Wir geben das folgende Lemma ohne Beweis.
Lemma 4.4.12. Es sei f : [a, b] â R eine stetige Funktion auf [a, b]. Dann ist f
sogar gleichmaĚĂig stetig auf [a, b].
Damit koĚnnen wir nun beweisen, dass stetige Funktionen Riemann-integrierbar
sind.
Satz 4.4.13 (Riemann-Integrierbarkeit stetiger Funktionen). Es
f : [a, b] â R eine stetige Funktion. Dann ist f Riemann-integrierbar.

sei

Beweis. Wir wollen die Behauptung mit Hilfe von Lemma 4.4.11 nachweisen.
Dazu sei Îľ > 0 beliebig. Die Funktion f ist nach Lemma 4.4.12 gleichmaĚĂig
stetig. Es gibt daher ein Î´ > 0, so dass fuĚr alle x, y â [a, b] mit |x â y| < Î´ gilt
Îľ
|f (x) â f (y)| <
=: Îľ0 .
(4.9)
2
Wir waĚhlen nun ein n â N mit Î´ > bâa
=: Âľ, eine aĚquidistante Zerlegung
n
a = x0 < x1 < ... < xn = b von [a, b], mit xk := a + kÂľ, fuĚr alle k = 0, ..., n und
definieren zwei Treppenfunktionen Ď, Ď â T[a,b] durch
(
f (xk ) + Îľ0 fuĚr x â (xkâ1 , xk ] und k = 1, ..., n,
Ď(x) :=
f (a)
x = a,
und
(
f (xk ) â Îľ0
Ď(x) :=
f (a)

fuĚr x â (xkâ1 , xk ] und k = 1, ..., n,
x = a.

Es gilt somit Ď(x)âĎ(x) â¤ Îľ, fuĚr alle x â [a, b]. Wir muĚssen noch zeigen, dass auf
[a, b] die Ungleichungen Ď â¤ f â¤ Ď erfuĚllt sind. FuĚr x = a ist nichts zu zeigen.
Es sei also x â (a, b] beliebig. Dann gibt es ein j â {0, ..., n} mit x â (xjâ1 , xj ]
und es gilt |x â xj | < |xj â xjâ1 | = Âľ < Î´. Nach (4.9) gilt also |f (x) â f (xk )| < Îľ0
und daher
Ď(x) = f (xk ) â Îľ0 < f (x) < f (xk ) + Îľ0 = Ď(x) .
Damit ist der Beweis abgeschlossen.



Kapiel 4: Analysis

M. Skutella

219

Bemerkung. Man kann die Riemann-Integrierbarkeit auch fuĚr andere Klassen
von Funktionen, wie etwa die stuĚckweise stetigen oder monotonen Funktionen
zeigen.
Wir formulieren nun noch einige wichtige Eigenschaften des Riemann-Integrals.
Lemma 4.4.14. Es seien f, g : [a, b] â R Riemann-integrierbare Funktionen
und Îť â R. Dann gilt
(i) Die Funktionen Îťf , f + g sind Riemann-integrierbar und es gilt
Zb

Zb
Îťf = Îť

a

Zb
f

und

a

Zb
(f + g) =

a

(ii) Gilt f (x) â¤ g(x), fuĚr alle x â [a, b], so ist

Zb
f+

a

Rb
a

fâ¤

Rb

g .
a

g.

a

Beweisskizze. Zu (i): Nach Definition gilt intba (f + g) â¤ Intba (f + g). Die Rechenregeln fuĚr Suprema und Infima liefern
Vor.

Intba (f + g) â¤ Intba (f ) + Intba (g) = intba (f ) + intba (g) â¤ intba (f + g) .
Vor.

FuĚr Îť âĽ 0 gilt Intba (Îťf ) = ÎťIntba (f ) = Îťintba (f ) = intba (Îťf ). FuĚr Îť â¤ 0 gilt
Vor.
schlieĂlich intba (Îťf ) = ÎťIntba (f ) = Îťintba (f ) = Intba (Îťf ).
Zu (ii): Die Behauptung folgt unmittelbar aus der Definition des Ober- und
Unterintegrals und Lemma 4.4.5.

Satz 4.4.15. Es seien f, g : [a, b] â R zwei Riemann-integrierbare Funktionen.
Dann ist auch die Funktion f Âˇ g Riemann-integrierbar.
Beweis. Wir beweisen zunaĚchst mit Hilfe von Lemma 4.4.9, dass die Funktion f 2
Riemann-integrierbar ist. Da f als Riemann-integrierbare Funktion beschraĚnkt
ist, koĚnnen wir ohne EinschraĚnkung annehmen, dass 0 â¤ f â¤ 1 gilt. Andernfalls
betrachten wir die nach vorigem Lemma ebenfalls integrierbare Funktion Îťf + c
mit geeigneten Îť, c â R.
Es sei nun Îľ > 0 beliebig. Nach Lemma 4.4.9 gibt es Treppenfunktionen
Ď, Ď â T[a,b] mit
Zb
0 â¤ Ď â¤ f â¤ Ď â¤ 1

(Ď â Ď)(x) dx <

und
a

Îľ
.
2

220

Mathematik fuĚr Informatiker

M. Skutella

Es gilt 0 â¤ Ď 2 â¤ f 2 â¤ Ď2 â¤ 1 und Ď2 , Ď 2 â T[a,b] . Punktweise gilt zudem
0 â¤ Ď + Ď â¤ 2, so dass Ď2 â Ď 2 = (Ď + Ď)(Ď â Ď) â¤ 2(Ď â Ď). Damit erhalten wir
schlieĂlich
Zb
Zb
2
2
(Ď â Ď ) â¤ 2 (Ď â Ď) < Îľ .
a

a

2

Also ist f nach Lemma 4.4.9 integrierbar.
FuĚr eine beliebige Riemann-integrierbare Funktion g folgt die Behauptung
deshalb aus der Gleichung f Âˇ g = 14 ((f + g)2 â (f â g)2 ).

Satz 4.4.16 (Mittelwertsatz der Integralrechnung). Es seien f, g : [a, b] â R
zwei stetige Funktionen mit g âĽ 0. Dann gibt es ein Îž â [a, b] mit
Zb

Zb
(f Âˇ g)(x) dx = f (Îž)

a

g(x) dx .
a

Beweis. Nach Satz 4.4.15 ist die Funktion f Âˇ g Riemann-integrierbar. Als stetige
Funktion besitzt f im Intervall [a, b] ein globales Maximum und ein globales
Minimum. Setze m := min{f (x) | x â [a, b]} und M := max{f (x) | x â [a, b]}.
Dann gilt mg â¤ f g â¤ M g und folglich
Zb
m

Zb
(m Âˇ g) â¤

g =
a

Zb

a

Zb
(f Âˇ g) â¤

a

Zb
(M Âˇ g) = M

a

g .
a

Rb
Rb
Es gibt deshalb ein Îś â [m, M ] mit (f Âˇ g) = Îś g. Da f stetig ist folgt nun mit
a

a

dem Zwischenwertsatz, dass es ein Îž â [a, b] gibt mit f (Îž) = Îś.



Korollar 4.4.17. Es sei f : [a, b] â R eine stetige Funktion. Dann gibt es ein
Îž â [a, b] mit
Zb
f (x) dx = f (Îž)(b â a) .
a

Beweis. Setze im Mittelwertsatz der Integralrechnung g âĄ 1.



Die Approximation einer Funktion f durch Treppenfunktionen liefert uns die
Existenz des Riemann-Integrals von f . Eine tatsaĚchliche Berechnung mittels geeigneter Treppenfunktionen ist zwar oft moĚglich, aber sehr muĚhsam. Wir benoĚtigen also noch etwas Werkzeug. Der obige Mittelwertsatz ist nun unser Hilfsmittel,
um den Zusammenhang zur Differentialrechnung herzustellen. Dies wird uns auch
eine vergleichsweise unkomplizierte MoĚglichkeit liefern, Integrale tatsaĚchlich zu
berechnen.

Kapiel 4: Analysis

4.4.3

M. Skutella

221

Integration und Differentiation

Wir bemerken zunaĚchst, dass man das Integral einer auf [a, b] Riemann-integrierbaren
Funktion f an einer beliebigen Stelle t â (a, b) aufteilen kann.
Lemma 4.4.18. Es sei f auf [a, b] Riemann-integrierbar und t â (a, b). Dann
ist f auch auf den Intervallen [a, t] und [t, b] Riemann-integrierbar und es gilt
Zb

Zt
f =

a

Zb
f+

a

f .
t

Beweisskizze. Man muss lediglich bemerken, dass die EinschraĚnkung einer Treppenfunktion auf ein Teilintervall von [a, b] wieder eine Treppenfunktion ist. Die
Integrierbarkeit von f folgt dann wieder mit Lemma 4.4.9 und die Formel fuĚr das
Integral folgt direkt aus der Definition des Ober- und Unterintegrals.

Wir haben bisher immer Integrationsgrenzen a, b â R mit a < b betrachtet,
moĚchten aber auch andere FaĚlle zulassen.
Definition 4.4.19. Es sei f eine auf [a, b] Riemann-integrierbare Funktion. Wir
Ra
Rt
Rs
setzen f (x) dx := 0 und f (x) dx := â f (x) dx, fuĚr s, t â [a, b] mit t â¤ s.
a

s

t

Mit diesen Konventionen koĚnnen wir mit Hilfe des Integrals einer Funktion f
eine neue Abbildung definieren.
Definition 4.4.20 (Integralfunktion). FuĚr eine Riemann-integrierbare FunktiRx
on f auf [a, b] kann durch If : [a, b] â R, x 7â f (t) dt eine weitere Funktion
a

If auf [a, b] definiert werden. Die Funktion If heiĂt die zu f gehoĚrende Integralfunktion.
Wir beschaĚftigen uns im Folgenden nur mit stetigen Funktionen. FuĚr diese ist
die Integralfunktion angenehm zu handhaben.
Satz 4.4.21 (Hauptsatz der Differential- und Integralrechnung). Es sei f eine
auf [a, b] stetige Funktion. Dann ist die zu f gehoĚrende Integralfunktion If stetig
differenzierbar auf [a, b] und es gilt If0 (x) = f (x).
Beweis. Wir betracheten den Differenzenquotienten fuĚr If . Sei dazu x â [a, b]
beliebig und h 6= 0. Es ist
If (x + h) â If (x)
1
=
h
h

x+h
Z
f (t) dt .
x

222

Mathematik fuĚr Informatiker

M. Skutella

Nach dem Mittelwertsatz der Integralrechnung gibt es nun ein Îžh â [x, x + h]
(bzw. [x + h, x] fuĚr h < 0) mit
x+h
Z
f (t) dt = f (Îžh )(x + h â x) = h Âˇ f (Îžh ) .
x

Wir erhalten damit

If (x + h) â If (x)
= f (Îžh ) .
h
FuĚr h â 0 konvergiert Îžh gegen x und mit der Stetigkeit von f erhalten wir somit
If (x + h) â If (x)
= f (x) .
hâ0
h
lim

Damit ist der Beweis abgeschlossen.



Definition 4.4.22 (Stammfunktion). Es seien f, F : [a, b] â R zwei Funktionen.
Ist F differenzierbar mit F 0 = f , so nennt man F eine Stammfunktion von f .
Wegen Satz 4.4.21 ist die Integralfunktion einer stetigen Funktion eine Stammfunktion.
Korollar 4.4.23. Ist f : [a, b] â R eine stetige Funktion, so ist die zu f gehoĚrende Integralfunktion If eine Stammfunktion von f .
Wir zeigen als naĚchstes, dass sich eine beliebige Stammfunktion von f nur um
eine Konstante von If unterscheiden kann.
Lemma 4.4.24. Es sei F : [a, b] â R eine Stammfunktion von f : [a, b] â R.
(i) Ist G : [a, b] â R eine weitere Stammfunktion von f , so gibt es ein Îť â R
mit F (x) = G(x) + Îť fuĚr alle x â [a, b].
(ii) Umgekehrt ist fuĚr ein beliebiges Âľ â R die durch H(x) := F (x)+Âľ definierte
Funktion H : [a, b] â R eine Stammfunktion von f .
Die Stammfunktion von f ist also bis auf eine Konstante eindeutig bestimmt.
Beweis. Da F 0 = G0 = f , ist (F â G)0 die Nullfunktion. Folglich ist F â G
konstant. Wegen der Ableitungsregeln gilt H 0 = F 0 = f .

Korollar 4.4.25. Ist f : [a, b] â R stetig und F : [a, b] â R eine Stammfunktion
von f , so gilt
Z b
f (x) dx = F (b) â F (a) .
a

Kapiel 4: Analysis

M. Skutella

223

Beweis. Wegen Korollar 4.4.23 und Lemma 4.4.24 gibt es ein Îť â R mit F (x) =
If (x) + Îť. Daher gilt
b

Z

f (x) dx = If (b) = If (b) â If (a) = F (b) â F (a) .
a

Damit ist der Beweis abgeschlossen.



Wir geben nur einige Beispiele fuĚr Stammfunktionen wichtiger Funktionen.
Beispiele.
(i) Die Exponentialfunktion exp ist eine Stammfunktion von sich selbst.
(ii) Die Logarithmus-Funktion ln ist eine Stammfunktion von x 7â 1/x.
(iii) Die Cosinus-Funktion ist eine Stammfunktion der Sinus-Funktion.

4.4.4

Integrationsregeln

Wir geben einige bekannte Regeln an, die sich bei der Integration von Funktionen
als nuĚtzlich erweisen.
Satz 4.4.26 (Substitutionsregel). Es sei g : [a, b] â R stetig differenzierbar
und f : g([a, b]) â R stetig mit Stammfunktion F . Dann ist F âŚ g eine Stammfunktion von (f âŚ g) Âˇ g 0 und es gilt
Z

b
0

Z

g(b)

(f âŚ g)(x) Âˇ g (x) dx =
a

f (y) dy .
g(a)

Beweis. Nach der Kettenregel in Satz 4.3.8 (iv) gilt

(F âŚ g)0 (x) = F 0 g(x) Âˇ g 0 (x) = (f âŚ g)(x) Âˇ g 0 (x) .
Damit erhaĚlt man mit Hilfe von Korollar 4.4.25
Z b
(f âŚ g)(x) Âˇ g 0 (x) dx = (F âŚ g)(b) â (F âŚ g)(a)
a


= F g(b) â F g(a)
Z g(b)
=
f (y) dy .
g(a)

Damit ist der Beweis abgeschlossen.



224

Mathematik fuĚr Informatiker

M. Skutella

Korollar 4.4.27. Es sei g : [a, b] â R stetig differenzierbar und streng monoton
mit g(a) = Îą und g(b) = Î˛. Weiter sei f : g([a, b]) â R stetig mit Stammfunktion F . Dann ist
Z

Î˛

g â1 (Î˛)

Z

(f âŚ g)(x) Âˇ g 0 (x) dx .

f (y) dy =
g â1 (Îą)

Îą

Beispiele.
(i) Wir wollen das Integral
Z

2/Ď

â
1/Ď

sin(1/x)
dx
x2

berechnen. Wir koĚnnen sofort die Substitutionsregel anwenden: Die Funktion g : [1/Ď, 2/Ď] â R mit g(x) = 1/x ist stetig differenzierbar mit Ableitung
g 0 (x) = â1/x2 und die Funktion f (x) = sin x ist auf g([1/Ď, 2/Ď]) = [ Ď2 , Ď]
stetig mit Stammfunktion F (x) = â cos x. Nach Substitutionsregel gilt also
Z

2/Ď

1/Ď

sin(1/x)
dx =
â
x2

Z

2/Ď

(f âŚ g)(x) Âˇ g 0 (x) dx

1/Ď

Z

g(2/Ď)

=

f (y) dy
g(1/Ď)

Z

Ď/2

=

sin y dy
Ď

Z

Ď

= â

sin y dy
Ď/2

= â (â cos(Ď) + cos(Ď/2)) = â 1 .
Wie das naĚchste Beispiel zeigt, ist man leider nicht immer in der komfortablen Situation, dass der Integrand von der Form (f âŚ g) Âˇ g 0 ist.
(ii) Wir zeigen nun
Z

â1

â

â3/2

2x + 3 dx =

1
.
3

Die Funktion g(x) := 2x + 3 ist auf [â 32 ,â
â1] stetig differenzierbar mit
0
Ableitung g (x) = 2. Die Funktion f (x) := x ist auf g([â 32 , â1]) = [0, 1]
3
stetig mit Stammfunktion F (x) = 23 x 2 . Es gilt
â

2x + 3 = (f âŚ g)(x) =

1
1
(f âŚ g)(x) Âˇ 2 = (f âŚ g)(x) Âˇ g 0 (x) .
2
2

Kapiel 4: Analysis

M. Skutella

225

â
Die Funktion fË(x) := 12 x ist auf [0, 1] ebenfalls stetig mit Stammfunktion
â
3
FĚ (x) = 13 x 2 und es gilt 2x + 3 = (fË âŚ g)(x) Âˇ g 0 (x). Die Substitutionsregel
liefert also
Z â1
Z â1
â
2x + 3 dx =
(fË âŚ g)(x) Âˇ g 0 (x) dx
â3/2

â3/2

Z

g(â1)

fË(y) dy

=
g(â3/2)
1

Z
=

0

1â
y dy
2

= FĚ (1) â FĚ (0) =

1
.
3

(iii) Die obigen Beispiele verdeutlichen, wieso die Substitutionsregel nuĚtzlich ist.
Man kann stoĚrende Anteileâ des Integranden durch Substitution ersetzen.
â
Man benutzt bei Berechnungen oft auch eine etwas heuristisch anmutende
Schreibweise, welche wir an
Z 10/4
1
â
dx
4x â 1
2/4
kurz illustrieren. Man setzt y := g(x) := 4x â 1. Dann ist die Ableitung
â
von y nach xâ gegeben durch
dy
:= g 0 (x) = 4
dx

=â

1
dx = dy .
4

Die Funktion f (y) := â1y ist auf [g(2/4), g(10/4)] stetig mit Stammfunktion
â
F (y) = 2 y. Damit ersetzenâ wir
â
Z 10/4
Z 4Âˇ 10 â1
4
1
1 1
â
dx =
dy
â
y4
4x â 1
2/4
4Âˇ 24 â1
Z
1 9 1
=
â dy
2 1 2 y
1â
= [ y ]91
2
â
1 â
= ( 9 â 1) = 1 .
2
Satz 4.4.28 (Partielle Integration). Es sei g : [a, b] â R stetig differenzierbar
und f : g([a, b]) â R stetig mit Stammfunktion F . Dann ist F Âˇ g eine Stammfunktion von f Âˇ g + F Âˇ g 0 und es gilt
Z b
Z b
f (x) Âˇ g(x) dx = F (b) Âˇ g(b) â F (a) Âˇ g(a) â
F (x) Âˇ g 0 (x) dx .
a

a

226

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Nach der Produktregel in Satz 4.3.8 (ii) gilt (F Âˇ g)0 = f Âˇ g + F Âˇ g 0 .
Folglich ist nach Korollar 4.4.25
Z b
F (b) Âˇ g(b) â F (a) Âˇ g(a) =
(f Âˇ g + F Âˇ g 0 )(x) dx
a
Z b
Z b
=
(f Âˇ g)(x) dx +
(F Âˇ g 0 )(x) dx .
a

a

Damit ist der Beweis abgeschlossen.



Beispiele.
Rb
(i) Es seien a, b â R beliebig. Wir betrachten das Integral a x Âˇ cos x dx. Die
Funktion g : [a, b] â R, g(x) := x ist stetig differenzierbar mit Ableitung
g 0 (x) = 1 und die Funktion f : [a, b] â R, f (x) := cos x ist stetig auf [a, b]
mit Stammfunktion F (x) = sin x. Mittels partieller Integration erhalten wir
Z b
Z b
x Âˇ cos x dx =
g(x) Âˇ f (x) dx
a
a
Z b
= F (b)g(b) â F (a)g(a) â
F (x)g 0 (x) dx
a
Z b
= b Âˇ sin b â a Âˇ sin a â
sin x dx
a

= b Âˇ sin b â a Âˇ sin a + cos b â cos a .
Rb
(ii) Es seien a, b â R>0 beliebig. Wir betrachten das Integral a lnxx dx. Die
Funktion g : [a, b] â R, g(x) := ln x ist stetig differenzierbar mit Ableitung
g 0 (x) = x1 und die Funktion f : [a, b] â R, f (x) := x1 ist stetig auf [a, b] mit
Stammfunktion F (x) = ln x. Mittels partieller Integration erhalten wir
Z b
Z b
ln x
f (x) Âˇ g(x) dx
dx =
x
a
a
Z b
= F (b)g(b) â F (a)g(a) â
F (x)g 0 (x) dx
a
Z b
1
= ln b ln b â ln a ln a â
ln x Âˇ dx .
x
a
Damit erhaĚlt man
Z

b

ln x
dx = (ln b)2 â (ln a)2
x

b

ln x
1
dx = ((ln b)2 â (ln a)2 ) .
x
2

2
a

und folglich
Z
a

Kapiel 4: Analysis

M. Skutella

227

Rb
(iii) Es seien a, b â R>0 beliebig. Wir betrachten das Integral a ln x dx. Folgender Trick ist oft hilfreich: ln x = 1 Âˇ ln x. Die Funktion g : [a, b] â R, g(x) :=
ln x ist stetig differenzierbar mit Ableitung g 0 (x) = x1 und die Funktion
f : [a, b] â R, f (x) := 1 ist stetig auf [a, b] mit Stammfunktion F (x) = x.
Mittels partieller Integration erhalten wir
Z b
Z b
ln x dx =
1 Âˇ ln x dx
a
a
Z b
=
f (x) Âˇ g(x) dx
a
Z b
F (x)g 0 (x) dx
= F (b)g(b) â F (a)g(a) â
a
Z b
1
= b ln b â a ln a â
x Âˇ dx
x
a
Z b
= b ln b â a ln a â
1 dx
a

= b ln b â a ln a â b + a
= (b ln b â b) â (a ln a â a) .
Wir haben insbesondere eine Stammfunktion G von g gefunden.

4.4.5

Uneigentliche Integrale

Definition 4.4.29 (Uneigentliche Integrale). Es seien a â R âŞ {ââ}, b â R âŞ
{â} und c â (a, b). Weiter sei f : (a, b) â R eine Funktion.
(i) Ist die EinschraĚnkung von f auf [c, d] fuĚr jedes d > c Riemann-integrierbar
und existiert der Grenzwert
Z d
lim
f (x) dx ,
dâb

c

so bezeichnet man ihn mit
Z

b

f (x) dx .
c

(ii) Ist die EinschraĚnkung von f auf [d, c] fuĚr jedes d < c Riemann-integrierbar
und existiert der Grenzwert
Z c
lim
f (x) dx ,
dâa

d

so bezeichnet man ihn mit
Z

c

f (x) dx .
a

228

Mathematik fuĚr Informatiker

M. Skutella

(iii) Existieren die Grenzwerte
b

Z

c

Z
f (x) dx

und

f (x) dx ,

c

a

so setzt man
b

Z

b

Z
f (x) dx :=

a

c

Z
f (x) dx +

c

f (x) dx .
a

Beispiele.
(i) Es seien Ra = ââ, c = 0, b = +â und f (x) = eâx . Dann existiert das
t
Integral 0 f (x) dx fuĚr alle t â RâĽ0 wegen der Stetigkeit von f und es gilt
t

Z

tâ+â

eâx dx = â eât + 1 ââ 1 .

0

Somit ist

+â

Z

âx

e

t

Z
=

0

eâx dx = 1 .

lim

tâ+â

0
2

(ii) Es seien Ra = ââ, c = 0, b = +â und f (x) = eâx . Dann existiert das
t
Integral 0 f (x) dx fuĚr alle t â RâĽ0 wegen der Stetigkeit von f .
2
2
Es gilt 0 â¤ eâx â¤ 1, fuĚr 0 â¤ x â¤ 1 und 0 â¤ eâx â¤ eâx , fuĚr 1 â¤ x â¤ t.
Wegen der Monotonie des Integrals folgt fuĚr t0 < t die Ungleichung
t

Z

âx2

e

t0

Z
dx =

0

âx2

e

t0
t0

>

âx2

e

t

Z
dx +

0 dx
t0

0
t0

Z

2

eâx dx

dx +

0

Z

t

Z

2

eâx dx .

=
0

Die Abbildung Ď : (0, +â) â R, Ď(t) :=
steigend. Zudem erhalten wir durch
Z

t

âx2

e
0

1

Z

Rt
0

2

eâx dx ist also streng monoton

Z

âx2

t

2

dx +
eâx dx
Z0 1
Z t 1
1 dx +
eâx dx
â¤

dx =

e

0

1

= 1 â eât + 1 â¤ 2 ,

Kapiel 4: Analysis

M. Skutella

229

dass Ď nach oben beschraĚnkt ist. Der Grenzwert lim

Rt

tâ+â 0

2

eâx dx existiert al-

so. Wegen
der Symmetrie von f folgt voĚllig analog, dass auch der Grenzwert
R 0 âx
2
dx existiert und es gilt
lim t e
tâââ

Z

+â

Z

âx2

e

0

dx =

Z

âx2

e

ââ

dx +

ââ

+â

2

eâx dx .

0

(iii) Es seien Ra = ââ, c = 0, b = +â und f (x) = sin x. Dann existiert das
t
Integral 0 f (x) dx fuĚr alle t â RâĽ0 wegen der Stetigkeit von f und es gilt
Rt
sin x dx = 1 â cos t. Der Grenzwert
0
Z

t

sin x dx =

lim

tâ+â

0

lim (1 â cos t)

tâ+â

existiert also nicht.
Bemerkung. Das letzte Beispiel von oben zeigt, dass fuĚr eine Funktion f :
(ââ, â) â R die Existenz des Grenzwertes
Z t
f (x) dx
lim
tââ

ât

nicht hinreichend fuĚr die Existenz des uneigentlichen Integrals
Z â
f (x) dx
ââ

ist. FuĚr t âĽ 0 gilt naĚmlich
Z t
sin x dx = â cos t + cos(ât) = â cos t + cos t = 0 ,
ât

so dass
Z

t

lim

tââ

4.5

sin x dx = 0 .
ât

Differentialgleichungen

Bei der Beschreibung vieler PhaĚnomene in Technik und Natur spielen Differentialgleichungen eine zentrale Rolle. Darunter fallen beispielsweise Wachstumsprozesse
von Populationen, die Entladung eines Kondensators oder Schwingungsprozesse
von Pendeln, Federn oder in elektrischen Schaltkreisen. Wir diskutieren zunaĚchst
einige Beispiele.

230

Mathematik fuĚr Informatiker

M. Skutella

Beispiele.
(i) Wir betrachten eine Population (Seerosen, Kaninchen, Bakterien etc.), die
zum Anfangszeitpunkt 0 die GroĚĂe y0 besitzt. Das Wachstum der Population haĚngt immer von der aktuellen GroĚĂe der Population ab. Bezeichnet
man die GroĚĂe der Population zum Zeitpunkt t mit y(t), so wird dadurch
eine Funktion y : [0, â) â R definiert. Das Wachstum der Population
zum Zeitpunkt t wird durch die Ableitung y 0 (t) beschrieben. Unter gewissen UmstaĚnden ist das Wachstum proportional zur PopulationsgroĚĂe, das
heiĂt
y 0 (t) = Îą Âˇ y(t)

(4.10)

fuĚr ein Îą > 0.
Die Gleichung (4.10) heiĂt Differentialgleichung. Zusammen mit der Anfangsbedingung y(0) = y0 spricht man von einem Anfangswertproblem.
(ii) Wir betrachten den AbkuĚhlungsprozess einer heiĂen Tasse Kaffee, die zum
Zeitpunkt t = 0 die Anfangstemperatur y0 hat. Die Temperatur des Kaffees
zum Zeitpunkt t bezeichnen wir mit y(t). Die Ableitung y 0 (t) der dadurch
definierten Funktion y : [0, â) â R gibt die AĚnderung der Temperatur des
Kaffees zum Zeitpunkt t an. Diese AĚnderung ist proportional zur Differenz
der Temperatur y(t) des Kaffees und der (konstanten) Umgebungstemperatur T , das heiĂt es gilt

y 0 (t) = Îą Âˇ y(t) â T
fuĚr ein Îą â R. Da sich der anfangs heiĂe Kaffee abkuĚhlt, sollte y 0 (t) < 0
gelten, so dass Îą < 0.
(iii) Die Schwingung eines Pendels kann wie folgt beschrieben werden. Die Auslenkung des Pendels aus der Gleichgewichtslage zum Zeitpunkt t wird mit y(t)
bezeichnet. Dann bezeichnet y 0 (t) die Geschwindigkeit und y 00 (t) die Beschleunigung zum Zeitpunkt t. Das Pendel strebt immer in seine Gleichgewichtslage zuruĚck und erfaĚhrt dabei eine Beschleunigung, die proportional
zu seiner Auslenkung ist, das heiĂt
y 00 (t) = âĎ 2 Âˇ y(t)
fuĚr ein Ď â R.
Definition 4.5.1 (GewoĚhnliche Differentialgleichung). Es sei F : Rn+2 â R. Die
Gleichung

F t, y(t), y 0 (t), y 00 (t), . . . , y (n) (t) = 0 ,
(4.11)

Kapiel 4: Analysis

M. Skutella

231

in der neben der unabhaĚngigen Variablen t und einer gesuchten Funktion y = y(t)
auch deren Ableitungen bis zur Ordnung n auftreten, heiĂt gewoĚhnliche Differentialgleichung n-ter Ordnung. Ist t0 aus dem Definitionsbereich von y, so heiĂen
gegebene Werte y(t0 ), y 0 (t0 ), . . . , y (nâ1) (t0 ) Anfangsbedingungen. Die Differentialgleichung (4.11) zusammen mit ihren Anfangsbedingungen wird Anfangswertproblem genannt.
Bei den oben diskutierten Beispielen handelt es sich also um gewoĚhnliche
Differentialgleichungen erster und zweiter Ordnung.

4.5.1

Lineare Differentialgleichungen

Definition 4.5.2 (Lineare homogene Differentialgleichung). FuĚr Îą â R \ {0}
nennen wir die gewoĚhnliche Differentialgleichung
y 0 (t) = Îą Âˇ y(t)
linear und homogen.
Satz 4.5.3. Es sei Îą â R. Zu gegebenen Werten t0 , y0 â R gibt es genau eine
Funktion y : R â R, die die lineare homogene Differentialgleichung
y 0 (t) = Îą Âˇ y(t)
loĚst und den Anfangswert y(t0 ) = y0 hat, naĚmlich

y(t) = exp Îą(t â t0 ) Âˇ y0 .

(4.12)

Beweis. Man rechnet leicht nach, dass die in (4.12) gegebene Funktion y die
Differentialgleichung und die Anfangswertbedingungen erfuĚllt. Wir nehmen an,
dass yĚ eine weitere Funktion mit diesen Eigenschaften ist. Wir betrachten die
Funktion f (t) := exp(âÎą(t â t0 )) Âˇ yĚ(t). Dann gilt nach Produktregel
f 0 (t) = â Îą Âˇ exp(âÎą(t â t0 )) Âˇ yĚ(t) + exp(âÎą(t â t0 )) Âˇ yĚ 0 (t)
= â Îą Âˇ exp(âÎą(t â t0 )) Âˇ yĚ(t) + exp(âÎą(t â t0 )) Âˇ Îą Âˇ yĚ(t)
= 0 .
Folglich ist f konstant, also f (t) = f (t0 ) = y0 . Damit erhaĚlt man
yĚ(t) = exp(Îą(t â t0 )) Âˇ f (t) = exp(Îą(t â t0 )) Âˇ y0 = y(t)
fuĚr alle t.



Definition 4.5.4 (Lineare inhomogene Differentialgleichung). Es sei g : R â R
stetig und Îą â R. Dann nennen wir die gewoĚhnliche Differentialgleichung
y 0 (t) = Îą Âˇ y(t) + g(t)
linear und inhomogen.

232

Mathematik fuĚr Informatiker

M. Skutella

Satz 4.5.5. Es sei g : R â R stetig und Îą â R. Zu gegebenen Werten t0 , y0 â R
gibt es genau eine Funktion y : R â R, die die lineare inhomogene Differentialgleichung
y 0 (t) = Îą Âˇ y(t) + g(t)
loĚst und den Anfangswert y(t0 ) = y0 hat, naĚmlich
Z

 t

y(t) = exp Îą(t â t0 ) Âˇ y0 + exp Îą(t â t0 )
exp âÎą(s â t0 ) Âˇ g(s) ds .
t0

Beweis. Man rechnet leicht nach, dass die gegebene Funktion y die Differentialgleichung und die Anfangswertbedingungen erfuĚllt. Wir nehmen an, dass yĚ
eine weitere Funktion mit diesen Eigenschaften ist. Wir betrachten die Funktion yĚ(t) := y(t) â yĚ(t), fuĚr die gilt
yĚ 0 (t) = y 0 (t) â yĚ 0 (t) = 0
und yĚ(t0 ) = y 0 (t0 ) â yĚ 0 (t0 ) = 0. Folglich ist yĚ die eindeutige LoĚsung der linearen
homogenen Differentialgleichung mit Îą = 0 und Anfangswert 0 und damit nach
Satz 4.5.3 die Nullfunktion. Folglich ist yĚ = y.


4.5.2

Eine nichtlineare Differentialgleichung

Wir betrachten in diesem Abschnitt beispielhaft die folgende nichtlineare Differentialgleichung:
y 0 (t) = Îą Âˇ y 2 â Î˛ Âˇ y
mit Îą, Î˛ â R \ {0}. Dadurch wird ein etwas komplexerer Wachstumsprozess einer
Population beschrieben, den wir im Folgenden studieren werden.
Zur LoĚsung der Differentialgleichung definieren wir die Funktion u := 1/y, fuĚr
die gilt
u0 = â

y0
Îą Âˇ y2 â Î˛ Âˇ y
=
â
= Î˛ÂˇuâÎą .
y2
y2

Die Funktion u erfuĚllt also eine einfache lineare inhomogene Differentialgleichung.
Damit erhaĚlt man (wir setzen t0 := 0)

Îą
u(t) = exp(Î˛ Âˇ t) Âˇ u0 +
1 â exp(Î˛ Âˇ t) .
Î˛
Daraus ergibt sich
y(t) =

Î˛ Âˇ y0
.
(Î˛ â Îą Âˇ y0 ) Âˇ exp(Î˛ Âˇ t) + Îą Âˇ y0

Wir diskutieren nun das Verhalten von y fuĚr bestimmte Werte der Parameter Îą
und Î˛.

Kapiel 4: Analysis

M. Skutella

233

â˘ Ist Îą < 0 und Î˛ < 0, so gilt fuĚr jeden beliebigen Startwert y0 , dass
lim y(t) =

tââ

Î˛
.
Îą

Das bedeutet also, dass sich die Population auf Dauer stabilisiert.
â˘ Ist Îą > 0 und Î˛ > 0 mit Î˛ > Îą Âˇ y0 , so gilt
lim y(t) = 0

tââ

und die Population stirbt aus.
â˘ Ist Îą > 0 und Î˛ > 0 mit Î˛ = Îą Âˇ y0 , so gilt
y(t) =

Î˛
Îą

fuĚr alle t.

Das heiĂt, die Population bleibt konstant.
â˘ Ist schlieĂlich Îą > 0 und Î˛ > 0 mit Î˛ < Îą Âˇ y0 , so gilt


1
Îą Âˇ y0
lim y(t) = â
fuĚr t1 :=
ln
.
tât1
Î˛
Îą Âˇ y0 â Î˛
Das heiĂt, die Population explodiert nach konstanter Zeit.

4.5.3

Lineare Schwingungsgleichung

Wir studieren in diesem Abschnitt die schon weiter oben betrachtete Schwingungsgleichung, die durch
y 00 (t) = â Ď 2 Âˇ y(t)
gegeben ist. Man spricht hier auch von einer freien und homogenen Schwingungsgleichung. Eine Verallgemeinerung dieser Differentialgleichung spielt bei der Beschreibung von Schwingungen in elektrischen Stromkreisen, wie sie in jedem Computer auftauchen (beispielsweise bei der Taktung des Prozessors), eine wichtige
Rolle.
Satz 4.5.6 (LoĚsung der freien homogenen Schwingungsgleichung). Es sei Ď â
R\{0}. Zu gegebenen Werten t0 , y0 , v0 â R gibt es genau eine Funktion y : R â R,
die die Differentialgleichung zweiter Ordnung
y 00 (t) = â Ď 2 Âˇ y(t)
loĚst und die Anfangswerte y(t0 ) = y0 und y 0 (t0 ) = v0 hat, naĚmlich
 v0

y(t) = y0 cos Ď(t â t0 ) + sin Ď(t â t0 ) .
Ď

234

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Man rechnet leicht nach, dass die gegebene Funktion y die Differentialgleichung und die Anfangswertbedingungen erfuĚllt. Wir nehmen an, dass yĚ
eine weitere Funktion mit diesen Eigenschaften ist. Wir betrachten die Funktion yĚ(t) := y(t) â yĚ(t), fuĚr die gilt
yĚ 00 + Ď 2 Âˇ yĚ = 0 .
Multipliziert man diese Gleichung mit 2yĚ 0 , so erhaĚlt man
0
0 = 2 Âˇ yĚ 00 Âˇ yĚ 0 + 2Ď 2 Âˇ yĚ Âˇ yĚ 0 = (yĚ 0 )2 + Ď 2 (yĚ 2 )0 .
Folglich ist die Funktion (yĚ 0 )2 + yĚ 2 konstant und zwar mit Wert
2
2
yĚ 0 (t0 ) + yĚ(t0 ) = 0 .
Daraus folgt sofort, dass yĚ 2 = 0, und damit y = yĚ.



Kapitel 5
Kombinatorik und
Graphentheorie
Die ersten beiden Abschnitte dieses Kapitels uĚber Kombinatorik basieren urspruĚnglich auf Â§12 AbzaĚhlende Kombinatorik und Â§13 Rekursion und erzeugende
Funktionen des Skriptes Lineare Algebra fuĚr Informatiker (Version 1996/2000)
von Gerd Wegner. Es wurde seither von Herrn MoĚller und Herrn Scharlau uĚberarbeitet. Ich danke den Genannten fuĚr das zur VerfuĚgung Stellen des Materials.
Im ersten Abschnitt geht es um abzaĚhlende Kombinatorik. ZunaĚchst werden
einige elementare Techniken wie das Prinzip des doppelten AbzaĚhlens besprochen.
Nach einer ausfuĚhrlichen Behandlung der Binomialkoeffizienten werden dann die
auch in der (endlichen) Stochastik benutzten ZaĚhlkoeffizienten fuĚr geordnete und
ungeordnete Auswahlen ohne und mit Wiederholung aus einer endlichen Menge hergeleitet. Weiter wird das Prinzip der Inklusion und Exklusion behandelt.
SchlieĂlich werden rekursive Anzahlformeln fuĚr Partitionen hergeleitet, vorrangig fuĚr Mengenpartitionen (Stirlingzahlen zweiter und erster Art), kurz auch fuĚr
Zahlpartitionen.
Im zweiten Teil werden rekursiv definierte Folgen behandelt. Es wird die Methode der erzeugenden Funktionen eingefuĚhrt und verschiedene Techniken fuĚr die
LoĚsung von Rekursionsgleichungen werden besprochen. Der Schwerpunkt liegt
auf linearen Rekursionen. Die LoĚsungen haĚngen von den Startwerten der Rekursion ab; im linearen Fall fuĚhrt das auf eine entsprechende lineare Struktur
auf der LoĚsungsmenge, die im Fall konstanter Koeffizienten zu einem vollstaĚndigen LoĚsungsverfahren fuĚhrt. Als Folgerung ergeben sich auch Aussagen uĚber das
Wachstum solcher rekursiver Folgen.
Im dritten Teil geben wir schlieĂlich eine kurze EinfuĚhrung in die Graphentheorie.
235

236

5.1
5.1.1

Mathematik fuĚr Informatiker

M. Skutella

AbzaĚhlende Kombinatorik
Einige elementare ZaĚhlprinzipien

Wir haben im Laufe der bisherigen Vorlesung schon mehrfach Dinge abgezaĚhlt,
etwa bei Teilmengen. Bei allen AbzaĚhlverfahren werden die folgenden Grundaussagen haĚufig stillschweigend verwendet. Wir haben diese Aussagen teilweise
bereits in Kapitel 1, Lemma 1.2.12 und Lemma 1.2.16 erwaĚhnt.
Lemma 5.1.1. Es seien M1 , . . . , Mr endliche Mengen. Dann gilt
S
P
(i) | rk=1 Mk | = rk=0 |Mk |, falls die Mengen paarweise disjunkt sind;
Q
Q
(ii) | rk=1 Mk | = rk=1 |Mk |.
Q
Dabei bezeichnet rk=1 Mk das r-fache kartesische Produkt M1 Ă M2 Ă Âˇ Âˇ Âˇ Ă Mr .
Beweis. Aussage (i) ist trivial, und (ii) erhaĚlt man mit Induktion uĚber r, wobei
man (x1 , . . . , xr ) mit ((x1 , . . . , xrâ1 ), xr ) identifiziert.

Als naĚchstes besprechen wir das sogenannte Prinzip des doppelten AbzaĚhlens;
es ist sehr einfach zu begruĚnden, liefert aber oft uĚberraschende Vereinfachungen.
Satz 5.1.2 (Doppeltes AbzaĚhlen). Es sei eine Relation R zwischen zwei endlichen Mengen M und N gegeben, also R â M Ă N . FuĚr x â M bezeichne r(x) die
Anzahl der mit x in Relation stehenden y â N , und entsprechend s(y) fuĚr y â N
die Anzahl der mit y in Relation stehenden x â M . Dann gilt
X
X
s(y) .
r(x) =
yâN

xâM

Beweis. FuĚr (x, y) â M Ă N setzen wir a(x, y) := 1, falls (x, y) â R und
a(x, y) := 0, falls (x, y) â
/ R. (Wenn man so will, betrachten wir die charakteristische Funktion a : M Ă N â {0, 1} der Teilmenge R â M Ă N .) Dann gilt
fuĚr x0 â M und y0 â N nach Definition
X
X
r(x0 ) =
a(x0 , y)
und
s(y0 ) =
a(x, y0 ) .
yâN

xâM

Es folgt
X
xâM

r(x) =

X
(x,y)âM ĂN

a(x, y) =

X

s(y) .

yâN

Beide in Frage stehenden Zahlen sind also gleich der Anzahl aller in Relation
stehenden Paare (x, y) (also |R|) und deshalb gleich.


Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

237

Wenn die beiden Mengen jeweils in einer konkreten AufzaĚhlung ihrer Elemente
gegeben sind als M = {x1 , x2 , . . . , xm } und N = {y1 , y2 , . . . , yn }, dann entspricht
die charakteristische Funktion a einer (booleschen) m Ă n-Matrix uĚber {0, 1},
die auch Inzidenzmatrix der Relation R genannt wird. Der Beweis von Satz 5.1.2
laĚuft dann darauf hinuas, dass man diese Matrix einmal spaltenweise und einmal
zeilenweise durchlaĚuft.
AbzaĚhlargumente werden auch benutzt, um (nicht-konstruktive) Existenzbeweise zu fuĚhren. Das Grundprinzip steckt dabei oft im sogenannten Dirichletschen
Schubfachprinzip: Wenn man n Objekte auf k FaĚcher verteilt und n > k ist, dann
landen in einem Fach mindestens zwei Objekte. Eine mathematisch praĚzise Form
dieser Aussage ist die folgende:
Satz 5.1.3 (Schubfachprinzip, âpigeonhole principleâ). Es sei f : X â Y eine
Abbildung zwischen endlichen Mengen und |X| > |Y |. Dann gibt es ein y â Y
mit |f â1 (y)| âĽ 2.
Beispiele.
(i) Eine Bibliothek habe mehr als 4000 BuĚcher. Keines der BuĚcher habe mehr
als 4000 Seiten. Dann gibt es (mindestens) zwei BuĚcher mit der gleichen
Seitenzahl.
(ii) Es sei X eine endliche Menge von Personen. Wir betrachten auf X die
Relation âx kennt yâ und nehmen an, diese Relation sei symmetrisch. Dann
gibt es in X gibt zwei Personen, die die gleiche Anzahl von anderen Personen
aus X kennen.
Denn: Es sei n = |X|. Wir betrachten die Funktion f : X â {0, . . . , n â 1},
wobei f (x) = m bedeutet, dass x â X genau m andere Personen in X kennt.
Das Schubfachprinzip ist nicht direkt anwendbar weil
|X| = n = |{0, . . . , n â 1}| .
Wir verwenden einen kleinen Trick und ersetzen {0, . . . , n â 1} durch das
Bild Y := f (X) â {0, . . . , n â 1}. Wir behaupten, dass Y eine echte Teilmenge von {0, . . . , n â 1} ist; dann ist |X| > |Y | und das Schubfachprinzip
anwendbar.
Erster Fall: Es gibt ein a â X mit f (a) = 0, also einen Einsiedler, der
niemanden kennt. Dann kennen die anderen ihn auch nicht; das heiĂt, keiner
kennt alle anderen. Somit ist n â 1 â
/ Y.
Zweiter Fall: Es gibt kein a â X mit f (a) = 0. Dann ist 0 â
/ Y , und die
Behauptung Y 6= {0, . . . , n â 1} gilt ebenfalls.

238

5.1.2

Mathematik fuĚr Informatiker

M. Skutella

Binomialkoeffizienten

Wir definieren zunaĚchst die sogenannten Binomialkoeffizienten, die uns schon
einmal in Kapitel 4, Abschnitt 4.1.5 begegnet sind.
Definition 5.1.4 (Binomialkoeffizienten). FuĚr n â N0 und k â N wird der
Binomialkoeffizient als
 
n
n nâ1
nâk+1
:=
Âˇ
Âˇ ... Âˇ
k
1
2
k
(lies: n uĚber kâ) definiert. FuĚr k = 0 setzt man
â
 
n
:= 1
fuĚr alle n â N0 .
0

Der ZaĚhler des definierenden Bruchs von nk wird fallende Faktorielle von n der
LaĚnge k genannt und mit (n)k bezeichnet, also
(n)k := n Âˇ (n â 1) Âˇ (n â 2) Âˇ . . . Âˇ (n â k + 1) .
Bemerkung. Wir fassen im Folgenden einige Eigenschaften von Binomialkoeffizienten zusammen.
(i) FuĚr n, k â N0 mit n âĽ k ist
 
n
n!
=
.
k
k! Âˇ (n â k)!
(ii) FuĚr n < k gilt

n
k



= 0.


(iii) FuĚr n â N0 gilt n0 = nn = 1.
(iv) FuĚr 0 â¤ k â¤ n gilt wegen (i) die Symmetrieeigenschaft
 


n
n
=
.
k
nâk

(v) Die Definition von xk ergibt auch fuĚr beliebiges x â R Sinn. Wenn x keine
ganze Zahl ist, ergibt sich auch fuĚr x < k ein von Null verschiedener Wert.
Satz 5.1.5 (Rekursionsformel fuĚr Binomialkoeffizienten). FuĚr k, n â N0 gilt



  
n+1
n
n
=
+
.
k+1
k+1
k

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

239

Beweis. FuĚr k = 0 uĚberpruĚft man die Behauptung direkt anhand der Definition.
FuĚr k > 0 gilt
 
n
n nâ1
nâk+1
=
Âˇ
Âˇ ... Âˇ
k
1
2
k
und entsprechend



nâk+1 nâk
n
n nâ1
Âˇ
Âˇ ... Âˇ
Âˇ
.
=
1
2
k
k+1
k+1

Erweitert man im Bruchvon nk ZaĚhler
und Nenner mit k + 1, dann laĚsst sich

n
einiges ausklammern, und man erhaĚlt die
bei der Addition von nk und k+1
Behauptung:
  


n
n
n nâ1
nâk+1
1
+
=
Âˇ
Âˇ ... Âˇ
Âˇ
Âˇ (k + 1) + (n â k)
k
k+1
1
2
k
k+1
=

n nâ1
nâk+1
1
Âˇ
Âˇ ... Âˇ
Âˇ
Âˇ (n + 1)
1
2
k
k+1

n+1 n
nâk+2 nâk+1
Âˇ Âˇ ... Âˇ
Âˇ
1
2
k
k+1


n+1
=
.
k+1

=

Damit ist der Beweis abgeschlossen.



Wir erlaĚutern noch die rekursive Berechnung der Binomialkoeffizienten gemaĚĂ
Satz 5.1.5. Sie wird oft in Form des sogenannten Pascalâschen Dreiecks notiert:
 
 
1
1
0
0
& .
 
2
1

 
2
0
& .
 
3
1

 
3
0
 
4
0

& .
 
4
1

 
2
2
& .
 
3
2

& .
 
4
2

 
3
3
& .
 
4
3

 
4
4

240

Mathematik fuĚr Informatiker

M. Skutella

u.s.w.
Mit konkreten Zahlen also
1

1

1
1
1
1

2
3

3

4
5

1

6
10

1
4

10

1
5

1

u.s.w.
Von Lemma 5.1.1 (i) macht man bei AbzaĚhlung mit Hilfe von Fallunterscheidungen Gebrauch, wobei darauf zu achten ist, dass die FaĚlle disjunkt sind
(und natuĚrlich andererseits alle MoĚglichkeiten erschoĚpfen). Ein einfaches Beispiel
hierfuĚr ist der Beweis zu folgendem bekannten Resultat, das wir schon in Kapiel 1
erwaĚhnt haben (siehe Lemma 1.2.14).
Lemma 5.1.6. Eine n-elementige Menge besitzt 2n Teilmengen, das heiĂt also
|P(M )| = 2n fuĚr |M | = n.
Beweis. Wir verwenden Induktion uĚber n: FuĚr |M | = 0, das heiĂt M = â, ist
P(M ) = {â} und damit |P(M )| = 1 = 20 . Es sei nun n > 0 und |M | = n,
also M 6= â. Wir zeichnen ein Element a in M aus und zerlegen P(M ) in zwei
disjunkte Klassen P(M ) = G1 âŞ G2 , naĚmlich in
G1 := {A | A â M â§ a 6â A} und in G2 := {A | A â M â§ a â A} .
Die Klasse G1 ist nichts anderes als P(M \ {a}). Daher ist nach Induktionsannahme |G1 | = 2nâ1 . Die Menge G2 wird durch die Zuordnung A 7â A\{a} bijektiv auf
P(M \ {a}) abgebildet, also ist auch |G2 | = 2nâ1 . Nun folgt mit Lemma 5.1.1 (i)
die Behauptung.

Die Idee dieses Beweises, durch geeignete Fallunterscheidung zu einer Rekursionsformel fuĚr die gesuchte Anzahl an zu kommen (die hier einfach an = 2anâ1
lautet), ist typisch fuĚr viele Anzahlbestimmungen und wird uns im Folgenden
noch oĚfter begegnen. Ebenso die Idee, durch Auszeichnung eines Elementes zu
dieser Rekursion zu gelangen.
Wir wollen nun Lemma 5.1.6 dahingehend verschaĚrfen, dass wir die Anzahl
der Teilmengen mit genau k Elementen, kurz als k-Teilmengen bezeichnet, bestimmen. Dieses fuĚhrt wieder auf die oben eingefuĚhrten Binomialkoeffizienten,
denn es gilt:
Satz 5.1.7. Es
 seien k, n â N0 . Die Anzahl der k-Teilmengen einer n-elementigen
n
Menge ist k .

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

241

Beweis. Es sei a(n, k) die gesuchte Anzahl. NatuĚrlich ist a(0, k) = 0 fuĚr alle k > 0
und a(n, 0) = 1 fuĚr alle n â N0 . FuĚr n âĽ 1 und k âĽ 1 verwenden wir dasselbe
Argument wie im Beweis zu Lemma 5.1.6: Ist |M | = n+1 und x ein fest gewaĚhltes
Element von M , so gilt fuĚr eine beliebige (k + 1)-Teilmenge von M :
â˘ Entweder enthaĚlt sie x nicht und ist damit eine (k + 1)-Teilmenge der nelementigen Menge M \ {x}.
â˘ Oder sie enthaĚlt x; solche (k+1)-Teilmengen von M entsprechen umkehrbar
eindeutig den k-Teilmengen von M \ {x}.
Daher gilt a(n + 1, k + 1) = a(n, k + 1) + a(n, k). Die Zahlen a(n, k) genuĚgen also
derselben Rekursionsformel wie die Binomialkoeffizienten nach Satz 5.1.5:



  
n+1
n
n
=
+
k+1
k+1
k
und auch denselben Anfangsbedingungen
 
 
n
0
a(n, 0) = 1 =
und a(0, k) = 0 =
0
k

fuĚr n â N0 und k â N.

Da durch die Rekursion und die Anfangsbedingungen
die Zahlen fuĚr alle n, k â N0

n
eindeutig bestimmt sind, folgt a(n, k) = k fuĚr alle k, n â N0 .

Auch dies ist eine mehrfach wiederkehrende Idee in der Kombinatorik: Nachweis der Gleichheit zweier Zahlenfolgen durch den Beweis, dass sie derselben
Rekursion und denselben Anfangsbedingungen genuĚgen.
Die Binomialkoeffizienten treten in der Kombinatorik vielfach auf. Ein Beispiel
ist die uns bereits aus Kapitel 4, Lemma 4.1.42 bekannte Binomialformel.
Satz 5.1.8 (Binomischer Lehrsatz). Es seien a und b aus einem kommutativen
Ring R mit Eins und n â N0 . Dann gilt
n

(a + b)

=

n  
X
n
k=0

k

ak bnâk .

Beweis. Beim Ausmultiplizieren von
(a + b)n = (a + b) Âˇ (a + b) Âˇ . . . Âˇ (a + b)
muĚssen wir uns bei jedem Faktor (a + b) fuĚr a oder b entscheiden. Wenn wir uns
bei den Faktoren mit den Nummern 1 â¤ i1 < i2 < Âˇ Âˇ Âˇ < ik â¤ n fuĚr a entscheiden, so entspricht jede solche Wahl eindeutig
 einer k-Teilmenge von {1, 2, . . . , n}.
n
HierfuĚr gibt es nach Satz 5.1.7 genau k MoĚglichkeiten. Wenn wir uns k mal

242

Mathematik fuĚr Informatiker

M. Skutella

fuĚr a entscheiden, tritt b genau n â k mal auf. Daher haben wir genau
manden ak bnâk . FuĚr die Summe bedeutet das
n  
X
n k nâk
n
(a + b) =
a b
.
k
k=0
Damit ist der Beweis abgeschlossen.

n
k



Sum-



FuĚr die Binomialkoeffizienten und fuĚr verwandte Zahlen gibt es eine FuĚlle von
IdentitaĚten. Zwei einfache Beispiele hierfuĚr sind
n  
X
n
k=0

k

= 2n

fuĚr alle n â N0

und
n  
X
n
k=0

k

(â1)k = 0

fuĚr alle n > 0.

Beides laĚsst sich sehr einfach sowohl mit Satz 5.1.8 wie auch mit Satz 5.1.7 und
Lemma 5.1.6 begruĚnden.
Der folgende Satz gibt ein etwas komplizierteres Beispiel einer IdentitaĚt fuĚr
Binomialkoeffizienten.
Satz 5.1.9. FuĚr m, n â N0 gilt


m+n
m



m    
X
m
n
=
Âˇ
.
k
k
k=0

Beweis. Man beachte zunaĚchst, dass beide Seiten symmetrisch in m und n sind,
da die auf der rechten Seite stehende Summe stets bei der kleineren der beiden
Zahlen abgebrochen werden kann; die uĚbrigen Summanden verschwinden. Es sei
daher ohne BeschraĚnkung der Allgemeinheit m â¤ n. Zum Beweis der Gleichung
zaĚhlt man in dem in Abbildung 5.1 dargestellten Rechteckgitter die Gesamtheit W aller kuĚrzesten Wege vom Punkt (0, 0) zum Punkt (n, m) auf zwei Weisen
ab. Jeder solche Weg besteht aus m senkrechten Einheitswegstrecken und n waagerechten Einheitswegstrecken in beliebiger Reihenfolge. Wenn wir in der Reihenfolge des Weges jede senkrechte Strecke durch 0â und jede waagerechte Strecke
â
durch 1â symbolisieren, so wird jeder kuĚrzeste Weg umkehrbar eindeutig dargeâ
stellt durch eine 0-1-Sequenz der LaĚnge m + n mit genau m Einsen. Die gesuchte

Anzahl ist also gleich der Anzahl dieser 0-1-Sequenzen und damit gleich m+n
.
m
Zum anderen benutzt jeder Weg aus W genau einen der Punkte xk = (mâk, k)
und es gibt (nach der ersten UĚberlegung) genau m
kuĚrzeste Wege von (0, 0)
k

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

243

(n, m)

xm

x0

(0, 0)

Abbildung 5.1: Jeder kuĚrzeste Weg von (0, 0) nach (n, m) muss durch einen der
Punkte xk , k = 0, . . . , m gehen.
nach xk und genau
zweite Anzahl:

n
mâk



kuĚrzeste Wege von xk nach (n, m). Das ergibt die


  
m 
m    
m   
X
X
X
m
n
m
m
n
n
Âˇ
=
Âˇ
=
Âˇ
.
k
mâk
mâj
j
k
k
j=0
k=0
k=0
Damit ist der Beweis abgeschlossen.



Einen zweiten Beweis fuĚr Satz 5.1.9 erhaĚlt man durch Anwendung von Satz 5.1.8
auf beide Seiten der Gleichung
(1 + t)m+n = (1 + t)m Âˇ (1 + t)n
und Vergleich der Koeffizienten von tm .

5.1.3

Auswahlen aus einer Menge

Viele einfache kombinatorischen Fragestellungen lassen sich zuruĚckfuĚhren auf gewisse Grundaufgaben, aus einer gegebenen endlichen Menge bestimmte Auswahlen zu treffen. Je nachdem, ob wir es zulassen, dass dabei ein und dasselbe Element
mehrfach ausgewaĚhlt wird (ohne oder mit Wiederholungen), und ob wir die Auswahl als geordnet betrachten (1. Element, 2. Element, . . .) oder als ungeordnet,
ergeben sich vier verschiedene Anzahlen.
Satz 5.1.10. Es seien k, n â N0 und M eine endliche Menge mit |M | = n
Elementen. Dann wird die Anzahl der MoĚglichkeiten fuĚr die Auswahl von k Elementen aus dieser n-elementigen Menge M gegeben durch

244

Mathematik fuĚr Informatiker

M. Skutella

Auswahl

Ziel

k
..
.
3
2
1
0
Start 1

2

3

4

5

6

7

8

ÂˇÂˇÂˇ

n

Objekte

Abbildung 5.2: Jeder kuĚrzeste Weg von (0, 0) nach (n, k) induziert genau eine
ungeordnete Auswahl mit Wiederholungen und umgekehrt.
geordnet
ohne Wiederholungen
mit Wiederholungen

(n)k
n

k

ungeordnet

n
k

n+kâ1
k

Die geordneten Auswahlen ohne Wiederholungen heiĂen k-Permutationen
und auch die uĚbrigen Auswahlen haben Namen, auf deren Nennung wir hier
aber verzichten.
Beweis. Bei der geordneten Auswahl ohne Wiederholungen haben wir es mit kTupeln aus der Menge M zu tun. Zur Besetzung der ersten Stelle des k-Tupels
hat man freie Auswahl unter allen n Elementen von M , also n MoĚglichkeiten. FuĚr
den zweiten Eintrag des k-Tupels bleiben noch n â 1 MoĚglichkeiten, da wir keine
Wiederholungen zulassen. Sind schlieĂlich k â 1 Stellen schon besetzt, so hat man
zur Besetzung der k-ten Stelle nur noch die Auswahl unter n â k + 1 Elementen.
Aufmultiplizieren der unabhaĚngigen MoĚglichkeiten ergibt die gewuĚnschte Zahl.
Den Fall der geordneten Auswahl mit Wiederholungen behandelt man analog,
wobei jetzt bei jeder Stelle die volle Auswahl aus allen n Elementen von M
besteht.
Ungeordnete Auswahlen ohne Wiederholung koĚnnen einfach als Teilmengen
aufgefasst werden. Somit folgt die Behauptung aus Satz 5.1.7.
Der Fall der ungeordneten Auswahl mit Wiederholungen ist etwas schwieriger
zu behandeln. Die Formel laĚsst sich wieder mit einem Gitterweg-Argument (vgl.
Abbildung 5.1 im Beweis zu Satz 5.1.9) beweisen. Wir betrachten die ganzzahligen
Gitterpunkte (x, y) mit den Koordinaten x â {1, . . . , n} und y â {0, . . . , k} (siehe
Abbildung 5.2). Die x-Koordinate entspreche einer Durchnummerierung der Elemente von M bzw. o.B.d.A. sei M = {1, 2, . . . , n}; da es bei einer ungeordneten

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

245

Auswahl auf die Reihenfolge nicht ankommt, koĚnnen wir sie gemaĚĂ dieser Nummerierung von M anordnen. Jede Auswahl entspricht dann einem kuĚrzesten Weg
im Gitter vom Start (0, 0) zum Ziel (n, k), indem wir die Benutzung einer senkrechten Strecke von (i, j) nach (i, j + 1) als Wahl des Elementes i interpretieren.
In der Abbildung (hier ist n = 11 und k = 6) entspricht also der markierte Weg
der Auswahl 3|3|4|7|9|10. Nach der UĚberlegung im Beweis zu Satz 5.1.9 ist die
(beachte, dass die Nummerierung in der Horizontalen
Anzahl also gleich n+kâ1
k
hier mit 1 beginnt).

Die in Satz 5.1.10 auftretenden Anzahlen lassen auch andere Interpretationen
zu. So ist zum Beispiel die Anzahl nk aller geordneten Auswahlen mit Wiederholungen von k Elementen aus n Elementen auch die Anzahl aller Abbildungen einer
k-Menge in eine n-elementige Menge, oder die Anzahl der EinordnungsmoĚglichkeiten von k unterscheidbaren Objekten in n unterscheidbare FaĚcher. Auch die
Anzahl der EinordnungsmoĚglichkeiten von k nicht unterscheidbaren Objekten
in n unterscheidbare FaĚcher tritt in Satz 5.1.10 auf (welche ist das?).
Die Binomialzahlen besitzen eine sowohl kombinatorisch wie auch (in Analogie
zu Satz 5.1.8) algebraisch motivierte Verallgemeinerung.
Definition 5.1.11. FuĚr n = n1 + . . . + nk mit n1 , . . . , nk â N0 , k â N heiĂt


n!
n
:=
n1 ! Âˇ . . . Âˇ nk !
n1 , . . . , n k
ein Multinomialkoeffizient.
Bemerkung.
(i) Speziell fuĚr k = 2, n = n1 + n2 ist


 
 
n
n
n
=
=
.
n 1 , n2
n1
n2
(ii) Wenn man im Fall k = n alle ni = 1 waĚhlt, so erhaĚlt man


n
= n! .
1, . . . , 1
Die kombinatorische Bedeutung der Multinomialkoeffizienten liegt in der folgenden Anzahlbestimmung:
Satz 5.1.12. Es seien n Objekte von k Sorten gegeben, wobei ni (nicht unterscheidbare) Objekte der i-ten Sorte vorhanden seien (fuĚr i = 1, . . . ,k); das Tun
pel (n1 , . . . , nk ) heiĂt die Spezifikation der Objekte. Dann ist n1 ,...,n
die Anzahl
k
der moĚglichen Anordnungen dieser Objekte als Folge der LaĚnge n.

246

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Es sei a die gesuchte Anzahl bei fester Spezifikation (n1 , . . . , nk ). Ersetzen wir die n1 Objekte der ersten Sorte durch n1 unterscheidbare Objekte, so
erhoĚht dies die Anzahl der moĚglichen Anordnungen um den Faktor n1 !, die Anzahl der PermutationsmoĚglichkeiten dieser n1 Elemente. Gleiches bei allen Sorten
durchgefuĚhrt ergibt schlieĂlich a Âˇ n1 ! Âˇ . . . Âˇ nk ! MoĚglichkeiten. Da nun aber alle
Elemente voneinander verschieden sind, ist diese Anzahl gleich n!, woraus die
Behauptung folgt.

Beispiel. FuĚr vier Objekte der Spezifikation (1, 1, 2), die wir uns durch die Buchstaben a, b, c, c gegeben denken, hat man die folgenden zwoĚlf AnordnungsmoĚglichkeiten:
abcc bacc cabc cbca
acbc bcac cacb ccab
accb bcca cbac ccba
Die algebraische Bedeutung der Multinomialkoeffizienten liegt in der folgenden Verallgemeinerung von Satz 5.1.8.
Satz 5.1.13. Es seien x1 , . . . , xk Elemente eines kommutativen Ringes und n â
N0 . Dann gilt

X 
n
n
Âˇ xn1 1 Âˇ . . . Âˇ xnk k .
(x1 + Âˇ Âˇ Âˇ + xk ) =
n
,
.
.
.
,
n
1
k
n ,...,n âĽ0
1
k
n1 +ÂˇÂˇÂˇ+nk =n

Beweis. Beim Ausmultiplizieren des Produktes auf der linken Seite der behaupteten Gleichung, bestehend aus den n Faktoren (x1 + . . . + xk ), tritt xn1 1 Âˇ . . . Âˇ xnk k
als Summand genau so oft auf, wie es AnordnungsmoĚglichkeiten von x1 (n1 mal),. . . ,xk (nk -mal) gibt.


5.1.4

Ein- und AusschlieĂen

Wir wollen jetzt eine haĚufig benoĚtigte Variante von Lemma 5.1.1 (i) betrachten. Wie bestimmt man die KardinalitaĚt einer als Vereinigung von Teilmengen
gegebenen Menge, wenn diese Teilmengen nicht paarweise disjunkt sind? Dazu ein Beispiel: Wieviele natuĚrlichen Zahlen â¤ 100 sind durch 2, 3 oder 5 teilbar? Bezeichnen wir mit Mk die Menge der durch k teilbaren Zahlen â¤ 100,
so wird also nach |M2 âŞ M3 âŞ M5 | gefragt. FuĚr eine einzelne Teilmenge gilt
|Mk | = 100
, wenn wir fuĚr x â R mit bxc wieder die groĚĂte ganze Zahl â¤ x
k
bezeichnen (GauĂklammer). Die Summe dieser EinzelkardinalitaĚten ergibt eine
zu groĂe Zahl, da hier die in den Durchschnitten liegenden Elemente mehrfach
gezaĚhlt werden. Das Abziehen der KardinalitaĚten aller zweifachen Durchschnitte,
also von |M2 âŠ M3 |, |M2 âŠ M5 | und |M3 âŠ M5 |, erbringt ein zu kleines Resultat, da
jetzt die Zahlen des dreifachen Durchschnitts M2 âŠ M3 âŠ M5 (also die durch 30

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

247

teilbaren Zahlen) zunaĚchst dreifach gezaĚhlt, dann aber auch wieder dreifach abgezogen wurden. Das richtige Ergebnis ist also
|M2 âŞ M3 âŞ M5 | = |M2 | + |M3 | + |M5 |
â |M2 âŠ M3 | â |M2 âŠ M5 | â |M3 âŠ M5 |
+ |M2 âŠ M3 âŠ M5 |





 

100
100
100
100
100
100
100
=
+
+
â
â
â
+
2
3
5
6
10
15
30
= 74 .
Diese hier am Beispiel dreier Mengen vorgefuĚhrte Berechnungsmethode laĚsst sich
verallgemeinern auf eine beliebige (endliche) Anzahl von Mengen, wobei wir auĂerdem noch, statt einfach die Elemente zu zaĚhlen, eine Gewichtung der Elemente
mit Werten aus einer additiven Gruppe (z.B. (K, +), K KoĚrper) zulassen koĚnnen.
Satz 5.1.14 (Ein- und AusschlieĂen, Inklusion-Exklusion). Es sei M eine nichtleere Menge, (G, +) eine abelsche Gruppe und w : M â G eine Abbildung (Gewichtsfunktion). Dann gilt fuĚr endliche Teilmengen M1 , . . . , Mr von M
w(M1 âŞ Âˇ Âˇ Âˇ âŞ Mr ) =

r
X

(â1)k+1

P

xâA

w(Mi1 âŠ Âˇ Âˇ Âˇ âŠ Mik ) ,

1â¤i1 <ÂˇÂˇÂˇ<ik â¤r

k=1

wobei w(A) :=

X

w(x) ist fuĚr endliche Teilmengen A â M .

Beweis. Wir verwenden Induktion uĚber r. FuĚr r = 1 ist nichts zu zeigen (die
Formel liefert w(M1 ) = w(M1 )) und im Falle r = 2 erhaĚlt man w(M1 âŞ M2 ) =
w(M1 )+w(M2 )âw(M1 âŠM2 ), was man wie beim vorausgehenden Beispiel mit drei
Mengen direkt bestaĚtigt. Es sei nun r > 2. Durch Klammerung und Anwendung
der Formel fuĚr zwei Mengen folgt zunaĚchst
w (M1 âŞ Âˇ Âˇ Âˇ âŞ Mrâ1 ) âŞ Mr



= w(M1 âŞ Âˇ Âˇ Âˇ âŞ Mrâ1 ) + w(Mr )
â w (M1 âŞ Âˇ Âˇ Âˇ âŞ Mrâ1 ) âŠ Mr



.

Der letzte Term kann mit Hilfe des Distributivgesetzes umgeformt werden in
w (M1 âŞ Âˇ Âˇ Âˇ âŞ Mrâ1 ) âŠ Mr




= w (M1 âŠ Mr ) âŞ Âˇ Âˇ Âˇ âŞ (Mrâ1 âŠ Mr ) .

Nun kann man auf den ersten und letzten Term die Induktionsannahme anwenden
und erhaĚlt damit (nach Umordnung) die Behauptung, wobei der letzte Term
diejenigen Summanden der Behauptung liefert, bei denen Mr beteiligt und k âĽ 2
ist.


248

Mathematik fuĚr Informatiker

M. Skutella

Die Formulierung von Satz 5.1.14 in der allgemeinen Form mit der Gewichtsfunktion spielt vor allem bei wahrscheinlichkeitstheoretischen Anwendungen (x
ein Elementarereignis und w(x) seine Wahrscheinlichkeit) eine Rolle. FuĚr den
Spezialfall G := Z und w(x) := 1 fuĚr alle x â M liefert Satz 5.1.14 die folgende
Anzahlformel.
Korollar 5.1.15. Es sei M eine nicht-leere Menge. Dann gilt fuĚr endliche Teilmengen M1 , . . . , Mr von M
|M1 âŞ Âˇ Âˇ Âˇ âŞ Mr | =

r
X
k=1

X

(â1)k+1

|Mi1 âŠ Âˇ Âˇ Âˇ âŠ Mik | .

1â¤i1 <ÂˇÂˇÂˇ<ik â¤r

Bemerkung. Die Formel vom Ein- und AusschlieĂen wird haĚufig auch in einer
komplementaĚren Form verwendet: Man fragt nach der Anzahl (oder dem Gewicht)
aller Elemente einer Menge M , die gewisse gegebene Eigenschaften E1 , . . . , Er
nicht haben, also nach der KardinalitaĚt (oder dem Gewicht) von M \ (M1 âŞ Âˇ Âˇ Âˇ âŞ
Mr ), wenn wir Mk := {x | x â M â§ x hat die Eigenschaft Ek } setzen. Mit
Satz 5.1.14 erhaĚlt man dafuĚr
r
X

(â1)k
w M \ (M1 âŞ Âˇ Âˇ Âˇ âŞ Mr ) = w(M ) +
k=1

X

w(Mi1 âŠ Âˇ Âˇ Âˇ âŠ Mik ) .

1â¤i1 <ÂˇÂˇÂˇ<ik â¤r

Ein klassisches Anwendungsbeispiel fuĚr die Formel vom Ein- und AusschlieĂen ist etwa das Problem von Montmort, das man (urspruĚnglich ein Lotterieproblem) in folgende Fragestellung einkleiden kann: n Ehepaare treffen sich zu einem
Tanzabend; wieviele MoĚglichkeiten gibt es, n Tanzpaare so zu bilden, dass keine
Ehepaare zusammen tanzen? Dies ist aĚquivalent zur Frage nach der Anzahl aller
fixpunktfreien Permutationen von n Elementen.
Definition 5.1.16 (Permutation, Fixpunkt).
(i) Es sei M eine Menge und f : M â M eine bijektive Abbildung. Dann
heiĂt f eine Permutation von M .
(ii) Ein Element x â M mit f (x) = x heiĂt Fixpunkt von f : M â M .
(iii) Eine Permutation f von M heiĂt fixpunktfrei, falls kein Element aus M ein
Fixpunkt von f ist, das heiĂt f (x) 6= x fuĚr alle x â M .
(iv) Die Gesamtheit aller Permutationen der Menge {1, 2, . . . , n} bezeichnet man
mit Sn . Die Menge Sn bildet zusammen mit der VerknuĚpfung von Abbildungen âŚ : Sn Ă Sn â Sn eine Gruppe, die symmetrische Gruppe.
Die Antwort auf die oben gestellte Frage gibt nun der folgende Satz:

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

249

Satz 5.1.17. Die Anzahl der fixpunktfreien Permutationen in Sn ist
Dn := n! Âˇ

n
X
(â1)k
k=0

k!

.

Die Zahlen Dn heiĂen Rencontre-Zahlen (nach dem âProbleĚme des Rencontresâ
von Montmort) oder Derangement-Zahlen.
Beweis. FuĚr k = 1, . . . , n bezeichne Pk die Menge aller Permutationen aus Sn
mit Fixpunkt k. Mit Korollar 5.1.15 in der komplementaĚren Form erhaĚlt man
Dn = |Sn \ (P1 âŞ . . . âŞ Pn )|
n
X
X
(â1)k
= n! +

|Pi1 âŠ Âˇ Âˇ Âˇ âŠ Pik | .

1â¤i1 <ÂˇÂˇÂˇ<ik â¤n

k=1

Da Pi1 âŠ Âˇ Âˇ Âˇ âŠ Pik die Menge aller Permutationen ist, die die k Elemente i1 , . . . , ik
als Fixpunkte haben, gibt es eine Bijektion zwischen Pi1 âŠÂˇ Âˇ ÂˇâŠPik und der Menge
der Permutationen von nâk Elementen Snâk . Folglich ist |Pi1 âŠÂˇ Âˇ ÂˇâŠPik | = (nâk)!,
so dass
Dn = n! +

n
X

X

(â1)k

(n â k)!

1â¤i1 <ÂˇÂˇÂˇ<ik â¤n

k=1
n
X

 
n
(â1)
= n! +
(n â k)!
k
k=1
= n! + n! Âˇ

k

n
X

(â1)k

k=1

= n! Âˇ

n
X

(â1)k

k=0

1
k!

1
.
k!

Damit ist der Beweis abgeschlossen.



Eine andere Einkleidung des Problems ist folgende: Wenn jemand n Briefe
und die zugehoĚrigen UmschlaĚge schreibt und dann die Briefe willkuĚrlich in die
UmschlaĚge steckt, wie groĂ ist die Wahrscheinlichkeit (berechnet als Bruchteil
von 1 aus dem VerhaĚltnis der Anzahl der hier zu betrachtenden MoĚglichkeiten
zur Anzahl aller MoĚglichkeiten), dass keiner der Adressaten den ihm zugedachten
Brief erhaĚlt? Diese Wahrscheinlichkeit wird gegeben durch
pn

n
X
Dn
1
:=
=
(â1)k
n!
k!
k=0

250

Mathematik fuĚr Informatiker

M. Skutella

und da dies die mit dem n-ten Glied abgebrochene Reihe fuĚr eâ1 ist, folgt
pn â

1
e

<

1
.
(n + 1)!

Die Wahrscheinlichkeit pn konvergiert also fuĚr n â â gegen 1/e und zwar
sehr rasch. Der Anteil der fixpunktfreien unter allen Permutationen einer nelementigen Menge ist also von n beinahe unabhaĚngig und n!e ist eine gute NaĚherung fuĚr Dn .

5.1.5

Partitionen und Stirlingzahlen zweiter Art

Eine Anzahl, die ebenfalls als Bestandteil vieler komplexerer AbzaĚhlprobleme
auftritt, ist die Anzahl der MoĚglichkeiten, eine gegebene Menge in eine vorgegebene Anzahl von Teilmengen zu zerlegen. Im Folgenden verallgemeinern wir den
Begriff Partition aus Definition 1.2.15.
Definition 5.1.18. Es sei k â N und M eine nicht-leere Menge. Eine k-Partition
von M ist eine Partition, die aus genau k nicht-leeren Teilmengen von M besteht,
das heiĂt
M =

k
[

Mi ,

mit Mi 6= â,

und Mi âŠ Mj = â fuĚr i 6= j.

i=1

Wir bezeichnen mit S(n, k) die Anzahl der verschiedenen k-Partitionen einer
n-elementigen Menge. Ferner setzen wir S(0, 0) := 1, S(n, 0) := 0 fuĚr n > 0
und S(0, k) := 0 fuĚr k > 0. Diese Zahlen heiĂen Stirlingzahlen zweiter Art.
Da nach Satz 1.5.5 die Partitionen einer Menge M umkehrbar eindeutig den
AĚquivalenzrelationen auf dieser Menge entsprechen, erhalten wir das folgende
Korollar.
Korollar 5.1.19. Es sei M eine nicht-leere endliche Menge und n = |M |. Die
Anzahl der AĚquivalenzrelationen mit genau k AĚquivalenzklassen auf M ist S(n, k).
Beispiel. Die k-Partitionen fuĚr k = 1, 2, 3, 4 einer 4-elementigen Menge {a, b, c, d}
werden (in naheliegender Notation) in Tabelle 5.1 gegeben. Daran kann man die
in der letzten Zeile angegebenen Werte der Stirlingzahlen S(4, k) fuĚr k = 1, 2, 3, 4
ablesen.
Satz 5.1.20 (Rekursionsformel fuĚr die Stirlingzahlen zweiter Art). FuĚr n, k â N
gilt
S(n, k) = S(n â 1, k â 1) + k Âˇ S(n â 1, k) .

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

k=

1
2
abcd a|bcd
b|acd
c|abd
d|abc
ab|cd
ac|bd
ad|bc
S(4, k) =
1
7

251

3
4
a|b|cd a|b|c|d
a|c|bd
a|d|bc
b|c|ad
b|d|ac
c|d|ab
6

1

Tabelle 5.1: Alle k-Partitionen der Menge {a, b, c, d} fuĚr k = 1, 2, 3, 4.
Beweis. FuĚr k = 1 oder k > n verifiziert man leicht die Richtigkeit der Formel.
Es sei also |M | = n âĽ 2. Wir waĚhlen wieder ein Element a â M fest und teilen
(in Analogie zum Beweis von Satz 5.1.7) die k-Partitionen von M in zwei Typen
ein:
â˘ Die Teilmenge {a} ist selbst eine Klasse. Dann bilden die uĚbrigen Klassen
eine (k â 1)-Partition von M \ {a}. Folglich gehoĚren genau S(n â 1, k â 1)
k-Partitionen zu diesem Typ.
â˘ Das Element a gehoĚrt zu einer Klasse A mit |A| âĽ 2. Diese k-Partitionen von
M werden durch Wegnahme von a wieder auf k-Partitionen von M \ {a}
abgebildet. Genauer gesagt haben jeweils k dieser k-Partitionen von M
dasselbe Bild, naĚmlich diejenigen, die man aus einer k-Partition von M \{a}
erhaĚlt, indem man jeweils eine der k Klassen um das Element a erweitert.
Daher gibt es k Âˇ S(n â 1, k) k-Partitionen des zweiten Typs.
Damit ist der Beweis abgeschlossen.



Diese Rekursionsformel erlaubt wie bei den Binomialkoeffizienten die sukzessive Berechnung der S(n, k) aus ihren in Definition 5.1.18 angegebenen Anfangswerten. In Tabelle 5.2 sind die Stirlingzahlen zweiter Art S(n, k) fuĚr kleine Werte
von n und k angegeben. Auch fuĚr die Stirlingzahlen gibt es viele SummenidentitaĚten, wofuĚr wir hier ein Beispiel angeben.
Satz 5.1.21. FuĚr n, k â N gilt
S(n, k) =


nâ1 
X
nâ1
i=0

i

Âˇ S(i, k â 1) .

Beweis. Wir beweisen dies kombinatorisch, indem wir die k-Partitionen einer nelementigen Menge M auf andere Weise abzaĚhlen. Es sei a â M fest gewaĚhlt. FuĚr

252

Mathematik fuĚr Informatiker
n\k
0
1
2
3
4
5
6

0
1
0
0
0
0
0
0

1
0
1
1
1
1
1
1

2
0
0
1
3
7
15
31

3
0
0
0
1
6
25
90

4
0
0
0
0
1
10
65

M. Skutella
5
0
0
0
0
0
1
15

6
0
0
0
0
0
0
1

Tabelle 5.2: Tabelle der Stirlingzahlen zweiter Art S(n, k).


nâ1
jedes i â {0, . . . , n â 1} gibt es nâ1âi
= nâ1
MoĚglichkeiten, eine Teilmenge A
i
von M mit a â A und |A| = n â i zu waĚhlen. Zu jeder dieser Teilmengen ist die
Anzahl der (k â 1)-Partitionen von M \ A gleich S(i, k â 1). Hieraus folgt die
Behauptung.


5.1.6

Stirlingzahlen erster Art

Es gibt noch andere Stirlingzahlen, die man von erster Artâ nennt. Vor der Defiâ
nition erinnern wir an die symmetrische Gruppe Sn , die aus allen Permutationen Ď
der Menge {1, . . . , n} besteht.
Definition 5.1.22 (Zyklus). Eine Permutation Ď der Menge {a1 , . . . , am } heiĂt
Zyklus, falls es zu jedem j â {1, . . . , m} ein k â N0 gibt, so dass Ď k (a1 ) = aj .
(Hier bezeichnet Ď k die k-fache HintereinanderausfuĚhrung von Ď.)
Beispiel. Die Permutation Ď von {2, 4, 5, 6, 7}, die gegeben ist durch
i
2
Ď(i) 5

4 5
7 4

6 7
2 6

ist ein Zyklus. Denn es gilt
2 = Ď 0 (2) ,

5 = Ď 1 (2) ,

4 = Ď 2 (2) ,

7 = Ď 3 (2) und 6 = Ď 4 (2) .

Man schreibt dann auch kurz Ď = (2, 5, 4, 7, 6) oder Ď = (5, 4, 7, 6, 2) oder Ď =
(4, 7, 6, 2, 5) etc.
Lemma 5.1.23. Jede Permutation Ď â Sn kann als Produkt von Zyklen geschrieben werden.
Wir erlaĚutern diese Einsicht nur kurz an einem Beispiel. Daraus sollte auch
klar werden, wie man das Lemma allgemein beweist.
Beispiel. Die Permutation Ď â S8 sei gegeben durch

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella
i
1
Ď(i) 3

253

2 3 4 5 6 7 8
5 1 2 4 8 7 6

Offenbar ist Ď(1) = 3 und Ď 2 (1) = Ď(3) = 1. Die Permutation Ď enthaĚltâ
â
also den Zyklus (1, 3). Auch 2 ist kein Fixpunkt und es gilt Ď(2) = 5, Ď(5) = 4
und Ď(4) = 2. Das ergibt den Zyklus (2, 5, 4). Weiter erhaĚlt man den Zyklus (6, 8)
und den trivialen Zyklus (7). Zusammenfassend gilt daher
Ď = (1, 3)(2, 5, 4)(6, 8)(7) .
Damit koĚnnen wir jetzt die Stirlingzahlen erster Ordnung definieren.
Definition 5.1.24. Die Anzahl der Permutationen aus Sn , die aus k Zyklen
bestehen, heiĂt Stirlingzahl erster Art und wird mit s(n, k) bezeichnet.
Bemerkung.
(i) Weil die Anzahl aller Permutationen n! ist, gilt
n
X

s(n, k) = n! .

k=1

(ii) Es gibt keine Permutation mit k = 0 Zyklen und nur eine Permutation in Sn
mit k = n Zyklen. In diesem Fall haben alle Zyklen die LaĚnge 1, also gibt
es n Fixpunkte und wir haben die identische Abbildung.
(iii) ZusaĚtzlich definiert man noch s(0, 0) := 1. Es gilt also
(
0 fuĚr k = 0, n â N,
s(n, k) =
1 fuĚr k = n â N0 .
Satz 5.1.25 (Rekursion fuĚr die Stirlingzahlen erster Art). FuĚr n, k â N gilt
s(n, k) = s(n â 1, k â 1) + (n â 1) Âˇ s(n â 1, k) .
Beweis. Wir betrachten eine Permutation aus Sn mit k Zyklen und unterscheiden
zwei FaĚlle. Erster Fall: Die Zahl n ist Fixpunkt. Dann bilden die restlichen k â
1 Zyklen eine Permutation von {1, . . . , n â 1}. Es gibt s(n â 1, k â 1) solche
Permutationen. Dies ist folglich auch die Anzahl der Permutationen aus Sn mit k
Zyklen und Fixpunkt n.
Zweiter Fall: Die Zahl n ist kein Fixpunkt, also in einem Zyklus der LaĚnge âĽ 2
enthalten. Entfernt man n aus diesem Zyklus, so erhaĚlt man eine Permutation
aus Snâ1 mit k Zyklen. Umgekehrt sei eine solche Permutation
(a1,1 , a1,2 , . . . , a1,`1 )(a2,1 , a2,2 , . . . , a2,`2 ) . . . (ak,1 , ak,2 , . . . , ak,`k )

254

Mathematik fuĚr Informatiker

M. Skutella

gegeben. Dann gilt zunaĚchst einmal `1 + `2 + Âˇ Âˇ Âˇ + `k = n â 1. Aus solchen Permutationen kann man durch EinfuĚgen von n in einen der Zyklen jede Permutation
aus Sn mit k Zyklen bekommen, bei der n nicht Fixpunkt ist.
Im ersten Zyklus kann man n nach jedem a1,j einfuĚgen, j = 1, . . . , `1 . Jedesmal
erhaĚlt man einen anderen (`1 + 1)-Zyklus. (EinfuĚgen vor a11 ist gleichwertig mit
EinfuĚgen nach a1,`1 , also kein neuer Zyklus). Allgemein bekommt man durch
EinfuĚgen von n im Zyklus der LaĚnge ` genau ` verschiedene Zyklen der LaĚnge `+1.
Man kann n in jeden Zyklus einfuĚgen. Daher ergeben sich genau
`1 + `2 + Âˇ Âˇ Âˇ + `k = n â 1
verschiedene MoĚglichkeiten.
Dieses Verfahren ist anwendbar auf jede Permutation von Snâ1 mit k Zyklen,
also auf s(n â 1, k) Permutationen. Folglich gibt es (n â 1) Âˇ s(n â 1, k) Permutationen in Sn aus k Zyklen, die n nicht als Fixpunkt haben. Damit ist der Beweis
abgeschlossen.

Die Rekursion aus Satz 5.1.25 kann wie folgt veranschaulicht werden:
n=1:

0

1
1Âˇ

n=2:

&.
1

0
2Âˇ

n=3:

&.
2

0
3Âˇ

n=4:

4Âˇ

&.
50

1
3Âˇ

&.
11

4Âˇ

&.
24

&.
3
3Âˇ

&.
6

0

1
2Âˇ

&.
6
4Âˇ

&.
35

1
4Âˇ

&.
10

usw.

5.1.7

Zerlegungen einer natuĚrlichen Zahl

Bis jetzt haben wir Zerlegungen von Mengen betrachtet. In diesem Abschnitt wenden wir uns den Zerlegungen einer natuĚrlichen Zahl N â N als Summe natuĚrlicher
Zahlen zu:
N = n1 + n2 + Âˇ Âˇ Âˇ + nk , n1 , n2 , . . . , nk â N.
Diese Zerlegungen heiĂen Zahlpartitionen oder arithmetische Partitionen.
Definition 5.1.26. Es sei 1 â¤ k â¤ n. Die Anzahl der Zerlegungen von n in
genau k natuĚrliche Summanden ohne BeruĚcksichtigung der Reihenfolge wird
mit P (n, k) bezeichnet. Ferner sei P (0, 0) := 1 und P (n, k) := 0 fuĚr k = 0
und n > 0 sowie fuĚr k > n. Die P (n, k) heiĂen (arithmetische) Partitionszahlen.

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

255

Beispiele.
(i) Die moĚglichen Zerlegungen der Zahl 4 in zwei Summanden sind 3+1 und 2+
2; also ist P (4, 2) = 2.
(ii) Die Zerlegung der Zahl 7 in drei Summanden sind 5 + 1 + 1, 4 + 2 + 1,
3 + 3 + 1 und 3 + 2 + 2; also ist P (7, 3) = 4.
Jede k-Partition einer n-elementigen Menge M = M1 âŞ M2 âŞ Âˇ Âˇ Âˇ âŞ Mk bewirkt
eine Zerlegung von n in k natuĚrliche Summanden, naĚmlich n = |M1 | + |M2 | +
Âˇ Âˇ Âˇ+|Mk |, jedoch gehoĚren zu einer solchen Summenzerlegung im allgemeinen mehrere k-Partitionen der Menge. Daher fallen die arithmetischen Partitionszahlen
fuĚr groĂes n wesentlich kleiner aus als die mengentheoretischen Partitionszahlen S(n, k).
Auch fuĚr diese Partitionszahlen gibt es eine einfache Rekursionsformel.
Satz 5.1.27 (Rekursionsformel fuĚr die arithmetischen Partitionszahlen). FuĚr 1 â¤
k â¤ n gilt
P (n, k) = P (n â 1, k â 1) + P (n â k, k) .
Beweis. Die Zerlegungen von n in genau k Summanden zerfallen in zwei Klassen,
naĚmlich in solche, bei denen 1 als Summand auftritt und in solche, bei denen
saĚmtliche Summanden groĚĂer als 1 sind. Lassen wir bei den Zerlegungen des
ersten Typs einen Summanden 1 weg, so bleibt eine Zerlegung von n â 1 in
genau k â 1 Summanden und dafuĚr gibt es P (n â 1, k â 1) MoĚglichkeiten. Bei den
Zerlegungen des zweiten Typs koĚnnen wir von jedem Summanden 1 abziehen und
erhalten so eine Zerlegung von n â k in genau k Summanden, wofuĚr es P (n â k, k)
MoĚglichkeiten gibt.


5.2

Rekursion und erzeugende Funktionen

Hat man ein von einem ganzzahligen Parameter n abhaĚngendes Anzahlproblem,
so erhaĚlt man fuĚr die Anzahlen eine Zahlenfolge a0 , a1 , a2 , . . . und diese Folge
kann man (wie jede Zahlenfolge) als Koeffizientenfolge einer Potenzreihe
â
X

an tn

n=0

ansehen. Die Idee, auf diese Weise Potenzreihen bei der LoĚsung kombinatorischer
Aufgaben einzusetzen, geht auf Laplace zuruĚck. Falls auĂerdem die Potenzreihe
eine Funktion darstellt, die man in geschlossener Form angeben kann, so hat man
damit die MoĚglichkeit, die Information uĚber die Zahlenfolge a0 , a1 , a2 , . . . in Form
eines geschlossenen Funktionsausdrucks zu speichernâ. Nicht selten kann man
â
auf dem Umweg uĚber die Potenzreihen aus einer rekursiven Darstellung einer
Folge eine explizite Darstellung gewinnen.

256

Mathematik fuĚr Informatiker

M. Skutella

Im Folgenden werden wir zunaĚchst formale Potenzreihen und erzeugende
Funktionen definieren. Es werden einige Eigenschaften des Rings der formalen
Potenzreihen besprochen. Dann wird als Beispiel die Rekursionsgleichung fuĚr die
sogenannten Catalanâschen Zahlen geloĚst. Im zweiten Teil dieses Abschnitts werden, ausgehend vom Beispiel der Fibonacci-Zahlen, allgemein lineare Rekursionsgleichungen besprochen und unter gewissen Voraussetzungen vollstaĚndig geloĚst.
Im Folgenden bezeichne K immer den KoĚrper der reellen oder komplexen
Zahlen, also K â {R, C}.

5.2.1

Formale Potenzreihen und erzeugende Funktionen

Die in der Einleitung angesprochene Methode der Potenzreihen scheint zunaĚchst
einmal Analysiskenntnisse vorauszusetzen. Man kann jedoch Potenzreihen auch
als rein algebraischen Begriff einfuĚhren, entsprechend der EinfuĚhrung des Polynomringes R[t] in Kapitel 2, Abschnitt 2.2.2. Allerdings koĚnnen wir nicht einfach t
als ein neu hinzukommendes Element mit vertraĚglichenâ Recheneigenschaften
â
ansehen, denn unendliche Summen sind nicht definiert. Ein Polynom
n
X

ak tk

k=0

aus K[t] kann man als eine Abbildung Ď â K(N0 ) auffassen (mit Ď(k) = ak
fuĚr k = 0, . . . , n), also als eine Abbildung von N0 nach K mit Ď(k) = 0 fuĚr fast
alle k â N0 . Das heiĂt, dass nur fuĚr endlich viele k gilt Ď(k) 6= 0. LaĚsst man diese
Zusatzforderung an die Abbildung Ď weg, so erhaĚlt man die Menge KN0 aller Abbildungen von N0 nach K, die entsprechend eineindeutig mit Potenzreihen identifiziert werden koĚnnen. Wir wissen bereits aus Kapitel 3, Abschnitt 3.2.1, dass KN0
einen K-Vektorraum bildet. Die folgende Definition besagt, dass man KN0 sogar
als Ring auffassen kann.
Definition 5.2.1 (Ring der formalen Potenzreihen). Die Menge KN0 aller Abbildungen Ď : N0 â K bildet mit den VerknuĚpfungen
(ÎťĎ)(k) := Îť Âˇ Ď(k)

fuĚr Îť â K, k â N0 ,

(Ď + Ď)(k) := Ď(k) + Ď(k)

fuĚr Îť â K, k â N0 ,

einen K-Vektorraum und mit der Multiplikation
X
(Ď Âˇ Ď)(k) :=
Ď(i) Âˇ Ď(j)
i+j=k

einen Ring mit Einselement, den Ring K[[t]] der formalen Potenzreihen uĚber dem
KoĚrper K.

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

257

Die UĚberpruĚfung der Ringeigenschaften bereitet uĚberhaupt keine Schwierigkeiten. Wir ersparen uns daher die Einzelheiten.
Bemerkung.
(i) Eine formale Potenzreihe, als Abbildung Ď : N0 â K durch n 7â an definiert,
ist nichts anderes als eine (unendliche) Zahlenfolge a0 , a1 , a2 , . . . und wird
analog zu den Polynomen geschrieben als
â
X

an tn ,

n=0

unabhaĚngig von jeder Konvergenzforderung. Das Symbol t ist dann ein Rechensymbol und die Schreibweise dadurch begruĚndet, dass das formale Rechnen mit solchen Potenzreihen genau dem Rechnen mit Reihen entspricht.
Die Multiplikation entspricht genau dem Cauchyprodukt von Reihen (siehe
auch Satz 4.1.34):
!
!
â
â
â
X
X
X
X
n
n
cn tn mit cn =
ai b j .
an t Âˇ
bn t
=
n=0

n=0

n=0

i+j=n

Diese Koeffizienten ergeben sich beim formalen sukzessiven Ausmultiplizieren der beiden Reihen und dem anschlieĂenden Neuordnen der Glieder
nach Potenzen von t. Das bei Polynomen gewohnte Einsetzen von KoĚrperelementen x an Stelle von t (der Einsetzungshomomorphismus, siehe Kapitel 2, Abschnitt 2.2.4) hat dann allerdings im Allgemeinen keinen Sinn, da
das Einsetzen von Null verschiedener Elemente Konvergenzbetrachtungen
erforderlich macht.
(ii) Der Polynomring K[t] ist ein Unterring von K[[t]].
Definition 5.2.2 (Erzeugende Funktion). Es sei (an )nâN0 eine Folge aus KN0 .
Dann heiĂt die formale Potenzreihe
â
P
(i) a(t) :=
an tn die (gewoĚhnliche) erzeugende Funktion und
n=0

(ii) A(t) :=

â
P
n=0

an n
t
n!

die exponentielle erzeugende Funktion

der Zahlenfolge (an )nâN0 .
Im Falle der Konvergenz koĚnnen wir also a(t) bzw. A(t) als Funktion von t â K
auffassen und dann auch SaĚtze der Analysis zu Hilfe nehmen, z.B. das gliedweise
Differenzieren (siehe Satz 4.3.7). Insbesondere wird die exponentielle erzeugende Funktion mit dem Hintergedanken definiert, auch bei einer schnell wachsenden Zahlenfolge (an ) eine nicht nur fuĚr t = 0 konvergente Reihe zu erhalten.

258

Mathematik fuĚr Informatiker

M. Skutella

TatsaĚchlich kann man aber etwa die Differentiation auch als rein algebraische
Operation betrachten. Wir kommen darauf an Hand von Beispielen gleich noch
zuruĚck.
Beispiel. Es sei an := 1 fuĚr alle n â N0 . Dann ist die erzeugende Funktion die
bekannte geometrische Reihe mit dem Konvergenzradius 1:
a(t) =

â
X

tn =

n=0

1
.
1ât

DieseP
Gleichung ist aber auch rein algebraisch sinnvoll; sie kann so gelesen werden,
n
dass â
n=0 t und 1 â t im Ring K[[t]] invertierbare Elemente und zueinander
invers sind. Die entsprechende Gleichung
!
â
X
tn Âˇ (1 â t) = 1
n=0

bestaĚtigt man durch Ausmultiplizieren gemaĚĂ Definition 5.2.1 (Cauchyprodukt).
In Verallgemeinerung des Beispiels gilt:
Lemma 5.2.3 (Invertierbare Potenzreihen). FuĚr die Menge K[[t]]â der invertierbaren Potenzreihen (also der Einheiten im Ring aller Potenzreihen) gilt
(â
)
X
K[[t]]â =
an tn â K[[t]] a0 6= 0 .
n=0

Beweis. Zu ââ: Ist
â

Pâ

an tn invertierbar, so existiert
!
!
â
â
X
X
an tn Âˇ
bn tn
= 1 .

n=0

n=0

Pâ

n
n=0 bn t

mit

n=0

Dann gilt nach Definition des Produktes in K[[t]], dass a0 b0 = 1 und daher a0 6= 0.
Zu ââ: Man setzt b0 := a0â1 und definiert dann iterativ
â
n
1 X
bn := â
Âˇ
ak bnâk .
a0 k=1
P
n
Mit der dadurch definierten formalen Potenzreihe â
n=0 bn t gilt dann
!
!
â
â
X
X
an tn Âˇ
bn tn
= 1 .
n=0

Damit ist der Beweis abgeschlossen.

n=0



Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

259

Wir diskutieren einige weitere Beispiele erzeugender Funktionen.
Beispiele.
(i) P
FuĚr die Folge an := n! hat die gewoĚhnliche erzeugende Funktion a(t) :=
â
n
n=0 n!t keinen positiven Konvergenzradius (d.h. sie konvergiert fuĚr kein
t 6= 0). Dagegen ist die exponentielle erzeugende Funktion
A(t) :=

â
X
n!
n=0

n!

â
X

tn =

tn =

n=0

1
,
1ât

also wieder die geometrische Reihe. Dies demonstriert die Wirkung der Faktoren n!1 in der exponentiellen erzeugenden Funktion als Konvergenz erâ
zeugende Faktorenâ und macht deutlich, dass die exponentielle erzeugende
Funktion vor allem in Zusammenhang mit analytischen Betrachtungen von
Interesse ist.
(ii) Die erzeugende Funktion von an := n erhaĚlt man mittels gliedweiser Differentiation aus dem Beispiel oben:
!0
â
â
â
X
X
X
n
nâ1
n
a(t) : =
nt = t Âˇ
nt
= tÂˇ
t
n=0


= tÂˇ

n=1

1
1ât

0
=

n=0

t
.
(1 â t)2

Diese Differentiation kann auch als rein algebraische Operation wie folgt definiert werden:
Definition 5.2.4 (Formale Derivation). Die formale Derivation oder formale
Ableitung wird definiert als Abbildung
D : K[[t]] ââ K[[t]]
â
â
P
P
.
an tn 7ââ
(n + 1)an+1 tn
n=0

n=0

Bemerkung. Man rechnet leicht nach, dass die uĚblichen wohlbekannten Differentiationsregeln gelten, d.h. es gilt fuĚr alle a(t), b(t) â K[[t]] und alle Îť, Âľ â K
insbesondere


D Îť Âˇ a(t) +Âľ Âˇ b(t) = Îť Âˇ D a(t)) + Âľ Âˇ D(b(t)
(LinearitaĚt),

D a(t) Âˇ b(t) = b(t) Âˇ D a(t) + a(t) Âˇ D b(t)
(Produktregel).
Die Gleichung a(t) = t/(1 â t)2 aus dem letzten Beispiel koĚnnen wir in K[[t]]
2
auch lesen als a(t)
Âˇ (1 â t)
= t und in dieser Form auch einfach durch Ausmul
Pâ
n
tiplizieren von
Âˇ (1 â t)2 bestaĚtigen.
n=0 nt

260

Mathematik fuĚr Informatiker

M. Skutella


Beispiel. Es sei m â N fest. FuĚr an := m
(beachte, dass an = 0 fuĚr n > m)
n
haben wir gemaĚĂ Satz 5.1.8 als erzeugende Funktion
â
m  
X
X
m n
n
a(t) :=
an t =
t = (1 + t)m .
n
n=0
n=0
Hier besteht offenbar eine besonders enge Verwandtschaft zwischen der kombinatorischen Fragestellung, die die Zahlenfolge definiert, und der erzeugenden Funktion dieser Folge. Wir werden dies noch analysieren und fuĚr Verallgemeinerungen
nutzen.
ZunaĚchst wollen wir an einem Beispiel skizzieren, wie man die erzeugende
Funktion einsetzen kann, um fuĚr eine kombinatorisch definierte Zahlenfolge zu
einer expliziten Formel zu kommen.
Definition 5.2.5 (Catalanâsche Zahlen). Die Anzahl cn der MoĚglichkeiten, ein nfaches Produkt einer Menge (M, Âˇ) mit einer VerknuĚpfung, die weder kommutativ
noch assoziativ zu sein braucht, durch Klammerung auf die Produktbildung von
Paaren zuruĚckzufuĚhren (ohne diese Klammerung ist das n-fache Produkt fuĚr n >
2 in einer nichtassoziativen Struktur gar nicht erklaĚrt), wird die n-te Catalanâsche
Zahl genannt. Dabei ist c0 := 0 und c1 := 1.
Zur Illustration seien die KlammerungsmoĚglichkeiten fuĚr 2 â¤ n â¤ 4 explizit
aufgelistet:
n = 2 : (x1 x2 )

c2 = 1

n = 3 : ((x1 x2 )x3 ), (x1 (x2 x3 ))

c3 = 2

n=4:

(((x1 x2 )x3 )x4 ), ((x1 x2 )(x3 x4 )), ((x1 (x2 x3 ))x4 ),
(x1 ((x2 x3 )x4 )), (x1 (x2 (x3 x4 )))

c4 = 5

Eine andere Interpretation dieser Anzahl cn ist die Anzahl verschiedener binaĚrer
â
WurzelbaĚumeâ mit n Enden (BlaĚttern). Abbildung 5.3 zeigt diese verschiedenen WurzelbaĚume fuĚr n = 4 in der Reihenfolge, wie sie den eben aufgelisteten
Klammerungen entsprechen.
Satz 5.2.6.
(i) Die Catalanâschen Zahlen cn genuĚgen der Rekursion
cn =

n
X

ck Âˇ cnâk

fuĚr n âĽ 2.

k=0

(ii) Ihre erzeugende Funktion genuĚgt der Funktionalgleichung
c(t)2 â c(t) + t = 0
und wird als reelle Funktion fuĚr x â¤ 1/4 gegeben durch
â
c(x) = 12 (1 â 1 â 4x) .

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

261

Abbildung 5.3: Die fuĚnf binaĚren WurzelbaĚume mit 4 BlaĚttern.
(iii) FuĚr n âĽ 1 werden die Catalanâschen Zahlen gegeben durch


1 2n â 2
cn =
.
n nâ1
Beweis. Zu (i): Die aĚuĂerste Klammer eines n-fachen, mit Klammern versehenen
Produktes verklammert ein k-faches Produkt mit einem (nâk)-fachen, wobei k â
{1, . . . , n â 1} ist. FuĚr diese Teilprodukte
gibt es ck bzw. cnâk MoĚglichkeiten und
Pnâ1
damit fuĚr das gesamte Produkt
k=1 ck Âˇ cnâk MoĚglichkeiten. Wegen c0 = 0 kann
P
man das auch in der Form nk=0 ck Âˇ cnâk schreiben.
Zu (ii): Diese Rekursionsformel setzt man nun in die formale Potenzreihe ein,
wozu man, da die Formel ja nur fuĚr n âĽ 2 gilt, die ersten beiden Summanden
abtrennt:
!
â
â
â
n
X
X
X
X
c(t) =
cn tn = c0 + c1 t +
cn tn = t +
ck cnâk tn .
n=0

n=2

n=2

k=0

Man erkennt, dass die rechts stehende Reihe gerade das Produkt der erzeugenden
Funktion mit sich selbst ist, also gilt
c(t) = t + c(t)2 .
Nun greift die reelle Analysis ein. FuĚr solche x â R, fuĚr die c(x) definiert ist
(d.h., fuĚr die die Reihe konvergiert), hat
â man jetzt eine quadratische Gleichung
fuĚr c(x), deren AufloĚsung c(x) = (1 â 1 â 4x)/2
â liefert (da c(0) = 0).
Zu (iii): Man kann die Funktion c(x) = (1 â 1 â 4x)/2 als Potenzreihe darstellen, deren Koeffizienten dann die angegebene explizite Gestalt der cn liefert.
Wir verzichten auf weitere Details des Beweises.


262

Mathematik fuĚr Informatiker

M. Skutella

Nicht immer erhaĚlt man die erzeugende Funktion so einfach wie hier. Das
Verfahren, eine Rekursion (falls vorhanden) in die formale Potenzreihe einzusetzen, um damit eine Funktionalgleichung fuĚr die erzeugende Funktion zu gewinnen, laĚsst sich jedoch stets anwenden. Bei manchen kombinatorischen Problemen
kann man jedoch die erzeugende Funktion direkt aus der Problemstellung heraus gewinnen. Wir greifen dazu das obige Beispiel der Binomialkoeffizienten noch
einmal auf.

Beispiel. Nach Satz 5.1.10 oder Satz 5.1.7 ist nk die Anzahl der MoĚglichkeiten, k (verschiedene) Elemente aus einer n-elementigen Menge auszuwaĚhlen. Es
seien u1 , . . . , un beliebige reelle Zahlen und t eine Unbestimmte. Dann ist
(1 + u1 t) Âˇ (1 + u2 t) Âˇ . . . Âˇ (1 + un t)
ein Polynom aus R[t] und Ausmultiplizieren fuĚhrt zu
1 + (u1 + Âˇ Âˇ Âˇ + un ) Âˇ t
+ (u1 u2 + u1 u3 + Âˇ Âˇ Âˇ + u1 un + u2 u3 + Âˇ Âˇ Âˇ + unâ1 un ) Âˇ t2
+ Âˇ Âˇ Âˇ + (u1 u2 . . . un ) Âˇ tn .
Der Term tk hat also als Koeffizienten die Summe aller Auswahlen (als Produkte
geschrieben) von k verschiedenen Elementen aus der Zahlenmenge {u1 , u2 , . . . , un }.
Setzen wir alle uk gleich 1, so gibt daher dieser Koeffizient die Anzahl der kAuswahlen an, naĚmlich nk .
Diese Idee wird in dem folgenden Satz verallgemeinert.
Satz 5.2.7 (Erzeugende Funktion fuĚr Auswahlen). Die erzeugende Funktion fuĚr
die Anzahl derjenigen Auswahlen mit Wiederholung aus n verschiedenen Elementen, bei denen die Vielfachheit des k-ten Elementes (fuĚr k â {1, . . . , n}) aus einer
gegebenen Zahlenmenge Nk â N0 stammt, wird gegeben durch
!
n
X
Y
tj
.
k=1

jâNk

Beweis. Es seien wieder u1 , . . . , un beliebige reelle Zahlen. Beim Ausmultiplizieren von
!
!
!
X
X
X
u1 j tj Âˇ
u2 j tj Âˇ . . . Âˇ
un j tj
jâN1

jâN2

jâNn

erhaĚlt man eine Summe oder (falls wenigstens eine der Zahlenmengen Nj unendlich ist) eine Reihe, in welcher der Koeffizient von tk die Summe all derjenigen kAuswahlen mit Wiederholung (wie oben als Produkt geschrieben) von u1 , . . . , un
ist, bei denen die HaĚufigkeit von uj (j â {1, . . . , n}) durch eine Zahl aus der Menge Nj gegeben wird. Setzen wir wieder alle uj gleich 1, so gibt der so entstehende
Koeffizient von tk gerade die Anzahl dieser k-Auswahlen an.


Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

263

Beispiel. Was ist die Anzahl der 4-Auswahlen von a, b, c, d, wenn die HaĚufigkeit
des Auftretens von a genau 0 oder 3, von b 0, 1 oder 2, von c beliebig und von
d kongruent 1 modulo 3 ist? Nach Satz 5.2.7 ist die erzeugende Funktion fuĚr die
Anzahl solcher k-Auswahlen mit Wiederholung
(1 + t3 ) Âˇ (1 + t + t2 ) Âˇ (1 + t + t2 + t3 + . . . ) Âˇ (t + t4 + t7 + t10 + . . . )
= t + 2t2 + 3t3 + 5t4 + . . . .
Die Anzahl der Auswahlen der gesuchten Art ist also 5, was man hier auch leicht
durch explizite Angabe dieser Auswahlen uĚberpruĚfen kann. In geschlossener Form
schreibt sich diese erzeugende Funktion uĚbrigens als
t + t4
.
1 â 2t + t2
Korollar 5.2.8. Die erzeugende Funktion fuĚr die Anzahl ak aller k-Auswahlen
mit Wiederholung aus einer Menge mit n Elementen ist
!n

â 
â
X
X
n+kâ1 k
1
j
t .
t
=
=
k
(1 â t)n
j=0
k=0
Beweis. Die Behauptung folgt mit Satz 5.1.10, wonach wir diese Anzahl ja schon
kennen. Man kann diese Potenzreihenentwicklung fuĚr (1 â t)ân aber auch direkt
beweisen (zum Beispiel mit Induktion nach n unter Benutzung der Rekursionsformel fuĚr die Binomialkoeffizienten), was dann einen neuen Beweis fuĚr diese Anzahl
liefert.

FuĚr weitere Beispiele dieser Art, bei denen man die erzeugende Funktion direkt aus der Fragestellung heraus konstruieren kann, sei auf die Literatur uĚber
Kombinatorik verwiesen.

5.2.2

Lineare Rekursionsgleichungen

Wir wollen die bei der Behandlung der Catalanâschen Zahlen aufgetretenen rekursiv definierten Zahlenfolgen aufgreifen und hierzu zunaĚchst ein weiteres Beispiel
einer besonders wichtigen Zahlenfolge, die Fibonacci-Zahlen betrachten. Wir haben diese Zahlenfolge bereits in Kapitel 2, Abschnitt 2.1.3 betrachtet, fuĚhren sie
jetzt jedoch mittels einer kombinatorischen Definition ein.
Definition 5.2.9 (Fibonacci-Zahlen). Die n-te Fibonacci-Zahl fn (n âĽ 2) ist
die Anzahl aller 0/1-Sequenzen der LaĚnge n â 2, die keine benachbarten Einsen
enthalten. Ferner setzen wir f0 := 0 und f1 := 1.
Bemerkung. Es ist also f2 = 1 (die leere Sequenz), f3 = 2, f4 = 3, f5 = 5, f6 = 8
etc.

264

Mathematik fuĚr Informatiker

M. Skutella

Satz 5.2.10 (Fibonacci-Zahlen). FuĚr die Fibonacci-Zahlen gilt:
(i) fn = fnâ1 + fnâ2 fuĚr n âĽ 2.
t
.
1 â t â t2
 â n k
j
(iii) Eine explizite Darstellung ist fn = 12 + â15 1+2 5
.
(ii) Die erzeugende Funktion ist f (t) =

Beweis. Zu (i): Es sei Mn die Menge aller 0/1-Sequenzen der LaĚnge n â 2, die
(Îľ)
der angegebenen Bedingung genuĚgen, und davon Mn die Menge derjenigen, die
an der letzten Stelle die Ziffer Îľ haben, fuĚr Îľ â {0, 1}. Es ist demnach
Mn = Mn(0) âŞË Mn(1)

und somit fn = |Mn | = |Mn(0) | + |Mn(1) | .

(0)

Nun ist |Mn | = |Mnâ1 |, da AnhaĚngen einer 0 an eine Sequenz der LaĚnge n â 3
(0)
eine bijektive Abbildung Mnâ1 â Mn liefert. Ist die letzte Stelle einer Sequenz
der LaĚnge n â 2 mit einer 1 besetzt, so ist der VorgaĚnger notwendigerweise eine 0
(1)
(0)
und das liefert |Mn | = |Mnâ1
| = |Mnâ2 |. Aus beidem folgt die Behauptung.
Pâ
n
Zu (ii): Es sei f (t) =
n=0 fn t die erzeugende Funktion der FibonacciZahlen. Wie bei den Catalanâschen Zahlen erhalten wir durch Umformen und
Einsetzen der Rekursion eine Funktionalgleichung fuĚr f (t), die hier linear ist und
damit durch AufloĚsung ohne weiteres die geschlossene Form von f (t) liefert:
f (t) =

â
X

fn tn = t +

â
X

fnâ1 tn +

fnâ2 tn

n=2

n=2

n=0

â
X

2

= t + t Âˇ f (t) + t Âˇ f (t) .
Damit erhaĚlt man
f (t) =

t
.
1 â t â t2

Zu (iii): Die Nullstellen des Nenners sind (â1 Âą
wir durch Partialbruchzerlegung
1
f (t) = â
5

1

1â

â
1+ 5
t
2

â

1

1â

â

5)/2 und damit erhalten

â
1â 5
t
2

!
.

P
1
n n
Nun ist 1âat
= â
n=0 a t und dies koĚnnen wir auf beide BruĚche in der Klammer
anwenden. Damit folgt
â !n
â !n !
1
1+ 5
1â 5
fn = â
â
.
2
2
5
 â n
Da auĂerdem â15 1â2 5
< 12 fuĚr alle n â N und fn eine ganze Zahl ist, folgt
die Behauptung.


Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

265

Dass die Auswertung der Rekursion hier bei den Fibonaccizahlen so problemlos funktioniert, liegt an der besonders einfachen Bauart dieser Rekursion: Sie
ist linear und homogen und hat konstante Koeffizienten (NaĚheres siehe folgende
Definition). FuĚr solche FaĚlle besprechen wir gleich noch ein vereinfachtes Auswertungsverfahren. Zur Demonstration der Zugkraft obiger Methode wollen wir
sie jedoch noch auf ein einfaches inhomogenes Beispiel anwenden.
Beispiel. Die Folge (an ) sei rekursiv definiert durch an = 2anâ1 + 1 mit dem
Startwert a0 = 0. Durch Einsetzen dieser Rekursion in die erzeugende Funktion
erhalten wir
a(t) =

â
X

n

an t

n=0

=

â
X

n

(2anâ1 + 1)t

= tÂˇ

n=1

â
X

(2an + 1)tn

n=0

t
= 2t Âˇ a(t) +
.
1ât
Daher gilt
1
1
t
= â
+
(1 â t)(1 â 2t)
1 â t 1 â 2t
â
â
â
X
X
X
n
n n
= â
t +
2 t =
(2n â 1)tn .

a(t) =

n=0

n=0

n=0

Also ist an = 2n â 1.
Definition 5.2.11 (Lineare Rekursion). Eine lineare Rekursion r-ten Grades mit
konstanten Koeffizienten ist eine Gleichung
(R)

an = c1 anâ1 + c2 anâ2 + Âˇ Âˇ Âˇ + cr anâr + c0

fuĚr n âĽ r,

mit c0 , . . . , cr â K und cr 6= 0. Im Fall c0 = 0 heiĂt sie homogen, sonst inhomogen.
Ersetzen wir c0 durch 0, so nennen wir das die zugehoĚrige homogene Rekursion
und bezeichnen sie mit (R0 ). Das Polynom
Ď(t) := tr â c1 trâ1 â Âˇ Âˇ Âˇ â cr
heiĂt charakteristisches Polynom der Rekursion.
Bemerkung. ZunaĚchst haben wir hier absichtlich keine Startwerte vorgegeben.
DemgemaĚĂ ist die LoĚsung nicht eindeutig und (R0 ) hat jedenfalls an = 0 fuĚr
alle n â N0 als LoĚsung. Neben dem charakteristischen Polynom betrachten wir
noch
Ď(t) := 1 â c1 t â Âˇ Âˇ Âˇ â cr tr .
Dieses Polynom erhaĚlt man formal aus Ď(t) in der Form Ď(t) = tr Ď(1/t).

266

Mathematik fuĚr Informatiker

M. Skutella

Satz 5.2.12 (LoĚsung homogener linearer Rekursionen). Die LoĚsungsmenge der
homogenen Rekursion, aufgefasst als Menge formaler Potenzreihen,
(â
)
X
L(R0 ) :=
an tn | (an )nâN0 genuĚgt (R0 )
n=0

ist ein r-dimensionaler Unterraum von K[[t]]. Es gilt
L(R0 ) = Ď(t)â1 Âˇ K[t]r ,
wobei K[t]r die Menge aller Polynome aus K[t] vom Grade kleiner gleich r â 1
einschlieĂlich dem Nullpolynom bezeichnet.
Beweis.
cr 6= 0 ist Ď(t) â K[[t]]â , das heiĂt Ď(t)â1 existiert. Es sei
Pâ Wegen
k
nun k=0 bk t â Ď(t) Âˇ K[[t]], also
â
X

bk tk = (1 â c1 t â Âˇ Âˇ Âˇ â cr tr ) Âˇ

â
X

an tn ,

n=0

k=0

wobei a(t) â K[[t]] beliebig ist. Dann ist

Pâ

n=0

an tn â L(R0 ) aĚquivalent zu

bk = ak â c1 akâ1 â Âˇ Âˇ Âˇ â cr akâr = 0

fuĚr k âĽ r

und das ist die Behauptung.



Bemerkung. Man sieht nun auch, wie man zu gegebenen Startbedingungen a0 , . . . , arâ1
sofort die erzeugende Funktion in geschlossener Darstellung bekommt. Sie wird
gegeben durch
a(t) =

b0 + b1 t + Âˇ Âˇ Âˇ + brâ1 trâ1
1 â c1 t â Âˇ Âˇ Âˇ â cr tr

mit
b0 = a0
b1 = a1 â c1 a0
..
.
brâ1 = arâ1 â c1 arâ2 â Âˇ Âˇ Âˇ â crâ1 a0 .
Aus dieser geschlossenen Form die explizite Darstellung der an zu gewinnen,
erfordert dann Partialbruchzerlegung. Im Falle der Fibonacci-Zahlen hatten wir
insofern GluĚck, als der Nenner Ď(t) = 1 â t â t2 zwei verschiedene (und sogar
reelle) Nullstellen hatte. Dies ist der einfachste Fall.
Satz 5.2.13 (LoĚsung inhomogener linearer Rekursionen).

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

267

(i) an = q n ist eine LoĚsung von (R0 ) genau dann, wenn Ď(q) = 0.
(ii) Hat Ď(t) r paarweise verschiedene, reelle Nullstellen q1 , . . . , qr , so ist
an = Îť1 q1n + Âˇ Âˇ Âˇ + Îťr qrn

mit Îť1 , . . . , Îťr â K

die allgemeine LoĚsung von (R0 ).
Bemerkung. Man kann bei Satz 5.2.13 (ii) natuĚrlich auch mit komplexen Nullstellen von Ď(t) arbeiten, bekommt damit aber auch komplexe Werte fuĚr die an .
Beweisskizze. Zu (i): Diese AĚquivalenz ergibt sich unmittelbar durch Einsetzen.
Zu (ii): Nach (i) sind dies jedenfalls LoĚsungen, da die Linearkombination von
LoĚsungen ja wieder eine LoĚsung ist. In Frage steht also nur, ob man auf diese
Weise alle LoĚsungen bekommt. Dazu ist nur zu zeigen (wenn wir wieder zur
Potenzreihenschreibweise uĚbergehen), dass die Potenzreihen
â
X

qi n tn

mit i â {1, . . . , r}

n=0

den ganzen Raum L(R0 ) aufspannen. Da wir schon wissen (vgl. Satz 5.2.12), dass
dieser Raum L(R0 ) die Dimension r hat, genuĚgt hierfuĚr die lineare UnabhaĚngigkeit der Vektoren
ďŁŤ
ďŁś
1
ďŁŹ qi ďŁˇ
ďŁŹ
ďŁˇ
ďŁŹ q2 ďŁˇ
fuĚr i â {1, . . . , r}.
ďŁŹ i ďŁˇ
ďŁŹ .. ďŁˇ
ďŁ­ . ďŁ¸
qirâ1
Wir gehen nicht auf weitere Details ein.



Bemerkung.
(i) Bei einem Rekursionsproblem mit vorgegebenen Startwerten nimmt man
die Anpassung der allgemeinen LoĚsung durch geeignete Wahl der Parameter Îť1 , . . . , Îťr â K. Bei der Fibonacci-Rekursion etwa haben wir
â
â
1+ 5
â1 + 5
q1 = â
und
q2 =
2
2
als allgemeine LoĚsung, also an = Îť1 q1 n + Îť2 q2 n . Um die Startwerte a0 = 0
und a1 = 1 zu realisieren, waĚhlt man
1
Îť1 = â
5

und

1
Îť2 = â â .
5

268

Mathematik fuĚr Informatiker

M. Skutella

(ii) Wir erwaĚhnen noch ohne Beweis, dass man beim Auftreten einer k-fachen
Nullstelle qj von Ď(t) neben qjn auch noch nqj n , . . . , nkâ1 qj n als LoĚsungen
der homogenen Rekursion hat. Die allgemeine LoĚsung ist dann also Linearkombination von solchen Termen.
Bei inhomogenen Rekursionen wird die Sache schwieriger. AĚhnlich zum Fall
linearer Gleichungssysteme gilt der folgende Satz.
Satz 5.2.14 (LoĚsung inhomogener linearer Rekursionen). Der LoĚsungsraum L(R)
(als Unterraum von K[[t]]) einer inhomogenen Rekursion ist ein Translat des
LoĚsungsraumes
L(R0 ) der zugehoĚrigen homogenen Rekursion. Das heiĂt, gilt
Pâ
n
n=0 an t â L(R), so ist
L(R) =

â
X

an tn + L(R0 ) .

n=0

Dies verifiziert man wie bei linearen Gleichungssystemen.
L(R0 ) kann man nach den vorgenannten Methoden allgemein bestimmen und
das Problem der Bestimmung von L(R) reduziert sich damit auf die Aufgabe,
irgendeine LoĚsung zu finden. DafuĚr gibt es keine in jedem Fall zugkraĚftige Methode, man verwendet spezielle LoĚsungsansaĚtze in AbhaĚngigkeit vom Aussehen
des StoĚrgliedes c0 . Ein haĚufiger Fall ist etwa der, dass c0 ein Polynom in n ist
(was insbesondere den Fall einschlieĂt, dass c0 eine Konstante ist). Ein hierfuĚr
bewaĚhrter LoĚsungsansatz ist, fuĚr an ebenfalls ein Polynom vom gleichen Grade
mit zunaĚchst unbestimmten Koeffizienten anzusetzen und dann die Koeffizienten
durch Einsetzen zu bestimmen. Statt allgemeiner Formulierung rechnen wir nur
ein Beispiel.
Beispiel. Es sei an = 2anâ1 + n2 â 2n + 2 und wir suchen die LoĚsung zum
Startwert a0 = 1. Die homogene Rekursion an = 2anâ1 hat die allgemeine
LoĚsung an = Îť2n und zur Bestimmung einer LoĚsung der inhomogenen Rekursion machen wir den Ansatz an = xn2 + yn + z. Dies in die Rekursion eingesetzt
fuĚhrt zur Gleichung

xn2 + yn + z = 2 x(n â 1)2 + y(n â 1) + z + y(n â 1) + z + n2 â 2n + 2 .
Nach Potenzen in n ergibt das
(x + 1)n2 + (y â 4x â 2)n + (2x â 2y + z + 2) = 0 .
Dies kann nur dann fuĚr alle n â N gelten, wenn die Koeffizienten der Potenzen
von n einzeln verschwinden:
ďŁą
x+1 = 0
ďŁ´
ďŁ´
ďŁ˛
y â 4x â 2 = 0
ďŁ´
ďŁ´
ďŁł
2x â 2y + z + 2 = 0

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella
1

269

3

5
2
4

Abbildung 5.4: Ein Graph mit Knotenmenge V = {1, 2, 3, 4, 5} und Kantenmenge
E = {e1 , . . . , e8 }, mit e1 = {1, 2}, e2 = {1, 3}, e3 = {1, 5}, e4 = {2, 3}, e5 = {2, 4},
e6 = {2, 5}, e7 = {3, 5} und e8 = {4, 5}.
Dieses Gleichungssystem hat die eindeutige LoĚsung x = â1, y = â2 und z = â4.
Somit ist an = Îť2n â n2 â 2n â 4 die allgemeine LoĚsung und die gewuĚnschte
Anfangsbedingung wird mit Îť = 5 befriedigt.

5.3

Graphentheorie

Graphen spielen in sehr vielen Bereichen eine wichtige Rolle. Sie dienen unter
anderem zur Modellierung von Netzen, wie etwa Computernetzen, Verkehrsnetze,
Telekommunikationsnetze etc.

5.3.1

Grundlegende Begriffe der Graphentheorie

Definition
5.3.1 (Endliche Graphen). Es sei V eine endliche Menge und E â

{u, v} | u, v â V und u 6= v . Dann heiĂt das Tupel G = (V, E) ein (endlicher)
Graph mit Knotenmenge V und Kantenmenge E. Ist e = {u, v} â E, so sagt
man, dass die Kante e die beiden Knoten u und v verbindet; u und v heiĂen auch
Endknoten von e. Die Knoten u und v heiĂen in diesem Fall adjazent und man
sagt, dass die Kante e = {u, v} inzident zu u und v ist.
Beispiel. Ein Beispiel eines Graphen ist in Abbildung 5.4 abgebildet.
Bemerkung. Ein Graph ist nach Definition also nichts anderes als eine endliche
Menge V zusammen mit einer symmetrischen Relation auf V : Zwei Knoten aus V
stehen in Relation zueinander, falls sie durch eine Kante verbunden sind.
Bemerkung. Man kann die Definition von Graphen in verschiedene Richtungen verallgemeinern, um unterschiedlichen AnspruĚchen bei der Modellierung von
Netzwerken gerecht zu werden.
(i) So kann man beispielsweise Kanten zulassen, die einen Knoten mit sich
selbst verbinden (sogenannte Schleifen) oder man kann erlauben, dass mehrere Kanten dasselbe Knotenpaar verbinden (sogenannte parallele Kanten).

270

Mathematik fuĚr Informatiker

M. Skutella

5

1

4

2

3

Abbildung 5.5: Der vollstaĚndige Graph auf fuĚnf Knoten K5 .
(ii) Man kann an Stelle der ungerichteten Kanten auch gerichtete Kanten (oder
BoĚgen) betrachten. In diesem Fall spricht man von gerichteten Graphen oder
Digraphen D = (V, A) mit Knotenmenge V und Bogenmenge A â V Ă V .
Eine Kante a = (u, v) â A ist dann von Knoten u â V nach Knoten v â V
gerichtet.
Der Einfachheit halber beschraĚnken wir uns hier auf den in Definition 5.3.1 beschriebenen Fall einfacher Graphen.

Die Anzahl der Kanten eines Graphen auf n Knoten ist offenbar durch n2 nach
oben beschraĚnkt. Graphen, die diese obere Schranke erreichen, heiĂen vollstaĚndig.
Definition 5.3.2 (VollstaĚndige Graphen). Ein Graph G = (V, E) heiĂt vollstaĚndig,
falls jedes Knotenpaar durch eine
 Kante verbunden wird, das heiĂt, falls fuĚr die
Anzahl der Kanten |E| = |V2 | gilt. Den vollstaĚndigen Graphen auf n Knoten
bezeichnet man mit Kn .
Beispiel. In Abbildung 5.5 ist der vollstaĚndige Graph mit fuĚnf Knoten dargestellt.
Wir fuĚhren als naĚchstes den Begriff des Grads eines Knoten ein.
Definition 5.3.3 (Knotengrad). Es sei G = (V, E) ein Graph. Der Grad d(u)
eines Knotens u â V ist die Anzahl der zu diesem Knoten inzidenten Kanten,
also
d(u) := |{e â E | u â e}| .
Beispiel. Wir betrachten noch mal den Graphen aus Abbildung 5.4. Der Knoten
1 hat Grad 3, Knoten 2 hat Grad 4, Knoten 3 hat Grad 3, Knoten 4 hat Grad
2 und Knoten 5 hat Grad 4. Im K5 aus Abbildung 5.5 hat jeder Knoten Grad 4.
Ganz allgemein hat im Kn jeder Knoten den Grad n â 1.

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

271

Satz 5.3.4. Es sei G = (V, E) ein Graph. Dann gilt
X
d(u) = 2|E| .
uâV

Beweis.
P Man uĚberzeugt sich leicht davon, dass jede Kante aus E in der Summe uâV d(u) genau zweimal gezaĚhlt wird, naĚmlich einmal fuĚr jeden der beiden
Endknoten der Kante.

Alternativ kann man Satz 5.3.4 auch mit Hilfe von Satz 5.1.2 (doppeltes
AbzaĚhlen) beweisen.
Beispiel. Der Graph G = (V, E) in Abbildung 5.4 besteht aus |V | = 5 Knoten
und |E| = 8 Kanten. Wenn wir die Knotengrade addieren, erhalten wir
5
X

d(i) = 3 + 4 + 3 + 2 + 4 = 16 = 2|E|.

i=1

Als naĚchstes beschaĚftigen wir uns mit Kantenfolgen und Wegen in Graphen.
Definition 5.3.5 (Kantenfolgen, Wege, Kreise). Es sei G = (V, E) ein Graph
und v0 , . . . , vn â V mit ei := {viâ1 , vi } â E fuĚr i = 1, . . . , n.
(i) Dann heiĂt e1 , . . . , en eine Kantenfolge von v0 zu vn . Ist v0 = vn , so heiĂt
die Kantenfolge geschlossen.
(ii) Sind die Knoten v0 , . . . , vn paarweise verschieden, so nennt man die Kantenfolge e1 , . . . , en auch Weg oder Pfad (von v0 nach vn ).
(iii) Ist die Kantenfolge e1 , . . . , en geschlossen und sind die Knoten v1 , . . . , vn
paarweise verschieden, so handelt es sich um einen Kreis.
Beispiel. In dem in Abbildung 5.5 dargestellten K5 ist
{1, 2}, {2, 4}, {4, 5}, {5, 1}, {1, 4}, {4, 3}
eine Kantenfolge von Knoten 1 zu Knoten 3. Diese Kantenfolge ist jedoch kein
Weg, da Knoten mehrfach besucht werden. Die Kantenfolge
{1, 2}, {2, 4}, {4, 5}, {5, 3}
ist ein Weg von Knoten 1 zu Knoten 3. HaĚngt man noch die Kante {3, 1} an, so
erhaĚlt man den Kreis
{1, 2}, {2, 4}, {4, 5}, {5, 3}, {3, 1} .
Siehe dazu auch Abbildung 5.6.

272

Mathematik fuĚr Informatiker
5

M. Skutella

5

1

4

2

5

1

3

4

2

3

1

4

2

3

Abbildung 5.6: Eine Kantenfolge, ein Weg und ein Kreis im K5 .
1

6
7

8

2

9

5

10
3

4

Abbildung 5.7: Eine Kantenfolge von 1 nach 10 und eine von 10 nach 8 liefert
eine Kantenfolge von 1 nach 8.
Lemma 5.3.6. Es sei G = (V, E) ein Graph und u, v, w â V . Ist e1 , . . . , en
eine Kantenfolge von u nach v und f1 , . . . , fm eine Kantenfolge von v nach w, so
ist e1 , . . . , en , f1 , . . . , fm eine Kantenfolge von u nach w.
Beweis. Folgt sofort aus Definition 5.3.5.



Beispiel. In dem in Abbildung 5.7 dargestellten Graphen sind
{1, 2}, {2, 3}, {3, 7}, {7, 9}, {9, 10},
und
{10, 2}, {2, 1}, {1, 6}, {6, 5}, {5, 4}, {4, 8},
zwei Wege von 1 nach 10 bzw. von 10 nach 8, also insbesondere Kantenfolgen.
Zusammen liefern Sie eine Kantenfolge von 1 nach 8, welche aber kein Weg mehr
ist.
Satz 5.3.7. Es sei G = (V, E) ein Graph und u, v â V zwei Knoten. Gibt es eine
Kantenfolge von u nach v, so gibt es auch einen Weg von u nach v.

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

273

Beweis. Wir betrachten eine Kantenfolge von u nach w, die aus der minimalen
Anzahl Kanten besteht. Diese kuĚrzeste Kantenfolge sei
{v0 , v1 }, {v1 , v2 }, . . . , {vnâ1 , vn } ,
mit v0 = u und vn = w. Diese Kantenfolge ist ein Weg von u nach w. Denn
andernfalls gibt es i, j â {0, 1, . . . , n} mit i < j und vi = vj . Dann erhaĚlt man
jedoch durch AbkuĚrzenâ eine kuĚrzere Kantenfolge von u nach w, naĚmlich
â
{v0 , v1 }, {v1 , v2 }, . . . , {viâ1 , vi }, {vj , vj+1 }, . . . , {vnâ1 , vn } .
Dies ist ein Widerspruch zur Wahl der urspruĚnglichen Kantenfolge.



Definition 5.3.8 (Teilgraph). Es sei G = (V, E) ein Graph. Der Graph G0 =
(V 0 , E 0 ) heiĂt Teilgraph von G, falls V 0 â V und E 0 â E gilt. Der Teilgraph G0
heiĂt aufspannend, falls V 0 = V gilt.
Bemerkung. Man beachte, dass (V 0 , E 0 ) nicht fuĚr jede moĚgliche Wahl von Teilmengen V 0 â V und E 0 â E einen Teilgraphen von G = (V, E) darstellt. Damit (V 0 , E 0 ) ein Graph ist, muss naĚmlich gelten, dass e â V 0 fuĚr alle e â E 0 .
Beispiele.
(i) Die Abbildung 5.8 zeigt drei Teilgraphen G1 = (V1 , E1 ) mit
V1 = {1, 2, 3, 4, 5}, E1 = {{5, 1}, {5, 2}, {5, 3}, {5, 4}},
G2 = (V2 , E2 ) mit
V2 = {1, 2, 4, 5}, E2 = {{5, 1}, {1, 4}}
und G3 = (V3 , E3 ) mit
V3 = {1, 2, 3, 4, 5}, E3 = â
von K5 .
(ii) Die Abbildung 5.9 zeigt keinen Graphen, also insbesondere keinen Teilgraphen von K5 . Die untere mit Knoten 3 inzidente Kante {2, 3} ist unzulaĚssig,
weil Knoten 2 nicht in der Knotenmenge des vermeintlichen Teilgraphen
enthalten ist.

5.3.2

ZusammenhaĚngende Graphen und Euler-Touren

Definition 5.3.9 (ZusammenhaĚngende Graphen). Ein Graph G = (V, E) heiĂt
zusammenhaĚngend, falls es zu jedem Knotenpaar u, v â V einen Weg von u nach v
gibt.

274

Mathematik fuĚr Informatiker
5

G1

G2

1

4

2

5

G3

1

3

M. Skutella

4

5

1

2

4

2

3

Abbildung 5.8: Drei Teilgraphen von K5
5

1

4

3

Abbildung 5.9: Kein Teilgraph von K5 , Knoten 2 fehlt.
Satz 5.3.10 (Zusammenhangskomponenten). Es sei G = (V, E) ein Graph.
Dann gibt es eine Partition der Knotenmenge V in Teilmengen V1 , . . . , Vk und eine Partition der Kantenmenge E in Teilmengen E1 , . . . , Ek , so dass Gi = (Vi , Ei )
ein zusammenhaĚngender Teilgraph von G ist, fuĚr i = 1, . . . , k. Die Teilgraphen G1 , . . . , Gk sind bis auf ihre Reihenfolge eindeutig und heiĂen Zusammenhangskomponenten von G. Ist G zusammenhaĚngend, so ist k = 1.
Beispiel. Der Graph G = (V, E) in Abbildung 5.10 besteht aus drei Zusammenhangskomponenten G1 = (V1 , E1 ), G2 = (V2 , E2 ) und G3 = (V3 , E3 ) mit
V1 = {5, 6, 7}, V2 = {2, 3, 4}, V3 = {1}, E1 = {e5 , e6 , e7 }, E2 = {e2 , e3 , e4 } und
E3 = â.
Beweis von Satz 5.3.10. Wir betrachten die folgende AĚquivalenzrelation auf der
Knotenmenge V : Zwei Knoten u und v stehen in Relation zueinander, falls es
einen Weg von u nach v gibt. Man uĚberpruĚft leicht, dass es sich dabei tatsaĚchlich
um eine AĚquivalenzrelation handelt.
Es seien V1 , . . . , Vk die AĚquivalenzklassen dieser AĚquivalenzrelation und Ei :=
{e â E | e â Vi } fuĚr i = 1, . . . , k. Dann bilden V1 , . . . , Vk eine Partition von V
und wir muĚssen noch zeigen, dass auch E1 , . . . , Ek eine Partition von E bilden.
Da diese Kantenteilmengen nach Definition paarweise disjunkt sind, bleibt zu

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella
G1
6

e7

275

G2
e6
4

2
e4

G3
5

e2
1

e3
7

e5
3

Abbildung 5.10: Ein Graph G mit drei Zusammenhangskomponenten G1 , G2 , G3 .
zeigen, dass ihre Vereinigung die gesamte Kantenmenge E ist. Wir nehmen an,
dass es eine Kante e = {u, v} â E \ (E1 âŞ Âˇ Âˇ Âˇ âŞ Ek ) gibt. Dann muĚssen die beiden
Endknoten u und v in unterschiedlichen Knotenteilmengen liegen, also u â Vi
und v â Vj mit i 6= j. Das fuĚhrt aber zu einem Widerspruch, da zwei durch eine
Kante verbundene Knoten nach Definition in Relation zueinander stehen und
deshalb nicht unterschiedlichen AĚquivalenzklassen angehoĚren koĚnnen.
Wir zeigen als naĚchstes, dass die so definierten Teilgraphen Gi = (Vi , Ei )
zusammenhaĚngend sind, fuĚr i = 1, . . . , k. Nach Definition gibt es zu jedem Knotenpaar u, v â Vi einen Weg von u nach v in G. Man sieht leicht, dass dieser
Weg nur Knoten aus Vi besuchen kann und daher alle seine Kanten aus Ei sind.
Folglich handelt es sich dabei auch um einen Weg von u nach v in Gi .
Die Eindeutigkeit der Teilgraphen G1 , . . . , Gk kann man wie folgt zeigen. Wir
nehmen an, dass G0i = (Vi0 , Ei0 ), i = 1, . . . , k 0 , auch den Bedingungen des Satzes
genuĚgen. Da G0i zusammenhaĚngend ist, gibt es zwischen je zwei Knoten aus Vi0
einen Weg in G0i und damit auch in G. Folglich muss Vi0 eine Teilmenge einer
AĚquivalenzklasse Vj sein. Um zu zeigen, dass Vi0 = Vj gilt, nehmen wir im Widerspruch dazu an, dass es ein ` 6= i gibt, so dass auch V`0 â Vj gilt. Es sei u â Vi0
und v â V`0 . Da u, v â Vj , gibt es einen Weg von u nach v in G. Dieser Weg
muss offenbar eine Kante e enthalten, die aus Vi0 hinausfuĚhrt, das heiĂt, genau
einer der beiden Endknoten von e ist in Vi0 . Dann kann aber die Kante e nicht
0
in Ei0 und auch in keiner anderen Kantenteilmenge Em
, m 6= i, liegen. Dies ist
ein Widerspruch.
Wir haben also gezeigt, dass Vi0 = Vj gelten muss. Genauso kann man jetzt
zeigen, dass dann Ei0 = Ej gilt. Damit ist der Beweis abgeschlossen.

Definition 5.3.11 (Eulerâsche Graphen, Euler-Touren). Ein zusammenhaĚngender Graph G = (V, E) heiĂt Eulerâsch, falls es eine geschlossene Kantenfolge gibt,
die jede Kante aus E genau einmal enthaĚlt. Eine solche geschlossene Kantenfolge
heiĂt Euler-Tour.
Beispiel. Der Graph G aus Abbildung 5.11 ist Eulerâsch. Eine Euler-Tour ist

276

Mathematik fuĚr Informatiker
2

M. Skutella

10
1

3

9
11

4

8
6
5

7

Abbildung 5.11: Ein Eulerâscher Graph G.
z.B. durch die Kantenfolge
{1, 2}, {2, 3}, {3, 4}, {4, 5}, {5, 6}, {6, 7}, {7, 8}, {8, 9}, {9, 10},
{10, 1}, {1, 6}, {6, 11}, {11, 1}
gegeben. Wenn wir aus G die Kante {6, 12} oder die Kante {11, 12} entfernen,
ist G nicht mehr Eulerâsch. Man kann zwar Kantenfolgen finden, die keine Kante
zweimal enthalten, aber keine geschlossene Kantenfolge mit dieser Eigenschaft.
Satz 5.3.12 (Satz von Euler). Ein zusammenhaĚngender Graph G = (V, E) ist
genau dann Eulerâsch, wenn der Grad jedes Knotens aus V gerade ist.
Beispiel. Der Graph G aus Abbildung 5.11 illustriert den obigen Satz. In G hat
jeder Knoten geraden Grad. Der Knoten 1 hat Grad null, die Knoten 11 und 6
haben Grad vier und alle uĚbrigen Knoten haben Grad zwei. Wenn wir aus G etwa
die Kante {11, 12} entfernen, verringert sich der Grad von Knoten 11 um eins
und G verliert die Euler-Eigenschaft.
Der folgende Beweis von Satz 5.3.12 liefert nicht nur die Existenz einer EulerTour in G, sondern gleichzeitig auch einen Algorithmus zur Berechnung einer
Euler-Tour.
Beweis von Satz 5.3.12. Ist G Eulerâsch, so muss der Grad jedes Knotens gerade
sein, da die Eulertour bei jedem Besuch eines Knotens v â V genau zwei zu v
inzidente Kanten verwendet.
Wir nehmen im Folgenden an, dass G zusammenhaĚngend ist und der Grad
jedes Knotens gerade ist. Ausgehend von einem beliebigen Knoten v â V konstruieren wir eine Kantenfolge, die keine Kante aus E mehr als einmal benutzt.
Sind wir mit der Kantenfolge von v ausgehend an einem Knoten u angekommen,
waĚhlen wir, wenn moĚglich, eine zu u inzidente Kante, die noch nicht benutzt
wurde. Gibt es keine solche Kante mehr, so muss u = v sein. Denn andernfalls

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

277

Abbildung 5.12: Ein Wald.
enthaĚlt unsere Kantenfolge bislang eine ungerade Zahl von Kanten, die zu u inzident sind. Da der Grad von u gerade ist, muss es also eine weitere Kante geben,
die noch nicht benutzt wurde. Auf diese Weise erhalten wir also eine geschlossene
Kantenfolge e1 , . . . , ek , in der keine Kante zweimal vorkommt. Sind das bereits
alle Kanten aus E, so sind wir fertig.
Es sei also im Folgenden e0 â E \ {e1 , . . . , ek }. Wir zeigen zunaĚchst, dass es
einen Knoten v â (e1 âŞ Âˇ Âˇ Âˇ âŞ ek ) gibt und eine zu v inzidente Kante e, die nicht
in der geschlossenen Kantenfolge enthalten ist. Ist einer der beiden Endknoten u
von e0 in e1 âŞÂˇ Âˇ ÂˇâŞek enthalten, so koĚnnen wir v = u und e = e0 setzen. Andernfalls
gibt es einen Weg von u zu einem Knoten w â (e1 âŞ Âˇ Âˇ Âˇ âŞ ek ). Dann sei v der erste
Knoten aus e1 âŞ Âˇ Âˇ Âˇ âŞ ek auf diesem Weg und e die Kante des Weges, auf der v
erreicht wird.
LoĚschen wir die Kanten der geschlossenen Kantenfolge e1 , . . . , ek aus E, so
besitzt der dadurch entstandene Teilgraph G0 von G noch immer die Eigenschaft,
dass alle Knoten in G0 geraden Grad haben. Folglich koĚnnen wir wie oben ausgehend von v eine geschlossene Kantenfolge in G0 konstruieren und an geeigneter
Stelle in die zuvor konstruierte geschlossene Kantenfolge e1 , . . . , ek einsetzen, so
dass eine laĚngere geschlossene Kantenfolge entsteht.
Das beschriebene Vorgehen wiederholt man so lange, bis die geschlossene Kantenfolge alle Kanten von G enthaĚlt. Da sich die LaĚnge der geschlossenen Kantenfolge bei jeder Iteration vergroĚĂert, ist man nach endlich vielen Schritten am Ziel
angelangt.


5.3.3

BaĚume und WaĚlder

Definition 5.3.13 (BaĚume, WaĚlder). Ein Graph G = (V, E) heiĂt Wald, falls G
keinen Kreis enthaĚlt. Ein zusammenhaĚngender Wald heiĂt Baum.
Beispiele.
(i) Die Abbildung 5.12 zeigt einen unzusammenhaĚngenden, kreisfreien Graphen, also einen Wald. Die Zusammenhangskomponenten sind natuĚrlich
ebenfalls kreisfrei und somit BaĚume.
(ii) Die Abbildung 5.13 zeigt einen zusammenhaĚngenden, kreisfreien Graphen,
also einen Baum.

278

Mathematik fuĚr Informatiker

M. Skutella

Abbildung 5.13: Ein Baum.

Abbildung 5.14: Klassische Darstellung eines Baumes.
(iii) BaĚume werden klassisch wie in Abbildung 5.14 dargestellt und dann als
WurzelbaĚume bezeichnet. Ein Wurzelbaum ist ein Baum T = (V, E) zusammen mit einem ausgezeichneten Knoten w â V , welchen man als Wurzel bezeichnet. Dieser wird in Darstellungen dann meist als hoĚchster Knoten eingezeichnet und ist in Abbildung 5.14 rot dargestellt. Alle Wege von
der Wurzel zu einem anderen Knoten verlaufen die ganze Zeit abwaĚrts. Die
Knoten, die unterhalb eines bestimmten Knotens liegen und von diesem aus
uĚber eine Kante erreicht werden koĚnnen, heiĂen Nachfolger dieses Knotens.

(iv) In Abbildung 5.15 haben alle Knoten des Wurzelbaumes hoĚchstens zwei
Nachfolger. Ein solcher Baum wird als binaĚrer Baum oder als binaĚrer Wurzelbaum bezeichnet.
Satz 5.3.14. Jeder zusammenhaĚngende Graph enthaĚlt einen Baum als aufspannenden Teilgraphen. So ein Teilgraph wird auch spannender Baum oder aufspannender Baum genannt.
Beweis. Es sei G = (V, E) ein zusammenhaĚngender Graph. Ist G kreisfrei, so
ist G selbst ein aufspannender Baum und wir sind fertig. Anderfalls sei e1 , . . . , ek
ein Kreis in G. Wir betrachten den aufspannenden Teilgraphen G0 von G der
durch LoĚschen der Kante ek entsteht.
Wir behaupten, dass G0 zusammenhaĚngend ist. Es seien u, v â V beliebig.
Dann gibt es einen Weg f1 , . . . , f` von u nach v in G. Ist fi 6= ek fuĚr i = 1, . . . , `,

Kapitel 5

G. Wegner, H. M. MoĚller, R. Scharlau, M. Skutella

279

Abbildung 5.15: Ein binaĚrer Wurzelaum.
so ist dies auch ein Weg in G0 . Andernfalls sei fi = ek fuĚr ein i â {1, . . . , `}. Dann
ist
f1 , . . . , fiâ1 , e1 , . . . , ekâ1 , fi+1 , . . . , f`
oder
f1 , . . . , fiâ1 , ekâ1 , . . . , e1 , fi+1 , . . . , f`
eine Kantenfolge von u nach v in G0 . Wegen Satz 5.3.7 gibt es dann auch einen
Weg von u nach v in G0 . Folglich ist G0 zusammenhaĚngend.
Durch das LoĚschen von ek hat man den Kreis e1 , . . . , ek zerstoĚrt. Ist G0 kreisfrei, so sind wir fertig. Andernfalls wiederholt man das beschriebene Vorgehen so
lange, bis alle Kreise zerstoĚrt sind. Da G nur endlich viele Kanten enthaĚlt, endet
das Verfahren nach endlich vielen Schritten.

Definition 5.3.15 (BlaĚtter in BaĚumen). Ein Knoten eines Baumes mit Knotengrad 1 heiĂt Blatt.
Beispiel. In Abbildung 5.14 sind die BlaĚtter des Wurzelbaumes blau eingefaĚrbt.
Satz 5.3.16. Es sei G = (V, E) ein Baum mit mindestens zwei Knoten, das
heiĂt |V | âĽ 2. Dann besitzt G mindestens zwei BlaĚtter.
Beweis. Es sei e1 , . . . , ek ein laĚngster Weg in G. Dieser Weg fuĚhrt von einem Knoten u â V zu einem anderen Knoten v â V . Wir behaupten, dass u und v BlaĚtter
sind. Denn angenommen d(u) âĽ 2, so gibt es auĂer e1 eine weitere zu u inzidente
Kante e0 . Der andere Endknoten von e kann kein Knoten des Weges e1 , . . . , ek
sein, da dadurch ein Kreis in G geschlossen wuĚrde. Folglich ist e0 , e1 , . . . , ek ein
Weg, der laĚnger ist als e1 , . . . , ek . Dies ist ein Widerspruch. FuĚr den Knoten v
argumentiert man analog.

Satz 5.3.17. Ein Baum G = (V, E) besitzt genau eine Kante weniger als Knoten,
das heiĂt |E| = |V | â 1.

280

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Wir beweisen die Behauptung durch vollstaĚndige Induktion uĚber die
Anzahl der Knoten |V |. Die Behauptung ist offenbar wahr fuĚr den eindeutigen
Baum mit einem Knoten ({v}, â). Es sei jetzt G = (V, E) ein Baum mit |V | âĽ 2.
Wegen Satz 5.3.16 besitzt G ein Blatt v â V mit inzidenter Kante e â E. Der
Teilgraph G0 von G, der durch LoĚschen von v und e entsteht ist offenbar zusammenhaĚngend und kreisfrei, also ein Baum. Damit besitzt G0 nach Induktionsvoraussetzung genau einen Knoten mehr als Kanten. Folglich gilt dieselbe
Eigenschaft fuĚr G.

Bemerkung. Die Satzaussage ist sehr intuitiv und laĚsst sich an Abbildung 5.14
gut veranschaulichen. Wir starten mit dem Wurzelknoten (rot markiert). FuĚr jede
Kante, die wir an die Wurzel anhaĚngen moĚchten, muĚssen wir auch einen zusaĚtzlichen Knoten, den Endknoten der jeweiligen Kante, zur Knotenmenge hinzufuĚgen.
Diese Knoten sind dann entweder BlaĚtter (blau markiert) oder es werden weitere
Kanten und ebensoviele Knoten angefuĚgt. Dies geschieht solange, bis nur noch
BlaĚtter angefuĚgt werden. Es muĚssen also zur Wurzel ebensoviele Knoten wie Kanten angefuĚgt werden und es gibt stets einen Knoten mehr, als es Kanten gibt.
Korollar 5.3.18. Ist G = (V, E) ein zusammenhaĚngender Graph, so gilt |E| âĽ
|V | â 1.
Beweis. Die Behauptung folgt unmittelbar aus Satz 5.3.17 und Satz 5.3.14.



Definition 5.3.19 (Zyklomatische Zahl). Es sei G = (V, E) ein Graph. Dann
heiĂt
Î˝(G) := |E| â |V | + 1
die zyklomatische Zahl von G.
Korollar 5.3.20. Es sei G = (V, E) ein zusammenhaĚngender Graph. Dann
gilt Î˝(G) âĽ 0. Ist Î˝(G) = 0, so ist G ein Baum.
Beweis. Folgt unmitelbar aus Korollar 5.3.18 und Satz 5.3.17.



Korollar 5.3.21. Ist G = (V, E) ein Graph und Î˝(G) < 0, so ist G nicht zusammenhaĚngend.

Kapitel 6
Algebra
Wir setzen in diesem Kapitel die in Kapitel 2, Abschnitt 2.2 begonnene Behandlung grundlegender algebraischer Strukturen fort. Wir knuĚpfen dabei nahtlos an
den genannten Abschnitt an. Es empfiehlt sich daher, vor der LektuĚre dieses
Kapitels noch einmal die in Abschnitt 2.2 gelegten Grundlagen zu wiederholen.

6.1
6.1.1

Gruppentheorie
Untergruppen und erzeugte Untergruppen

Wir geben zunaĚchst die folgende aĚquivalente Charakterisierung von Untergruppen
an.
Lemma 6.1.1. Es sei (G, âŚ) eine Gruppe. Eine nichtleere Teilmenge H â G
bildet genau dann eine Untergruppe von G, wenn fuĚr alle x, y â H gilt, dass x âŚ
y â1 â H.
Beweis. Die Notwendigkeit der gegebenen Bedingung folgt sofort aus der Tatsache, dass eine Untergruppe selbst wieder eine Gruppe ist (siehe Lemma 2.2.7).
Um zu zeigen, dass die Bedingung auch hinreichend ist, muĚssen wir die drei Eigenschaften aus Definition 2.2.6 uĚberpruĚfen.
Zu (i): Da H nicht leer ist, gibt es ein x â H, so dass auch e = x âŚ xâ1 â H.
Zu (iii): FuĚr x â H gilt xâ1 = e âŚ xâ1 â H. Zu (ii): Es seien x, y â H. Nach dem
eben gezeigten gilt y â1 â H, so dass x âŚ y = x âŚ (y â1 )â1 â H.

Bemerkung. Wir verwenden wie bei Zahlen die folgende Notation. FuĚr ein Element x â G der Gruppe (G, âŚ) und eine natuĚrliche Zahl n â N sei xn die n-fache
VerknuĚpfung von x mit sich selbst. Weiter sei x0 := e und xân := (xâ1 )n = (xn )â1 .
Dann gilt fuĚr q, r â Z, dass xq âŚ xr = xq+r .
Lemma 6.1.2. Es sei (G, âŚ) eine Gruppe und x â G. Dann ist H := {xq | q â Z}
die kleinste Untergruppe von G, die x enthaĚlt. Wir schreiben auch H = hxi und
nennen hxi die von x erzeugte Untergruppe von G.
281

282

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Mit Hilfe von Lemma 6.1.1 zeigt man leicht, dass H eine Untergruppe
von G ist. Offenbar enthaĚlt jede Untergruppe U von G mit x â U auch alle
Elemente aus H.

Bemerkung. Alternativ kann man Lemma 6.1.2 beweisen, indem man feststellt,
dass hxi das Bild des durch Ď(q) := xq definierten Gruppenhomomorphismus
von (Z, +) nach (G, âŚ) ist. Nach Lemma 2.2.15 ist das Bild eines Gruppenhomomorphismus nach G eine Untergruppe von G.
Lemma 6.1.3. Es sei (G, âŚ) eine endliche Gruppe mit neutralem Element e
und x â G. Dann gilt fuĚr k := |hxi|, dass xk = e und
hxi = {x0 , x1 , x2 , x3 , . . . , xkâ1 } .
Man nennt hxi auch zyklische Untergruppe von G oder zyklische Gruppe.
Beweis. Da G endlich ist, gibt es 0 â¤ i < j mit xi = xj . Durch Multiplikation
dieser Gleichung mit xâi erhaĚlt man xjâi = e. Wir waĚhlen jetzt k 0 â N minimal
0
0
mit xk = e. Insbesondere gilt dann xâ1 = xk â1 . Aus der obigen Betrachtung
folgt fuĚr 0 â¤ i < j < k 0 , dass xi 6= xj . Es genuĚgt also zu zeigen, dass
0

hxi = {x0 , x1 , x2 , x3 , . . . , xk â1 } .
Dies folgt aus der Tatsache, dass xq = x(q

mod k0 )

fuĚr alle q â Z.



In Verallgemeinerung der in Lemma 6.1.2 eingefuĚhrten Sprechweise definieren
wir jetzt allgemeiner die von einigen Elementen aus G erzeugte Untergruppe
von G.
Satz 6.1.4. Es sei (G, âŚ) eine Gruppe und X eine nichtleere Teilmenge von G.
Dann ist

H := x1 q1 âŚ Âˇ Âˇ Âˇ âŚ xk qk | k â N, x1 , . . . , xk â X und q1 , . . . , qk â {1, â1}
die kleinste Untergruppe von G, die X enthaĚlt. Wir schreiben auch H = hXi und
nennen hXi die von X erzeugte Untergruppe von G.
Beweis. Man rechnet leicht nach, dass H eine Untergruppe von G ist. Es ist auch
klar, dass jede Untergruppe von G, die X enthaĚlt, auch alle Elemente aus H
enthalten muss.

Beispiele. In den UĚbungen haben wir bereits eine Diedergruppe, die Symmetriegruppe des Quadrats D4 â S4 , kennengelernt.
(i) Die von der Drehung Ď1 = (1, 2, 3, 4) erzeugte zyklische Untergruppe hĎ1 i
enthaĚlt auch alle anderen Drehungen aus D4 , das heiĂt
h(1, 2, 3, 4)i = {id, (1, 2, 3, 4), (1, 3) âŚ (2, 4), (1, 4, 3, 2)} .

Kapitel 6: Algebra

M. Skutella

283

(ii) Die von der Spiegelung Ď1 = (2, 4) erzeugte zyklische Untergruppe hĎ1 i
enthaĚlt hingegen nur die IdentitaĚt und Ď1 .
(iii) Nehmen wir zu Ď1 noch die Spiegelung Ď2 = (1, 3) hinzu, so erhalten wir
hĎ1 , Ď2 i = {id, Ď1 , Ď2 , Ď2 }, wobei Ď2 = (1, 3) âŚ (2, 4) die Drehung des Vierecks
um den Winkel Ď ist.
(iv) Wenn wir aber zu Ď1 die Drehung Ď1 hinzufuĚgen, erhalten wir neben allen
Drehungen auch alle Spiegelungen. Es gilt also hĎ1 , Ď1 i = D4 .
Die Gruppe D4 ist nicht die einzige Diedergruppe. Wir praĚzisieren dies im naĚchsten Abschnitt.
Untergruppen von Permutationsgruppen
Da wir uns bisher hauptsaĚchlich mit der symmetrischen Gruppe Sn beschaĚftigt
haben, diskutieren wir kurz noch einige konkrete Permutationsgruppen und wichtige Untergruppen von Permutationsgruppen.
(i) Die Gruppe (S2 , âŚ) enthaĚlt zwei Elemente und ist isomorph zu (Z2 , +).
(ii) Die Gruppe (S3 , âŚ) enthaĚlt sechs Elemente und kann als Diedergruppe D3 ,
der Gruppe der Spiegelungen und Drehungen eines gleichseitigen Dreiecks,
interpretiert werden. Diese ist nicht abelsch und daher von (Z6 , +) verschieden.
(iii) FuĚr n âĽ 3 erklaĚrt man die Diedergruppe Dn als Symmetriegruppe eines
regelmaĚĂigen n-Ecks. Nummeriert man dessen Eckpunkte fortlaufend mit
1, ..., n, so wird Dn als Untergruppe non Sn von den Permutationen


1 2
3
... n
Ď = (1, ..., n) und Ď =
1 n n â 1 ... 2
erzeugt. Hierbei entspricht Ď einer Drehung des regelmaĚĂigen n-Ecks um
den Winkel 2Ď
und Ď einer Spiegelung an der Symmetrieachse durch den
n
Punkt 1. Die Gruppe Dn enthaĚlt 2n Elemente.
Wir wollen nun noch die alternierende Gruppe An definieren. DafuĚr benoĚtigen
wir zunaĚchst den Begriff des Signums einer Permutation.
Definition 6.1.5. FuĚr eine Permutation Ď â Sn definiert man das Signum durch
sgn(Ď) :=

Y Ď(i) â Ď(j)
i<j

iâj

.

284

Mathematik fuĚr Informatiker

M. Skutella

Bemerkung. Das Signum kann die Werte 1 und â1 annehmen und gibt an, ob
sich die Permutation Ď als Produkt einer geraden oder ungeraden Anzahl von
Transpositionen schreiben laĚsst (eine Transposition ist ein Zykel der LaĚnge zwei,
also etwa (i, j)). Ist sgn(Ď) = 1, so heiĂt Ď gerade, sonst ungerade.
Beispiel. Es sei Ď = (1, 2) âŚ (3, 4) â S4 . Dann ist
sgn(Ď) =

(Ď(1)âĎ(2))(Ď(1)âĎ(3))(Ď(1)âĎ(4))(Ď(2)âĎ(3))(Ď(2)âĎ(4))(Ď(3)âĎ(4))
(1â2)(1â3)(1â4)(2â3)(2â4)(3â4)

(2 â 1)(2 â 4)(2 â 3)(1 â 4)(1 â 3)(4 â 3)
(1 â 2)(1 â 3)(1 â 4)(2 â 3)(2 â 4)(3 â 4)
= (â1) Âˇ 1 Âˇ 1 Âˇ 1 Âˇ 1 Âˇ (â1) = 1 .
=

Lemma 6.1.6. Die Abbildung sgn : Sn â {â1, 1} von der Gruppe (Sn , âŚ) in die
multiplikative Gruppe ({â1, 1}, Âˇ ) ist ein Gruppenhomomorphismus.
Beweis. Es seien Ď, Ď 0 â Sn beliebig. Dann gilt
sgn(Ď âŚ Ď 0 ) =

Y (Ď âŚ Ď 0 )(i) â (Ď âŚ Ď 0 )(j)
i<j

=

Y
i<j

iâj
(Ď âŚ Ď 0 )(i) â (Ď âŚ Ď 0 )(j) Ď 0 (i) â Ď 0 (j)
Âˇ
Ď 0 (i) â Ď 0 (j)
iâj



Y (Ď âŚ Ď 0 )(i) â (Ď âŚ Ď 0 )(j) Y Ď 0 (i) â Ď 0 (j)
Âˇ
=
Ď 0 (i) â Ď 0 (j)
iâj
i<j
i<j
= sgn(Ď) Âˇ sgn(Ď 0 ) ,
da die Menge {(Ď 0 (i), Ď 0 (j)) | 1 â¤ i < j â¤ n} in Bijektion zu den 2-elementigen
Teilmengen von {1, ..., n} steht.

(iv) Man definiert die alternierende Gruppe An â Sn durch
An := Kern(sgn) = {Ď â Sn | sgn(Ď) = 1} .
Die alternierenden Gruppen spielen in der Gruppentheorie eine wichtige
Rolle und sind deshalb eine ErwaĚhnung wert. Wir gehen aber nicht weiter
ins Detail.
(v) Die Kleinâsche Vierergruppe V4 â S4 ist gegeben durch
V4 = {id, (1, 2) âŚ (3, 4), (1, 3) âŚ (2, 4), (1, 4) âŚ (2, 3)} .
Es gilt V4 â D4 und V4 â A4 . Das heiĂt, V4 ist Untergruppe von D4 und
von A4 .

Kapitel 6: Algebra

6.1.2

M. Skutella

285

Gruppenordnungen und der Satz von Lagrange

Wir definieren als naĚchstes die Ordnung einer Gruppe und die Ordnung eines
Elements einer Gruppe.
Definition 6.1.7 (Gruppenordnung, Ordnung eines Gruppenelements). Es sei (G, âŚ)
eine Gruppe.
(i) EnthaĚlt G unendlich viele Elemente, so ist die Ordnung von G unendlich.
Andernfalls ist die Ordnung von G die KardinalitaĚt der Menge G.
(ii) Die Ordnung eines Elements x â G ist die Ordnung der von x erzeugten
Untergruppe hxi.
Beispiel. Die zyklischen Untergruppen hĎ1 i und hĎ1 i aus Beispiel 6.1.1 haben
Ordnung 4 bzw. 2. Also hat Ď1 die Ordnung 4 und Ď1 die Ordnung 2. Allgemeiner
ist die Ordnung einer Drehung aus der Diedergruppe Dn stets ein Teiler von n,
wogegen jede Spiegelung aus Dn die Ordnung 2 hat. Die Gruppe Dn hat die
Ordnung 2n.
Bemerkung. Nach Lemma 6.1.3 ist die Ordnung eines Gruppenelements x die
kleinste natuĚrliche Zahl k mit xk = e.
Ziel dieses Abschnitts ist es zu zeigen, dass fuĚr den Fall endlicher Gruppen die
Ordnung einer Untergruppe ein Teiler der Gruppenordnung ist. Dazu benoĚtigen
wir den Begriff der Nebenklasse.
Definition 6.1.8 (Nebenklassen). Es sei (G, âŚ) eine Gruppe und H eine Untergruppe von G. FuĚr x â G nennen wir die Menge
x âŚ H := {x âŚ y | y â H}
die zu x gehoĚrende Linksnebenklasse von H. Analog heiĂt
H âŚ x := {y âŚ x | y â H}
die zu x gehoĚrende Rechtsnebenklasse von H.
Beispiel. Die symmetrische Gruppe S3 ist gegeben durch
S3 = {id, (1, 2), (1, 3), (2, 3), (1, 2, 3), (1, 3, 2)}
und die alternierende Gruppe A3 â S3 ist gegeben durch
A3 = {id, (1, 2, 3), (1, 3, 2)} .

286

Mathematik fuĚr Informatiker

M. Skutella

Die zu (1, 2) gehoĚrende Linksnebenklasse von A3 stimmt mit der zugehoĚrigen
Rechtsnebenklasse uĚberein.
(1, 2) âŚ A3 =
=
=
=

{(1, 2) âŚ id, (1, 2) âŚ (1, 2, 3), (1, 2) âŚ (1, 3, 2)}
{(1, 2), (2, 3), (1, 3)}
{id âŚ(1, 2), (1, 3, 2) âŚ (1, 2), (1, 2, 3) âŚ (1, 2)}
A3 âŚ (1, 2) .

Die zu (1, 2, 3) gehoĚrenden Links- und Rechtsnebenklassen der zyklischen Untergruppe h(1, 2)i sind hingegen verschieden.
(1, 2, 3) âŚ h(1, 2)i = {(1, 2, 3) âŚ id, (1, 2, 3) âŚ (1, 2)}
= {(1, 2, 3), (1, 3)}
h(1, 2)i âŚ (1, 2, 3) = {id âŚ(1, 2, 3), (1, 2) âŚ (1, 2, 3)}
= {(1, 2, 3), (2, 3)} 6= (1, 2, 3) âŚ h(1, 2)i .
Die Nebenklassen einer Untergruppe koĚnnen insbesondere als Urbilder unter
Gruppenhomomorphismen auftauchen.
Satz 6.1.9. Es seien (G, âŚ) und (G0 , â˘) Gruppen und Ď : G â G0 ein Gruppenhomomorphismus. Ist y â Bild(Ď) und x â G mit Ď(x) = y, so ist
Ďâ1 (y) = x âŚ Kern(Ď) = Kern(Ď) âŚ x .
Beweis. Im Folgenden bezeichnen wir das neutrale Element von G mit e und
das neutrale Element von G0 mit f . Wir zeigen, dass Ďâ1 (y) = x âŚ Kern(Ď). Der
Beweis, dass Ďâ1 (y) = Kern(Ď) âŚ x funktioniert voĚllig analog.
ZunaĚchst einmal gilt Ďâ1 (y) â x âŚ Kern(Ď), da fuĚr x0 â Kern(Ď) gilt, dass
Ď(x âŚ x0 ) = Ď(x) â˘ Ď(x0 ) = y â˘ f = y .
Es bleibt also zu zeigen, dass Ďâ1 (y) â x âŚ Kern(Ď). Es sei also z â Ďâ1 (y), das
heiĂt Ď(z) = y. Wir muĚssen zeigen, dass es ein x0 â Kern(Ď) gibt mit z = x âŚ x0 .
Setzen wir x0 := xâ1 âŚ z, dann gilt x0 â Kern(Ď), da
Ď(x0 ) = Ď(xâ1 ) â˘ Ď(z) = Ď(x)â1 â˘ Ď(z) = y â1 â˘ y = f .
AuĂerdem ist
x âŚ x0 = x âŚ xâ1 âŚ z = e âŚ z = z .
Damit ist der Beweis abgeschlossen.



Als Folgerung aus Satz 6.1.9 koĚnnen wir jetzt ein einfaches Kriterium fuĚr die
InjektivitaĚt eines Gruppenhomomorphismus notieren.

Kapitel 6: Algebra

M. Skutella

287

Korollar 6.1.10. Es seien (G, âŚ) und (G0 , â˘) Gruppen und Ď : G â G0 ein
Gruppenhomomorphismus. Dann ist Ď genau dann ein Gruppenmonomorphismus
(d.h. injektiv), wenn Kern(Ď) nur das neutrale Element e von G enthaĚlt.
Beweis. Die Notwendigkeit des genannten Kriteriums fuĚr die InjektivitaĚt von Ď
ist klar, da nach Lemma 2.2.14 das neutrale Element e von G immer im Kern
von Ď enthalten ist.
Wir muĚssen noch zeigen, dass die Bedingung hinreichend ist. Wir nehmen
also an, dass Kern(Ď) = {e}. Es seien also x, x0 â G mit Ď(x) = Ď(x0 ). Wegen
Satz 6.1.9 gilt dann
{x} = x âŚ {e} = x âŚ Kern(Ď) = x0 âŚ Kern(Ď) = x0 âŚ {e} = {x0 } .
Folglich ist also x = x0 und der Beweis ist abgeschlossen.



Beispiel. Es sei Ď â Sn beliebig. Die Abbildung
Ď Ď : Sn â Sn ,

Ď 7â Ď âŚ Ď âŚ Ď â1

heiĂt Konjugation (mit Ď). FuĚr Ď1 , Ď2 â Sn gilt:
ĎĎ (Ď1 âŚ Ď2 ) =
=
=
=
=

Ď âŚ (Ď1 âŚ Ď2 ) âŚ Ď â1
Ď âŚ (Ď1 âŚ id âŚĎ2 ) âŚ Ď â1
Ď âŚ (Ď1 âŚ (Ď â1 âŚ Ď) âŚ Ď2 ) âŚ Ď â1
(Ď âŚ Ď1 âŚ Ď â1 ) âŚ (Ď âŚ Ď2 âŚ Ď â1 )
ĎĎ (Ď1 ) âŚ ĎĎ (Ď2 ) .

Folglich ist ĎĎ ein Gruppenhomomorphismus. Ist ĎĎ (Ď1 ) = id, so gilt Ď âŚ Ď1 = Ď
und wegen der Eindeutigkeit des neutralen Elements folgt Ď1 = id. Der Kern
von ĎĎ besteht also nur aus der IdentitaĚt und Korollar 6.1.10 liefert, dass ĎĎ
ein injektiver Gruppenhomomorphismus ist. Da ĎĎ die endliche Menge Sn in sich
selbst abbildet, ist ĎĎ also auch bijektiv und damit ein Gruppenisomorphismus.
Es sei noch bemerkt, dass fuĚr einen r-Zyklus Ď = (x1 , ..., xr ) â Sn die Gleichung
ĎĎ (Ď) = (Ď(x1 ), ..., Ď(xr ))
(6.1)
gilt.
Wir koĚnnen jetzt den wichtigen Satz von Lagrange beweisen.
Satz 6.1.11 (Satz von Lagrange). Es sei (G, âŚ) eine endliche Gruppe und H â G
eine Untergruppe von G. Dann teilt die Ordnung von H die Ordnung von G. Den
Quotienten |G|/|H| nennt man auch den Index der Untergruppe H in G.

288

Mathematik fuĚr Informatiker

M. Skutella

Beweis. Wir definieren auf G eine Relation âź durch
x âź y :ââ xâ1 âŚ y â H .
Man rechnet leicht nach, dass es sich hier um eine AĚquivalenzrelation handelt, deren AĚquivalenzklassen den Linksnebenklassen von H entsprechen. Es gilt naĚmlich
x âź y ââ y â x âŚ H .
Die Linksnebenklassen von H bilden also eine Partition der Menge G. Wir zeigen
noch, dass die KardinalitaĚt einer beliebigen Linksnebenklasse x âŚ H von H gleich
der KardinalitaĚt von H ist. Daraus folgt dann die Behauptung und der Index
von H in G entspricht der Anzahl der verschiedenen Linksnebenklassen von H.
Um zu zeigen, dass |H| = |x âŚ H|, konstruieren wir eine bijektive Abbildung
von H nach xâŚH. Diese Abbildung ist gegeben durch y 7â xâŚy. Die SurjektivitaĚt
folgt sofort aus der Definition. Auch die InjektivitaĚt sieht man leicht, da aus xâŚy =
x âŚ y 0 folgt, dass
y = xâ1 âŚ (x âŚ y) = xâ1 âŚ (x âŚ y 0 ) = y 0 .
Damit ist der Beweis abgeschlossen.



Korollar 6.1.12. Es sei (G, âŚ) eine endliche Gruppe mit neutralem Element e
und x â G. Dann ist die Ordnung von x ein Teiler der Gruppenordnung |G| und
es gilt g |G| = e.
Beweis. Die Ordnung k von x ist nach Definition die Ordnung der von x erzeugten
Untergruppe hxi von G und damit nach Satz 6.1.11 ein Teiler der Ordnung von G.
Es sei also ` â N mit |G| = k Âˇ `. Dann ist
x|G| = xkÂˇ` = (xk )` = e` = e .
Damit ist der Beweis abgeschlossen.



Beispiel. Die Ordnung der Drehung Ď = (1, 2, . . . , n) â Dn ist n, die einer
Spiegelung Ď â Dn ist 2 und Dn hat die Ordnung 2n. Die Diedergruppe Dn ist
Untergruppe von Sn und Sn hat die Ordnung n!. Die Ordnung eines beliebigen
Zykels der LaĚnge k in Sn ist k.

6.1.3

Der Homomorphiesatz fuĚr Gruppen

In diesem Abschnitt beweisen wir einen wichtigen Satz uĚber Gruppen und Gruppenhomomorphismen â den Homomorphiesatz. Wir beginnen mit der Definition
spezieller Untergruppen, die Normalteiler genannt werden.
Definition 6.1.13 (Normalteiler). Es sei (G, âŚ) eine Gruppe und N â G eine
Untergruppe. Dann ist N ein Normalteiler, falls x âŚ N = N âŚ x fuĚr alle x â G.

Kapitel 6: Algebra

M. Skutella

289

Beispiele.
(i) Ist G eine abelsche Gruppe, so ist jede Untergruppe H von G ein Normalteiler in G.
(ii) Wir haben schon gesehen, dass die zu (1, 2) gehoĚrenden Links- und Rechtsnebenklassen von A3 uĚbereinstimmen. Da |S3 |/|A3 | = 6/3 = 2 ist, gibt es
nach dem Satz von Lagrange nur zwei verschiedene Links- und Rechtsnebenklassen von A3 . Die zweite Links- bzw. Rechtsnebenklasse ist gegeben
durch id âŚA3 = A3 = A3 âŚ id. Die alternierende Gruppe A3 ist also ein Normalteiler vom Index 2 in S3 . Dies gilt entsprechend fuĚr alle alternierenden
Gruppen An (n > 1).
(iii) Die Kleinâsche Vierergruppe V4 ist ein Normalteiler in S4 . Dies verifiziert
man direkt durch Nachrechnen, oder elegant mit Hilfe von Gleichung (6.1).
Bemerkung. Um nachzuweisen, dass eine Untergruppe H einer Gruppe G ein
Normalteiler ist, genuĚgt es zu zeigen, dass fuĚr alle x â G gilt:
H â xHxâ1

oder alternativ xHxâ1 â H .

Das wichtigste Beispiel fuĚr Normalteiler wird durch den Kern eines Gruppenhomomorphismus gegeben.
Lemma 6.1.14. Es seien (G, âŚ) und (G0 , â˘) zwei Gruppen und Ď : G â G0 ein
Gruppenhomomorphismus. Dann ist Kern(Ď) ein Normalteiler von G.
Beweis. Die Aussage folgt sofort aus Satz 6.1.9.



Unser Ziel ist es zu zeigen, dass die Nebenklassen eines Normalteilers mit einer
natuĚrlich definierten VerknuĚpfung wieder eine Gruppe bilden.
Satz 6.1.15 (Faktorgruppe, Quotientengruppe). Es sei (G, âŚ) eine Gruppe und N â
G ein Normalteiler. Wir bezeichnen die Menge der Nebenklassen von N mit G/N .
Dann bildet G/N zusammen mit der durch
(x âŚ N ) â˘ (y âŚ N ) := (x âŚ y) âŚ N
definierten VerknuĚpfung â˘ eine Gruppe, die sogenannte Faktor- oder Quotientengruppe von G modulo N . Die kanonische Projektion Ď : G â G/N, x 7â x âŚ N
ist ein surjektiver Homomorphismus mit Kern(Ď) = N .
Beweis. Wir muĚssen zunaĚchst zeigen, dass die oben angegebene VerknuĚpfung â˘
wohldefiniert ist. Ist x âŚ N = x0 âŚ N und y âŚ N = y 0 âŚ N , so muss gelten, dass
(x âŚ y) âŚ N = (x0 âŚ y 0 ) âŚ N .

290

Mathematik fuĚr Informatiker

M. Skutella

Da x âŚ N = x0 âŚ N , gibt es ein x00 â N mit x = x0 âŚ x00 . Analog gibt es ein y 00 â N
mit y = y 0 âŚ y 00 . Da N ein Normalteiler ist, gilt
(x âŚ y) âŚ N = (x0 âŚ x00 âŚ y 0 âŚ y 00 ) âŚ N = (x0 âŚ x00 âŚ y 0 ) âŚ (y 00 âŚ N )

= (x0 âŚ x00 âŚ y 0 ) âŚ N = x0 âŚ (x00 âŚ y 0 ) âŚ N


= x0 âŚ N âŚ (x00 âŚ y 0 ) = x0 âŚ (N âŚ x00 ) âŚ y 0
= x0 âŚ (N âŚ y 0 ) = x0 âŚ (y 0 âŚ N )
= (x0 âŚ y 0 ) âŚ N .
Jetzt uĚberpruĚft man leicht, dass (G/N, â˘) eine Gruppe ist. Die VerknuĚpfung â˘
ist assoziativ, da âŚ assoziativ ist. Das neutrale Element von G/N ist e âŚ N = N ,
wobei e das neutrale Element von G bezeichnet. Das zu x âŚ N inverse Element
in G/N ist xâ1 âŚ N . Man erhaĚlt nun unmittelbar durch Nachrechnen, dass die
Projektion Ď ein Gruppenhomomorphismus ist. Die SurjektivitaĚt von Ď und die
Aussage Kern(Ď) = N folgen ebenfalls sofort.

Der Gruppenhomomorphismus Ď : G â G/N erfuĚllt eine sogenannte universelle Eigenschaft, die G/N bis auf Isomorphie eindeutig charakterisiert:
Satz 6.1.16 (Universelle Eigenschaft). Es seien (G, â˘) und (G0 , Âˇ) zwei Gruppen, Ď : G â G0 ein Gruppenhomomorphismus und N â G ein Normalteiler
mit N â Kern(Ď). Dann existiert ein eindeutig bestimmter Gruppenhomomorphismus Ď : G/N â G0 , mit Ď = Ď âŚ Ď. Man sagt dann auch, dass das Diagramm
G DD

DD
DD
Ď DD
!

Ď

/ G0
<
z
zz
z
zz
zz Ď

G/N

kommutiertâ. Es gilt Bild(Ď) = Bild(Ď), Kern(Ď) = Ď Kern(Ď) und Kern(Ď) =
â â1
Ď (Kern(Ď)).
Beweis. Wenn Ď existiert, so muss
Ď(x â˘ N ) = Ď(Ď(x)) = Ď(x)
fuĚr alle x â G gelten, also ist Ď eindeutig bestimmt.
Umgekehrt koĚnnen wir Ď durch die Gleichung Ď(x â˘ N ) = Ď(x) definieren,
wenn wir zeigen, dass Ď(x) unabhaĚngig von der Wahl des RepraĚsentanten x0 â
x â˘ N ist. Das heiĂt, wenn x â˘ N = x0 â˘ N ist, so muss Ď(x) = Ď(x â˘ N ) =
Ď(x0 â˘ N ) = Ď(x0 ) gelten.
Es sei also xâ˘N = x0 â˘N , fuĚr zwei Elemente x, x0 â G. Dann gilt xâ1 â˘x0 â N â
Kern(Ď) und somit f = Ď(xâ1 â˘x0 ) = Ď(x)â1 ÂˇĎ(x0 ), wobei f das neutrale Element
in G0 bezeichnet. Damit ist Ď(x) = Ď(x0 ). Dass Ď ein Gruppenhomomorphismus
ist, ergibt sich sofort aus der Gruppenstruktur von G/N oder, anders ausgedruĚckt,
aus der Tatsache, dass Ď ein Epimorphismus von Gruppen ist.

Kapitel 6: Algebra

M. Skutella

291

Die Gleichung Kern(Ď) = Ď â1 (Kern(Ď)) folgt aus der Tatsache, dass Ď die
Komposition von Ď mit Ď ist. Weiter gelten Bild(Ď) = Bild(Ď) und Kern(Ď) =
Ď(Kern(Ď)) aufgrund der SurjektivitaĚt von Ď.

Damit koĚnnen wir nun den Homomorphiesatz fuĚr Gruppen beweisen.
Korollar 6.1.17 (Homomorphiesatz). Ist Ď : G â G0 ein surjektiver Gruppenhomomorphismus, so ist G0 isomorph zu G/ Kern(Ď).
Beweis. Der Kern von Ď ist nach Lemma 6.1.14 ein Normalteiler in G. Nach
der universellen Eigenschaft der kanonische Projektion existiert also ein Gruppenhomomorphismus Ď : G/ Kern(Ď) â G0 . Wegen der SurjektivitaĚt von Ď und
Bild(Ď) = Bild(Ď) ist auch Ď surjektiv. Die InjektivitaĚt von Ď folgt sofort aus
Kern(Ď) = Ď(Kern(Ď))) = e âŚ Kern(Ď) zusammen mit Korollar 6.1.10, denn
e âŚ Kern(Ď) ist das neutrale Element in G/N .

Korollar 6.1.18. Es sei Ď : G â G0 ein Gruppenhomomorphismus. Dann ist
G/ Kern(Ď) isomorph zu Bild(Ď).
Beweis. Bild(Ď) ist als Untergruppe von G0 selbst eine Gruppe und somit ist Ď :
G â Bild(Ď) ein surjektiver Gruppenhomomorphismus. Der Homomorphiesatz
liefert also die Behauptung.

Beispiel. Es sei X eine Menge, Y â X eine Teilmenge, (G, Âˇ) eine Gruppe mit
neutralem Element e â G und (GX , âŚ) die Gruppe der G-wertigen Funktionen
auf X. Dann ist N := {f â GX | f (y) = e fuĚr alle y â Y } ein Normalteiler in
GX und G/N ist isomorph zu GY , denn die EinschraĚnkungsabbildung Ď : GX â
GY , f 7â f |Y ist ein surjektiver Gruppenhomomorphismus.

6.2

Ringtheorie

In diesem Abschnitt werden wir die Resultate uĚber Gruppen aus Abschnitt 6.1
sinngemaĚĂ auf Ringe zu uĚbertragen versuchen. Dazu empfiehlt es sich zunaĚchst,
sich die Definitionen und elementaren Einsichten uĚber Ringe, Unterringe und
Ringhomomorphismen aus Kapitel 2, Abschnitt 2.2 in Erinnerung zu rufen.
Bemerkung. Es seien (R, +, Âˇ) und (R0 , â, ) Ringe mit Nullelementen 0 â
R und 00 â R0 . Dann ist der Ringhomomorphismus Ď : R â R0 genau dann
injektiv, wenn Kern(Ď) := {x â R | Ď(x) = 00 } nur aus dem Nullelement 0 â R
besteht. Dies folgt unmittelbar aus Korollar 6.1.10, da Ď nach Definition auch ein
Gruppenhomomorphismus von (R, +) nach (R0 , â) ist.
Wir geben in dem folgenden Lemma eine Charakterisierung von Unterringen
an, die unmittelbar aus der entsprechenden Charakterisierung von Untergruppen
in Lemma 6.1.1 folgt.

292

Mathematik fuĚr Informatiker

M. Skutella

Lemma 6.2.1. Es sei (R, +, Âˇ) ein Ring und â 6= S â R. Dann bildet S einen
Unterring von R, falls fuĚr alle x, y â S gilt, dass x â y â S und x Âˇ y â S.
Beweis. Die Behauptung folgt unmittelbar aus der Definition von Unterringen
(Definition 2.2.10) und Lemma 6.1.1.

Damit koĚnnen wir jetzt leicht den folgenden Satz beweisen.
Satz 6.2.2. Es seien (R, +, Âˇ) und (R0 , â, ) Ringe und Ď : R â R0 ein Ringhomomorphismus. Ist S ein Unterring von R, so ist das Bild Ď(S) ein Unterring
von R0 . Ist umgekehrt S 0 ein Unterring von R0 , so ist das Urbild Ďâ1 (S 0 ) ein
Unterring von R.
Beweis. Der Beweis folgt unmittelbar aus Lemma 6.2.1

6.2.1



Faktorringe und Ideale

Da die additive Gruppe (R, +) eines jeden Rings (R, +, Âˇ) kommutativ ist, ist jede
Untergruppe ein Normalteiler. Insbesondere ist jeder Unterring S â R ein Normalteiler von (R, +). Folglich kann man die Faktorgruppe (R/S, â) betrachten
und fragen, unter welchen UmstaĚnden R/S = {x + S | x â R} als Ring aufgefasst
werden kann. Wir wissen bereits, dass die Addition â auf R/S definiert wird
durch
(x + S) â (y + S) := (x + y) + S .
Daher waĚre es naheliegend, auch eine Multiplikation
durch
(x + S)

auf R/S zu definieren

(y + S) := (x Âˇ y) + S .

Damit diese Multiplikation wohldefiniert ist, muss fuĚr x, x0 , y, y 0 â R mit x + S =
x0 + S und y + S = y 0 + S gelten, dass
(x Âˇ y) + S = (x0 Âˇ y 0 ) + S .
Im Folgenden sei x Âˇ S und S Âˇ x fuĚr x â R und S â R definiert als
x Âˇ S := {x Âˇ s | s â S}

und

S Âˇ x := {s Âˇ x | s â S} .

Lemma 6.2.3. Es sei (R, +, Âˇ) ein Ring und S â R ein Unterring von R. Die
beiden folgenden Aussagen sind aĚquivalent:
(i) FuĚr alle x, x0 , y, y 0 â R mit x + S = x0 + S und y + S = y 0 + S gilt, dass
(x Âˇ y) + S = (x0 Âˇ y 0 ) + S.
(ii) FuĚr alle x â R gilt x Âˇ S â S und S Âˇ x â S.

Kapitel 6: Algebra

M. Skutella

293

Beweis. (i)â(ii)â: Es sei x â R und s â S. Dann ist s + S = 0 + S und folglich
â
wegen (i) (x Âˇ s) + S = (x Âˇ 0) + S = S. Daraus folgt x Âˇ s â S und daher x Âˇ S â S.
Analog zeigt man S Âˇ x â S.
(ii)â(i)â: Es seien x, x0 , y, y 0 â R mit x+S = x0 +S und y +S = y 0 +S. Dann
â
gilt x â x0 â S und y â y 0 â S. Wegen (ii) folgt daraus x Âˇ y â x0 Âˇ y = (x â x0 ) Âˇ y â S
und x0 Âˇ y â x0 Âˇ y 0 = x0 Âˇ (y â y 0 ) â S. Da S ein Unterring von R ist, ist (S, +) erst
recht Untergruppe von (R, +). Folglich ist
x Âˇ y â x0 Âˇ y 0 = (x Âˇ y â x0 Âˇ y) + (x0 Âˇ y â x0 Âˇ y 0 ) â S .
Also ist x Âˇ y + S = x0 Âˇ y 0 + S.



Man uĚberzeugt sich leicht davon, dass die Bedingung (ii) aus Lemma 6.2.3
nicht fuĚr beliebige Unterringe erfuĚllt ist:
Beispiel. Der KoĚrper der rationalen Zahlen (Q, +, Âˇ) ist ein Unterring des KoĚrpers
der reellen Zahlen (R, +, Âˇ). Es gilt jedoch nicht,
â dass q Âˇ r â Q fuĚr alle q â Q
und r â R. WaĚhle beispielsweise q = 1 und r = 2.
Definition 6.2.4 (Ideale). Es sei (R, +, Âˇ) ein Ring. Ein Unterring S â R heiĂt
Ideal, wenn x Âˇ S â S und S Âˇ x â S fuĚr alle x â R.
Lemma 6.2.5. Es sei (R, +, Âˇ) ein Ring und â 6= S â R. Die Teilmenge S ist
genau dann ein Ideal in R, wenn sâs0 â S, xÂˇs â S und sÂˇx â S fuĚr alle s, s0 â S
und x â R.
Beweis. Die Behauptung folgt direkt aus Lemma 6.2.1 und Definition 6.2.4.



Beispiele.
(i) FuĚr einen beliebigen Ring (R, +, Âˇ) sind die Teilringe {0} und R Ideale. Sie
heiĂen triviale Ideale. Jedes andere Ideal heiĂt nicht trivial. Ein Ideal S 6= R
heiĂt echtes Ideal.
(ii) Ist K ein KoĚrper, so sind die trivialen Ideale die einzigen Ideale in K. Denn
ist S 6= {0} ein Ideal, dann gibt es ein 0 6= s â S. Dieses Element s besitzt
ein Inverses sâ1 , so dass fuĚr beliebige x â K gilt, dass x = x Âˇ sâ1 Âˇ s â
(x Âˇ sâ1 ) Âˇ S â S. Folglich ist S = K.
(iii) Wir betrachten den Ring der ganzen Zahlen (Z, +, Âˇ). FuĚr beliebige q â Z
ist q Âˇ Z ein Ideal.
(iv) Ist R ein kommutativer Ring und R[X] der zugehoĚrige Polynomring, so
ist q Âˇ R[X] fuĚr q â R[X] offenbar ein Unterring von R[X] und sogar ein
Ideal.
Wegen Lemma 6.2.3 koĚnnen wir fuĚr einen Ring R und ein Ideal S â R den
Faktorring R/S definieren.

294

Mathematik fuĚr Informatiker

M. Skutella

Satz 6.2.6 (Faktorring, Restklassenring). Es sei (R, +, Âˇ) ein Ring und S â R
ein Ideal. Dann bildet die Menge R/S := {x + S | x â R} zusammen mit der
Addition
(x + S) â (y + S) := (x + y) + S
und der Multiplikation
(x + S)

(y + S) := (x Âˇ y) + S

einen Ring (R/S, â, ), den zu R und S gehoĚrenden Faktor- oder Restklassenring.
Beweis. Aus Lemma 6.2.3 folgt, dass nicht nur die uns bereits bekannte Addition â sondern auch die Multiplikation
wohldefiniert sind. Die Eigenschaften eines Rings uĚberpruĚft man nun leicht. Sie folgen direkt aus der Tatsache,
dass (R, +, Âˇ) ein Ring ist.

Beispiel. Es sei m âĽ 2. Wie schon weiter oben erwaĚhnt, ist mZ ein Ideal
des Rings Z. Den Faktorring Z/mZ kennen wir bereits aus Kapitel 2. Man
kann naĚmlich leicht zeigen, dass Z/mZ isomorph ist zu dem Ring (Zm , +m , Âˇm ).
ZunaĚchst uĚberzeugt man sich leicht davon, dass
Z/mZ = {0 + mZ, 1 + mZ, 2 + mZ, . . . , (m â 1) + mZ} .
Mit diesen Nebenklassen rechnet man so wie mit den Elementen von Zm .
Satz 6.2.7 (Erzeugte Ideale). Es sei (R, +, Âˇ) ein Ring mit Eins und â =
6 S â R.
Dann ist
( n
)
X
hSiI =
(xk Âˇ sk Âˇ yk ) xk , yk â R, sk â S, n â N
k=1

ein Ideal. Wir nennen hSiI das von S erzeugte Ideal.
Beweis. Nachrechnen!



Bemerkung. Man kann sich leicht davon uĚberzeugen, dass hSiI das bezuĚglich
Inklusion kleinste Ideal ist, das S enthaĚlt.
Wir halten im Folgenden noch den Spezialfall von Satz 6.2.7 fest, in dem die
Menge S nur aus einem Element besteht.
Korollar 6.2.8 (Hauptideale). Es sei (R, +, Âˇ) ein kommutativer Ring mit Eins
und s â R. Dann ist s Âˇ R = R Âˇ S das von s erzeugte Ideal. Man nennt dieses
ideal auch Hauptideal.

Kapitel 6: Algebra

M. Skutella

295

Damit koĚnnen wir jetzt eine einfache Charakterisierung von KoĚrpern angeben.
Satz 6.2.9. Es sei (R, +, Âˇ) ein kommutativer Ring mit Eins.
(i) Ein Element x â R ist genau dann eine Einheit, wenn das von x erzeugte
Hauptideal x Âˇ R der ganze Ring R ist, also x Âˇ R = R.
(ii) Der Ring R ist genau dann ein KoĚrper, wenn R nur die beiden trivialen
Ideale {0} und R enthaĚlt.
Beweis. Wir beweisen zunaĚchst die Aussage (i). Sei x â R eine Einheit. Dann
existiert ein y â R mit 1 = x Âˇ y â x Âˇ R. Da x Âˇ R ein Ideal in R ist, gilt nun
per Definition r = r Âˇ 1 â x Âˇ R, fuĚr alle r â R. Damit haben wir R â x Âˇ R und
die andere Inklusion ist klar. Ist umgekehrt das von x â R erzeugte Ideal x Âˇ R
schon der ganze Ring R, so gilt 1 â R = x Âˇ R. Es folgt, dass ein y â R existiert,
mit 1 = x Âˇ y und x ist folglich eine Einheit.
Die Aussage (ii) folgt nun unmittelbar. Wir haben weiter oben schon gesehen,
dass ein KoĚrper R nur die trivialen Ideale {0} und R enthaĚlt. Es ist also nur noch
die Umkehrung zu beweisen. Es sei dazu x â R \ {0} beliebig. Dann ist das von
x erzeugte Ideal x Âˇ R nicht das Nullideal {0} und folglich gilt x Âˇ R = R. Nach
Aussage (i) ist x damit eine Einheit in R. Da x beliebig gewaĚhlt war, folgt, dass
in R jedes Element auĂer dem Nullelement 0 eine Einheit ist und R ist damit ein
KoĚrper.

Lemma 6.2.10. Es seien (R, +, Âˇ) und (R0 , â, ) zwei Ringe und Ď : R â R0
ein Ringhomomorphismus. Dann ist Kern(Ď) ein Ideal in R.
Beweis. Wir rechnen die Behauptung einfach nach. Es seien 00 â R0 das Nullelement in R0 , r â R und a, b â Kern(Ď) beliebig. Dann gilt:
Ď(a â b) = Ď(a)

Ď(b) = 00

00 = 00

und
Ď(r Âˇ a) = Ď(r)
also a â b, r Âˇ a â Kern(Ď).

Ď(a) = Ď(r)

00 = 00 ,


Bemerkung. Das Bild Bild(Ď) eines Ringhomomorphismus Ď : R â R0 ist i.A.
nur ein Unterring und kein Ideal in R. Man betrachte etwa die Inklusionsabbildung Îš : K â K[X].
Wir beenden diesen Abschnitt mit dem Homomorphiesatz fuĚr Ringe. Die universelle Eigenschaft der Projektionsabbildung Ď : G â G/N, x 7â xâŚN von einer
Gruppe (G, âŚ) in die Faktorgruppe (G/N, â˘), wobei N â G ein Normalteiler in G
ist, uĚbertraĚgt sich in direkter Weise auf die Situation in Ringen. Ideale nehmen
hier die Position der Normalteiler ein. Wir formulieren anstelle der universellen
Eigenschaft diesmal direkt das Analogon des Homomorphiesatzes.

296

Mathematik fuĚr Informatiker

M. Skutella

Satz 6.2.11. Es seien (R, +, Âˇ) und (R0 , â, ) zwei Ringe und Ď : R â R0 ein
surjektiver Ringhomomorphismus. Dann ist R/ Kern(Ď) isomorph zu R0 und ein
Isomorphismus ist gegeben durch
ĎĚ : R/ Kern(Ď) â R0 ,

x + Kern(Ď) 7â Ď(x) .

Beweis. Die Mengen R und R0 bilden zusammen mit den VerknuĚpfungen + und â
kommutative Gruppen (R, +) und (R0 , â). Wir koĚnnen den Ringhomomorphismus Ď : R â R0 entsprechend als Gruppenhomomorphismus auffassen und den
Homomorphiesatz fuĚr Gruppen anwenden. (Als Ideal in (R, +, Âˇ) ist Kern(Ď) ein
Normalteiler in (R, +).)
Dieser liefert nun die kanonische Existenz eines Gruppenisomorphismus
Ď : R/ Kern(Ď) â R0 . Dabei ist Ď durch die Gleichung Ď(x + Kern(Ď)) = Ď(x)
charakterisiert und dank der Struktur des Faktorrings liefert eine einfache Rechnung, dass sich Ď zu einem Isomorphismus ĎĚ : R/ Kern(Ď) â R0 von Ringen
fortsetzt.

Korollar 6.2.12. Ist (K, +, Âˇ) ein KoĚrper, (R, â, ) ein Ring mit mindestens
zwei Elementen und Ď : K â R ein surjektiver Ringhomomorphismus. Dann
ist R isomorph zu K.
Beweis. Da Ď ein Ringhomomorphismus ist, gilt Ď(1K ) = 1R 6= 0R und deshalb
Kern(Ď) 6= K. Da Kern(Ď) aber ein Ideal in K ist, folgt Kern(Ď) = {0}. Der
Homomorphiesatz liefert die Behauptung.

Bemerkung. Der Beweis zeigt insbesondere, dass jeder Homomorphismus von
einem KoĚrper K in einen Ring R 6= 0 injektiv ist.

6.2.2

Polynomringe

Wir haben in Kapitel 2 bereits Teilbarkeitstheorie fuĚr ganze Zahlen betrieben
und den euklidischen Algorithmus kennen gelernt. In Polynomringen uĚber einem
KoĚrper K finden wir eine voĚllig analoge Situation vor.
Definition 6.2.13 (Teilbarkeit). Es sei (R, +, Âˇ) ein kommutativer Ring und a, b â
R. Man sagt, a teilt b, oder b ist durch a teilbar, wenn ein x â R mit b = x Âˇ a
existiert. Notation: a | b.
Die obige Definition spiegelt also ebenfalls die Situation in Z wieder. Das
folgende Lemma ist oft nuĚtzlich. Den Beweis uĚberlassen wir als einfache UĚbungsaufgabe.
Lemma 6.2.14. Es sei (R, +, Âˇ) ein kommutativer Ring mit Eins und a, b â R.
(i) a | b genau dann, wenn b Âˇ R â a Âˇ R,

Kapitel 6: Algebra

M. Skutella

297

(ii) Es sei R nullteilerfrei. Dann gilt a Âˇ R = b Âˇ R genau dann, wenn a = be gilt,
fuĚr eine Einheit e â Râ .
Wir beschaĚftigen uns nun mit dem Polynomring K[X] uĚber einem KoĚrper K
und wiederholen zunaĚchst kurz einige Fakten ohne Beweis.
Satz 6.2.15. Es sei (R, +, Âˇ) ein IntegritaĚtsbereich und p, q â R[X] \ {0}. Dann
gilt
grad(p Âˇ q) = grad(p) + grad(q) .
Korollar 6.2.16. Es sei K ein KoĚrper, dann ist K[X] nullteilerfrei und ein
Polynom p â K[X] ist genau dann eine Einheit, wenn grad(p) = 0 gilt.
Bemerkung. Wenn wir jedem Polynom p â K[X] seinen Grad grad(p) zuweisen, erhalten wir eine Abbildung grad : K[X] â N0 âŞ {â1}, p 7â grad(p), die
sogenannte Gradabbildung.
Wir koĚnnen, aĚhnlich wie in Z, Division mit Rest in K[X] durchfuĚhren. Hierbei
nimmt die Gradabbildung eine tragende Rolle ein.
Satz 6.2.17 (Division mit Rest). Es sei K ein KoĚrper und 0 6= f â K[X]. Dann
gibt es zu jedem g â K[X] eindeutig bestimmte Polynome q und r in K[X] mit
g = q Âˇ f + r und grad(r) < grad(f ).
Beweis. Wir beweisen zunaĚchst die Existenz der Zerlegung. Ist grad(g) < grad(f ),
so koĚnnen wir q = 0 und r = g waĚhlen. Sei also grad(g) âĽ grad(f ). Wir fuĚhren
nun eine Induktion uĚber grad(g) durch.
Es sei grad(g) = 0. Wegen grad(f ) â¤ grad(g) und f 6= 0 gilt dann grad(f ) = 0
und f ist demnach eine Einheit in K[X]. Wir waĚhlen also q = g Âˇ f â1 und r = 0.
Es sei die Existenz schon fuĚr alle Polynome g â K[X] mit grad(g) â¤ m â 1
bewiesen. Es sei nun
n
m
X
X
k
bk X k , mit n â¤ m und am , bn 6= 0.
ak X und f (X) =
g(X) =
k=0

k=0

mân
Eine kurze Rechnung liefert fuĚr g1 (X) := g(X)âam bâ1
f (X), dass grad(g1 ) â¤
n X
grad(g) â 1 gilt. Nach Induktionsvoraussetzung ist g1 = q1 Âˇ f + r1 , mit grad(r1 ) <
grad(f ). Dann ist
mân
g = (am bâ1
+ q1 )f + r1
n x

die gesuchte Zerlegung.
Wir beweisen nun die Eindeutigkeit der Zerlegung. Es sei g = q1 Âˇ f + r1 =
q2 Âˇ f + r2 , mit grad(r1 ), grad(r2 ) < grad(f ). Dann ist (q2 â q1 )f = r1 â r2 und es
gilt

grad(r1 â r2 ) = grad (q2 â q1 )f
= grad(q2 â q1 ) + grad(f )
> grad(q2 â q1 ) + max{grad(r1 ), grad(r2 )}
âĽ grad(q2 â q1 ) + grad(r1 â r2 ) .

298

Mathematik fuĚr Informatiker

M. Skutella

Es folgt nun grad(q2 âq1 ) < 0 und deshalb q1 = q2 . Damit muss aber auch r1 = r2
gelten.

Beispiel. Es seien g(X) = X 5 + 3X 4 + X 3 â 6X 2 â X + 1, f (X) = X 3 + 2X 2 +
X â 1 â Q[X].
(X 5 + 3X 4 + X 3 â 6X 2 â X + 1) : (X 3 + 2X 2 + X â 1) = X 2 + X â 2
âX 5 â 2X 4 â X 3 + X 2
X4
â 5X 2 â X + 1
âX 4 â 2X 3 â X 2 + X
â 2X 3 â 6X 2
+1
3
2
2X + 4X + 2X â 2
â 2X 2 + 2X â 1
Es gilt also g = (X 2 + X â 2) Âˇ f + (â2X 2 + 2X â 1).
Dank der Division mit Rest koĚnnen wir den euklidischen Algorithmus also,
genau wie fuĚr ganze Zahlen, auch fuĚr Polynome nutzen, etwa um den groĚĂten
gemeinsamen Teiler zweier Polynome zu bestimmen. Bevor wir uns damit im
naĚchsten Abschnitt befassen, formulieren wir noch zwei einfache Folgerungen aus
dem Satz.
Korollar 6.2.18. Es sei K ein KoĚrper und a â K. Im Polynomring K[X] ist
das Polynom f â K[X] genau dann durch (X â a) teilbar, wenn die durch f
gegebene Polynomfunktion in a eine Nullstelle hat.
Beweis. Ist f (X) = (X â a) Âˇ g(X), so ist offenbar f (a) = 0. Es sei nun umgekehrt f (a) = 0. Division
 mit Rest liefert f (X) = (X â a) Âˇ q(X) + r(X), mit
grad(r) < grad (X â a) = 1. Damit ist r konstant und wegen 0 = f (a) = r(a)
gilt r = 0.

Korollar 6.2.19. Es sei K ein KoĚrper. Dann ist jedes Ideal J â K[X] ein
Hauptideal.
Beweis. Es sei J â K[X] ein Ideal. Ist J = {0}, so sind wir fertig. Andernfalls
existiert ein h â J, h 6= 0. Dann ist A := {m â N0 | âh â J : grad(h) = m} 6= â
und A besitzt ein kleinstes Element n. Es sei nun f â J mit grad(f ) = n und g â
J beliebig. Dann ist g = q Âˇ f + r, mit grad(r) < grad(f ). Da alle Elemente 6= 0
in J mindestens den Grad n = grad(f ) haben, folgt aus r = g â q Âˇ f â J,
dass r = 0 ist. Es gilt also J = hf iI .


6.2.3

GroĚĂter gemeinsamer Teiler in Polynomringen

Wir beginnen mit der Definition von normierten Polynomen.

Kapitel 6: Algebra

M. Skutella

Definition 6.2.20 (Normierte Polynome). Ein Polynom f =
K[X] heiĂt normiert, falls an = 1 gilt.

299
Pn

k=0

ak X k â

Bemerkung. Man kann ein beliebiges Polynom f â K[X] normieren, indem
man f mit dem Inversen des Leitkoeffizienten multipliziert. Dies geht auch in
Polynomringen uĚber einem Ring R, solange der Leitkoeffizient des Polynoms eine
Einheit in R ist.
Den groĚĂten gemeinsamen Teiler und das kleinste gemeinsame Vielfache definiert man in Polynomringen analog zum Fall der ganzen Zahlen.
Definition 6.2.21 (ggT in Polynomringen). Es sei K ein KoĚrper und g, h â
K[X]\{0}. Ein Polynom f â K[X] heiĂt groĚĂter gemeinsamer Teiler von g und h,
falls f ein normiertes Polynom von maximalem Grad ist, welches g und h teilt. Notation: f = ggT(g, h). Die Polynome g und h heiĂen teilerfremd, falls ggT(g, h) =
1 gilt.
Definition 6.2.22 (kgV in Polynomringen). Es sei K ein KoĚrper und g, h â
K[X]\{0}. Ein Polynom f â K[X] heiĂt kleinstes gemeinsames Vielfaches von g
und h, falls f ein normiertes Polynom von minimalem Grad ist, welches von g
und h geteilt wird. Notation: f = kgV(g, h).
Der folgende Satz ist eine UĚbertragung des Lemmas von Bezout (siehe Korollar 2.4.4) auf Polynomringe.
Satz 6.2.23. Es sei K ein KoĚrper, g, h â K[X], wobei g oder h ungleich 0 seien.
Dann ist ggT(g, h) eindeutig bestimmt und es existieren Polynome s, t â K[X]
mit
ggT(g, h) = g Âˇ s + h Âˇ t .
Beweis. Wir bilden
J := g Âˇ K[X] + h Âˇ K[X] = {g Âˇ v + h Âˇ w | v, w â K[X]} .
Es ist leicht zu sehen, dass J ein Ideal 6= 0 ist. Nach Korollar 6.2.19 existiert also
ein normiertes Polynom f â J, so dass J = f Âˇ K[X] = hf iI ist. Wegen f â J =
g Âˇ K[X] + h Âˇ K[X] existieren Polynome s, t â K[X] mit f = g Âˇ s + h Âˇ t.
Wir zeigen nun, dass f der eindeutig bestimmte groĚĂte gemeinsame Teiler
von g und h ist. Es gilt g = g Âˇ 1 + h Âˇ 0 â J, also g = f Âˇ u, fuĚr ein u â K[X]
und f teilt folglich g. Analog folgt, dass f auch ein Teiler von h ist. Es sei nun f 0
ein weiterer gemeinsamer Teiler von g und h. Dann teilt f 0 auch g Âˇ s + h Âˇ t = f .
Demnach gilt grad(f 0 ) â¤ grad(f ) und f ist ein groĚĂter gemeinsamer Teiler von g
und h. Es bleibt der Nachweis der Eindeutigkeit.
Angenommen, f 0 ist normiert und grad(f 0 ) = grad(f ). Da f 0 ein Teiler von f
ist gilt f 0 = qf und es folgt, dass grad(q) = 0 gilt. Also ist q â K \ {0}. Da f
und f 0 normiert sind, ist q = 1 und folglich f = f 0 .


300

Mathematik fuĚr Informatiker

M. Skutella

Korollar 6.2.24. Es sei K ein KoĚrper und g, h â K[X], nicht beide gleich 0.
(i) Ist f â K[X] ein Teiler von g und h, so ist f ein Teiler von ggT(g, h).
(ii) Sind g, h â K[X] normiert, so ist g Âˇ h = kgV(g, h) Âˇ ggT(g, h).
(iii) Sind g, h 6= 0 und ist f â K[X] ein Vielfaches von g und h, so ist kgV(g, h)
ein Teiler von f .
Beweis. Die Aussage (i) haben wir schon im Beweis des obigen Satzes gesehen.
Zu Aussage (ii): Es gilt g = q1 ggT(g, h) und h = q2 ggT(g, h) fuĚr geeignete
Polynome q1 , q2 â K[X]; also g Âˇ h = q1 Âˇ q2 Âˇ ggT(g, h)2 . Wir zeigen nun, dass
u := q1 Âˇ q2 Âˇ ggT(g, h) = kgV(g, h) .
Offensichtlich gilt g | u und h | u. Es sei nun p â K[X] gegeben mit g | p und h | p.
Wir zeigen, dass u ein Teiler von p ist. Es gibt r, v â K[X] mit p = g Âˇ r = h Âˇ v.
Weiter gibt es nach Satz 6.2.23 Polynome s, t â K[X] mit ggT(g, h) = g Âˇ s + h Âˇ t.
Also ist
ggT(g, h)p =
=
=
=
=

(g Âˇ s + h Âˇ t) Âˇ p
sÂˇgÂˇp+tÂˇhÂˇp
sÂˇgÂˇhÂˇv+tÂˇhÂˇgÂˇr
g Âˇ h Âˇ (s Âˇ v + t Âˇ r)
ggT(g, h) Âˇ u Âˇ (s Âˇ v + t Âˇ r) .

KuĚrzen mit ggT(g, h) liefert p = u Âˇ (s Âˇ v + t Âˇ r), also u | p. Daraus folgt u =
kgV (g, h) und damit die Behauptung.
Aussage (iii) zeigt man aĚhnlich.

Zur Berechnung des groĚĂten gemeinsamen Teilers von zwei Polynomen kann
man, wie im Falle von ganzen Zahlen, den euklidischen Algorithmus verwenden.
Damit erhaĚlt man auch die in Satz 6.2.23 gegebene Darstellung des ggTs (durch
RuĚckwaĚrtseinsetzen). Da es hier eine unmittelbare Analogie zum in Kapitel 2
besprochenen Fall des Rings der ganzen Zahlen gibt, verzichten wir auf eine erneute detailierte Darstellung und verweisen stattdessen auf die entsprechenden
Abschnitte in Kapitel 2.

